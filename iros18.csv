"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication_Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"IROS 2018 Fan Challenge - Team DLR Augsburg","M. Schönheits; A. Schuster; P. Gänswürger; L. Larsen","Center for Lightweight-Production-Technology (ZLP), German Aerospace Center (DLR), Am Technologiezentrum 4, Augsburg, D-86159, Germany; Center for Lightweight-Production-Technology (ZLP), German Aerospace Center (DLR), Am Technologiezentrum 4, Augsburg, D-86159, Germany; Center for Lightweight-Production-Technology (ZLP), German Aerospace Center (DLR), Am Technologiezentrum 4, Augsburg, D-86159, Germany; Center for Lightweight-Production-Technology (ZLP), German Aerospace Center (DLR), Am Technologiezentrum 4, Augsburg, D-86159, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4158","4163","It's a hot summer in 2021 and the blistering sun is shining upon Madrid. You are enjoying some tinto de verano on your terraza. Sizzling in the scorching heat, you are trying to relax. With a simple gesture you call your robotic assistant to help you cool down a little bit. Without further ado, your robot provides some relaxing shade holding a parasol for you, picks up a fan autonomously and starts waving it and the gentle breeze brings you some light relief.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593792","","Fans;Grippers;Robot kinematics;End effectors;Cameras;Servomotors","human-robot interaction;service robots","hot summer;blistering sun;Madrid;scorching heat;simple gesture;robotic assistant;relaxing shade;team DLR Augsburg;IROS 2018 fan challenge;tinto de verano","","","11","","","","","IEEE","IEEE Conferences"
"Active Model Learning and Diverse Action Sampling for Task and Motion Planning","Z. Wang; C. R. Garrett; L. P. Kaelbling; T. Lozano-Pérez","IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS, MIT CSAIL, Madrid, Spain; IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS, MIT CSAIL, Madrid, Spain; IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS, MIT CSAIL, Madrid, Spain; IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS, MIT CSAIL, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4107","4114","The objective of this work is to augment the basic abilities of a robot by learning to use new sensorimotor primitives to enable the solution of complex long-horizon problems. Solving long-horizon problems in complex domains requires flexible generative planning that can combine primitive abilities in novel combinations to solve problems as they arise in the world. In order to plan to combine primitive actions, we must have models of the preconditions and effects of those actions: under what circumstances will executing this primitive achieve some particular effect in the world? We use, and develop novel improvements on, state-of-the-art methods for active learning and sampling. We use Gaussian process methods for learning the conditions of operator effectiveness from small numbers of expensive training examples collected by experimentation on a robot. We develop adaptive sampling methods for generating diverse elements of continuous sets (such as robot configurations and object poses) during planning for solving a new task, so that planning is as efficient as possible. We demonstrate these methods in an integrated system, combining newly learned models with an efficient continuous-space robot task and motion planner to learn to solve long horizon problems more efficiently than was previously possible.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594027","","Planning;Task analysis;Level set;Robot sensing systems;Gaussian processes;Training","Gaussian processes;learning (artificial intelligence);mobile robots;path planning;sampling methods","complex domains;flexible generative planning;state-of-the-art methods;active learning;Gaussian process methods;operator effectiveness;adaptive sampling methods;diverse elements;robot configurations;object poses;newly learned models;long horizon problems;active model learning;action sampling;motion planning;sensorimotor primitives;complex long-horizon problems;continuous-space robot task","","1","33","","","","","IEEE","IEEE Conferences"
"An Extrinsic Dexterity Approach to the IROS 2018 Fan Robotic Challenge","J. Kwiatkowski; J. Roberge; N. A. Nadeau; L. L'Écuyer-Lapierre; V. Duchaine","Ecole de technologie supérieure, Dept. of Automated Manufacturing Engineering, 1100 Notre-Dame Ouest, Montréal, Québec, Canada; Ecole de technologie supérieure, Dept. of Automated Manufacturing Engineering, 1100 Notre-Dame Ouest, Montréal, Québec, Canada; Ecole de technologie supérieure, Dept. of Automated Manufacturing Engineering, 1100 Notre-Dame Ouest, Montréal, Québec, Canada; Ecole de technologie supérieure, Dept. of Automated Manufacturing Engineering, 1100 Notre-Dame Ouest, Montréal, Québec, Canada; Ecole de technologie supérieure, Dept. of Automated Manufacturing Engineering, 1100 Notre-Dame Ouest, Montréal, Québec, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4139","4144","The 2018 IROS Fan Robotic Challenge tasked participants with programming a robot to autonomously open and close a Spanish folding fan, highlighting the obstacles still associated with the dexterous manipulation of objects for robotic systems. Since high DoFs grippers are complex to coordinate and overkill for many industrial processes, our approach used an under-actuated parallel gripper with a 3D-printed adaptation to precisely grasp the fan in such a manner that gravity could be leveraged to act on the fan to produce an extrinsic, or external, dexterity. With our approach, we completed the challenge in 12.38 seconds, resulting in a top three finish. Furthermore, using a multi-modal tactile sensor, we analyzed the vibrations in the grasp during the manipulation and were able to distinguish the opening and closing of the fan from the motion of the robot with a 83% accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594224","","Fans;Grippers;Robot kinematics;Service robots;Task analysis;End effectors","dexterous manipulators;grippers;motion control;tactile sensors;vibrations","extrinsic dexterity approach;IROS 2018 fan robotic challenge;Spanish folding fan;dexterous manipulation;robotic systems;external dexterity;high DoF grippers;3D-printed adaptation;multimodal tactile sensor","","","20","","","","","IEEE","IEEE Conferences"
"Forums","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","55","65","Provides an abstract for each of the Forum presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594044","","Service robots;Artificial intelligence;Companies;Europe;Smart cities","","","","","","","","","","IEEE","IEEE Conferences"
"Deformation Capture via Self-Sensing Capacitive Arrays (Video)","O. Glauser; D. Panozzo; O. Hilliges; O. Sorkine-Hornung","Department of Computer Science, ETH Zurich, Switzerland; New York University, Courant Institute of Mathematical Sciences, USA; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5545","5545","In this video we present soft self-sensing capacitive arrays and demonstrate their use in capturing dense surface deformations without requiring line of sight. The capacitive arrays are made of two electrode patterns embedded into a single silicone compound. The overlaps of the electrode strip patterns form local capacitors. As the sensor is stretched the local capacitance measurements change. We introduce a fabrication technique that allows to produce such sensors while only requiring hardware readily available in modern fablabs. The resulting sensors are able to densely capture area changes as they deform. Since they do not directly measure bend, a prior is required to fully reconstruct the underlying motion. We propose a deep neural network regressing the sensor geometry from the local area measurements. A motion capture system is used for training data acquisition. At runtime vertex positions are predicted and used as positional constraints to deform a mesh using a state-of-the-art elastic surface energy. The flexibility and accuracy of the introduced sensors is demonstrated in a series of controlled experiments and by fabricating a prototype sensor and applying it to capture deforming skeletal and non-skeletal objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594203","","Robot sensing systems;Strain;Electrodes;Fabrication;Intelligent robots;Compounds;Capacitors","capacitance;capacitance measurement;capacitive sensors;computerised instrumentation;data acquisition;deformation;mesh generation;neural nets","deformation capture;soft self-sensing capacitive arrays;dense surface deformations;electrode patterns;single silicone compound;electrode strip patterns;local capacitors;local capacitance measurements change;fabrication technique;modern fablabs;resulting sensors;area changes;underlying motion;deep neural network;sensor geometry;local area measurements;motion capture system;runtime vertex positions;state-of-the-art elastic surface energy;prototype sensor;deforming skeletal","","","0","","","","","IEEE","IEEE Conferences"
"Research on Carved Turns of a Skiing Humanoid Robot on a Real-World Slope","J. Han; D. Yoon; H. Song; B. Kim; Y. Kim; C. Park; Y. Eum; J. Moon","Department of Robotics, Hanyang University, Ansan, Gyeonggi-do, 15588, South Korea; Hanyang University, ERICA IUCF, Ansan, Gyeonggi-do, 15588, South Korea; Hanyang University, ERICA IUCF, Ansan, Gyeonggi-do, 15588, South Korea; Department if Interdisciplinary Engineering Systems, Hanyang University, Ansan, Gyeonggi-do, 15588, South Korea; Department if Interdisciplinary Engineering Systems, Hanyang University, Ansan, Gyeonggi-do, 15588, South Korea; Sookmyung Women´s University, PRIME Project Group, Seoul, 04310, South Korea; Department of Physical Education, Seoul National University, Seoul, 08826, South Korea; Department of Physical Education, Seoul National University, Seoul, 08826, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Humans play sports to improve their athletic ability. The robot, especially humanoid robot, is also able to improve its athletic performances, such as reaction speed and balancing, through robot sports. Therefore, robots have been developed through performing various robot sports events such as robot soccer, robot marathon, robot fight and so on. In this reason, The Ski Robot Challenge was held in South Korea in commemoration of the PyeongChang 2018 Winter Olympic Games. The event was an Alpine slalom skiing competition in the almost same rules to human's but on a relatively short course (80m). To participate in this ski tournament, the skiing robot DIANA has been developed. In this video, the skiing robot technologies were introduced. At first, she must be able to recognize the flags. The deep learning method was used to recognize them. Secondly, she had a motion pattern to perform the carving turn, the most difficult and fastest skiing technique. In order to improve the stability, she compensated her motion to follow reference COP, based on the measured F/T sensor data. In addition, IMU sensor was used to remove instantaneous disturbance. Using these methods, the humanoid robot, DIANA, that can perform the carved turn on a realworld slope was successfully developed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593796","","Humanoid robots;Sports;Robot sensing systems;Moon;Service robots;Intelligent robots","humanoid robots;learning (artificial intelligence);mobile robots;motion control;sport","South Korea;deep learning method;motion pattern;IMU sensor;skiing humanoid Robot;realworld slope;carved turn;skiing robot DIANA;Alpine slalom skiing competition;PyeongChang 2018 Winter Olympic Games;robot sports events","","","0","","","","","IEEE","IEEE Conferences"
"Autonomous Underwater Vehicle Navigation in Structured Environment","D. Park; Y. Lee; K. Jung; H. Kang; H. Ki; J. Lee; Y. Choi; J. Li; H. Myung; H. Choi; J. Suh","Korea Institute of Robot convergence (KIRO); Korea Research Institute of Ship and Ocean Engineering (KRISO); Dept. of Civil and Environmental Eng, Korea Advanced Institute of Science and Technology (KAIST); Korea Institute of Robot convergence (KIRO); Korea Institute of Robot convergence (KIRO); Korea Institute of Robot convergence (KIRO); Korea Institute of Robot convergence (KIRO); Korea Institute of Robot convergence (KIRO); Dept. of Civil and Environmental Eng, Korea Advanced Institute of Science and Technology (KAIST); Korea Research Institute of Ship and Ocean Engineering (KRISO); Dept. of Mechanical System Eng, Pukyong National University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5039","5039","With the increase in developments in underwater infrastructure, the demand for development of autonomous vehicle navigation system in structured environment is also increased. However, the localization in a structured environment is a challenging problem due to signal uncertainties and distortions. In order to overcome these problems, we propose the camera and sonar aided integrated navigation system. In the proposed sensor-fusion-based localization scheme, the AUV estimates its own position continuously using artificial landmarks. The artificial landmarks for image sonar is deployed along the path to guide the AUV to the structure. The active vision markers are installed on the jacket structure, and they function as both landmarks and waypoints. This approach prevents the inherent drift of dead-reckoning velocities and collision with structures. The proposed approach was verified through a real sea experiment. The AUV conducted the full autonomous navigation from the dock to the jacket structure, and then returned to the dock without collision or significant localization error. These results show the feasibility of full autonomous navigation in a structured environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594429","","Sonar navigation;Oceans;Sonar;Autonomous robots;Industries;Intelligent robots;Autonomous underwater vehicles","autonomous underwater vehicles;cameras;geophysical image processing;image sensors;marine navigation;oceanographic techniques;position measurement;sensor fusion;sonar","AUV navigation system;autonomous underwater vehicle navigation system;signal uncertainties;signal distortion;cameras;position estimation;image sonar aided integrated navigation system;active vision markers;inherent drift of dead-reckoning velocities;jacket structure;artificial landmarks;sensor-fusion-based localization scheme;integrated navigation system","","","","","","","","IEEE","IEEE Conferences"
"Blade-Type Crawler Capable of Running on the Surface of Water as Bio-Inspired by a Basilisk Lizard","Y. Yamada; T. Nakamura","Chuo University, Faculty of Science and Engineering, Bunkyo-ku, Tokyo, 1-13-27 Kasuga, 112-8551, Japan; Chuo University, Faculty of Science and Engineering, Bunkyo-ku, Tokyo, 1-13-27 Kasuga, 112-8551, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","For unmanned rescue, observation, and/or research, vehicles with high terrain adaptability, high speed, and high reliability are needed to reach hard-to-reach-locations. In order to extend the areas that can be explored, we propose a method and a robot capable of running on the surface of water without having to bypass the puddles and streams that exist on uneven terrain. The method that enables the robot to run on the water surface is bio-inspired by the basilisk lizard that can walk on the surface of water. We developed a blade-type crawler robot with a simple and reliable mechanism, capable of traversing uneven terrain at high speed. The robot with the method was tested on a real water surface and the result confirmed the ability of the robot to run on the water surface.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594397","","Crawlers;Blades;Wheels;Rough surfaces;Surface roughness;Legged locomotion","blades;legged locomotion;motion control;robot dynamics","hard-to-reach-locations;water surface;basilisk lizard;blade-type crawler robot;terrain adaptability","","","18","","","","","IEEE","IEEE Conferences"
"Visual-Inertial Teach and Repeat Powered by Google Tango","M. Fehr; T. Schneider; R. Siegwart","ETH Zurich, Autonomous Systems Lab, Leonhardstrasse 21, 8092 Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Leonhardstrasse 21, 8092 Zurich, Switzerland; ETH Zurich, Autonomous Systems Lab, Leonhardstrasse 21, 8092 Zurich, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593416","","Robots;Inspection;Task analysis;Collision avoidance;Google;Autonomous systems;Visualization","automatic optical inspection;autonomous aerial vehicles;collision avoidance;control engineering computing;Global Positioning System;mobile robots;pose estimation;robot vision;trajectory control","human operator;visual inspection task;autonomous aerial vehicle;Google Tango visual-inertial mapping framework;pose estimates;GPS-denied environments;inspection points;feature-based localization map;industrial facilities;multicopters;visual-inertial teach;hedge maze","","","0","","","","","IEEE","IEEE Conferences"
"On-Chip Virtual Vortex Gear and Its Application","T. Takayama; C. Dylan Tsai; M. Kaneko","The Department of Mechanical Engineering, Osaka University, Suita, Japan; The Department of Mechanical Engineering, National Chiao Tung University, Hsinchu, Taiwan; The Department of Mechanical Engineering, Osaka University, Suita, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5544","5544","This video presents a microfluidic phenomenon called “Virtual Vortex Gear (VVG)” and an application of it. The video contains 4 parts and is described as follows: The 1st part shows an application of VVG as a controllable valve in a micro fluidic system and the on and off of the valve are controlled by different flow speeds. The valve is turned on when the flow speed is high enough, and vice versa. The 2nd part shows the generation of VVG and its mechanism. When the flow speed, which is proportional to Reynolds Number, is gradually increased, the flow pattern evolves in the order as (1)parallel streamlines, (2)one vortex, (3)two vortices and eventually (4)three vortices including the last vortex inside the circular chamber. The evolution indicates the transmission of flow energy from the main stream to the inside of the chamber when the flow speed is over a certain range. In addition, every two adjacent vortices rotate in opposite directions which is just like a set of gears, and that is why we named it “VVG”. In the 3rd part, an application of VVG for chemical injection is demonstrated. A colored liquid is represented for the chemical and is surrounded by different sheath flow for the control of injection locations. It is found that only the fluid in a particular pinpoint can be injected into the target chamber. Furthermore, the complex but stable 3D flow patterns are visualized from the video. The last part of the video shows that different amount of chemical injection can be performed in different chambers along the same main stream and the distribution of the color is gradually become uniform by spontaneous diffusing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593418","","Gears;Valves;Chemicals;Mechanical engineering;Microfluidics;Conferences;Intelligent robots","flow visualisation;microchannel flow;pattern formation;valves;vortices","VVG;controllable valve;microfluidic system;flow speed;flow energy;chemical injection;sheath flow;3D flow patterns;On-Chip Virtual Vortex Gear;Reynolds number;parallel streamlines;circular chamber;target chamber;spontaneous diffusing","","","","","","","","IEEE","IEEE Conferences"
"The Art of Manipulation: Learning to Manipulate Blindly","S. Haddadin; L. Johannsmeier","Technical University Munich, Munich School of Robotics and Machine Intelligence, Chair of Robotics and Systems Intelligence, Munich, 80797, Germany; Technical University Munich, Munich School of Robotics and Machine Intelligence, Chair of Robotics and Systems Intelligence, Munich, 80797, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Performing skillfull manipulation is a very challenging task for robots. So far, even experts could barely program them to e.g. perform the well known peg-in-hole problem in the real world. Autonomously acquiring such skills, let alone generalizing them to new tasks, is still a major challenge. Typically, manipulation learning is approached with the help of large computation power, very long learning times, or possibly both. However, the performance achieved up to now is still far from human performance. We show the results of our new paradigm to robot manipulation. It bridges and unifies basic motor control, simple and complex manipulation strategies and high-level manipulation planning. The robots show autonomous skill learning, intra-class and inter-class generalization of insertion skills at human-level performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593923","","Task analysis;Motor drives;Planning;Intelligent robots;Art;Bridges","human-robot interaction;learning (artificial intelligence);manipulators;path planning","peg-in-hole problem;manipulation learning;human performance;robot manipulation;high-level manipulation planning;autonomous skill learning;inter-class generalization;insertion skills;human-level performance;manipulation strategies;basic motor control","","","5","","","","","IEEE","IEEE Conferences"
"Towards an Automatic Spasticity Assessment by Means of Collaborative Robots","M. Hernandez; E. Daniel Oña; J. M. Garcia-Haro; A. Jardon; C. Balaguer","Avda. de la Universidad 30, Robotics Lab, University Carlos III of Madrid, Leganes, Madrid, (28911), Spain; Avda. de la Universidad 30, Robotics Lab, University Carlos III of Madrid, Leganes, Madrid, (28911), Spain; Avda. de la Universidad 30, Robotics Lab, University Carlos III of Madrid, Leganes, Madrid, (28911), Spain; Avda. de la Universidad 30, Robotics Lab, University Carlos III of Madrid, Leganes, Madrid, (28911), Spain; Avda. de la Universidad 30, Robotics Lab, University Carlos III of Madrid, Leganes, Madrid, (28911), Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Summary form only given. Robotics can play a significant role in the rehabilitation of patients with spasticity by improving their early diagnosis and reducing the costs associated with care. Spasticity is a muscle control disorder characterized by an increase in muscle tone with exaggerated stretch reflexes, as one component of the upper motor neuron syndrome. Furthermore, spasticity is present in other pathologies, such as cerebral palsy, spina bifida, brain stroke among others. This video shows the ongoing research on developing a platform for the modelling and the assessment of spasticity using collaborative robots as clinical tool. Our aim is to develop methods for non-invasive biomechanical modelling of upper limbs joints using 7-DOF Rosen Kinematics [1], mixed with a non-linear state of Hills force-velocity relation [2], improved by introducing new parameters such as rigidity, viscoelasticity, extensibility and thixotropy. After a learning phase performed by the therapist, the robot replicates the trajectories required to perform the assessment. The video also describes the detailed analysis of passive movement response (force/torque and position/velocity)of the limb. These parameters will be used to determine the degree of spasticity of patients in a fast and objective manner, while simultaneously developing new clinical scales, such as a modified version of Ashworth [3].","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594158","Collaborative robotics;Movement capture;Rehabilitation;Spasticity;Upper limb modelling","Collaboration;Biological system modeling;Muscles;Brain modeling;Biomechanics;Intelligent robots","biomechanics;brain;medical disorders;medical robotics;muscle;neurophysiology;patient rehabilitation;shear modulus;viscoelasticity","exaggerated stretch reflexes;upper motor neuron syndrome;collaborative robots;noninvasive biomechanical modelling;automatic spasticity assessment;muscle control disorder;muscle tone;upper limb joints;patient rehabilitation;7-DOF Rosen kinematics;nonlinear state;Hills force-velocity relation;rigidity;viscoelasticity;extensibility;thixotropy;passive movement response","","","3","","","","","IEEE","IEEE Conferences"
"DNN-based Speech Recognition System dealing with Motor State as Auxiliary Information of DNN for Head Shaking Robot","M. Lee; J. Chang","Electronic Engineering Department, University of Hanyang, Seoul, 04763, Republic of Korea; Electronic Engineering Department, University of Hanyang, Seoul, 04763, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1859","1863","In this paper, a deep neural network (DNN) based integrated background noise suppression and acoustic modeling for speech recognition proposed in which on/off state of the motor for the head shaking robot is employed as the relevant auxiliary information of the DNN input. Since the motor sound being generated when the robot is moving or shaking its head severely degrades the performance of the speech recognition accuracy, we propose to use the motor on/off state as additional information when designing the DNN-based recognition system. Our speech recognition algorithm consists of two parts including the feature mapping model for feature enhancement and the acoustic model for phoneme recognition. As for the feature mapping, the stacked DNN is designed for the precise feature enhancement such that the lower DNN and upper DNN are trained separately and combined after which the motor state is plugged into both the lower DNN and upper DNN in addition to the input noisy speech. Then, the acoustic model is trained upon the feature enhancement model in which the motor state is again used as the augmented feature. The proposed technique to suppress the acoustic and motor noises was evaluated in term of the phoneme error rate (PER) and showed a significant improvement over the conventional system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593396","","Robots;Speech recognition;Speech enhancement;Noise measurement;Feature extraction;Mel frequency cepstral coefficient","acoustic signal processing;neural nets;robots;signal denoising;speech processing;speech recognition","motor state;head shaking robot;deep neural network;acoustic modeling;speech recognition algorithm;feature mapping model;acoustic model;phoneme recognition;feature enhancement model;speech recognition system;auxiliary information;DNN;background noise suppression","","","15","","","","","IEEE","IEEE Conferences"
"“Hammer: Robot Programming Interface for Common People”","A. Brunete; M. Hernando; E. Gambao","Universidad Politecnica de Madrid, Centre for Automation and Robotics (CAR UPM-CSIC), C/Jose Gutierrez Abascal 2, Madrid, 28006, Spain; Universidad Politecnica de Madrid, Centre for Automation and Robotics (CAR UPM-CSIC), C/Jose Gutierrez Abascal 2, Madrid, 28006, Spain; Universidad Politecnica de Madrid, Centre for Automation and Robotics (CAR UPM-CSIC), C/Jose Gutierrez Abascal 2, Madrid, 28006, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5539","5539","This video shows the main features of Hammer, a tablet-based end-user interface for industrial robot programming, in a real environment: a robotic cell created for the Hephestos European project. Hammer is an Android application that makes easier to program tasks for industrial robots like polishing, milling or grinding. It is based on the Scratch programming language, but specifically design and created for Android OS. It is a visual programming concept that allows non-skilled operators to create programs. The application allows to monitor the tasks while it is being executed by overlapping real time information through augmented reality. The application includes a teach pendant screen that can be customized according to the operator needs at every moment. The application is designed for online programming and reprogramming; easy use of learn-by-demonstration methods; easy connection with the robot control and sensors systems; and safety-system integration. It aims to be intuitive, easy to use, and simple. The application has four main parts: customized teach pendant, robot programming IDE and simulator, manual-guidance interface and augmented-reality-based-monitoring system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594453","Industrial Robots;Human-Centered Robotics;Intelligent and Flexible Manufacturing","Service robots;Robot programming;Task analysis;Robot sensing systems;Intelligent robots","Android (operating system);augmented reality;control engineering computing;industrial robots;production engineering computing;robot programming;user interfaces;visual programming","Hammer;robot programming interface;tablet-based end-user interface;industrial robot programming;Hephestos European project;Android application;Android OS;visual programming concept;online programming;reprogramming;robot control;manual-guidance interface;augmented-reality-based-monitoring system;scratch programming language;sensors systems","","","","","","","","IEEE","IEEE Conferences"
"Waiter Robot Application: Balance Control for Transporting Objects","J. m. Garcia-Haro; E. Daniel Oña; S. Martinez; J. Hernandez-Vicen; C. Balaguer","Robotics Lab, University Carlos III of Madrid, Avda. de la Universidad 30, Madrid, Leganes (28911), Spain; Robotics Lab, University Carlos III of Madrid, Avda. de la Universidad 30, Madrid, Leganes (28911), Spain; Robotics Lab, University Carlos III of Madrid, Avda. de la Universidad 30, Madrid, Leganes (28911), Spain; Robotics Lab, University Carlos III of Madrid, Avda. de la Universidad 30, Madrid, Leganes (28911), Spain; Robotics Lab, University Carlos III of Madrid, Avda. de la Universidad 30, Madrid, Leganes (28911), Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Dynamic balance control for humanoid robots encounters difficulties such as stability, speed, and smoothness. In most of the previous studies, joints act as controller of the Center of Mass (CoM)supported using a simplified mathematical model. Then, the stability of the motion is guaranteed using the Zero Moment Point (ZMP)stability criterion. In this video, a humanoid robot [1] will carry a tray secured to the wrist and the objects to be transported will be placed on the tray. This condition implies that the object is not grasped and therefore, the robot arm will be the only point of support of the object through the tray. Thus, the manipulation control system must be able to detect the stability of the object and act according to the different perturbations applied to it. A 3D balance control system for non-grasping tasks is presented and it is based on the ZMP criterion and 3D inverted pendulum equations. The perception system required is based on the use of Force-Torque sensors [2], computer vision [3], and their integration. The effectiveness of the proposed approach is being investigated with the humanoid robot TEO.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593760","Balance;Manipulation;Force-Torque;Vision;Humanoid","Humanoid robots;Stability criteria;Sensors;Mathematical model;Control systems","force control;humanoid robots;manipulators;motion control;nonlinear control systems;pendulums;position control;robot vision;stability","waiter robot application;dynamic balance control;simplified mathematical model;robot arm;manipulation control system;nongrasping tasks;ZMP criterion;humanoid robot TEO;zero moment point stability criterion;force-torque sensors;computer vision;center of mass;CoM","","","3","","","","","IEEE","IEEE Conferences"
"Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles","L. Briñón-Arranz; M. Muschinowski; J. Dumon; N. Marchand","Grenoble INp, Univ. Grenoble Alpes, CNRS, GIPSA-lab, Grenoble, France; Grenoble INp, Univ. Grenoble Alpes, CNRS, GIPSA-lab, Grenoble, France; Grenoble INp, Univ. Grenoble Alpes, CNRS, GIPSA-lab, Grenoble, France; Grenoble INp, Univ. Grenoble Alpes, CNRS, GIPSA-lab, Grenoble, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","1","This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593511","","Generators;Intelligent robots;Trajectory;Multi-robot systems;Distributed algorithms","aircraft control;distributed algorithms;mobile robots;multi-robot systems;tracking;trajectory control","multirobot systems;geometric parameters;distributed algorithm;tracking controller;robots position;distributed trajectory generator;mini aerial vehicles;distributed reconfigurable formation generator","","","0","","","","","IEEE","IEEE Conferences"
"Development and Error Compensation of a Flexible Multi-Joint Manipulator Applied in Nuclear Fusion Environment","S. Shi; Y. Cheng; H. Pan; W. Zhao; H. Wu","Chinese Academy of Sciences, Institute of Plasma Physics, Hefei, 230031, China; Chinese Academy of Sciences, Institute of Plasma Physics, Hefei, 230031, China; Chinese Academy of Sciences, Institute of Plasma Physics, Hefei, 230031, China; Chinese Academy of Sciences, Institute of Plasma Physics, Hefei, 230031, China; Lappeenranta University of Technology, Laboratory of Intelligent Machines, Finland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3587","3592","Experimental Advanced Superconducting Tokamak (EAST) is the world's first fully superconducting tokamak fusion device with non-circular cross-section which was built in China The EAST articulated maintenance arm (EAMA) system is developed for real-time detection and rapid repair operations to damaged internal components during plasma discharges without breaking the EAST ultra-high vacuum (UHV) condition. To achieve the desired objectives, the EAMA system design should guarantee that the robot can stably run in the harsh environments of high temperature (80-120 °C) and high vacuum (~ 10<sup>-5</sup>Pa). Meanwhile, the errors caused by the deformation of long flexible robot arms should also be predicted and compensated in real-time to obtain high accuracy for maintenance operations. In this paper, the vacuum-available design scheme of the manipulator system was firstly introduced. Secondly, inverse kinematics and obstacle avoidance strategy of the highly redundant EAMA robot was built. Then, flexible errors were predicted utilizing a back-propagation neural network (BPNN) model which was established on the basis of real experimental data. Finally, an integrated control strategy for error prediction and compensation was developed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593621","","Manipulators;Kinematics;Predictive models;Load modeling;Error compensation;Strain","backpropagation;collision avoidance;error compensation;fusion reactor design;fusion reactor instrumentation;high energy physics instrumentation computing;manipulator kinematics;neural nets;physical instrumentation control;plasma toroidal confinement;Tokamak devices","nuclear fusion environment;Experimental Advanced Superconducting Tokamak;noncircular cross-section;real-time detection;plasma discharges;EAMA system design;vacuum-available design scheme;error prediction;EAST articulated maintenance arm;repair operations;internal components;high temperature environments;flexible robot arms;error compensation;flexible multijoint manipulator;EAST ultrahigh vacuum condition;inverse kinematics;obstacle avoidance strategy;back-propagation neural network;integrated control strategy;temperature 80.0 degC to 120.0 degC","","","9","","","","","IEEE","IEEE Conferences"
"Excuse Me, May I Say Something? A Robot Facilitating Q&A for Lectures","O. Palinko; J. Shimaya; K. Hoeck; K. Ogawa; N. Jinnai; Y. Yoshikawa; H. Ishiguro","Osaka University, Intelligent Robotics Laboratory; Osaka University, Intelligent Robotics Laboratory; Department of Social Anthropology, University of Manchester; Osaka University, Intelligent Robotics Laboratory; Osaka University, Intelligent Robotics Laboratory; Osaka University, Intelligent Robotics Laboratory; Osaka University, Intelligent Robotics Laboratory","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5546","5546","Hiroshi Ishiguro gave a lecture to a group of young students. We employed CommU, the desktop social robot, to manage the questions and answers for the talk. We encouraged the students to ask questions anytime. Half of the classroom was told to ask questions by raising their hand while the other half was shown an online messaging system developed for CommU, which allows the audience to post questions, which the robot would directly say. We had a gatekeeper to monitor for invalid sentences. In the middle of the presentation we asked the students to shift roles. The robot used a neural network based estimator of interruptibility to find the best time to speak. We did not expect too many questions, but the audience really embraced using the robot. They posted 44 questions to the presenter through CommU. On the other hand they asked 8 direct questions by raising their hands and standing up. Students thought that they gained more information from the lecturer using the robot than using the conventional method. In this instance we didnt stop the students from asking too many questions, but in a real-world application the gatekeeper will have to play an important role.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593656","","Logic gates;Intelligent robots;Monitoring;Neural networks","computer aided instruction;humanoid robots;human-robot interaction;Internet;neural nets","young students;CommU;desktop social robot;online messaging system;robot facilitating Q&a;Hiroshi Ishiguro","","","","","","","","IEEE","IEEE Conferences"
"A 7-Dof Wire-Driven Lightweight Arm with Wide Wrist Motion Range","Y. Tsumaki; Y. Suzuki; N. Sasaki; E. Obara; S. Kanazawa","Dept. of Mechanical Systems Engineering, Yamagata University, 4-3-16 Jonan, Yonezawa, 992-8510, Japan; Yuya Suzuki is with Secom Industries, Ltd; Dept. of Mechanical Systems Engineering, Yamagata University, 4-3-16 Jonan, Yonezawa, 992-8510, Japan; Dept. of Mechanical Systems Engineering, Yamagata University, 4-3-16 Jonan, Yonezawa, 992-8510, Japan; Dept. of Mechanical Systems Engineering, Yamagata University, 4-3-16 Jonan, Yonezawa, 992-8510, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Till date, various seven-degrees-of-freedom (7-DOF)robot arms have been developed globally. In general, the robot arms utilized in factories are required to possess speed, power, and accuracy. They are isolated from humans using a fence to ensure human safety. However, a home robot should work near humans at an appropriate speed without a fence. One approach to meeting this requirement involves the installation of various sensors on the robot to control and stop the robot safely even if a collision has occurred. However, a robot system is complicated and expensive. In order to give inherent safety to the robot, we should lighten the robot arm. In this study, a 7-DOF lightweight arm with a wide wrist-motion range is introduced. The weight of movable parts is approximately 2.87 kg. To achieve such properties, we propose the use of three mechanisms: a shoulder mechanism with hollow cylinders, a wrist mechanism with a wide workspace, and an integrated wrist and elbow mechanisms of high power. To verify its feasibility, a prototype of the robot is designed and developed. The experimental results demonstrate its powerful performance and wide workspace of the wrist.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593515","","Wires;Wrist;Shoulder;Manipulators;Collision avoidance;Robot sensing systems","health and safety;motion control;prototypes;robots;sensors","human safety;wrist mechanism;wide wrist motion range;sensors;robot prototype;integrated wrist-elbow mechanisms;shoulder mechanism;robot safety;robot arms;7-DOF wire-driven lightweight arm","","","15","","","","","IEEE","IEEE Conferences"
"RAMCIP - A Service Robot for MCI Patients at Home","G. Peleka; A. Kargakos; E. Skartados; I. Kostavelis; D. Giakoumis; I. Sarantopoulos; Z. Doulgeri; M. Foukarakis; M. Antona; S. Hirche; E. Ruffaldi; B. Stanczyk; A. Zompas; J. Hernandez-Farigola; N. Roberto; K. Rejdak; D. Tzovaras","Centre for Research and Technology Hellas / Information Technologies Institute (CERTH/ITI), Thessaloniki, 6th Km. Charilaou-Thermi Rd., GR 57001, Greece; Centre for Research and Technology Hellas / Information Technologies Institute (CERTH/ITI), Thessaloniki, 6th Km. Charilaou-Thermi Rd., GR 57001, Greece; Centre for Research and Technology Hellas / Information Technologies Institute (CERTH/ITI), Thessaloniki, 6th Km. Charilaou-Thermi Rd., GR 57001, Greece; Centre for Research and Technology Hellas / Information Technologies Institute (CERTH/ITI), Thessaloniki, 6th Km. Charilaou-Thermi Rd., GR 57001, Greece; Centre for Research and Technology Hellas / Information Technologies Institute (CERTH/ITI), Thessaloniki, 6th Km. Charilaou-Thermi Rd., GR 57001, Greece; Thessaloniki, Greece; Aristotle University of Thessaloniki; Thessaloniki, Greece; Aristotle University of Thessaloniki; Institute of Computer Science, FORTH-ICS, Crete, Greece; Institute of Computer Science, FORTH-ICS, Crete, Greece; Department of Electrical and Computer Engineering, Technical University of Munich, Chair of Information-oriented Control, Munich, Germany; Scuola Superiore Sant’ Anna, Pisa, Italy; ACCREA Engineering, Lublin, Poland; The Shadow Robot Company, London, UK; Institut Catala de Neurociencies Aplicades, Alzheimer Research Center and Memory Clinic of Fundacio ACE, Barcelona, Catalonia, Spain; Institut Catala de Neurociencies Aplicades, Alzheimer Research Center and Memory Clinic of Fundacio ACE, Barcelona, Catalonia, Spain; Department of Neurology, Medical University of Lublin, Lublin, Poland; Centre for Research and Technology Hellas / Information Technologies Institute (CERTH/ITI), Thessaloniki, 6th Km. Charilaou-Thermi Rd., GR 57001, Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This video features RAMCIP, a new service robot developed to provide proactive and discreet assistance to elderly with Mild Cognitive Impairments (MCI), supporting their daily activities at home. Starting with a thorough analysis of needs and requirements of the target population, the RAMCIP robot was developed as an integrated ensemble of advanced H/W and S/W components, realizing the robot skills of perception, cognition, safe navigation, grasping, manipulation, and human-robot communication, ample to operate in real, rather challenging domestic environments. The RAMCIP use-cases include proactive assistance provision to user's cooking, eating and medication activities, through discreet user monitoring and robot interventions by reminders and robotic manipulations., RAMCIP can bring the medicine, recognize fallen objects and electric appliance that has been forgotten turned on. It also recognizes the user walking in low-light conditions and turns on the light, as well as detects cases of emergency such as a fall. The robot provides also the user with cognitive training games and stimulates the user to contact with relatives through video-calls. Pilot trials of the RAMCIP robot have been performed in real homes of more than ten different users, in Barcelona, Spain; the video at hand exhibits the robot performing the target use cases.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594214","","Service robots;Information technology;Intelligent robots;Computer science;Companies;Random access memory","assisted living;cognition;diseases;geriatrics;handicapped aids;human-robot interaction;medical robotics;service robots","daily activities;Mild Cognitive Impairments;discreet assistance;MCI patients;service robot;home;RAMCIP robot;cognitive training games;robotic manipulations;discreet user monitoring;medication activities;proactive assistance provision;human-robot communication","","","0","","","","","IEEE","IEEE Conferences"
"High Power Hand with Retention Mechanism","T. Mouri; H. Kawasaki","the Mechanical Engineering Department, Gifu University, Gifu, Japan; the Mechanical Engineering Department, Gifu University, Gifu, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5543","5543","When a disaster occurs, high output power should be available for rescue operation even if the electric supply is insufficient at site. This video presents a novel multi-fingered robot hand for extreme environments without a sufficient electric supply. The robot hand has four fingers with 16 joints and 12 degrees of freedom. The finger has a retention mechanism using no electrical power supply and a fingertip force of 150 [N]. Holding without power supply shows that our robot hand can lift a heavy barbell and keep its posture without using electrical power. The high fingertip force shows that steel cans can be crushed by the robot hand. In addition, dexterous motion of our robot hand shows that each finger allows flexion/extension and adduction/abduction. High-power manipulation shows that the robot hand can grasp and manipulate a hammer drill for making a hole in a concrete plate. The robot hand has a high potential for performing various tasks by obtaining high power output and electrical power saving.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594216","","Robots;Thumb;Power supplies;Force;Mechanical engineering;Conferences","biomechanics;dexterous manipulators;disasters;motion control;plates (structures);power system control","retention mechanism;electrical power supply;electrical power saving;high power hand;multifingered robot hand;power manipulation;dexterous motion","","","","","","","","IEEE","IEEE Conferences"
"Development of Rimless Wheel with Controlled Wobbling Mass","Y. Hanazawa","Dept. of Applied Science for Integrated System Engineering, Graduate School of Engineering, Kyushu Institute of Technology, 1-1 Sensui, Tobata, Kitakyushu, Fukuoka, 804-8550, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4333","4339","This paper presents a novel method for generating level-ground walking for a rimless wheel with a controlled wobbling mass. Our rimless wheel achieves level-ground walking by simply controlling the wobbling mass attached to the wheel. We mathematically demonstrate that the controlled wobbling mass generates propulsive effects for the rimless wheel. The walking speed of the rimless wheel can be changed by varying the amplitude of the wobbling mass: thus slow walking to high-speed walking can be realized for the wheel. Moreover, we have developed a robot based on a rimless wheel to show effectiveness of our proposed methods. We then analyze the walking properties with respect to the physical parameters and control parameters of our robot through numerical simulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593812","","Legged locomotion;Wheels;Trajectory;Torso;Mathematical model","gait analysis;legged locomotion;numerical analysis;robot dynamics;wheels","controlled wobbling mass;rimless wheel;level-ground walking;propulsive effects;physical parameters;control parameters;numerical simulation;robots","","","13","","","","","IEEE","IEEE Conferences"
"Toward the Next Generation of Robotic Waiters","L. Moriello; D. Chiaravalli; L. Biagiotti; C. Melchiorri","Department of Electrical, Electronic and Information Engineering “Guglielmo Marconi”, University of Bologna, Viale del Risorgimento 2, 40136 Bologna, Italy; Department of Electrical, Electronic and Information Engineering “Guglielmo Marconi”, University of Bologna, Viale del Risorgimento 2, 40136 Bologna, Italy; The Department of Engineering “Enzo Ferrari”, University of Modena and Reggio Emilia, via Pietro Vivarelli 10, 41125 Modena, Italy; Department of Electrical, Electronic and Information Engineering “Guglielmo Marconi”, University of Bologna, Viale del Risorgimento 2, 40136 Bologna, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5541","5541","The gap between human waiters and state-of-the-art robot systems that try to serve something to drink is often embarrassing, with the former able to manipulate glasses and trays or glasses on trays with incredible dexterity and the latter that move at incredible slowness. In this video, we want to show that robots can do it better by moving a bottle or a tankard full of beer that are simply placed on a flat steel plate connected the flange of a robot manipulator. The robot tracks the trajectory defined by a human operator that moves its hand in the 3D space, with a motion capture system that acquires in real time the position. A feed-forward controller, placed between the user and the robot and based on the combination of a smoother and proper orientation compensation, counteracts the lateral accelerations and suppress sloshing phenomena of the liquids. Eventually a camera mounted on the robot arm provides a visual feedback to the operator with monitoring purposes. The challenge for the operator was to drop the carried object. will the feed-forward control be robust enough to avoid this event, even at high speed? Watch the video and find out!","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594475","","Glass;Manipulators;Intelligent robots;Next generation networking;Steel;Tracking","compensation;feedforward;manipulators;service robots","sloshing phenomena;orientation compensation;robotic waiters;feed-forward control;robot arm;feed-forward controller;motion capture system;robot manipulator","","","","","","","","IEEE","IEEE Conferences"
"Cooperative UAVs as a Tool for Aerial Inspection of Large Scale Aging Infrastructure","C. Kanellakis; S. S. Mansouri; E. Fresk; D. Kominiak; G. Nikolakopoulos","The authors are with the Robotics Group at the Control Engineering Division of the Department of Computer, Electrical and Space Engineering, Lulea University of Technology, Lulea SE-97187, Sweden; The authors are with the Robotics Group at the Control Engineering Division of the Department of Computer, Electrical and Space Engineering, Lulea University of Technology, Lulea SE-97187, Sweden; The authors are with the Robotics Group at the Control Engineering Division of the Department of Computer, Electrical and Space Engineering, Lulea University of Technology, Lulea SE-97187, Sweden; The authors are with the Robotics Group at the Control Engineering Division of the Department of Computer, Electrical and Space Engineering, Lulea University of Technology, Lulea SE-97187, Sweden; The authors are with the Robotics Group at the Control Engineering Division of the Department of Computer, Electrical and Space Engineering, Lulea University of Technology, Lulea SE-97187, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5040","5040","This work presents an aerial tool towards the autonomous cooperative coverage and inspection of a large scale 3D infrastructure using multiple Unmanned Aerial Vehicles (UAVs). In the presented approach the UAVs are relying only on their onboard computer and sensory system, deployed for inspection of the 3D structure. In this application each agent covers a different part of the scene autonomously, while avoiding collisions. The autonomous navigation of each platform on the designed path is enabled by the localization system that fuses Ultra Wideband with inertial measurements through an Error- State Kalman Filter. The visual information collected from the aerial team is collaboratively processed to create the 3D model. The performance of the overall setup has been experimentally evaluated in realistic wind turbine inspection experiments, providing dense 3D reconstruction of the inspected structures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593996","","Inspection;Three-dimensional displays;Tools;Intelligent robots;Aging;Unmanned aerial vehicles;Robot sensing systems","autonomous aerial vehicles;collision avoidance;image reconstruction;inspection;Kalman filters;mobile robots;robot vision;wind turbines","UAVs;Aerial inspection;aerial tool;autonomous cooperative coverage;multiple Unmanned Aerial Vehicles;onboard computer;sensory system;autonomous navigation;localization system;Ultra Wideband;aerial team;realistic wind turbine inspection experiments;dense 3D reconstruction;inspected structures;state Kalman filter;3D infrastructure;large scale aging infrastructure","","","","","","","","IEEE","IEEE Conferences"
"Hear the Egg - Demonstrating Robotic Interactive Auditory Perception","E. Strahl; M. Kerzel; M. Eppe; S. Griffiths; S. Wermter","Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5041","5041","We present an illustrative example of an interactive auditory perception approach performed by a humanoid robot called NICO, the Neuro Inspired COmpanion [1]. The video demonstrates a material classification task in the style of a classic TV game show. NICO and another candidate are supposed to determine the content of small plastic capsules that are visually indistinguishable. Shaking the capsules produces audio signals that range from rattling stones, over tinkling coins to swooshing sand. NICO can perceive and analyze these sounds to determine the material of the capsules content.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593959","","Humanoid robots;Mel frequency cepstral coefficient;Intelligent robots;Plastics;Recurrent neural networks;Gold","audio signal processing;hearing;humanoid robots;image classification;interactive video;mobile robots;robot vision;video retrieval","neuro inspired companion;plastic capsules;classic TV game show;material classification task;NICO;humanoid robot;interactive auditory perception approach;egg-demonstrating robotic interactive auditory perception;capsules content","","","3","","","","","IEEE","IEEE Conferences"
"Human-Robot-Cooperation Real Time Robot Path Planning for Dynamic HRC-Applications","I. M. Bdiwi; I. S. Hou; K. Delang","Robotics Department, Fraunhofer Institute for Machine Tools and Forming Technology IWU; Robotics Department, Fraunhofer Institute for Machine Tools and Forming Technology IWU; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5542","5542","Human-Robot shared workspace is a dynamic and unstructured environment. In such environment, pre-programmed robot paths might cause collisions or production disruptions. In order to solve this problem, motion planning framework has been proposed that adapts the robot's movement (path and speed)according to the human movement or any other dynamic obstacles in real time. Firstly, it defines the safety distance between robot and human or other obstacles. During run-time the 3D-Smart-Sensors capture the current position of human and other dynamic/static obstacles in human-robot shared workspace. The proposed framework plans and optimizes collision free robot trajectories with consideration for safety distance, path length and executing time. Once a new optimal trajectory is found, the framework controls the robot to adjust its movement paths. Moreover, the proposed framework can adjust the robot velocity based on the 3D-Zone Model of human-robot shared workspace. Therefore, the robot can reach its goal quickly and safely in a dynamic and unstructured environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594014","","Robots;Collision avoidance;Real-time systems;Machine tools;Dynamics;Safety;Trajectory","collision avoidance;human-robot interaction;mobile robots;optimisation;path planning","collision optimization;real time robot path planning;dynamic obstacles;motion planning framework;pre-programmed robot paths;dynamic HRC-applications;human-robot-cooperation;unstructured environment;robot velocity;movement paths;free robot trajectories;framework plans;human-robot shared workspace;human obstacles","","","","","","","","IEEE","IEEE Conferences"
"Integrating Human-Provided Information into Belief State Representation Using Dynamic Factorization","R. Chitnis; L. P. Kaelbling; T. Lozano-Pérez","MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3551","3558","In partially observed environments, it can be useful for a human to provide the robot with declarative information that represents probabilistic relational constraints on properties of objects in the world, augmenting the robot's sensory observations. For instance, a robot tasked with a search-and-rescue mission may be informed by the human that two victims are probably in the same room. An important question arises: how should we represent the robot's internal knowledge so that this information is correctly processed and combined with raw sensory information? In this paper, we provide an efficient belief state representation that dynamically selects an appropriate factoring, combining aspects of the belief when they are correlated through information and separating them when they are not. This strategy works in open domains, in which the set of possible objects is not known in advance, and provides significant improvements in inference time over a static factoring, leading to more efficient planning for complex partially observed tasks. We validate our approach experimentally in two open-domain planning problems: a 2D discrete gridworld task and a 3D continuous cooking task. A supplementary video can be found at http://tinyurl.com/chitnis-iros-18.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594468","","Planning;Robot sensing systems;Task analysis;Markov processes;Intelligent robots;Probabilistic logic","mobile robots;path planning;probability","3D continuous cooking task;2D discrete gridworld task;open-domain planning problems;complex partially observed tasks;efficient planning;static factoring;possible objects;open domains;appropriate factoring;efficient belief state representation;raw sensory information;internal knowledge;sensory observations;probabilistic relational constraints;declarative information;partially observed environments;dynamic factorization","","","23","","","","","IEEE","IEEE Conferences"
"Workshops","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","68","90","Provides an abstract for each of the workshop presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593620","","Conferences;Service robots;Diseases;Task analysis;Grasping;Robot sensing systems","","","","","","","","","","IEEE","IEEE Conferences"
"Plenary sessions","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","38","54","Provides an abstract for each of the plenary presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594490","","Artificial intelligence;Humanoid robots;Robot sensing systems;Collaboration;Biographies;Neural networks","","","","","","","","","","IEEE","IEEE Conferences"
"Stochastic Optimization for Autonomous Vehicles with Limited Control Authority","D. Jones; G. A. Hollinger; M. J. Kuhlman; D. A. Sofge; S. K. Gupta","Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Corvallis, OR, 97330, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Corvallis, OR, 97330, USA; Navy Center for Applied Research in Artificial Intelligence, Naval Research Laboratory, Washington, DC, 20375, USA; Navy Center for Applied Research in Artificial Intelligence, Naval Research Laboratory, Washington, DC, 20375, USA; Aerospace and Mechanical Engineering Department, Center for Advanced Manufacturing at the University of Southern California, Los Angeles, CA, 90089, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2395","2401","In this work, we present a Stochastic Gradient Ascent (SGA) algorithm for multi-vehicle information gathering that accounts for limitations on a vehicle's control authority caused by external forces. By representing vehicle paths using a novel action space representation, rather than a state space representation, we remove the need to perform feasibility calculations on the vehicle's path. Our algorithm uses a stochastic optimization scheme by sampling perturbed action sequences around the current best known sequence to estimate the gradient of a state space information function with respect to the action sequence. Additionally, we use sequential greedy allocation to plan for multiple vehicles. Results are shown using a Navy Coastal Ocean Model (NCOM) for the Gulf of Mexico (GoM). SGA shows improvement in the amount of information gained over a greedy baseline. Additionally, we compare to Monte Carlo Tree Search (MCTS) Method, which is able to gather competitive amounts of information but is more computationally intensive than our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594020","","Oceans;Optimization;Stochastic processes;Approximation algorithms;Trajectory;Aerospace electronics;Robots","gradient methods;greedy algorithms;mobile robots;optimisation;state-space methods;stochastic processes","SGA;multivehicle information gathering;action space representation;stochastic optimization scheme;perturbed action sequences;state space information function;sequential greedy allocation;autonomous vehicles;stochastic gradient ascent algorithm;vehicle control authority;navy coastal ocean model;NCOM;Gulf of Mexico;GoM;Monte Carlo tree search method;MCTS","","","23","","","","","IEEE","IEEE Conferences"
"DROAN - Disparity-Space Representation for Obstacle Avoidance: Enabling Wire Mapping & Avoidance","G. Dubey; R. Madaan; S. Scherer","Carnegie Mellon University, The Robotics Institute, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA; Carnegie Mellon University, The Robotics Institute, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA; Carnegie Mellon University, The Robotics Institute, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6311","6318","Wire detection, depth estimation and avoidance is one of the hardest challenges towards the ubiquitous presence of robust autonomous aerial vehicles. We present an approach and a system which tackles these three challenges along with generic obstacle avoidance as well. First, we perform monocular wire detection using a convolutional neural network under the semantic segmentation paradigm, and obtain a confidence map of wire pixels. Along with this, we also use a binocular stereo pair to detect other generic obstacles. We represent wires and generic obstacles using a disparity space representation and do a C-space expansion by using a non-linear sensor model we develop. Occupancy inference for collision checking is performed by maintaining a pose graph over multiple disparity images. For avoidance of wire and generic obstacles, we use a precomputed trajectory library, which is evaluated in an online fashion in accordance to a cost function over proximity to the goal. We follow this trajectory with a path tracking controller. Finally, we demonstrate the effectiveness of our proposed method in simulation for wire mapping, and on hardware by multiple runs for both wire and generic obstacle avoidance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593499","","Wires;Robot sensing systems;Three-dimensional displays;Cameras;Trajectory;Uncertainty","collision avoidance;graph theory;image segmentation;image sensors;mobile robots;motion control;neural nets;robot vision;stereo image processing","multiple disparity images;C-space expansion;disparity space representation;generic obstacles;wire pixels;confidence map;semantic segmentation paradigm;convolutional neural network;monocular wire detection;generic obstacle avoidance;robust autonomous aerial vehicles;depth estimation;DROAN - disparity-space representation","","","34","","","","","IEEE","IEEE Conferences"
"Joint Stem Detection and Crop-Weed Classification for Plant-Specific Treatment in Precision Farming","P. Lottes; J. Behley; N. Chebrolu; A. Milioto; C. Stachniss","The University of Bonn, Germany; The University of Bonn, Germany; The University of Bonn, Germany; The University of Bonn, Germany; The University of Bonn, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8233","8238","Applying agrochemicals is the default procedure for conventional weed control in crop production, but has negative impacts on the environment. Robots have the potential to treat every plant in the field individually and thus can reduce the required use of such chemicals. To achieve that, robots need the ability to identify crops and weeds in the field and must additionally select effective treatments. While certain types of weed can be treated mechanically, other types need to be treated by (selective) spraying. In this paper, we present an approach that provides the necessary information for effective plant-specific treatment. It outputs the stem location for weeds, which allows for mechanical treatments, and the covered area of the weed for selective spraying. Our approach uses an end-to-end trainable fully convolutional network that simultaneously estimates stem positions as well as the covered area of crops and weeds. It jointly learns the class-wise stem detection and the pixel-wise semantic segmentation. Experimental evaluations on different real-world datasets show that our approach is able to reliably solve this problem. Compared to state-of-the-art approaches, our approach not only substantially improves the stem detection accuracy, i.e., distinguishing crop and weed stems, but also provides an improvement in the semantic segmentation performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593678","","Agriculture;Decoding;Image segmentation;Feature extraction;Semantics;Task analysis;Robots","agricultural robots;agriculture;agrochemicals;control engineering computing;convolutional neural nets;crops;image classification;image segmentation;learning (artificial intelligence);robot vision;spraying","crop production;robots;mechanical treatments;class-wise stem detection;conventional weed control;spraying process;convolutional network;farming process;agrochemicals;environmental impact;pixel-wise semantic segmentation","","1","23","","","","","IEEE","IEEE Conferences"
"Constrained Control of Robotic Manipulators Using the Explicit Reference Governor","K. Merckaert; B. Vanderborght; M. M. Nicotra; E. Garone","Robotics & Multibody Mechanics (R&MM) research group of Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, 1050, Belgium; Robotics & Multibody Mechanics (R&MM) research group of Vrije Universiteit Brussel (VUB) and Flanders Make, Brussels, 1050, Belgium; Department of aerospace engineering, University of Michigan, Ann Arbor, MI, USA; Department SAAS, Université Libre de Bruxelles, Brussels, 1050, Belgium","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5155","5162","Robotic manipulators that are intended to interact with humans in their operating region are systems that need formal safety guarantees. Current solutions cannot handle both input and state constraints, have difficulties handling nonconvex constraints, or are computationally too expensive. To tackle these drawbacks, we analyzed a constrained control strategy, the Explicit Reference Governor (ERG), which can address both input and state constraints, and does not require any online optimization, thus making it computationally inexpensive. This paper presents the theory of the ERG for a general robotic manipulator and shows simulations for a specific 2DOF planar robotic manipulator. The proposed control scheme is able to steer the robot arm to the desired end-effector position, or an admissible approximation, in the presence of limited joint ranges, actuator saturations, and static obstacles. As a result, the ERG is a promising tool for the control of robotic manipulators subject to constraints.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593857","","Manipulator dynamics;Safety;End effectors;Actuators;Navigation","actuators;collision avoidance;end effectors;manipulators;position control","robot arm;ERG;Explicit Reference Governor;nonconvex constraints;constrained control;2DOF planar robotic manipulator;end-effector position;actuator saturations;static obstacles;joint ranges","","","30","","","","","IEEE","IEEE Conferences"
"Social Cohesion in Autonomous Driving","N. C. Landolfi; A. D. Dragan","Sciences' University of California, Department of Electrical Engineering and Computer, Berkeley, 94720, Berkeley; Sciences' University of California, Department of Electrical Engineering and Computer, Berkeley, 94720, Berkeley","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8118","8125","Autonomous cars can perform poorly for many reasons. They may have perception issues, incorrect dynamics models, be unaware of obscure rules of human traffic systems, or follow certain rules too conservatively. Regardless of the exact failure mode of the car, often human drivers around the car are behaving correctly. For example, even if the car does not know that it should pull over when an ambulance races by, other humans on the road will know and will pull over. We propose to make socially cohesive cars that leverage the behavior of nearby human drivers to act in ways that are safer and more socially acceptable. The simple intuition behind our algorithm is that if all the humans are consistently behaving in a particular way, then the autonomous car probably should too. We analyze the performance of our algorithm in a variety of scenarios and conduct a user study to assess people's attitudes towards socially cohesive cars. We find that people are surprisingly tolerant of mistakes that cohesive cars might make in order to get the benefits of driving in a car with a safer, or even just more socially acceptable behavior.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593682","","Automobiles;Roads;Autonomous automobiles;Trajectory;Autonomous vehicles","automobiles;control engineering computing;mobile robots;road safety;road traffic;statistical analysis;traffic information systems","social cohesion;autonomous driving;autonomous car;perception issues;incorrect dynamics models;obscure rules;human traffic systems;exact failure mode;socially cohesive cars;nearby human drivers;socially acceptable behavior","","","14","","","","","IEEE","IEEE Conferences"
"Real-Time Tumor Tracking for Pencil Beam Scanning Proton Therapy","S. Vemprala; S. Saripalli; C. Vargas; M. Bues; Y. Hu; J. Shen","Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA; Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA; Department of Radiation Oncology, Mayo Clinic Arizona, Phoenix, Arizona, USA; Department of Radiation Oncology, Mayo Clinic Arizona, Phoenix, Arizona, USA; Department of Radiation Oncology, Mayo Clinic Arizona, Phoenix, Arizona, USA; Department of Radiation Oncology, Mayo Clinic Arizona, Phoenix, Arizona, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4434","4440","In this paper, we describe the method and implementation of a real-time tumor tracking system for a pencil beam scanning (PBS) proton therapy system. PBS is an advanced cancer treatment system that can benefit from precise localization of the tumors through motion. We utilize techniques such as cross-correlation matching, correlation filters and small object saliency, creating an array of methods that can detect and track fiducial markers implanted in the cancer tumors. The final aim is to control the proton beam using real-time image guidance. Our technique works robustly on various types of markers such as ceramic/metallic fiducials, visicoil markers and surgical clips. Left and right views of an X-ray fluoroscopy system were utilized to also triangulate the marker positions in full 3D as they are tracked through normal breathing movement and organ motion. We have tested our detection system on data from several patients with different tumor locations both offline and in real-time and wish to implement it within a full treatment system soon. To the best of the authors knowledge, this is the first real time tracking system for PBS therapy that is applicable for various types of fiducials and tumor locations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593861","","Tumors;Real-time systems;X-ray imaging;Particle beams;Target tracking;Correlation","biological organs;cancer;diagnostic radiography;image motion analysis;medical image processing;pneumodynamics;proton beams;radiation therapy;tumours","tumor locations;ceramic-metallic fiducials;surgical clips;correlation filters;cross-correlation matching;advanced cancer treatment system;pencil beam scanning proton therapy system;real-time tumor tracking system;PBS therapy;organ motion;normal breathing movement;X-ray fluoroscopy system;visicoil markers;real-time image guidance;proton beam;cancer tumors;fiducial markers","","","12","","","","","IEEE","IEEE Conferences"
"Object Recognition Through Active Sensing Using a Multi-Fingered Robot Hand with 3D Tactile Sensors","S. Funabashi; S. Morikuni; A. Geier; A. Schmitz; S. Ogasa; T. P. Torno; S. Somlor; S. Sugano","Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Dept. of Modern Mechanical Engineering, Waseda University, Tokyo, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2589","2595","This paper investigates tactile object recognition with relatively densely distributed force vector measurements and evaluates what kind of tactile information is beneficial for object recognition. The uSkin tactile sensors are embedded in an Allegro Hand, and provide 240 triaxial force vector measurements in total in all fingers. Active object sensing is used to gather time-series training and testing data. A simple feedforward, a recurrent, and a convolutional neural network are used for recognizing objects. Evaluations with different number of employed measurements, static vs. time series data and force vector vs. only normal force vector measurements show that the high-dimensional information provided by the sensors is indeed beneficial. An object recognition rate of up to 95% for 20 objects was achieved.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594159","","Force;Force measurement;Object recognition;Tactile sensors","control engineering computing;convolutional neural nets;dexterous manipulators;object recognition;recurrent neural nets;tactile sensors;time series","multifingered robot hand;triaxial force vector measurements;3D tactile sensors;distributed force vector measurements;feedforward neural network;recurrent neural network;time-series training;active object sensing;Allegro Hand;uSkin tactile sensors;tactile object recognition;time series data","","","24","","","","","IEEE","IEEE Conferences"
"C-blox: A Scalable and Consistent TSDF-based Dense Mapping Approach","A. Millane; Z. Taylor; H. Oleynikova; J. Nieto; R. Siegwart; C. Cadena","ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","995","1002","In many applications, maintaining a consistent dense map of the environment is key to enabling robotic platforms to perform higher level decision making. Several works have addressed the challenge of creating precise dense 3D maps from visual sensors providing depth information. However, during operation over longer missions, reconstructions can easily become inconsistent due to accumulated camera tracking error and delayed loop closure. Without explicitly addressing the problem of map consistency, recovery from such distortions tends to be difficult. We present a novel system for dense 3D mapping which addresses the challenge of building consistent maps while dealing with scalability. Central to our approach is the representation of the environment as a collection of overlapping Truncated Signed Distance Field (TSDF) subvolumes. These subvolumes are localized through feature-based camera tracking and bundle adjustment. Our main contribution is a pipeline for identifying stable regions in the map, and to fuse the contributing subvolumes. This approach allows us to reduce map growth while still maintaining consistency. We demonstrate the proposed system on a publicly available dataset and simulation engine, and demonstrate the efficacy of the proposed approach for building consistent and scalable maps. Finally we demonstrate our approach running in real-time onboard a lightweight Micro Aerial Vehicle (MAV).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593427","","Cameras;Simultaneous localization and mapping;Image reconstruction;Three-dimensional displays;Robot vision systems","autonomous aerial vehicles;image reconstruction;image sensors;robot vision;SLAM (robots)","truncated signed distance field;TSDF subvolumes;lightweight micro aerial vehicle;scalable maps;map growth;bundle adjustment;feature-based camera tracking;dense 3D mapping;map consistency;delayed loop closure;accumulated camera tracking error;precise dense 3D maps;higher level decision making;robotic platforms;consistent dense map","","","28","","","","","IEEE","IEEE Conferences"
"Learning Oscillator-Based Gait Controller for String-Form Soft Robots Using Parameter-Exploring Policy Gradients","M. Ishige; T. Umedachil; T. Taniguchi; Y. Kawahara","University of Tokyo, Graduate School of Information Science and Technology, 7-3-1 Hongo, Bunkyo-ku, Tokyo, umedachi, Japan mishige; University of Tokyo, Graduate School of Information Science and Technology, 7-3-1 Hongo, Bunkyo-ku, Tokyo, umedachi, Japan mishige; Department of Human and Computer Intelligence, Rit-sumeikan University, 56-1 Tojiin Kitamachi, Kita Ward, Kyoto; University of Tokyo, Graduate School of Information Science and Technology, 7-3-1 Hongo, Bunkyo-ku, Tokyo, umedachi, Japan mishige","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6445","6452","This paper presents a methodology to design mechanosensor feedback to oscillator-based controller for worm-like soft-bodied robots. A reinforcement learning technique, i.e., PEPG, is employed to embed appropriate mechanosensor feedback to harness global entrainment among the controller, the body dynamics, and the environment without explicitly designing the interaction between the oscillators. Another reinforcement learning, actor-critic, was applied to train the controller for the simulation models to analyze the effectiveness of PEPG in the system. Furthermore, the gait controller was trained under different body dynamics, i.e., the physical model of a caterpillar and an earthworm. We found that PEPG is suitable for the system probably because it does not add exploration noise to actions and it conducts episode based parameter updates. The simulation results show the proposed method can acquire distinct behavior, i.e., caterpillars' crawling, inching and earthworms' crawling, under different body dynamics. The outcome implies, that by utilizing appropriate learning method, desired functionality can be achieved in soft-bodied robots without explicitly designing their behavior.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594338","","Robot sensing systems;Oscillators;Reinforcement learning;Force;Actuators;Springs","gradient methods;learning (artificial intelligence);legged locomotion;mobile robots","actor-critic;oscillators;harness global entrainment;appropriate mechanosensor feedback;reinforcement learning technique;parameter-exploring policy gradients;string-form soft robots;oscillator-based gait controller;soft-bodied robots;appropriate learning method;episode based parameter updates;exploration noise;physical model;PEPG;simulation models","","","22","","","","","IEEE","IEEE Conferences"
"Vision Based Forward Sensitive Reactive Control for a Quadrotor VTOL","J. Stevens; R. Mahony","Australian Centre of Excellence for Robotic Vision, Australian National University; Australian Centre of Excellence for Robotic Vision, Australian National University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5232","5238","Deployment of aerial robotic vehicles for real world tasks such as home deliveries, close range aerial inspection, etc., require robotic vehicles to fly through complex and cluttered 3D environments such as forests, shrubbery or into balconies, garages, or sheds. Dense high-speed optical flow can provide real-time motion cues for obstacle avoidance that does not require 3D full reconstruction of the environment. However, classical reactive control does not `look ahead' and tends to bounce off obstacles rather than generating a smooth trajectory that anticipates and avoids upcoming obstacles. In this paper, we consider deriving a fully image based control criteria that forward predicts a cylinder of free space into the image flow representation of the environment and steers the vehicle by manoeuvering this cylinder through the upcoming environment. The length and radius of the cylinder provide a guarantee that the vehicle can indeed fly through the space identified and the fact that it is predicted forward into the environment leads to smooth anticipation of upcoming obstacles. Results are obtained for a quadrotor flying autonomously through a forest environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593606","","Optical sensors;Optical imaging;Adaptive optics;Velocity measurement;Robot sensing systems;Cameras","aircraft control;autonomous aerial vehicles;collision avoidance;helicopters;image sequences;mobile robots;robot vision","dense high-speed optical flow;real-time motion cues;obstacle avoidance;smooth trajectory;image flow representation;forest environment;forward sensitive reactive control;quadrotor VTOL;aerial robotic vehicles;3D full reconstruction;fully image based control criteria","","","22","","","","","IEEE","IEEE Conferences"
"Printing Strain Gauges on Intuitive Surgical da Vinci Robot End Effectors","R. Peña; M. J. Smith; N. P. Ontiveros; F. L. Hammond; R. J. Wood","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, 02138, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, 02138, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, 02138, USA; Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, 30332, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, 02138, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","806","812","Force feedback during robotic surgery is critical in order to minimize potential injury to the patient and decrease recovery time from surgical procedures. Here we describe the use of a novel strain gauge printing method to apply low profile, low cost sensors directly to the surface of da Vinci surgical robot end effectors (Intuitive Surgical, Inc.) to sense deflection and provide force feedback. This additive, vapor-deposition-based sensor fabrication method is used to deposit strain gauges directly onto the surfaces of the end effectors with minimal disruption to the device and without the need for adhesives or machining operations. Initial experiments characterize sensor performance and indicate the applicability of the proposed approach for force feedback during minimally invasive procedures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594517","","Sensors;Surface treatment;End effectors;Shafts;Strain;Strain measurement;Surgery","biomedical equipment;biomedical measurement;end effectors;force feedback;medical robotics;needles;strain gauges;surgery","printing strain gauges;robotic surgery;strain gauge printing method;da Vinci surgical robot end effectors;additive deposition-based sensor fabrication method;vapor-deposition-based sensor fabrication method;sensor performance;minimally invasive procedures","","","22","","","","","IEEE","IEEE Conferences"
"Target Localization with Drones using Mobile CNNs","Y. Lu; Z. Wang; Z. Tang; T. Javidi","Department of Electrical and Computer Engineering, University of California, San Diego; Department of Electrical and Computer Engineering, University of California, San Diego; Department of Electrical and Computer Engineering, University of California, San Diego; Department of Electrical and Computer Engineering, University of California, San Diego","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2566","2573","Fast and accurate visual search is an enabler for many applications of drones. Prior works use POMDPs to produce effective search strategies. As the observation models are from heuristics, the robustness of these approaches on the field is unclear. This work builds a testbed that combines latest developments in related areas, including mobile CNNs for inference on mobile platforms and policy search with point based methods, in a POMDP framework. A dataset for a simple but realistic application, search for a single basketball, is collected to train the perception modules, investigate their error characteristics and validate the control algorithm. From simulation using realistic parameters, we found the significant role persistent factors in the environment can play in designing a fast search strategy. Failure to taking these factors into account results in up to 60% longer search time at the same success rate. Our empirical tests using mobile CNN and real data reveals that prior assumptions on error rates as functions of heights are wrong. The errors grows non-linearly, and there is significant between false positive and false negative rates. Our findings shed new lights on what to consider in designing visual search strategies in a drone platform and is one step towards a fast and robust algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594163","","Drones;Sensors;Search problems;Data collection;Computational modeling;Delays;Visualization","aerospace robotics;decision theory;learning (artificial intelligence);Markov processes;search problems","target localization;accurate visual search;effective search strategies;observation models;latest developments;mobile platforms;policy search;point based methods;POMDP framework;single basketball;perception modules;error characteristics;control algorithm;realistic parameters;fast search strategy;longer search time;real data;error rates;false positive rates;false negative rates;visual search strategies;drone platform;robust algorithm;mobile CNN","","","24","","","","","IEEE","IEEE Conferences"
"Underwater Surveying via Bearing Only Cooperative Localization","H. Damron; A. Q. Li; I. Rekleitis","Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3957","3963","Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593431","","Cameras;Springs;Robot kinematics;Lakes;Robot sensing systems","mobile robots;path planning;remotely operated vehicles;underwater vehicles","bearing only cooperative localization;aerial ground vehicles;underwater domain;robotic applications;cave mapping;marine archeology surveying;fresh water;South Carolina;visibility conditions;depth sensors;magnetic sensors;inertial sensors;Florida;Barbados","","","37","","","","","IEEE","IEEE Conferences"
"Sensor-Based Reactive Execution of Symbolic Rearrangement Plans by a Legged Mobile Manipulator","V. Vasilopoulos; T. T. Topping; W. Vega-Brown; N. Roy; D. E. Koditschek","Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, 19104; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, Massachusetts, 02139; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, Massachusetts, 02139; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3298","3305","We demonstrate the physical rearrangement of wheeled stools in a moderately cluttered indoor environment by a quadrupedal robot that autonomously achieves a user's desired configuration. The robot's behaviors are planned and executed by a three layer hierarchical architecture consisting of: an offline symbolic task and motion planner; a reactive layer that tracks the reference output of the deliberative layer and avoids unanticipated obstacles sensed online; and a gait layer that realizes the abstract unicycle commands from the reactive module through appropriately coordinated joint level torque feedback loops. This work also extends prior formal results about the reactive layer to a broad class of nonconvex obstacles. Our design is verified both by formal proofs as well as empirical demonstration of various assembly tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594342","","Task analysis;Grippers;Robot sensing systems;Robot kinematics;Mobile robots;Manipulators","collision avoidance;feedback;legged locomotion;manipulators;mobile robots;motion control;path planning;torque control","motion planner;reactive layer;reference output;deliberative layer;unanticipated obstacles;gait layer;abstract unicycle commands;reactive module;appropriately coordinated joint level torque feedback loops;empirical demonstration;sensor-based reactive execution;symbolic rearrangement plans;legged mobile manipulator;physical rearrangement;wheeled stools;moderately cluttered indoor environment;quadrupedal robot;layer hierarchical architecture;offline symbolic task","","","26","","","","","IEEE","IEEE Conferences"
"Kalman Filter Based Observer for an External Force Applied to Medium-sized Humanoid Robots","L. Hawley; R. Rahem; W. Suleiman","Electrical and Computer Engineering Department, Faculty of Engineering, University of Sherbrooke, Quebec, Canada; Electrical and Computer Engineering Department, Faculty of Engineering, University of Sherbrooke, Quebec, Canada; Electrical and Computer Engineering Department, Faculty of Engineering, University of Sherbrooke, Quebec, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1204","1211","External force observer for humanoid robots has been widely studied in the literature. However, most of the proposed approaches generally rely on information from six-axis force/torque sensors, which the small or medium-sized humanoid robots usually do not have. As a result, those approaches cannot be applied to this category of humanoid robots, which is widely used nowadays in education or research. In this paper, we improve the external force observer in [1] to handle the case of an external force applied in any direction and at an arbitrary point of the robot structure. The new observer is based on Kalman filter formulation and it allows the estimation of the three force components. The observer is simple to implement and can easily run in real time using the embedded processor of a medium-sized humanoid robot such as Nao or Darwin-OP. Moreover, the observer does not require any change to the robot hardware as it only uses measurements from the available force-sensing resistors (FSR) inserted under the feet of the humanoid robot and from the robot inertial measurement unit (IMU). The proposed observer was extensively validated on a Nao humanoid robot. In all conducted experiments, the observer successfully estimated the external force within a reasonable margin of error.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593610","","Force;Humanoid robots;Robot sensing systems;Observers;Force measurement","force sensors;humanoid robots;Kalman filters;legged locomotion","medium-sized humanoid robot;external force observer;force/torque sensors;small robots;medium-sized humanoid robots;robot structure;Kalman filter formulation;force components;robot hardware;robot inertial measurement unit;Nao humanoid robot;external force;force-sensing resistors","","","20","","","","","IEEE","IEEE Conferences"
"Similarity of the Impact of Humanoid and In-Person Communications on Frontal Brain Activity of Older People","S. Keshmiri; H. Sumioka; R. Yamazaki; M. Okubo; H. Ishiguro","Advanced Telecommunications Research Institute International (ATR), Kyoto, Japan; Advanced Telecommunications Research Institute International (ATR), Kyoto, Japan; School of Social Sciences, Waseda University, Japan; Hiroshi Ishiguro Laboratories (HIL) at ATR; Graduate School of Engineering Science, Osaka University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2286","2291","We report results of the analyses of the effect of communication through a humanoid robot in comparison with in-person, video-chat, and speaker on frontal brain activity of older people during an storytelling experiment. Our results suggest that whereas communicating through a physically embodied medium potentially induces a significantly higher pattern of brain activation with respect to video-chat and speaker, its difference is non-significant in comparison with in-person communication. These results imply that communicating through a humanoid robot induces a pattern of brain activity in older people that is potentially similar to in-person communication. Our findings benefit researchers and practitioners in rehabilitation and elderly care facilities in search of effective means of communication with their patients to increase their involvement in the incremental steps of their treatments. Moreover, they imply the utility of brain information as a promising sensory gateway in characterization of the behavioural responses in human-robot interaction.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594521","","Brain;Humanoid robots;Time series analysis;Media;Senior citizens;Data acquisition","brain;geriatrics;handicapped aids;humanoid robots;human-robot interaction;medical robotics","older people;in-person communication;brain information;frontal brain activity;humanoid robot;video-chat;speaker;brain activation;storytelling experiment;sensory gateway;behavioural responses;human-robot interaction","","","32","","","","","IEEE","IEEE Conferences"
"Fractional-Order Trajectory-Following Control for Two-Legged Dynamic Walking","K. Leyden; B. Goodwine","Department of Aerospace & Mechanical Engineering, University of Notre Dame, Notre Dame, IN, 46556, USA; Department of Aerospace & Mechanical Engineering, University of Notre Dame, Notre Dame, IN, 46556, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","699","704","This research seeks greater efficiency for walking robots. Efficiency can be improved in two ways: better performance (i.e., less wasted motion) and reduced energy consumption. Fractional-order control is a pathway to both of these improvements because of the flexibility it offers in designing a control strategy. Compared to the existing proportional-derivative architecture, changing the order of the derivative - the number of derivatives taken - to real numbers other than 1 has yielded both types of improvement for a simulated walker. The evidence of better performance is the leg angles' improvement in maintaining a desired relationship with respect to one another. Depending on the controller chosen, the walker can also be made to achieve the original level of performance with reduced control signals and less torque delivered to the hip joint, implying greater energy efficiency.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593749","","Legged locomotion;Mathematical model;Gravity;Aerodynamics;PD control;Trajectory","control system synthesis;energy conservation;legged locomotion;motion control;PD control;position control;robot dynamics","simulated walker;two-legged dynamic walking;walking robots;energy consumption;energy efficiency;fractional-order trajectory-following control;proportional-derivative architecture","","","30","","","","","IEEE","IEEE Conferences"
"Bimanual Assembly of Two Parts with Relative Motion Generation and Task Related Optimization","S. Stavridis; Z. Doulgeri","Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece, Center for Research and Technology Hellas (CERTH), Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece, Center for Research and Technology Hellas (CERTH), Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7131","7136","Bimanual assembly of two parts require that a relative target pose is reached prior to the joining operation. Rather than utilizing one arm as a fixture for holding one of the parts while the other performs the assembly, motion generation in the relative end-effector frame is proposed that involves both arms. The proposed approach considers bimanual motion in a dynamic and uncertain environment addressing avoidance of collision with obstacles as well as the robot itself and the environment. Moreover, configurations that optimize the motion and force capabilities for the sucessful and efficient completion of the task are taken into account. A task priority strategy is adopted achieving online performance. Experimental results on the YuMi bimanual robot using the Stack-Of- Tasks hierarchical solver validate the performance of the proposed approach in a folding assembly task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593928","","Task analysis;Collision avoidance;End effectors;Ellipsoids;Robot kinematics","collision avoidance;end effectors;motion control;optimisation;robotic assembly","end-effector frame;stack-of- tasks hierarchical solver;collision avoidance;optimization;relative motion generation;bimanual assembly;YuMi bimanual robot;task priority strategy","","","20","","","","","IEEE","IEEE Conferences"
"“Oh! I am so sorry!”: Understanding User Physiological Variation while Spoiling a Game Task","R. Agrigoroaie; A. Cruz-Maya; A. Tapus","U2IS, ENSTA-ParisTech, Universite Paris-Saclay, Autonomous Systems and Robotics Laboratory, Palaiseau, France; U2IS, ENSTA-ParisTech, Universite Paris-Saclay, Autonomous Systems and Robotics Laboratory, Palaiseau, France; U2IS, ENSTA-ParisTech, Universite Paris-Saclay, Autonomous Systems and Robotics Laboratory, Palaiseau, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","313","319","This paper investigates how individuals react in a situation when an experimenter (human or robot) either tells them to stop in the middle of playing the Jenga game, or accidentally bumps into a table and makes the tower fall down. The mood of the participants and different physiological parameters (i.e., galvanic skin response (GSR) and facial temperature variation) are extracted and analysed based on the condition, experimenter, and psychological questionnaires (i.e., TEQ, TEIQ, RST-PQ). This study was a between participants study with 23 participants. Our results show that multiple GSR parameters (e.g., latency, amplitude, number of peaks) differ significantly based on the condition and the experimenter the participants interacted with. The temperature variation in three regions of interest (i.e., forehead, left, and right periorbital regions) are good indicators of how ready an individual is to react in an unforeseen situation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593395","","Poles and towers;Games;Collision avoidance;Physiology;Robot sensing systems","computer games;human-robot interaction;psychology","Jenga game;galvanic skin response;psychological questionnaires;multiple GSR parameters;user physiological variation;game task;tower fall down","","","20","","","","","IEEE","IEEE Conferences"
"Distributed Sensing Subject to Temporal Logic Constraints","Z. Serlin; K. Leahy; R. Tron; C. Belta","Department of Mechanical Engineering, Boston University, Boston, MA, USA; Massachusetts Institute of Technology Lincoln Laboratory, Lexington, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4862","4868","This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593574","","Robot sensing systems;Linear programming;Task analysis;Planning;Automata","entropy;formal specification;greedy algorithms;multi-agent systems;optimisation;temporal logic","distributed sensing subject;temporal logic constraints;temporal logic specifications;local objective functions;motion plans;objective function;information entropy;unassigned agents;satisfaction guarantees;optimality loss;local greedy minimization;TL constraints;specification complexity;TL specification;product automaton based approach","","","24","","","","","IEEE","IEEE Conferences"
"Magnetic- Visual Sensor Fusion-based Dense 3D Reconstruction and Localization for Endoscopic Capsule Robots","M. Turan; Y. Almalioglu; E. P. Ornek; H. Araujo; M. F. Yanik; M. Sitti","Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Germany; Computer Science Department, University of Oxford, Oxford, UK; Informatics Department, Technical University of Muenich, Germany; Institute for Systems and Robotics, University of Coimbra, Portugal; Department of Information Technology and Electrical Engineering, Zurich, Switzerland; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1283","1289","Reliable and real-time 3D reconstruction and localization functionality is a crucial prerequisite for the navigation of actively controlled capsule endoscopic robots as an emerging, minimally invasive diagnostic and therapeutic technology for use in the gastrointestinal (GI) tract. In this study, we propose a fully dense, non-rigidly deformable, strictly real-time, intraoperative map fusion approach for actively controlled endoscopic capsule robot applications which combines magnetic and vision-based localization, with non-rigid deformations based frame-to-model map fusion. The performance of the proposed method is evaluated using four different ex-vivo porcine stomach models. Across different trajectories of varying speed and complexity, and four different endoscopic cameras, the root mean square surface reconstruction errors vary from 1.58 to 2.17 cm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594485","","Magnetic resonance imaging;Robot sensing systems;Magnetic separation;Three-dimensional displays;Cameras;Endoscopes","biomedical optical imaging;cameras;endoscopes;image fusion;image reconstruction;medical image processing;medical robotics;robot vision","visual sensor fusion-based dense 3D reconstruction;real-time 3D reconstruction;actively controlled capsule endoscopic robots;minimally invasive diagnostic technology;therapeutic technology;gastrointestinal tract;intraoperative map fusion approach;actively controlled endoscopic capsule robot applications;magnetic vision-based localization;nonrigid deformations;frame-to-model map fusion;ex-vivo porcine stomach models;root mean square surface reconstruction errors;endoscopic camera","","","32","","","","","IEEE","IEEE Conferences"
"Robust Exploration with Multiple Hypothesis Data Association","J. Wang; B. Englot","Department of Mechanical Engineering, Stevens Institute of Technology, Castle Point on Hudson, Hoboken, NJ, 07030, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Castle Point on Hudson, Hoboken, NJ, 07030, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3537","3544","We study the ambiguous data association problem confronting simultaneous localization and mapping (SLAM), specifically for the autonomous exploration of environments lacking rich features. In such environments, a single false positive assignment might lead to catastrophic failure, which even robust back-ends may be unable to resolve. Inspired by multiple hypothesis tracking, we present a novel approach to effectively manage multiple hypotheses (MH) of data association inherited from traditional joint compatibility branch and bound (JCBB), which entails the generation, ordering and elimination of hypotheses. We analyze the performance of MHJCBB in two particular situations, one applying it to SLAM over a predefined trajectory and the other showing its applicability in exploring unknown environments. Statistical results demonstrate that MHJCBB's maintenance of diverse hypotheses under ambiguous conditions significantly improves map accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593753","","Simultaneous localization and mapping;Trajectory;Noise measurement;State estimation;Optimization;Measurement uncertainty","image fusion;mobile robots;robot vision;SLAM (robots);target tracking;tree searching","joint compatibility branch;simultaneous localization and mapping;map accuracy;diverse hypotheses;multiple hypothesis tracking;robust back-ends;catastrophic failure;single false positive assignment;rich features;autonomous exploration;SLAM;ambiguous data association problem;multiple hypothesis data association;robust exploration","","","23","","","","","IEEE","IEEE Conferences"
"The Effect of Swing Leg Retraction on Biped Walking Stability is Influenced by the Walking Speed and Step-Length","R. Bao; T. Geng","Burnel University, London, UK; Middlesex University, London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3257","3262","Swing Leg Retraction (SLR) is observed in human walking and running. Previous studies have concluded that SLR improves the stability and robustness of biped walking. But this conclusion was based on analysis of robot models that can only walk at a very small range of step-lengths and slow or fixed speeds. By contrast, humans can walk with a large range of speeds and step-lengths. Moreover, human walking patterns have a special feature that has not been considered in the previous studies on SLR effects: At a given walking speed, v, humans prefer a step-length, s, which satisfies the power law, s-v<sup>β</sup>. Therefore, previous studies on SLR can't tell us whether their conclusion will still hold in the full range of human walking patterns (i.e., various walking speeds and step-lengths). This is the question we want to answer in this paper. In this study, using a simple biped model, we studied how the SLR affects the walking stability in the full range of human walking speeds/step-lengths. Preliminary analysis of both models suggests the same conclusion: (1) SLR improves the stability more evidently in human-preferred walking patterns than in other walking patterns. (2) In walking patterns that are very unlike human-preferred ones, the SLR improves the stability very little, or even deteriorates it drastically. Therefore, the new finding of our study is that how the SLR affects the biped walking stability depends on the walking speed and step-length. SLR does not always improve the stability of biped walking.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593932","Biped robots;Swing leg retraction;Human walking","Legged locomotion;Mathematical model;Analytical models;Stability criteria;Foot","gait analysis;legged locomotion;mechanical stability;mechanical variables control","walking speed;swing leg retraction;human-preferred walking patterns;human walking speeds/step-lengths;simple biped model;SLR effects;human walking patterns;biped walking stability","","","14","","","","","IEEE","IEEE Conferences"
"Feedback Linearizing Controller for a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism","J. C. Cambera; V. Feliu-Batlle","University of Castilla-La Mancha, Instituto de Investigaciones Energéticas y Aplicaciones Industriales (INEI), Ciudad Real, Spain; University of Castilla-La Mancha, Escuela Técnica Superior de Ingenieros Industriales, Ciudad Real, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6404","6410","Despite the benefits that the spring based gravity compensation mechanism has brought to the field of rigid robotic manipulators, there have been no substantial efforts toward transferring these developments to the field of flexible link robotics. In this paper, we present an input state feedback linearization controller for the tip positioning of a flexible link arm with a gravity compensation system based on springs. The controller is implemented into a double loop control scheme, in which the inner loop addresses the motor position control in presence of joint friction, and the outer loop deals with vibration cancellation and the tracking of fourth-order trajectories for the tip position of the flexible arm. Taking into considerations the interacting forces between the flexible link and the gravity compensation mechanism, and also the characteristics of the control law, we propose a sensory system to measure all the relevant signals. The proposed controller is tested on an experimental prototype built in our laboratory.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594409","","Gravity;Springs;Torque;DC motors;Actuators;Manipulators","closed loop systems;compensation;flexible manipulators;friction;linearisation techniques;position control;springs (mechanical);state feedback;vibration control","single link flexible arm;passive gravity compensation mechanism;flexible link robotics;input state feedback linearization controller;gravity compensation system;springs;double loop control scheme;motor position control;flexible link arm tip positioning;joint friction;vibration cancellation","","","18","","","","","IEEE","IEEE Conferences"
"Jet-HR1: Stepping Posture Optimization for Bipedal Robot Over Large Ditch Based on a Ducted-fan Propulsion System*","B. Liu; Z. Huang; J. Wei; C. Shi; J. Ota; Y. Zhang","Guangdong University of Technology, School of Automation, Guangzhou, 510006, P. R. China; Guangdong University of Technology, School of Automation, Guangzhou, 510006, P. R. China; University of Tokyo, Center for Engineering (RACE), Chiba, 277-8568, Japan; Tianjin University, Key Lab for Mechanism Theory and Equipment Design of Ministry of Education, School of Mechanical Engineering, Tianjin, 300072, China; University of Tokyo, Center for Engineering (RACE), Chiba, 277-8568, Japan; Guangdong University of Technology, School of Automation, Guangzhou, 510006, P. R. China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6010","6015","This paper reports the latest progress of an ongoing project utilizing a ducted-fan propulsion system to improve a humanoid robot's ability to step over a broad ditch with a height difference between the two sides. This work focuses on the methods of calculating the boundary and optimizing stepping posture to use less thrust and keep the robot balanced while stepping over the ditch. With the proposed methods and new two-dimensional gaits, the prototype robot, named Jet-HRl (Jet Humanoid Robot ver.l) was able to completely step over a broad ditch with 450mm in width (up to 97% of the robot's leg's length), and a height difference of 100mm between two sides.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594055","","Legged locomotion;Foot;Fans;Propulsion;Gravity;Humanoid robots","aerospace propulsion;ducts;fans;gait analysis;humanoid robots;legged locomotion;optimisation","ducted-fan propulsion system;prototype robot;stepping posture optimization;bipedal robot;two-dimensional gaits;Jet-HRl;jet humanoid robot","","","19","","","","","IEEE","IEEE Conferences"
"Virtual Occupancy Grid Map for Submap-based Pose Graph SLAM and Planning in 3D Environments","B. Ho; P. Sodhi; P. Teixeira; M. Hsiao; T. Kusnur; M. Kaess","Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; MIT, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, 02139, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Department of Electrical & Electronics Engineering, BITS Pilani K. K. Birla Goa Campus, India; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2175","2182","In this paper, we propose a mapping approach that constructs a globally deformable virtual occupancy grid map (VOG-map) based on local submaps. Such a representation allows pose graph SLAM systems to correct globally accumulated drift via loop closures while maintaining free space information for the purpose of path planning. We demonstrate use of such a representation for implementing an underwater SLAM system in which the robot actively plans paths to generate accurate 3D scene reconstructions. We evaluate performance on simulated as well as real-world experiments. Our work furthers capabilities of mobile robots actively mapping and exploring unstructured, three dimensional environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594234","","Simultaneous localization and mapping;Three-dimensional displays;Path planning;Robot kinematics;Casting","graph theory;image reconstruction;mobile robots;path planning;pose estimation;robot vision;SLAM (robots)","3D scene reconstructions;virtual occupancy grid map;mobile robots;VOG-map;submap-based pose graph SLAM;underwater SLAM system;path planning;free space information","","","18","","","","","IEEE","IEEE Conferences"
"A Framework for Teaching Impedance Behaviours by Combining Human and Robot ‘Best Practice’","Y. Zhao; A. Sena; F. Wu; M. J. Howard","Department of Informatics, King's College, London, Center for Robotics Research, London, UK; Department of Informatics, King's College, London, Center for Robotics Research, London, UK; Department of Informatics, King's College, London, Center for Robotics Research, London, UK; Department of Informatics, King's College, London, Center for Robotics Research, London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3010","3015","This paper presents a programming by demonstration framework for teaching impedance modulation using human demonstrations. Physiologically, human stiffness and damping are coupled at the muscle level, restricting the ability to modulate impedance according to task demands. Robotic systems often do not have this restriction (stiffness and damping can be varied independently), but the challenge is to devise an appropriate variable impedance profile for a given task. In this paper, the task critical component is first learned for imitation and a robot-specific controller is then blended into the control using the null space. In doing so, the control cheme takes advantage of both human and robot `best practice'. Experimental results on a physical robot suggest an order of magnitude better mean performance, with lower variance, can be achieved using the blended scheme.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593502","","Impedance;Task analysis;Damping;Modulation;Robot kinematics;Covariance matrices","control engineering education;educational robots;learning (artificial intelligence);manipulators;mobile robots;motion control;muscle;robot dynamics;robot programming","human robot best practice;physical robot;teaching impedance;impedance modulation;human demonstrations;human stiffness;damping;muscle level;task demands;robotic systems;task critical component;robot-specific controller;variable impedance profile","","","22","","","","","IEEE","IEEE Conferences"
"Feasibility of the UR5 Industrial Robot for Robotic Rehabilitation of the Upper Limbs After Stroke","E. Kyrkjebø; M. Johan Laastad; Ø. Stavdahl","Norwegian Research Council, 280771; Department of Engineering Cybernetics, Norwegian University of Science and Technology; Department of Engineering Cybernetics, Norwegian University of Science and Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","Robot-assisted therapy is an emerging form of rehabilitation treatment for motor recovery of the upper limbs after neurological injuries such as stroke or spinal cord injury. Robotic rehabilitation devices have the potential to reduce the physical strain put on therapists due to the high-effort one-to-one interactions between the therapist and patient involving repetitive high-intensity movements to restore arm and hand functions. Numerous custom robotic devices have been developed in recent years to aid in physical rehabilitation of stroke patients, but most commercially available systems are high-cost devices because of low production volumes and high development costs. In this paper, we analyse the safety and functionality of the UR5 collaborative industrial robot from universal Robots equipped with an external force/torque sensor in a real-time control system for typical rehabilitation exercises. The aim of the paper is to show that a new class of general-purpose industrial robots designed for human-robot collaboration may prove a viable alternative to custom designs. Experiments show that robotic rehabilitation of the upper limbs using a standard industrial robot manipulator UR5 may be feasible. Results have the potential to make robotic rehabilitation more available as a high-quality therapeutic treatment for more patients.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594413","","Service robots;Robot sensing systems;Training;Task analysis;Safety;Collision avoidance","human-robot interaction;industrial robots;injuries;medical robotics;motion control;neurophysiology;patient rehabilitation;patient treatment","human-robot collaboration;upper limbs;robot-assisted therapy;rehabilitation treatment;robotic rehabilitation devices;high-effort one-to-one interactions;physical rehabilitation;stroke patients;UR5 collaborative industrial robot;therapeutic treatment;rehabilitation exercises;high-intensity movements;neurological injuries","","","27","","","","","IEEE","IEEE Conferences"
"Development and Evaluation of an Intuitive Flexible Interface for Teleoperating Soft Growing Robots","H. El-Hussieny; U. Mehmood; Z. Mehdi; S. Jeong; M. Usman; E. W. Hawkes; A. M. Okarnura; J. Ryu","Korea University of Technology and Education, School of Mechanical Engineering, Cheonan-si, Republic of Korea; Korea University of Technology and Education, School of Mechanical Engineering, Cheonan-si, Republic of Korea; Korea University of Technology and Education, School of Mechanical Engineering, Cheonan-si, Republic of Korea; Korea University of Technology and Education, School of Mechanical Engineering, Cheonan-si, Republic of Korea; Korea University of Technology and Education, School of Mechanical Engineering, Cheonan-si, Republic of Korea; Department of Mechanical Engineering, University of California, Santa Barbara, CA, 93106, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, 94305, USA; Korea University of Technology and Education, School of Mechanical Engineering, Cheonan-si, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4995","5002","Mobility by growth is a new paradigm in robotic systems design and their applications in the real world. Soft, tip-extending, or “growing”, robots have potential applications including inspection and navigation in disaster scenarios. However, due to their growing capability, such robots create unique challenges for intuitive human control. In this paper, a new flexible interface is proposed to intuitively map human bending commands into movements of the growing robot while providing shape information of the robot in order to improve situational awareness. Several command mappings are proposed, and a subjective study was conducted to assess the intuitiveness of the developed interface and mappings compared with other commercially available interfaces. The interfaces were evaluated using four metrics in two virtual task scenarios. The proposed interface with shape mapping performed better than the other interfaces, especially when the vine robot rolls over unintentionally during complex tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593896","","Shape;Robot sensing systems;Robot kinematics;Three-dimensional displays;Kinematics;Current measurement","bending;mobile robots;path planning;service robots;telerobotics;user interfaces","intuitive flexible interface;teleoperating soft growing robots;robotic systems design;tip-extending;navigation;disaster scenarios;intuitive human control;intuitively map human bending;shape information;command mappings;developed interface;commercially available interfaces;virtual task scenarios;shape mapping;vine robot rolls","","","33","","","","","IEEE","IEEE Conferences"
"Vessel Pose Estimation for Obstacle Avoidance in Needle Steering Surgery Using Multiple Forward Looking Sensors","V. Virdyawan; F. R. Y Baena","Mechanical Engineering Department, Mechatronics in Medicine Laboratory, Imperial College London, London, UK; Mechanical Engineering Department, Mechatronics in Medicine Laboratory, Imperial College London, London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3845","3852","During percutaneous interventions in the brain, puncturing a vessel can cause life threatening complications. To avoid such a risk, current research has been directed towards the development of steerable needles. However, there is a risk that vessels of a size which is close to or smaller than the resolution of commonly used preoperative imaging modalities (0.59 × 0.59 × 1 mm) would not be detected during procedure planning, with a consequent increase in risk to the patient. In this work, we present a novel ensemble of forward looking sensors based on laser Doppler flowmetry, which are embedded within a biologically inspired steerable needle to enable vessel detection during the insertion process. Four Doppler signals are used to classify the pose of a vessel in front of the advancing needle with a high degree of accuracy (2° and 0.1 mm RMS errors), where relative measurements between sensors are used to correct for ambiguity. By using a robotic assisted needle insertion process, and thus a precisely controlled insertion speed, we also demonstrate how the setup can be used to discriminate between tissue bulk motion and vessel motion. In doing so, we describe a sensing apparatus applicable to a variety of needle steering systems, with the potential to eliminate the risk of hemorrhage during percutaneous procedures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594198","","Needles;Probes;Phantoms;Sensors;Doppler effect;Gold;Grey matter","biomedical optical imaging;blood vessels;brain;collision avoidance;Doppler measurement;image motion analysis;laser applications in medicine;medical image processing;medical robotics;needles;pose estimation;steering systems;surgery","percutaneous procedures;hemorrhage;vessel motion;tissue bulk motion;Doppler signals;multiple forward looking sensors;preoperative imaging modalities;vessel pose estimation;needle steering systems;robotic assisted needle insertion process;vessel detection;biologically inspired steerable needle;laser Doppler flowmetry;life threatening complications;percutaneous interventions;needle steering surgery;obstacle avoidance","","","39","","","","","IEEE","IEEE Conferences"
"Comparison of Dynamic Models for Non-Contact Micromanipulation Based on Dielectrophoretic Actuation","V. Gauthier; A. Bolopion; M. Gauthier","AS2M department CNRS, FEMTO-ST Institute Univ Bour-gogne Franche-Cornté, 24 rue Alain Savary, Besancon, 25000, France; AS2M department CNRS, FEMTO-ST Institute Univ Bour-gogne Franche-Cornté, 24 rue Alain Savary, Besancon, 25000, France; AS2M department CNRS, FEMTO-ST Institute Univ Bour-gogne Franche-Cornté, 24 rue Alain Savary, Besancon, 25000, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4869","4874","Several approaches are proposed in the literature to calculate the drag force, the electric field and the induced dielectrophoretic force. This paper analyzes the performances of various models for closed loop control of dielectrophoretic systems in comparison with experiments. This article compares their performance in terms of accuracy, computation time, and memory consumption. Four classical approaches are available to calculate the electric field. Their performances are analyzed in the paper. We have shown that combining the dipolar model of dielectrophoresis force with an anisotropic drag force (integrating the wall-effect) provides an interesting ratio precision/computation time. This paper provides an original comparison of several models described in literature whose performances have been compared with experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594377","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594377","","Force;Drag;Computational modeling;Dielectrophoresis;Electrodes;Trajectory;Mathematical model","closed loop systems;drag;electrophoresis;microfluidics;micromanipulators;physics computing","wall-effect;dielectrophoretic systems;closed loop control;induced dielectrophoretic force;dielectrophoretic actuation;noncontact micromanipulation;anisotropic drag force;dielectrophoresis force;dipolar model","","","17","","","","","IEEE","IEEE Conferences"
"Probabilistic Collision Threat Assessment for Autonomous Driving at Road Intersections Inclusive of Vehicles in Violation of Traffic Rules","S. Noh","Electronics and Telecommunications Research Institute(ETRI), Daejeon, 34129, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4499","4506","In this paper, we propose a probabilistic collision threat assessment algorithm for autonomous driving at road intersections that assesses a given traffic situation at an intersection reliably and robustly for an autonomous vehicle to cross the intersection safely, even in the face of violation vehicles (that is, vehicles in violation of traffic rules at the intersection). To this end, the proposed algorithm employs a detailed digital map to predict future paths of observed vehicles and then utilizes the predicted future paths to identify potential threats (vehicles) and potential collision areas, regardless of whether observed vehicles are obeying traffic rules at the intersection. Next, by means of Bayesian networks and time window filtering under an independent and distributed reasoning structure, it assesses the potential threats regarding the possibility of collision reliably and robustly, even under uncertain and incomplete noise data. Then, it has been tested and evaluated through in-vehicle testing on a closed urban test road under traffic conditions inclusive of non-violation and violation vehicles. In-vehicle testing results show that the performance of the proposed algorithm is sufficiently reliable to be used in decision-making for autonomous driving at intersections in terms of reliability and robustness, even in the face of violation vehicles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593645","","Roads;Reliability;Principal component analysis;Probabilistic logic;Prediction algorithms;Autonomous vehicles","belief networks;collision avoidance;decision making;mobile robots;probability;road safety;road traffic;road vehicles","traffic rules violation;vehicles road intersections inclusive;Bayesian networks;time window filtering;decision-making;in-vehicle testing;nonviolation vehicles;closed urban test road;violation vehicles;autonomous vehicle;probabilistic collision threat assessment algorithm;autonomous driving","","","32","","","","","IEEE","IEEE Conferences"
"Unmanned Aerial Auger for Underground Sensor Installation","Y. Sun; A. Plowcha; M. Nail; S. Elbaum; B. Terry; C. Detweiler","Department of Mechanical Engineering, University of Nebraska-Lincoln, Lincoln, NE, 68588, USA; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE, 68588, USA; Department of Mechanical Engineering, University of Nebraska-Lincoln, Lincoln, NE, 68588, USA; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE, 68588, USA; Department of Mechanical Engineering, University of Nebraska-Lincoln, Lincoln, NE, 68588, USA; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE, 68588, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1374","1381","Using an Unmanned Aerial Systems (UAS) to autonomously deploy soil sensors enables their installation in otherwise hard to access locations. In this paper, we present a system that integrates a UAS and a digging mechanism which can carry, secure, and install a small sensor into dirt effectively and efficiently. The integrated system includes 1) a low profile, light-weight, inexpensive auger mechanism, 2) a sensor carrying and deploying mechanism with low power consumption, and 3) sensors and software that control and evaluate the auger performance during digging. When tested on a suite of target soils and a target depth of 120mm, the system achieved a success rate of 100% for indoor tests and 92.5% for outdoors, verifying the potential of the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593824","","Force;Robot sensing systems;Substrates;Fasteners;Monitoring;Soil moisture","Auger effect;autonomous aerial vehicles;geophysical equipment;geophysical techniques;sensors;soil;underground equipment","digging mechanism;power consumption;unmanned aerial systems;target soil sensors;unmanned aerial auger performance;UAS;underground sensor installation;depth 120.0 mm","","","22","","","","","IEEE","IEEE Conferences"
"Self-Assembly of a Class of Infinitesimally Shape-Similar Frameworks","I. Buckley; M. Egerstedt","Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, Atlanta, GA, 30332, USA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, Atlanta, GA, 30332, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3751","3756","Formation control strategies are fundamentally impacted by the sensing modalities present in the multi-robot team. Infinitesimal shape-similarity describes frameworks for which maintaining the relative angles between robots in formation also maintains the shape up to translation, rotation, and uniform scaling; however, ensuring invariance of the formation to these motions requires that the robots measure a sufficient number of angles, which means that the topology of the frame-work must be carefully designed. In this paper, we investigate the self-assembly of a class of infinitesimally shape-similar frameworks by robots equipped with bearing-only sensors. To accomplish self-assembly, we introduce a rank condition on the shape-similarity matrix for analyzing frameworks; we then use this rank condition to show that triangulations are infinitesimally shape-similar. A graph grammar is presented to assemble triangulations, and a controller is designed to achieve self-assembly of a team of differential-drive robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594381","Multi-Robot Systems","Robot sensing systems;Transmission line matrix methods;Self-assembly;Shape;Trajectory","mobile robots;multi-robot systems;self-assembly","robots measure;frame-work;infinitesimally shape-similar frameworks;shape-similarity matrix;differential-drive robots;formation control strategies;multirobot team;infinitesimal shape-similarity","","","15","","","","","IEEE","IEEE Conferences"
"Towards Autonomous Stratospheric Flight: A Generic Global System Identification Framework for Fixed-Wing Platforms","J. Lee; T. Muskardin; C. R. Pacz; P. Oettershagen; T. Stastny; I. Sa; R. Siegwart; K. Kondak","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, 82234, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, 82234, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, 82234, Germany; Swiss Federal Institute of Technology Zurich (ETH Zurich), Autonomous Systems Lab, Zurich, Leonhardstrasse 21, 8092, Switzerland; Swiss Federal Institute of Technology Zurich (ETH Zurich), Autonomous Systems Lab, Zurich, Leonhardstrasse 21, 8092, Switzerland; Swiss Federal Institute of Technology Zurich (ETH Zurich), Autonomous Systems Lab, Zurich, Leonhardstrasse 21, 8092, Switzerland; Swiss Federal Institute of Technology Zurich (ETH Zurich), Autonomous Systems Lab, Zurich, Leonhardstrasse 21, 8092, Switzerland; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, 82234, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6233","6240","System identification of High Altitude Long Endurance fixed-wing aerial vehicles is challenging as its operating flight envelope covers wide ranges of altitudes and Mach numbers. We present a new global system identification framework geared towards such fixed-wing aerial platforms where the aim is to build a global aerodynamic model without many repetitions of local system identification procedures or the use of any aerodynamic database. Instead we apply parameter identification techniques to virtually created system identification data and update the identified parameters with available flight test data. The proposed framework was evaluated using data set outside the flight envelope of the available flight test data, i.e. at different airspeeds considering both interpolation and extrapolation scenarios. The error analysis has shown that the obtained longitudinal aerodynamic model can accurately predict the pitch rate and pitch angle, mostly within a tolerance of +1.5 degrees/s and +2 degrees respectively. Such a cost and time efficient model development framework enables high fidelity simulation and precise control which ultimately leads to higher success rates in autonomous missions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594126","","Aerodynamics;Atmospheric modeling;Aircraft;Mathematical model;Databases;Data models;Unmanned aerial vehicles","aerodynamics;aerospace components;aircraft control;aircraft testing;autonomous aerial vehicles;error analysis;interpolation;Mach number;parameter estimation","Mach numbers;parameter identification techniques;fixed-wing platforms;flight test data;aerodynamic model;autonomous stratospheric flight;generic global system identification;high altitude long endurance fixed-wing aerial vehicles;extrapolation analysis;error analysis;autonomous missions;time efficient model","","","17","","","","","IEEE","IEEE Conferences"
"Real-Time Workload Classification during Driving using HyperNetworks","R. Wang; P. V. Amadori; Y. Demiris","Department of Electrical and Electronic Engineering, Imperial College London, Personal Robotics Lab, UK; Department of Electrical and Electronic Engineering, Imperial College London, Personal Robotics Lab, UK; Department of Electrical and Electronic Engineering, Imperial College London, Personal Robotics Lab, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3060","3065","Classifying human cognitive states from behavioral and physiological signals is a challenging problem with important applications in robotics. The problem is challenging due to the data variability among individual users, and sensor artefacts. In this work, we propose an end-to-end framework for real-time cognitive workload classification with mixture Hyper Long Short Term Memory Networks (m-HyperLSTM), a novel variant of HyperNetworks. Evaluating the proposed approach on an eye-gaze pattern dataset collected from simulated driving scenarios of different cognitive demands, we show that the proposed framework outperforms previous baseline methods and achieves 83.9% precision and 87.8% recall during test. We also demonstrate the merit of our proposed architecture by showing improved performance over other LSTM-based methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594305","","Adaptation models;Data models;Physiology;Task analysis;Real-time systems;Robot sensing systems","cognition;medical signal processing;pattern classification;recurrent neural nets;signal classification;traffic engineering computing","m-HyperLSTM;mixture hyper long short term memory networks;cognitive demands;data variability;robotics;physiological signals;behavioral signals;human cognitive states;eye-gaze pattern dataset;HyperNetworks;real-time cognitive workload classification;sensor artefacts","","","28","","","","","IEEE","IEEE Conferences"
"Extracting the Relationship between the Spatial Distribution and Types of Bird Vocalizations Using Robot Audition System HARK","S. Sumitani; R. Suzuki; S. Matsubayashi; T. Arita; K. Nakadai; H. G. Okuno","Graduate School of Informatics, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, 464-8601, Japan; Graduate School of Informatics, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, 464-8601, Japan; Center for Open Innovation Research and Education Graduate School of Engineering, Osaka University, 201 Yamadaoka, Suita, Osaka, 565-0871, Japan; Graduate School of Informatics, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, 464-8601, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, 2-12-1 Ookayama Meguro-ku, Tokyo, 152-8552, Japan; Graduate School of Fundamental Science and Engineering, Waseda University, 2-4-12 Okubo, Shinjuku, Tokyo, 169-0072, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2485","2490","For a deeper understanding of ecological functions and semantics of wild bird vocalizations (i.e., songs and calls), it is important to clarify the fine-scaled and detailed relationships among their characteristics of vocalizations and their behavioral contexts. However, it takes a lot of time and effort to obtain such data using conventional recordings or by human observation. Bringing out a robot to a field is our approach to solve this problem. We are developing a portable observation system called HARKBird using a robot audition HARK and microphone arrays to understand temporal patterns of vocalizations characteristics and their behavioral contexts. In this paper, we introduce a prototype system to 2D localize vocalizations of wild birds in real-time, and to classify their song types after recording. We show that the system can estimate the position of songs of a target individual and classify their songs with a reasonable quality to discuss their song - behavior relationships.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594130","","Birds;Microphone arrays;Two dimensional displays;Robots;Real-time systems;Arrays","acoustic signal processing;biocommunications;microphone arrays;robots;zoology","HARK robot audition system;song-behavior relationships;HARKBird;wild birds;2D localize vocalizations;vocalizations characteristics;microphone arrays;portable observation system;wild bird vocalizations;ecological functions;spatial distribution","","1","17","","","","","IEEE","IEEE Conferences"
"Recruitment Near Worksites Facilitates Robustness of Foraging E-Puck Swarms to Global Positioning Noise","L. Pitonakova; A. Winfield; R. Crowder","Dep. of Electronics and Computer Science, Univ. of Southampton, UK; Univ. of the West of England, Bristol Robotics Laboratory, Bristol, UK; Dep. of Electronics and Computer Science, Univ. of Southampton, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4276","4281","We compare the ability of two different robot controllers for collective foraging to cope with noise in robot global positioning data and show how recruitment, in the form of broadcast messages near worksites, can make swarms more robust. Swarms of five e-puck robots are used in a semi-virtual environment, facilitated by the VICON positioning system. This setup allows us to control the amount of noise in the robot positioning data and to generate pseudo-random environments, while retaining important physical aspects of the experiment. The effect of inherent noise in the robot infra-red sensors, used for obstacle avoidance, is noted and the importance of modelling such noise in agent-based simulations is highlighted.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593788","","Robot kinematics;Robot sensing systems;Servers;Task analysis;Recruitment","collision avoidance;mobile robots;position control","worksites facilitates robustness;foraging e-puck swarms;global positioning noise;collective foraging;robot global positioning data;broadcast messages;e-puck robots;semivirtual environment;VICON positioning system;robot positioning data;pseudorandom environments;important physical aspects;inherent noise;robot infra-red sensors;robot controllers","","","17","","","","","IEEE","IEEE Conferences"
"A Multi-Task Priority Framework for Redundant Robots with Multiple Kinematic Chains under Hard Joint and Cartesian Constraints","A. Peñalver; J. J. Fernández; A. Soriano; P. J. Sanz","Departament d'Enginyeria i Ciència dels Computadors, Universitat Jaume I, Interactive and Robotic Systems Laboratory (IRSLab), Av. de Vicent Sos Baynat, s/n, Castelló de la Plana, 12071, Spain; Departament d'Enginyeria i Ciència dels Computadors, Universitat Jaume I, Interactive and Robotic Systems Laboratory (IRSLab), Av. de Vicent Sos Baynat, s/n, Castelló de la Plana, 12071, Spain; Departament d'Enginyeria i Ciència dels Computadors, Universitat Jaume I, Interactive and Robotic Systems Laboratory (IRSLab), Av. de Vicent Sos Baynat, s/n, Castelló de la Plana, 12071, Spain; Departament d'Enginyeria i Ciència dels Computadors, Universitat Jaume I, Interactive and Robotic Systems Laboratory (IRSLab), Av. de Vicent Sos Baynat, s/n, Castelló de la Plana, 12071, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2410","2417","This paper introduces an extension of the reverse priority framework for the kinematic control of redundant robots. It integrates, in a unified framework, the treatment of multiple tasks, multiple kinematic chains, different joint priorities and hard constraints. The management of multiple tasks is based on the reverse priority method, that has been modified so that it makes possible the assignment of different priorities to each joint in order to accomplish the tasks. This framework is also suitable for robotic systems with multiple kinematic chains, which could share several joints. Moreover, it can deal with bilateral and unilateral constraints, that can be defined either at joint or cartesian space. Hard constraints are considered at each priority level, instead of treating them separately at the highest priority level. The proposed framework has been evaluated in simulation and in real experiments with a redundant underwater vehicle-manipulator system at sea.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593967","","Task analysis;Kinematics;Jacobian matrices;Redundancy;End effectors","redundant manipulators","multiple kinematic chains;hard joint;reverse priority framework;kinematic control;redundant robots;reverse priority method;robotic systems;bilateral constraints;unilateral constraints;multitask priority framework;joint priorities;Cartesian constraints","","","17","","","","","IEEE","IEEE Conferences"
"FarSight: Long-Range Depth Estimation from Outdoor Images","M. A. Reza; J. Kosecka; P. David","Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Computer Science, George Mason University, Fairfax, VA, USA; U.S. Army Research Laboratory, Adelphi, MD, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4751","4757","This paper introduces the problem of long-range monocular depth estimation for outdoor urban environments. Range sensors and traditional depth estimation algorithms (both stereo and single view) predict depth for distances of less than 100 meters in outdoor settings and 10 meters in indoor settings. The shortcomings of outdoor single view methods that use learning approaches are, to some extent, due to the lack of long-range ground truth training data, which in turn is due to limitations of range sensors. To circumvent this, we first propose a novel strategy for generating synthetic long-range ground truth depth data. We utilize Google Earth images to reconstruct large-scale 3D models of different cities with proper scale. The acquired repository of 3D models and associated RGB views along with their long-range depth renderings are used as training data for depth prediction. We then train two deep neural network models for long-range depth estimation: i) a Convolutional Neural Network (CNN) and ii) a Generative Adversarial Network (GAN). We found in our experiments that the GAN model predicts depth more accurately. We plan to open-source the database and the baseline models for public use.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593971","","Three-dimensional displays;Solid modeling;Estimation;Image reconstruction;Urban areas;Google;Meters","convolutional neural nets;image reconstruction;image sensors;rendering (computer graphics);stereo image processing;unsupervised learning","long-range depth estimation;outdoor images;long-range monocular depth estimation;outdoor urban environments;range sensors;outdoor settings;outdoor single view methods;synthetic long-range ground truth depth data;long-range depth renderings;depth prediction;depth estimation algorithms;Generative Adversarial Network;GAN;size 10.0 m","","","25","","","","","IEEE","IEEE Conferences"
"Multi-Layer Coverage Path Planner for Autonomous Structural Inspection of High-Rise Structures","S. Jung; S. Song; P. Youn; H. Myung","Korea Advanced Institute of Science and Technology, Urban Robotics Laboratory, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Urban Robotics Laboratory, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Urban Robotics Laboratory, Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology, Urban Robotics Laboratory, Daejeon, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, a novel 3D coverage path planning method, which is efficient and practical for inspection of high-rise structures such as buildings or towers, using an unmanned aerial vehicle (UAV) is presented. Our approach basically focuses on developing a model-based path planner for structural inspection with a prior map, which is opposite to a non-model based exploration. The proposed method uses a volumetric map which is made before the path planning. With the map, the whole structure is divided into several layers for efficient path planning. Firstly, in each layer, a set of the normal vectors of the center point of every voxel is calculated, and then the opposing vectors become viewpoints. Due to too many viewpoints and an overlapped inspection surface, we down-sample them with a voxel grid filter. Then, the shortest tour connecting the reduced viewpoints must be computed with the Traveling Salesman Problem (TSP) solver. Lastly, all the paths in each layer are combined to form the complete path. The results are verified using simulations with a rotary wing UAV and compared with other state-of-the-art algorithm. It is proven that our method performs much better for structural inspection with respect to computation time as well as the coverage completeness.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593537","","Inspection;Three-dimensional displays;Path planning;Planning;Unmanned aerial vehicles;Solid modeling;Spirals","autonomous aerial vehicles;inspection;path planning;structural engineering;travelling salesman problems","autonomous structural inspection;high-rise structures;buildings;towers;unmanned aerial vehicle;multi-layer coverage path planner;3D coverage path planning;traveling salesman problem","","","23","","","","","IEEE","IEEE Conferences"
"Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control","J. Di Carlo; P. M. Wensing; B. Katz; G. Bledt; S. Kim","Department of Electrical Engineering and Computer Science at the Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Department of Aerospace and Mechanical Engineering at the University of Notre Dame, Notre Dame, IN, 46556; Department of Mechanical Engineering at the Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Department of Electrical Engineering and Computer Science at the Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Department of Mechanical Engineering at the Massachusetts Institute of Technology, Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594448","","Robot kinematics;Legged locomotion;Dynamics;Predictive control;Convex functions;Predictive models","convex programming;legged locomotion;predictive control;robot dynamics;torque control","torque-controlled quadruped robot;convex model-predictive control;MIT cheetah 3;dynamic locomotion;ground reaction force planning problems;convex optimization;robot dynamics","","2","31","","","","","IEEE","IEEE Conferences"
"Preference-Based Assistance Prediction for Human-Robot Collaboration Tasks","E. C. Grigore; A. Roncone; O. Mangin; B. Scassellati","Computer Science Department, Social Robotics Lab, Yale University, New Haven, CT, 06511, USA; Computer Science Department, Social Robotics Lab, Yale University, New Haven, CT, 06511, USA; Computer Science Department, Social Robotics Lab, Yale University, New Haven, CT, 06511, USA; Computer Science Department, Social Robotics Lab, Yale University, New Haven, CT, 06511, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4441","4448","Human-Robot Collaboration (HRC) aims to develop robots that provide assistance to human workers while performing physical tasks. Such assistance comes in the form of supportive behaviors that are different from the actions part of the task, and that are meant to help a human worker more effectively accomplish the task. Learning how to provide useful behaviors that are tailored to a human peer represents a difficult challenge. This is due to the need of large amounts of training data in the form of real world observations that include information about such preferences. This data needs to encode not only the structure and progression of the task, but also the different workers' preferences with respect to when and what assistance the robot should provide. Our work separates the challenge of learning a model of the task (which requires a large amount of training data) from that of learning supportive behavior preferences for the interaction (which has obvious restrictions for the number of user-provided demonstrations to which we have access). We first learn a hidden Markov model (HMM) from a training set consisting of observed human workers performing the considered task in simulation. We then use this model to predict, while observing the human peer, what supportive behaviors a robot should offer throughout the task. Building upon the hidden state representation, our system is able to learn the supportive behaviors based on as few as five user-annotated demonstrations, learning a personalized supportive behavior model. We evaluate our system on a user study with 14 participants, and show results on par with human-level prediction for the task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593716","","Task analysis;Hidden Markov models;Service robots;Collaboration;Legged locomotion;Data models","control engineering computing;hidden Markov models;human-robot interaction;learning (artificial intelligence)","human-robot collaboration tasks;learning supportive behavior preferences;human-level prediction;personalized supportive behavior model;observed human workers;hidden Markov model;training data;human peer;physical tasks;human worker;robots;preference-based assistance prediction","","","26","","","","","IEEE","IEEE Conferences"
"UNDERWORLDS: Cascading Situation Assessment for Robots","S. Lemaignan; Y. Sallami; C. Wallhridge; A. Clodic; T. Belpaeme; R. Alami","University of the West of England, Bristol Robotics Lab, Bristol, United Kingdom; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, France; Plymouth University, CRNS, Plymouth, United Kingdom; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, France; Plymouth University, CRNS, Plymouth, United Kingdom; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7750","7757","We introduce UNDERWORLDS, a novel lightweight framework for cascading spatio-temporal situation assessment in robotics. UNDERWORLDS allows programmers to represent the robot's environment as real-time distributed data structures, containing both scene graphs (for representation of 3D geometries) and timelines (for representation of temporal events). UNDERWORLDS supports cascading representations: the environment is viewed as a set of worlds that can each have different spatial and temporal granularities, and may inherit from each other. UNDERWORLDS also provides a set of high-level client libraries and tools to introspect and manipulate the environment models. This article presents the design and architecture of this open-source tool, and explores some applications, along with examples of use.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594094","","Robots;Three-dimensional displays;Solid modeling;Computer architecture;Tools;Software;Task analysis","manipulators;mobile robots","spatio-temporal situation assessment;novel lightweight framework;cascading situation assessment;temporal granularities;cascading representations;temporal events;real-time distributed data structures;UNDERWORLDS","","","30","","","","","IEEE","IEEE Conferences"
"Learning to Touch Objects Through Stage-Wise Deep Reinforcement Learning","F. de La Bourdonnaye; C. Teulière; J. Triesch; T. Chateau","Pascal Institute CNRS, university of Clermont Auvergne, Aubière, UMR6602, France; Pascal Institute CNRS, university of Clermont Auvergne, Aubière, UMR6602, France; Frankfurt Institute for Advanced Studies, Frankfurt am Main, Germany; Pascal Institute CNRS, university of Clermont Auvergne, Aubière, UMR6602, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Learning complex behaviors through reinforcement learning is particularly challenging when reward is only available upon successful completion of the full behavior. In manipulation robotics, so-called shaping rewards are often used to overcome this problem. However, these usually require human engineering or (partial)world models describing, e.g., the kinematics of the robot or high-level modules for perception. Here we propose an alternative method to learn an object palm-touching task through a weakly-supervised and stagewise learning of simpler tasks. First, the robot learns to fixate the object with its cameras. Second, the robot learns eye-hand coordination by learning to fixate its end effector. Third, using the previously acquired skills an informative shaping reward can be computed which facilitates efficient learning of the object palm-touching task. We demonstrate in simulation that learning the full task with this shaping reward is comparable to learning with an informative supervised reward.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593362","","Task analysis;Robot kinematics;End effectors;Cameras;Robot vision systems;Kinematics","end effectors;learning (artificial intelligence)","stage-wise deep reinforcement learning;complex behaviors;manipulation robotics;high-level modules;object palm-touching task;weakly-supervised learning;informative shaping reward;informative supervised reward;efficient learning","","","29","","","","","IEEE","IEEE Conferences"
"UAV/UGV Search and Capture of Goal-Oriented Uncertain Targets*This research was supported in part by ISF grant #1337/15 and part by a grant from MOST, Israel and the JST Japan","M. Sinay; N. Agmon; O. Maksimov; G. Levy; M. Bitan; S. Kraus","NA; NA; NA; NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8505","8512","This paper considers a new, complex problem of UAV/UGV collaborative efforts to search and capture attackers under uncertainty. The goal of the defenders (UAV/UGV team) is to stop all attackers as quickly as possible, before they arrive at their selected goal. The uncertainty considered is twofold: the defenders do not know the attackers' location and destination, and there is also uncertainty in the defenders' sensing. We suggest a real-time algorithmic framework for the defenders, combining entropy and stochastic-temporal belief, that aims at optimizing the probability of a quick and successful capture of all of the attackers. We have empirically evaluated the algorithmic framework, and have shown its efficiency and significant performance improvement compared to other solutions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594273","","Games;Uncertainty;Search problems;Real-time systems;Task analysis;Mathematical model;Roads","autonomous aerial vehicles;mobile robots;multi-robot systems;optimisation;probability;remotely operated vehicles","UAV/UGV collaborative efforts;stochastic-temporal belief;attacker capture;defender real-time algorithmic framework;probability optimization;goal-oriented uncertain targets;UAV/UGV search","","","39","","","","","IEEE","IEEE Conferences"
"Localization of Classified Objects in SLAM using Nonparametric Statistics and Clustering","A. Iqbal; N. R. Gans","Electrical and Computer Engineering, The University of Texas at Dallas, 800 W Campbell Rd, Richardson, TX, 75080, USA; Electrical and Computer Engineering, The University of Texas at Dallas, 800 W Campbell Rd, Richardson, TX, 75080, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","161","168","Traditional Simultaneous Localization and Mapping (SLAM) approaches build maps based on points, lines or planes. These maps visually resemble the environment but without any semantic or information about the objects in the environment. Recent advancements in machine learning have made object detection highly accurate and reliable with large set of objects. Object detection can effectively help SLAM to incorporate semantics in the mapping process. One of the main obstacles is data association between detected objects over time. We demonstrate a nonparametric statistical approach to solve the data association between detected objects over consecutive frames. Then we use an unsupervised clustering method to identify the existence of objects in the map. The complete process can be run in parallel with SLAM. The performance of our algorithm is demonstrated on several public datasets, which shows promising results in locating objects in SLAM.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593541","","Simultaneous localization and mapping;Semantics;Object detection;Cameras;Three-dimensional displays","feature extraction;learning (artificial intelligence);mobile robots;nonparametric statistics;object detection;pattern clustering;robot vision;SLAM (robots);statistical analysis","nonparametric statistical approach;data association;mapping process;object detection;machine learning;semantic information;nonparametric statistics;classified objects;locating objects;SLAM;unsupervised clustering method;detected objects","","","34","","","","","IEEE","IEEE Conferences"
"Teaching Robots to Predict Human Motion","L. Gui; K. Zhang; Y. Wang; X. Liang; J. M. F. Moura; M. Veloso","Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","562","567","Teaching a robot to predict and mimic how a human moves or acts in the near future by observing a series of historical human movements is a crucial first step in human-robot interaction and collaboration. In this paper, we instrument a robot with such a prediction ability by leveraging recent deep learning and computer vision techniques. First, our system takes images from the robot camera as input to produce the corresponding human skeleton based on real-time human pose estimation obtained with the OpenPose library. Then, conditioning on this historical sequence, the robot forecasts plausible motion through a motion predictor, generating a corresponding demonstration. Because of a lack of high-level fidelity validation, existing forecasting algorithms suffer from error accumulation and inaccurate prediction. Inspired by generative adversarial networks (GANs), we introduce a global discriminator that examines whether the predicted sequence is smooth and realistic. Our resulting motion GAN model achieves superior prediction performance to state-of-the-art approaches when evaluated on the standard H3.6M dataset. Based on this motion GAN model, the robot demonstrates its ability to replay the predicted motion in a human-like manner when interacting with a person.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594452","","Robots;Gallium nitride;Generative adversarial networks;Predictive models;Cameras;Skeleton;Decoding","human-robot interaction;image motion analysis;learning (artificial intelligence);pose estimation;robot vision","deep learning;superior prediction performance;human moves;human motion;teaching robots;motion GAN model;predicted sequence;generative adversarial networks;forecasting algorithms;high-level fidelity validation;motion predictor;historical sequence;OpenPose library;robot camera;computer vision techniques;prediction ability;human-robot interaction;historical human movements","","","37","","","","","IEEE","IEEE Conferences"
"Active Object Perceiver: Recognition-Guided Policy Learning for Object Searching on Mobile Robots","X. Ye; Z. Lin; H. Li; S. Zheng; Y. Yang","Arizona State University, Active Perception Group at the School of ComputingInformatics, and Decision Systems Engineering, Tempe, AZ, USA; Adobe Systems, Inc. San Jose, CA, USA; Aibee; Arizona State University, Active Perception Group at the School of ComputingInformatics, and Decision Systems Engineering, Tempe, AZ, USA; Arizona State University, Active Perception Group at the School of ComputingInformatics, and Decision Systems Engineering, Tempe, AZ, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6857","6863","We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs. While scene-driven visual navigation has been widely studied, prior efforts on learning navigation policies for robots to find objects are limited. The problem is often more challenging than target scene finding as the target objects can be very small in the view and can be in an arbitrary pose. We approach the problem from an active perceiver perspective, and propose a novel framework that integrates a deep neural network based object recognition module and a deep reinforcement learning based action prediction mechanism. To validate our method, we conduct experiments on both a simulation dataset (AI2-THOR)and a real-world environment with a physical robot. We further propose a new decaying reward function to learn the control policy specific to the object searching task. Experimental results validate the efficacy of our method, which outperforms competing methods in both average trajectory length and success rate.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593720","","Robots;Task analysis;Object recognition;Navigation;Search problems;Visualization;Neural networks","indoor navigation;learning (artificial intelligence);mobile robots;neural nets;object recognition;robot vision","AI2-THOR dataset;action prediction mechanism;deep reinforcement learning;visual navigation;indoor environment;mobile robots;recognition-guided policy learning;active object perceiver;object searching task;physical robot;object recognition module;deep neural network","","","15","","","","","IEEE","IEEE Conferences"
"Synthesizing Neural Network Controllers with Probabilistic Model-Based Reinforcement Learning","J. C. Gamboa Higuera; D. Meger; G. Dudek","Center for Intelligent Machines and the School of Computer Science, McGill University, Montreal, Canada; Center for Intelligent Machines and the School of Computer Science, McGill University, Montreal, Canada; Center for Intelligent Machines and the School of Computer Science, McGill University, Montreal, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2538","2544","We present an algorithm for rapidly learning neural network policies for robotics systems. The algorithm follows the model-based reinforcement learning paradigm and improves upon existing algorithms: PILeO and a sample-based version of PILeo with neural network dynamics (Deep-PILeO). To improve convergence, we propose a model-based algorithm that uses fixed random numbers and clips gradients during optimization. We propose training a neural network dynamics model using variational dropout with truncated Log-Normal noise. These improvements enable data-efficient synthesis of complex neural network policies. We test our approach on a variety of benchmark tasks, demonstrating data-efficiency that is competitive with that of PILeO, while being able to optimize complex neural network controllers. Finally, we assess the performance of the algorithm for learning motor controllers for a six legged autonomous underwater vehicle. This demonstrates the potential of the algorithm for scaling up the dimensionality and dataset sizes, in more complex tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594018","","Robots;Optimization;Vehicle dynamics;Task analysis;Heuristic algorithms;Neural networks;Stochastic processes","learning (artificial intelligence);mobile robots;neurocontrollers;underwater vehicles","complex neural network controllers;motor controllers;probabilistic model-based reinforcement learning;robotics systems;sample-based version;Deep-PILeO;model-based algorithm;random numbers;clips gradients;neural network dynamics model;data-efficient synthesis;complex neural network policies;data-efficiency;truncated log-normal noise","","","32","","","","","IEEE","IEEE Conferences"
"Evaluating Robotic Devices of Non-Wearable Transferring Aids Using Whole-Body Robotic Simulator of the Elderly","Y. Matsumoto; K. Ogata; I. Kajitani; K. Homma; Y. Wakita","Robot Innovation Research Center National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba-shi, 1-1-1 Umezono, Japan; Robot Innovation Research Center National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba-shi, 1-1-1 Umezono, Japan; Robot Innovation Research Center National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba-shi, 1-1-1 Umezono, Japan; Robot Innovation Research Center National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba-shi, 1-1-1 Umezono, Japan; Robot Innovation Research Center National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba-shi, 1-1-1 Umezono, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper describes the development of a whole-body robotic simulator of an elderly person for evaluating robotics devices for nursing care. To improve the quality of life of the elderly persons, physical assistance such as transfer, movement, and bathroom assistance is important. It is also important to reduce the workload of caregivers in an aging society. In recent years, assistive robotic devices for nursing care have been developed and commercialized for such purposes. However, such devices have not become popular in the care facilities yet. One of the reasons is that it is still difficult to evaluate the effects of the devices on the care receivers and caregivers. In particular, it is necessary to quantitatively evaluate the effect of the devices on the human body from the viewpoint of safety and comfort. We have developed a whole-body robotic system to simulate the pose and motion of the elderly persons. The purpose of this system is to realize quantitative physical evaluation of robotics devices for nursing care of the human body. The experimental results of the preliminary evaluation of assistive robotic devices are also presented.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594022","","Safety;Legged locomotion;Receivers;Senior citizens;Medical services","assisted living;geriatrics;handicapped aids;medical robotics;patient care;service robots","quantitative physical evaluation;whole-body robotic system;assistive robotic devices;physical assistance;nursing care;elderly person;whole-body robotic simulator;nonwearable transferring aids","","","17","","","","","IEEE","IEEE Conferences"
"Regularizing Reinforcement Learning with State Abstraction","R. Akrour; F. Veiga; J. Peters; G. Neumann","CLAS/IAS. TU Darmstadt, Darmstadt, 64289, Germany; CLAS/IAS. TU Darmstadt, Darmstadt, 64289, Germany; CLAS/IAS. TU Darmstadt, Darmstadt, 64289, Germany; CLAS/IAS. TU Darmstadt, Darmstadt, 64289, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","534","539","State abstraction in a discrete reinforcement learning setting clusters states sharing a similar optimal action to yield an easier to solve decision process. In this paper, we generalize the concept of state abstraction to continuous action reinforcement learning by defining an abstract state as a state cluster over which a near-optimal policy of simple shape exists. We propose a hierarchical reinforcement learning algorithm that is able to simultaneously find the state space clustering and the optimal sub-policies in each cluster. The main advantage of the proposed framework is to provide a straightforward way of regularizing reinforcement learning by controlling the behavioral complexity of the learned policy. We apply our algorithm on several benchmark tasks and a robot tactile manipulation task and show that we can match state-of-the-art deep reinforcement learning performance by combining a small number of linear policies.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594201","","Reinforcement learning;Complexity theory;Convergence;Shape;Clustering algorithms;Task analysis;Partitioning algorithms","learning (artificial intelligence);optimisation;pattern clustering","deep reinforcement learning performance;optimal sub-policies;state space clustering;hierarchical reinforcement learning algorithm;near-optimal policy;state cluster;abstract state;continuous action reinforcement learning;similar optimal action;discrete reinforcement;state abstraction;learned policy","","","30","","","","","IEEE","IEEE Conferences"
"Planning to Monitor Wildfires with a Fleet of UAVs","R. Bailon-Ruiz; S. Lacroix; A. Bit-Monnot","LAAS-CNRS CNRS, Université de Toulouse, Toulouse, France; LAAS-CNRS CNRS, Université de Toulouse, Toulouse, France; University of Sassari, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4729","4734","We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind. The approach tailors a generic Variable Neighborhood Search method to these models and associated constraints. Simulation results show ability to plan observation trajectories for a small fleet of UAVs, and to update the plans when new information on the fire are incorporated in the fire model.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593859","","Trajectory;Monitoring;Cameras;Ignition;Planning;Fuels;Shape","autonomous aerial vehicles;emergency management;fires;path planning;search problems;wildfires","fire propagation process;observation trajectories;fire model;wildfire monitoring;variable neighborhood search method;fixed-wing UAV fleet","","","20","","","","","IEEE","IEEE Conferences"
"Adaptive Robot Body Learning and Estimation Through Predictive Coding","P. Lanillos; G. Cheng","Institute for Cognitive Systems, Institute for Cognitive Systems (ICS), Technische Universität München, Arcisstrae 21, München, 80333, Germany; Institute for Cognitive Systems, Institute for Cognitive Systems (ICS), Technische Universität München, Arcisstrae 21, München, 80333, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4083","4090","The predictive functions that permit humans to infer their body state by sensorimotor integration are critical to perform safe interaction in complex environments. These functions are adaptive and robust to non-linear actuators and noisy sensory information. This paper introduces a computational perceptual model based on predictive processing that enables any multisensory robot to learn, infer and update its body configuration when using arbitrary sensors with Gaussian additive noise. The proposed method integrates different sources of information (tactile, visual and proprioceptive) to drive the robot belief to its current body configuration. The motivation is to provide robots with the embodied perception needed for self-calibration and safe physical human-robot interaction. We formulate body learning as obtaining the forward model that encodes the sensor values depending on the body variables, and we solve it by Gaussian process regression. We model body estimation as minimizing the discrepancy between the robot body configuration belief and the observed posterior. We minimize the variational free energy using the sensory prediction errors (sensed vs expected). In order to evaluate the model we test it on a real multi-sensory robotic arm. We show how different sensor modalities contributions, included as additive errors, improve the refinement of the body estimation and how the system adapts itself to provide the most plausible solution even when injecting strong sensory visuo-tactile perturbations. We further analyse the reliability of the model when different sensor modalities are disabled. This provides grounded evidence about the correctness of the perceptual model and shows how the robot estimates and adjusts its body configuration just by means of sensory information.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593684","Bio-inspired perception;body-schema;predictive processing;embodied artificial intelligence;learning and adaptive systems;humanoid robotics","Robot sensing systems;Visualization;Estimation;Computational modeling;Adaptation models","actuators;adaptive control;Bayes methods;Gaussian processes;humanoid robots;human-robot interaction;learning (artificial intelligence);manipulator kinematics;mobile robots;regression analysis;sensor fusion","nonlinear actuators;noisy sensory information;computational perceptual model;predictive processing;arbitrary sensors;Gaussian additive noise;Gaussian process regression;robot body configuration belief;sensory prediction errors;multisensory robotic arm;additive errors;adaptive robot body learning;predictive coding;predictive functions;sensorimotor integration;human-robot interaction;sensor modalities contributions;sensory visuo-tactile perturbations","","1","31","","","","","IEEE","IEEE Conferences"
"ARIADNE with Ambiguity Resolution: Visual Marker Based Rapid Initialization of PPP-AR","K. Watanabe","Japan Aerospace Exploration Agency, Research and Development Directorate, Ibaraki, 2-1-1 Sengen, Tsukuba, 305-8505, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7362","7368","Precise Point Positioning (PPP) offers advantages over Real-Time Kinematic (RTK) positioning in that it needs no ground base station or a rover to provide a communication channel with the base station. Therefore, PPP is expected to be applied in various fields, such as precise agriculture, intelligent transportation, construction, and mining. One major drawback of PPP is that it takes several tens of minutes for initial convergence to reach an adequate level of accuracy, and how to shorten the convergence time remains the key issue regarding the proliferation of PPP. In our previous work, we proposed a method of drastically reducing this initial convergence time of PPP (called “ARIADNE”) by using an accurate fiducial marker whose position in Earth-fixed coordinates has been accurately measured using an onboard camera. In this contribution, in order to improve both the positioning accuracy and reliability, we introduce some new techniques to ARIADNE: (1) carrier phase ambiguity resolution (AR); and (2) estimating displacement of the marker's orientation. AR results in doubling the positioning accuracy, while displacement estimation enables the detection of any change in the marker's installation orientation and compensation for the effect thereof in the initialization process. Analytical results based on actual data acquired with a prototype system show that the above method and techniques work very well with a realistic setup of PPP-AR and marker performance, and successfully reduce the initial convergence time from tens of minutes to less than a minute.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593863","","Global navigation satellite system;Position measurement;Antenna measurements;Antennas;Convergence;Cameras","agriculture;Global Positioning System","carrier phase ambiguity resolution;precise point positioning;real-time kinematic positioning;accurate fiducial marker;ARIADNE;Earth-fixed coordinates;mining;precise agriculture;ground base station;visual marker;PPP-AR;initialization process;positioning accuracy;initial convergence time","","","12","","","","","IEEE","IEEE Conferences"
"Multi-Agent Planning for Coordinated Robotic Weed Killing","W. McAllister; D. Osipychev; G. Chowdhary; A. Davis","University of Illinois at Urbana-Champaign, Dept. of Electrical and Computer Engineering; University of Illinois at Urbana-Champaign, Dept. of Agricultural and Biological Engineering; University of Illinois at Urbana-Champaign, Dept. of Agricultural and Biological Engineering; USDA-ARS, Urbana, IL","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7955","7960","This work presents a strategy for coordinated multi-agent weeding under conditions of partial environmental information. The goal of this work is to demonstrate the feasibility of coordination strategies for improving the weeding performance of autonomous agricultural robots. We show that, given a sufficient number of agents, the algorithm can successfully weed fields with various initial seed bank densities, even when multiple days are allowed to elapse before weeding commences. Furthermore, the use of coordination between agents is demonstrated to strongly improve system performance as the number of agents increases, enabling the system to eliminate all the weeds in the field, as in the case of full environmental information, when the planner without coordination failed to do so. As a domain to test our algorithms, we have developed an open source simulation environment, Weed World, which allows real-time visualization of coordinated weeding policies, and includes realistic weed generation. In this work, experiments are conducted to determine the required number of agents and their required transit speed, for given initial seed bank densities and varying allowed days before the start of the weeding process.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593429","","Agriculture;Robot kinematics;Optimization;Immune system;Chemicals;Soil","agriculture;crops;environmental factors;industrial robots;mobile robots;multi-agent systems;path planning","multiagent planning;coordinated robotic Weed killing;coordinated multiagent weeding;partial environmental information;coordination strategies;weeding performance;autonomous agricultural robots;system performance;Weed World;coordinated weeding policies;realistic weed generation;initial seed bank densities;weeding process;required number","","","17","","","","","IEEE","IEEE Conferences"
"Enhanced Explosive Motion for Torque Controlled Actuators Through Field Weakening Control","W. Roozing; N. Kashiri; N. G. Tsagarakis","The authors are with the Department of Advanced Robotics (Fondazione), Istituto Italiano di Tecnologia via Morego 30, Genova, 16163, Italy; The authors are with the Department of Advanced Robotics (Fondazione), Istituto Italiano di Tecnologia via Morego 30, Genova, 16163, Italy; The authors are with the Department of Advanced Robotics (Fondazione), Istituto Italiano di Tecnologia via Morego 30, Genova, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","This work presents a method to increase the peak output speed of surface permanent magnet synchronous machine (SPMSM) motor drives with application in robotics using field weakening control. Contrary to most existing works, the strategy is stateless and operates using only a motor torque reference as input, making it suitable for robotics applications in which reference torque and speed are continuously and rapidly changing. Based on the system dynamics and constraints, we obtain four different operating modes. The strategy is extensively validated using three different experiments, which show an increase in peak velocity of up to 33%. The results demonstrate that the proposed strategy is effective in extending the dynamic performance and explosive motion capabilities of robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593608","","Torque;Robots;Permanent magnet motors;Actuators;Synchronous motors;AC motors;Voltage control","actuators;machine control;motor drives;permanent magnet motors;robots;synchronous motors;torque control","surface permanent magnet synchronous machine motor drives;operating modes;constraints;system dynamics;reference torque;robotics applications;motor torque reference;motor drives;field weakening control;torque controlled actuators;enhanced explosive motion;peak velocity","","1","17","","","","","IEEE","IEEE Conferences"
"Transferring Visuomotor Learning from Simulation to the Real World for Robotics Manipulation Tasks","P. D. H. Nguyen; T. Fischer; H. J. Chang; U. Pattacini; G. Metta; Y. Demiris","Istituto Italiano di Tecnologia, Icub Facility, Genova, 16163, Italy; Imperial College, Personal Robotics Lab, London, SW7 2AZ, UK; Imperial College, Personal Robotics Lab, London, SW7 2AZ, UK; Istituto Italiano di Tecnologia, Icub Facility, Genova, 16163, Italy; Istituto Italiano di Tecnologia, Icub Facility, Genova, 16163, Italy; Imperial College, Personal Robotics Lab, London, SW7 2AZ, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6667","6674","Hand-eye coordination is a requirement for many manipulation tasks including grasping and reaching. However, accurate hand-eye coordination has shown to be especially difficult to achieve in complex robots like the iCub humanoid. In this work, we solve the hand-eye coordination task using a visuomotor deep neural network predictor that estimates the arm's joint configuration given a stereo image pair of the arm and the underlying head configuration. As there are various unavoidable sources of sensing error on the physical robot, we train the predictor on images obtained from simulation. The images from simulation were modified to look realistic using an image-to-image translation approach. In various experiments, we first show that the visuomotor predictor provides accurate joint estimates of the iCub's hand in simulation. We then show that the predictor can be used to obtain the systematic error of the robot's joint measurements on the physical iCub robot. We demonstrate that a calibrator can be designed to automatically compensate this error. Finally, we validate that this enables accurate reaching of objects while circumventing manual fine-calibration of the robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594519","","Robot kinematics;Head;Task analysis;Robot sensing systems;Visualization;Manipulators","calibration;humanoid robots;learning (artificial intelligence);manipulators;motion control;neural nets;robot vision;stereo image processing","robotic manipulation tasks;physical iCub robot;joint measurements;systematic error;accurate joint estimates;visuomotor predictor;image-to-image translation approach;physical robot;sensing error;unavoidable sources;underlying head configuration;stereo image pair;visuomotor deep neural network predictor;hand-eye coordination task;iCub humanoid;complex robots;accurate hand-eye coordination;visuomotor learning","","","36","","","","","IEEE","IEEE Conferences"
"Persistent Anytime Learning of Objects from Unseen Classes","M. Denninger; R. Triebel","Dep. of Perception and Cognition, Institute of Robotics and Mechatronics German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Dep. of Perception and Cognition, Institute of Robotics and Mechatronics German Aerospace Center (DLR), Oberpfaffenhofen, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4075","4082","We present a fast and very effective method for object classification that is particularly suited for robotic applications such as grasping and semantic mapping. Our approach is based on a Random Forest classifier that can be trained incrementally. This has the major benefit that semantic information from new data samples can be incorporated without retraining the entire model. Even if new samples from a previously unseen class are presented, our method is able to perform efficient updates and learn a sustainable representation for this new class. Further features of our method include a very fast and memory-efficient implementation, as well as the ability to interrupt the learning process at any time without a significant performance degradation. Experiments on benchmark data for robotic applications show the clear benefits of our incremental approach and its competitiveness with standard offline methods in terms of classification accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594165","Learning and Adaptive Systems;Object Detection;Segmentation and Categorization;Online Learning","Training;Vegetation;Robots;Semantics;Standards;Training data;Uncertainty","image classification;random forests","random forest classifier;semantic mapping;object classification;standard offline methods;incremental approach;robotic applications;data samples","","","24","","","","","IEEE","IEEE Conferences"
"Learned Hand Gesture Classification Through Synthetically Generated Training Samples","K. Lindgren; N. Kalavakonda; D. E. Caballero; K. Huang; B. Hannaford","Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA; Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA; Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA; Dept. of Engineering, Trinity College, 300 Summit St, Hartford, CT, 06106, USA; Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3937","3942","Hand gestures are a natural component of human-human communication. Simple hand gestures are intuitive and can exhibit great lexical variety. It stands to reason that such a user input mechanism can have many benefits, including seamless interaction, intuitive control and robustness to physical constraints and ambient electrical, light and sound interference. However, while semantic and logical information encoded via hand gestures is readily decoded by humans, leveraging this communication channel in human-machine interfaces remains a challenge. Recent data-driven deep learning approaches are promising towards uncovering abstract and complex relationships that manual and direct rule-based classification schemes fail to discover. Such an approach is amenable towards hand gesture recognition, but requires myriad data which can be collected physically via user experiments. This process, however, is onerous and tedious. A streamlined approach with less overhead is sought. To that end, this work presents a novel method of synthetic hand gesture dataset generation that leverages modern gaming engines. Furthermore, preliminary results indicate that the dataset, despite being synthetic and requiring no physical data collection, is both accurate and rich enough to train a real-world hand gesture classifier that operates in real-time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593433","","Training;Gesture recognition;Training data;Real-time systems;Engines;Task analysis;Computer vision","gesture recognition;human computer interaction;image classification;learning (artificial intelligence)","user input mechanism;intuitive control;physical constraints;ambient electrical interference;light interference;sound interference;semantic information;logical information;communication channel;human-machine interfaces;hand gesture recognition;synthetic hand gesture dataset generation;physical data collection;real-world hand gesture classifier;learned hand gesture classification;synthetically generated training samples;natural component;human-human communication;rule-based classification schemes;data-driven deep learning approaches","","","20","","","","","IEEE","IEEE Conferences"
"Using human studies to analyze capabilities of underactuated and compliant hands in manipulation tasks","J. Morrow; A. Kothari; Y. H. Ong; N. Harlan; R. Balasubramanian; C. Grimm","NA; NA; NA; NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2949","2954","We present a human-subjects study approach that supports the analysis of the manipulation performance of robotic hands that have the same morphology but different actuation and compliance. Specifically, we use this approach to analyze three different types of hands (one underactuated, one fully actuated, one fully actuated with compliant distal joints) as they are used to perform two manipulation tasks. The first task uses a power grasp (spraying with a spray bottle), the second a precision grasp (tracing a line on a bowl with a pen). We show that compliance in the distal joints significantly improves performance and task completion. We also show that humans choose significantly different poses for the same task when using a fully-actuated versus underactuated hand, which also results in superior task performance. Our results suggest that humans use a combination of under-actuated and fully-actuated techniques, which when used on robotic systems would also improve their performance on manipulation tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594344","","Task analysis;Grasping;Robots;Spraying;Shape;Potentiometers;Rubber","actuators;manipulators","human studies;underactuated hands;compliant hands;manipulation tasks;human-subjects;manipulation performance;robotic hands;compliance;compliant distal joints;task completion;different poses;superior task performance;fully-actuated techniques;actuation;robotic systems","","","23","","","","","IEEE","IEEE Conferences"
"Electing an Approximate Center in a Huge Modular Robot with the k-BFS SumSweep Algorithm","A. Naz; B. Piranda; J. Bourgeois; S. C. Goldstein","CNRS, University Bourgogne Franche-Comté, FEMTO-ST Institute, Montbéliard, France; CNRS, University Bourgogne Franche-Comté, FEMTO-ST Institute, Montbéliard, France; CNRS, University Bourgogne Franche-Comté, FEMTO-ST Institute, Montbéliard, France; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4825","4832","Among the diversity of the existing modular robotic systems, we consider in this paper the subset of distributed modular robotic ensembles composed of resource-constrained identical modules that are organized in a lattice structure and which can only communicate with neighboring modules. These modular robotic ensembles form asynchronous distributed embedded systems. In many algorithms dedicated to distributed system coordination, a specific role has to be played by a leader, i.e., a single node in the system. This leader can be elected using various criteria. A possible strategy is to elect a center node, i.e., a node that has the minimum distance to all the other nodes. Indeed, this node is ideally located to communicate with all the others and this leads to better performance in many algorithms. The contribution of this paper is to propose the k-BFS SumSweep algorithm designed to elect an approximate-center node. We evaluated our algorithm both on hardware modular robots and in a simulator for large ensembles of robots. Experimental results show that k-BFS SumSweep is often the most accurate approximation algorithm (with an average relative accuracy between 90% to 100%) while using the fewest messages in large-scale systems, requiring only a modest amount of memory per node, and converging in a reasonable length of time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593612","Distributed algorithm;Modular robots;Center election","Approximation algorithms;Robot kinematics;Voting;Heuristic algorithms;Probabilistic logic;Embedded systems","approximation theory;distributed control;embedded systems;large-scale systems;mobile robots;multi-robot systems;tree searching","asynchronous distributed embedded systems;distributed system coordination;approximation algorithm;memory per node;neighboring modules;lattice structure;resource-constrained identical modules;distributed modular robotic ensembles;huge modular robot;large-scale systems;hardware modular robots;approximate-center node;k-BFS SumSweep algorithm","","","32","","","","","IEEE","IEEE Conferences"
"Kinodynamic Comfort Trajectory Planning for Car-Like Robots","H. Shin; D. Kim; S. Yoon","Korea Advanced Institute of Science and Technology (KAIST), School of Computing; Korea Advanced Institute of Science and Technology (KAIST), School of Computing; Korea Advanced Institute of Science and Technology (KAIST), School of Computing","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6532","6539","As personal autonomous mobility is getting to be more widely adopted, it is more important to consider comfortability of stuffs and persons carried by such mobility. In this work, we define the comfort of a trajectory as forces, specifically, translational force, received to objects carried by a robot while following the trajectory by measuring impulse. To maximize such a comfort, we propose a novel, kinodynamic comfort path planning method based on our definition of comfort. Our work is based on direct collocation method for handling our nonconvex objective function. We also introduce Bidirectional Obstacle Detection(BOD)that identifies the distances along the perpendicular directions to the trajectory. This is mainly designed for avoiding obstacles while minimizing forces causing discomfort. Our experimental results show that our method can compute trajectories whose comfort measures can be up to 18 times higher than those computed by prior related objectives, e.g., squared velocity used for generating smooth trajectory.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593397","","Robots;Acceleration;Planning;Trajectory optimization;System dynamics;Linear programming","automobiles;collision avoidance;concave programming;force control;mobile robots;object detection;trajectory control","translational force;direct collocation method;smooth trajectory;kinodynamic comfort trajectory planning;car-like robots;personal autonomous mobility;comfortability;kinodynamic comfort path planning method;nonconvex objective function;bidirectional obstacle detection;obstacle avoidance;smooth trajectory generation","","","31","","","","","IEEE","IEEE Conferences"
"Towards an Adaptive-Compliance Aerial Manipulator for Contact- Based Interaction","S. Hamaza; I. Georgilas; T. Richardson","University of Bristol and University of the West of England, Bristol Robotics Laboratory, Bristol, UK; Dept. of Mechanical Engineering, University of Bath, Bath, UK; University of Bristol and University of the West of England, Bristol Robotics Laboratory, Bristol, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","As roles for unmanned aerial vehicles (UAVs)continue to diversify, the ability to sense and interact closely with the environment becomes increasingly important. Within this paper we report on the initial flight tests of a novel adaptively compliant actuator which will allow a UAV to carry out such tasks as the “pick and placement” of remote sensors, structural testing and contact-based inspection. Three key results are discussed and presented; the ability to physically apply forces with the UAV through the use of an active compliant manipulator; the ability to tailor these forces through tuning of the manipulator controller gains; and the ability to apply a rapid series of physical pulses in order to excite remotely placed sensors, e.g. vibration sensors. A series of over sixty flight tests have been used to generate initial results which clearly demonstrate the potential of this new type of compliant aerial actuator.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593576","","Manipulator dynamics;End effectors;Sensors;Force;Task analysis;Inspection","actuators;autonomous aerial vehicles;inspection;manipulators","adaptive-compliance aerial manipulator;contact-based interaction;unmanned aerial vehicles;UAV;initial flight tests;novel adaptively compliant actuator;pick placement;remote sensors;structural testing;contact-based inspection;key results;active compliant manipulator;manipulator controller gains;physical pulses;vibration sensors;initial results;compliant aerial actuator","","","26","","","","","IEEE","IEEE Conferences"
"FOCS: Planning by Fusion of Optimal Control & Search and its Application to Navigation","P. Micelli; M. Likhachev","University of Parma, Department of Engineering and Architecture, Parma, PR, 43124, Italy; Carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8082","8088","Both Optimal Control and Search-based Planning are used extensively for path planning and have their own set of advantages and disadvantages. In this paper, we propose an algorithm FOCS (Fusion of Optimal Control and Search) that combines these two classes of approaches together. FOCS finds a path exploiting the advantages of both approaches while providing a bound on the sub-optimality of its solution. The returned path is a concatenation of the path found in the implicit graph constructed by search and the path generated by following the negative gradient of the value function obtained as a solution of the Hamilton-Jacobi-Bellman equation. We analyze the algorithm and illustrate its effectiveness in finding a minimum-time path for a car-like vehicle in different environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594487","","Planning;Optimal control;Robots;Optimized production technology;Heuristic algorithms;Dynamic programming;Search problems","graph theory;optimal control;path planning","car-like vehicle;Hamilton-Jacobi-Bellman equation;FOCS;minimum-time path;returned path;sub-optimality;path planning;Search-based Planning;Optimal Control & Search","","","17","","","","","IEEE","IEEE Conferences"
"A Series Elastic Tactile Sensing Array for Tactile Exploration of Deformable and Rigid Objects","Z. Kappassov; D. Baimukashev; O. Adiyatov; S. Salakchinov; Y. Massalin; H. A. Varol","Dept. of Robotics and Mechatronics, Nazarbayev University, 53Kabanbay Batyr Ave, Astana, Z05H0P9, Kazakhstan; Dept. of Robotics and Mechatronics, Nazarbayev University, 53Kabanbay Batyr Ave, Astana, Z05H0P9, Kazakhstan; Dept. of Robotics and Mechatronics, Nazarbayev University, 53Kabanbay Batyr Ave, Astana, Z05H0P9, Kazakhstan; Dept. of Robotics and Mechatronics, Nazarbayev University, 53Kabanbay Batyr Ave, Astana, Z05H0P9, Kazakhstan; Dept. of Robotics and Mechatronics, Nazarbayev University, 53Kabanbay Batyr Ave, Astana, Z05H0P9, Kazakhstan; Dept. of Robotics and Mechatronics, Nazarbayev University, 53Kabanbay Batyr Ave, Astana, Z05H0P9, Kazakhstan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","520","525","Tactile sensing arrays are used to detect contacts of robotic systems with the environment. They are particularly useful for scenarios in which vision-based sensors cannot be used. Thanks to the presence of multiple sensing elements, tactile arrays also provide spatial information about the contact location. In this work, we present our series elastic tactile array to enable tactile exploration for position-controlled robot manipulators. Sixteen compliant sensing elements are arranged as a 4×4 array. This allows the position-controlled robot to explore objects via palpation. Tactile sensing was accomplished by measuring the change of the magnetic field caused by neodymium magnets embedded into the series elastic elements. We demonstrate the efficacy of our sensor with two sets of experiments involving physical interaction scenarios. Firstly, we show that the sensor can be used to differentiate between rigid and deformable objects. Secondly, we show that point clouds of objects can be generated quickly with our sensor module attached to a position-controlled robot manipulator as an end-effector.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593755","","Magnetic sensors;Pins;Tactile sensors;Saturation magnetization","elasticity;manipulators;position control;tactile sensors","deformable objects;rigid objects;series elastic elements;sixteen compliant sensing elements;position-controlled robot manipulator;series elastic tactile array;contact location;tactile arrays;multiple sensing elements;vision-based sensors;robotic systems;tactile sensing arrays;tactile exploration;series elastic tactile sensing array","","","22","","","","","IEEE","IEEE Conferences"
"PH Model-Based Shape Reconstruction of Heterogeneous Continuum Closed Loop Kinematic Chain: An Application to Skipping Rope","I. Singh; Y. Amara; O. Lakhal; A. Melingui; R. Merzouki","CRIStAL, CNRS-UMR 9189, Polytech Lille, Villeneuve d'Ascq, 59655, France; Ecole Militaire Polytechnique, 16111, Algeria; CRIStAL, CNRS-UMR 9189, Polytech Lille, Villeneuve d'Ascq, 59655, France; University of Yaounde 1, Ecole Nationale Superieure Polytechnique, Yaounde, 8390, Cameroon; CRIStAL, CNRS-UMR 9189, Polytech Lille, Villeneuve d'Ascq, 59655, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8682","8688","Soft robotics is a swiftly growing research area these days. Modeling continuum robots accurately is still a demanding field. The paper aims to propose a shape reconstruction method and the estimation of the kinematic behavior of heterogeneous continuum robot in closed loop kinematic configuration, by using Pythagorean Hodograph (PH) curves. The validation of the model approach has been tested on cooperative continuum robots, namely Compact Bionic Handling Arms (CBHA), driving an intermediate flexible rope (a passive flexible link), by using a 3D tracking system. Experimental comparison of the proposed approach with the existing approaches is performed in terms of accuracy as well as the time cost.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593934","","Manipulators;Shape;Kinematics;Biological system modeling;Electron tubes;Mathematical model","closed loop systems;manipulator dynamics;manipulator kinematics;mobile robots;position control","skipping rope;soft robotics;demanding field;shape reconstruction method;kinematic behavior;heterogeneous continuum robot;closed loop kinematic configuration;Pythagorean Hodograph curves;Compact Bionic Handling Arms;intermediate flexible rope;PH model-based shape reconstruction;heterogeneous continuum closed loop kinematic chain;continuum robots","","","22","","","","","IEEE","IEEE Conferences"
"Human Gaze Following for Human-Robot Interaction","A. Saran; S. Majumdar; E. S. Shor; A. Thomaz; S. Niekum","University of Texas at Austin, Department of Computer Science, Austin, TX, 78712, USA; University of Texas at Austin, Department of Electrical and Computer Engineering, Austin, TX, 78712, USA; University of Texas at Austin, Department of Electrical and Computer Engineering, Austin, TX, 78712, USA; University of Texas at Austin, Department of Electrical and Computer Engineering, Austin, TX, 78712, USA; University of Texas at Austin, Department of Computer Science, Austin, TX, 78712, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8615","8621","Gaze provides subtle informative cues to aid fluent interactions among people. Incorporating human gaze predictions can signify how engaged a person is while interacting with a robot and allow the robot to predict a human's intentions or goals. We propose a novel approach to predict human gaze fixations relevant for human-robot interaction tasks-both referential and mutual gaze-in real time on a robot. We use a deep learning approach which tracks a human's gaze from a robot's perspective in real time. The approach builds on prior work which uses a deep network to predict the referential gaze of a person from a single 2D image. Our work uses an interpretable part of the network, a gaze heat map, and incorporates contextual task knowledge such as location of relevant objects, to predict referential gaze. We find that the gaze heat map statistics also capture differences between mutual and referential gaze conditions, which we use to predict whether a person is facing the robot's camera or not. We highlight the challenges of following a person's gaze on a robot in real time and show improved performance for referential gaze and mutual gaze prediction.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593580","","Task analysis;Real-time systems;Head;Cameras;Robot vision systems;Videos","control engineering computing;face recognition;gaze tracking;human-robot interaction;learning (artificial intelligence)","single 2D image;human gaze predictions;human-robot interaction tasks;fluent interactions;mutual gaze prediction;gaze heat map statistics;referential gaze;deep learning approach;human gaze fixations","","1","28","","","","","IEEE","IEEE Conferences"
"Neurorobotic Approach to Study Huntington Disease Based on a Mouse Neuromusculoskeletal Model","S. Oota; Y. Okamura-Oho; K. Ayusawa; Y. Ikegami; A. Murai; E. Yoshida; Y. Nakamura","RIKEN, Bioresource Information Division, Tsukuba, 3-1-1 Koya-dai, 305-0074, JAPAN; Jissen Women's University, Tokyo, 4-1-1 Osakaue, Hino, 191-8510, Japan; UMI3218/RL, Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology, CNRS-AIST JRL (Joint Robotics Laboratory), Japan; University of Tokyo, Department of Mechano-Informatics, Japan; National Institute of Advanced Industrial Science and Technology, Human Informatics Research Institute, Japan; UMI3218/RL, Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology, CNRS-AIST JRL (Joint Robotics Laboratory), Japan; University of Tokyo, Department of Mechano-Informatics, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6720","6727","Motor functions of the biological system has been forged through 4 billion years evolution. From a neurorobotics view, it is important not only to know how well it works, but also how it fails. To quantitatively describe early onset symptoms of a neurodegenerative disease, we analyzed phenotypes of genetically engineered Huntington disease (HD) model mice, which reveal progressive impaired motor functions. We devised a simple yet sensitive paradigm called the crystalized motion profile (CMP), by which we successfully detected subtle difference between normal and abnormal mice in terms of whole-body level motor coordination. Our long-term objective is to remodel human mind and body to regain impaired motor and cognitive functions with ageing. To do so, we are developing a soft neurorobotic suit that provides integrated cognitive and physical interventions to users. Our analysis on the HD model mice is important as the first step to bridge between molecular mechanisms (altered genetic code) and the macroscopic neuro-musculoskeletal model. With this, we can extrapolate from knowledge of non-human mammals to human to derive the remodeling.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594491","","Mice;Diseases;Joints;Robots;Kinematics;Bones;Biological system modeling","biomechanics;cognition;diseases;genetics;medical robotics;muscle;neurophysiology","altered genetic code;macroscopic neuro-musculoskeletal model;neurorobotic approach;mouse neuromusculoskeletal model;biological system;neurorobotics view;early onset symptoms;neurodegenerative disease;genetically engineered Huntington disease model mice;progressive impaired motor functions;crystalized motion profile;normal mice;abnormal mice;whole-body level motor coordination;long-term objective;human mind;cognitive functions;soft neurorobotic suit;HD model mice;molecular mechanisms;macroscopic neuromusculoskeletal model","","","50","","","","","IEEE","IEEE Conferences"
"Wireframe Mapping for Resource-Constrained Robots","A. Caccavale; M. Schwager","Stanford University, Department of Mechanical Engineering, Stanford, CA, 94305; Stanford University, Department of Aeronautics & Astronautics, Stanford, CA, 94305","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents a novel wireframe map structure for resource-constrained robots operating in a rectilinear 2D environment. The wireframe representation compactly represents geometry, in addition to transient situations such as occlusions and boundaries of unexplored regions. We formulate a particle filter to suit this sparse wireframe map structure. Functions for calculating the likelihood of scans, merging wireframes, and resampling are developed to accommodate this map representation. The wireframe structure with the particle filter allows for severe discrete map errors to be corrected, leading to accurate maps with small storage requirements. We show in a simulation study that the algorithm attains a map of an environment with 1 % error, compared to an occupancy grid map obtained with GMapping which attained 23% error with the same storage requirements. A simulation mapping a large environment demonstrates the algorithms scalability.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594057","","Simultaneous localization and mapping;Uncertainty;Two dimensional displays;Geometry;Navigation","mobile robots;path planning","simulation mapping;wireframe mapping;resource-constrained robots;wireframe representation;particle filter;sparse wireframe map structure;map representation;wireframe structure;occupancy grid map;discrete map errors","","","18","","","","","IEEE","IEEE Conferences"
"A Distributed Swarm Aggregation Algorithm for Bar Shaped Multi-Agent Systems","R. F. Carpio; L. Di Giulio; E. Garone; G. Ulivi; A. Gasparri","Department of Engineering, University of “Roma Tre”, Via della Vasca Navale 79, Rome, 00146, Italy; Safety Office of the Experimental Department at CERN, Geneva, 1211, Switzerland; Control and Systems Analysis Dep., Faculty of Applied Science, Université Libre de Bruxelles, Brussels, 1050, Belgium; Department of Engineering, University of “Roma Tre”, Via della Vasca Navale 79, Rome, 00146, Italy; Department of Engineering, University of “Roma Tre”, Via della Vasca Navale 79, Rome, 00146, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4303","4308","In this work we consider a swarm of agents shaped as bars with a certain orientation in the state space. Members of the swarm have to reach an aggregate state, while guaranteeing the collision avoidance and possibly achieving an angular consensus. By relying on a segment-to-segment distance definition, we propose a control law, which guides the agents towards this goal. A theoretical analysis of the proposed control scheme along with simulations and experimental results is provided. The proposed framework can be used to model several application scenarios ranging from collaborative transportation to precision farming, where each agent may represent either a large robot or a group of robots intent to carry bar-like shaped loads. Representative examples include: a fleet of robot-teams performing a collaborative object transportation task in an automated logistic setting, or a fleet of autonomous tractors each carrying a large atomizer to spray chemical products for pest and disease control in a precision farming setting.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594236","","Bars;Multi-agent systems;Robot kinematics;Collision avoidance;Aggregates;Load modeling","collision avoidance;logistics;mobile robots;multi-agent systems;multi-robot systems","control scheme;collaborative transportation;bar-like shaped loads;robot-teams;collaborative object transportation task;precision farming setting;distributed swarm aggregation algorithm;bar shaped multiagent systems;state space;aggregate state;collision avoidance;angular consensus;segment-to-segment distance definition;control law;autonomous tractors","","","30","","","","","IEEE","IEEE Conferences"
"Improving the Parallel Execution of Behavior Trees","M. Colledanchise; L. Natale","Istituto Italiano di Tecnologia, iCub Facility, Genoa, Italy; Istituto Italiano di Tecnologia, iCub Facility, Genoa, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7103","7110","Behavior Trees (BTs) have become a popular framework for designing controllers of autonomous agents in the computer game and in the robotics industry. One of the key advantages of BTs lies in their modularity, where independent modules can be composed to create more complex ones. In the classical formulation of BTs, modules can be composed using one of the three operators: Sequence, Fallback, and Parallel. The Parallel operator is rarely used despite its strong potential against other control architectures such as Finite State Machines. This is due to the fact that concurrent actions may lead to unexpected problems similar to the ones experienced in concurrent programming. In this paper, we outline how to tackle the aforementioned problem by introducing Concurrent BTs (CBTs) as a generalization of BTs in which we include the notions of progress and resource usage. We show how CBTs allow safe concurrent executions of actions and we analyze the approach from a mathematical standpoint. To illustrate the use of CBTs, we provide a set of use cases in realistic robotics scenarios.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593504","","Task analysis;Robots;Synchronization;Games;Programming;Monitoring;Concurrent computing","computer games;control system synthesis;finite state machines;mobile robots;trees (mathematics)","control architectures;concurrent programming;CBTs;autonomous agents;computer game;robotics industry;finite state machines;parallel execution;concurrent BTs;parallel operator;behavior trees","","","21","","","","","IEEE","IEEE Conferences"
"Human Intention Estimation based on Neural Networks for Enhanced Collaboration with Robots","D. Nicolis; A. M. Zanchettin; P. Rocco","Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy; Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy; Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1326","1333","In human-robot collaboration, the robot is required to provide assistance to the user by facilitating task execution. However, due to stability requirements, a well-damped admittance behavior of the robot is necessary during interaction, thus inducing fatigue in the operator. While available schemes involve variable impedance controllers to mitigate this effect, here we propose an alternative approach entailing a proactive robot behavior that assists in the cooperative execution of trajectories towards desired goals, by estimating the user intention. To this end, we make use of Recurrent Neural Networks (RNNs) to predict and classify cooperative motions, on the basis of a set of predefined goals in the workspace and model-based generated data of human movements. Manual guidance validation experiments are conducted on a 6 d.o.f. ABB IRB140 industrial robot equipped with a force sensor.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594415","","Trajectory;Task analysis;Robot sensing systems;Neural networks;Damping;Estimation","damping;force sensors;human-robot interaction;industrial robots;motion control;recurrent neural nets;sensors;stability;trajectory control","recurrent neural networks;RNNs;force sensor;human-robot collaboration;human intention estimation;ABB IRB140 industrial robot;model-based generated data;proactive robot behavior;variable impedance controllers;admittance behavior;stability requirements","","","22","","","","","IEEE","IEEE Conferences"
"Real-time 3D Reconstruction Using a Combination of Point-Based and Volumetric Fusion","Z. Xia; J. Kim; Y. S. Park","Illinois Institute of Technology, Chicago, US; Illinois Institute of Technology, Chicago, US; Argonne National Laboratory","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8449","8455","Real-time 3D reconstruction using low-cost commodity sensors like Kinect or Xtion has been successfully applied in a wide range of fields like augmented reality, robotic teleoperation, and medical diagnosis. Due to the assumption of static scene, popular 3D reconstruction technologies such as KinectFusion and KinFu, find truthful reconstruction with fast motion camera or segmenting a moving object to be a challenge. In this paper, we propose a weighted iterative closest point (ICP) algorithm that uses both depth and RGB information to enhance the stability of camera tracking. Additionally, a GPU-based region growing method that combines depth, normal and intensity level as similarity criteria, is also applied to segment foreground moving objects accurately. For real-time processing and GPU memory efficiency, we also design a combination of point-based and volumetric representation to reconstruct moving objects and static scene, respectively. Both qualitative and quantitative results show that our proposed method improves real-time 3D reconstruction on the performance of camera tracking and segmentation of moving objects with reduced computational complexity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594061","","Cameras;Three-dimensional displays;Pose estimation;Sensors;Real-time systems;Iterative closest point algorithm;Systematics","cameras;image colour analysis;image fusion;image motion analysis;image reconstruction;image segmentation;iterative methods;object detection;stereo image processing","3D reconstruction technologies;point-based and volumetric representation;Kinect sensors;Xtion sensors;augmented reality;robotic teleoperation;medical diagnosis;KinectFusion;KinFu;GPU-based region growing method;weighted iterative closest point algorithm;moving object;fast motion camera;truthful reconstruction;low-cost commodity sensors;volumetric fusion;camera tracking","","","16","","","","","IEEE","IEEE Conferences"
"Interspecies Retargeting of Homologous Body Posture Based on Skeletal Morphing","K. Ayusawa; Y. Ikegami; A. Murai; Y. Yoshiyasu; E. Yoshida; S. Oota; Y. Nakamura","Joint Robotics Laboratory, UMI3218/RL, Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology, CNRS-AIST JRL, Japan; University of Tokyo, Department of Mechano-Informatics, Japan; National Institute of Advanced Industrial Science and Technology, Informatics Research Institute, Japan; Joint Robotics Laboratory, UMI3218/RL, Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology, CNRS-AIST JRL, Japan; Joint Robotics Laboratory, UMI3218/RL, Intelligent Systems Research Institute, National Institute of Advanced Industrial Science and Technology, CNRS-AIST JRL, Japan; RIKEN, BioResource Center, Japan; National Institute of Advanced Industrial Science and Technology, Informatics Research Institute, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6712","6719","The paper aims to develop a methodology of transferring the knowledge obtained from the experiments of laboratory animals to human musculoskeletal system. To achieve the goal, we propose a method for estimating the homologous posture of the mammalian skeletal system corresponding to the human body posture. We hypothesize the homology of bone geometry between mammalian species implies that of biomechanical functions. The method relies on this homology and determines the homologous postures according to the anatomical landmarks of bone geometry. This paper shows the results of the analysis on homologous postures between the human and mouse skeletal models to validate our hypothesis. A pilot study also introduces comparison of mechanical functions between the two models by using the homologous postures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594240","","Bones;Mice;Joints;Geometry;Computational modeling","biomechanics;computerised tomography;image morphing;medical image processing;physiological models","skeletal morphing;bone geometry homology;mammalian species;biomechanical functions;human skeletal models;mouse skeletal models;human body posture;mammalian skeletal system;human musculoskeletal system;homologous body posture","","","25","","","","","IEEE","IEEE Conferences"
"Magnetic Navigation of a Rotating Colloidal Swarm Using Ultrasound Images","Q. Wang; L. Yang; J. Yu; C. Vong; P. W. Yan Chiu; L. Zhang","Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong SAR, China; Chinese University of Hong Kong, Technology Center for Innovative Medicine, Shatin NT, Hong Kong SAR, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong SAR, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5380","5385","Microrobots are considered as promising tools for biomedical applications. However, the imaging of them becomes challenges in order to be further applied on in vivo environments. Here we report the magnetic navigation of a paramagnetic nanoparticle-based swarm using ultrasound images. The swarm can be generated using simple rotating magnetic fields, resulting in a region containing particles with a high area density. Ultrasound images of the swarm shows a periodic changing of imaging contrast. The reason for such dynamic contrast has been analyzed and experimental results are presented. Moreover, this swarm exhibits enhanced ultrasound imaging in comparison to that formed by individual nanoparticles with a low area density, and the relationship between imaging contrast and area density is testified. Furthermore, the microrobotic swarm can be navigated near a solid surface at different velocities, and the imaging contrast show negligible changes. This method allows us to localize and navigate a microrobotic swarm with enhanced ultrasound imaging indicating a promising approach for imaging of microrobots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593898","","Magnetic resonance imaging;Ultrasonic imaging;Nanoparticles;Magnetic recording;Magnetic moments;Navigation","biomedical ultrasonics;image enhancement;magnetic particles;medical image processing;medical robotics;microrobots;nanomedicine;nanoparticles","magnetic navigation;rotating colloidal swarm;ultrasound images;paramagnetic nanoparticle-based swarm;simple rotating magnetic fields;microrobotic swarm;enhanced ultrasound imaging;imaging contrast;microrobot imaging;nanoparticle;solid surface","","","26","","","","","IEEE","IEEE Conferences"
"Object Detection and Pose Estimation Based on Convolutional Neural Networks Trained with Synthetic Data","J. Josifovski; M. Kerzel; C. Pregizer; L. Posniak; S. Wermter","Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Viewlicity GmbH, Schferkampsallee 42, Hamburg, 20357, Germany; Viewlicity GmbH, Schferkampsallee 42, Hamburg, 20357, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6269","6276","Instance-based object detection and fine pose estimation is an active research problem in computer vision. While the traditional interest-point-based approaches for pose estimation are precise, their applicability in robotic tasks relies on controlled environments and rigid objects with detailed textures. CNN-based approaches, on the other hand, have shown impressive results in uncontrolled environments for more general object recognition tasks like category-based coarse pose estimation, but the need of large datasets of fully-annotated training images makes them unfavourable for tasks like instance-based pose estimation. We present a novel approach that combines the robustness of CNNs with a fine-resolution instance-based 3D pose estimation, where the model is trained with fully-annotated synthetic training data, generated automatically from the 3D models of the objects. We propose an experimental setup in which we can carefully examine how the model trained with synthetic data performs on real images of the objects. Results show that the proposed model can be trained only with synthetic renderings of the objects' 3D models and still be successfully applied on images of the real objects, with precision suitable for robotic tasks like object grasping. Based on the results, we present more general insights about training neural models with synthetic images for application on real-world images.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594379","","Solid modeling;Three-dimensional displays;Task analysis;Pose estimation;Training;Data models;Training data","convolutional neural nets;image resolution;image texture;object detection;object recognition;pose estimation;rendering (computer graphics);robot vision;solid modelling","instance-based object detection;fine pose estimation;robotic tasks;CNN-based approaches;general object recognition tasks;fully-annotated training images;neural models;interest-point-based approaches;category-based coarse pose estimation;fine-resolution instance-based 3D pose estimation;convolutional neural networks","","","28","","","","","IEEE","IEEE Conferences"
"Passivity Based Iterative Learning of Admittance-Coupled Dynamic Movement Primitives for Interaction with Changing Environments","A. Kramberger; E. Shahriari; A. Gams; B. Nemec; A. Ude; S. Haddadin","Dept. of Automatics, Biocybernetics and Robotics, Dept. of Automatics, Biocybernetics and Robotics, The authors are with the Humanoid and Cognitive Robotics Lab, Jožzef Stefan Institute, Ljubljana, Slovenia; Technical University of Munich, Munich School of Robotics and Machine Intelligence, Munich, Germany; Dept. of Automatics, Biocybernetics and Robotics, Dept. of Automatics, Biocybernetics and Robotics, The authors are with the Humanoid and Cognitive Robotics Lab, Jožzef Stefan Institute, Ljubljana, Slovenia; Dept. of Automatics, Biocybernetics and Robotics, Dept. of Automatics, Biocybernetics and Robotics, The authors are with the Humanoid and Cognitive Robotics Lab, Jožzef Stefan Institute, Ljubljana, Slovenia; Dept. of Automatics, Biocybernetics and Robotics, Dept. of Automatics, Biocybernetics and Robotics, The authors are with the Humanoid and Cognitive Robotics Lab, Jožzef Stefan Institute, Ljubljana, Slovenia; Technical University of Munich, Munich School of Robotics and Machine Intelligence, Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6023","6028","Encoding desired motions into dynamic movement primitives (DMPs) is a common way for generating compact task representations that are able to handle sensor-based goal adaptations. At the same time, a robot should not only express adaptive motion capabilities at planning level, but use also contact wrench feedback in the adaptation and learning process of the DMP. Despite first approaches exist in this direction, no fully integrated approach has been proposed so far. In this paper, we introduce a new class of admittance-coupled DMPs that addresses environmental changes by including contact wrench feedback dynamics into the DMP formalism. Moreover, a novel iterative learning approach is devised that is based on monitoring the overall system passivity analysis in terms of reference power tracking. Simulations and experimental results with the Kuka LWR robot maintaining a non-rigid contact with the environment (wiping a surface) are shown for supporting the validity of our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593647","","Robots;Impedance;Trajectory;Force feedback;Dynamics;Task analysis;Admittance","adaptive control;feedback;iterative learning control;learning systems;manipulator dynamics;motion control;path planning","admittance-coupled dynamic movement primitives;compact task representations;sensor-based goal adaptations;adaptive motion capabilities;learning process;environmental changes;contact wrench feedback dynamics;iterative learning approach;system passivity analysis;Kuka LWR robot;nonrigid contact;passivity based iterative learning;reference power tracking","","","24","","","","","IEEE","IEEE Conferences"
"P-CAP: Pre-Computed Alternative Paths to Enable Aggressive Aerial Maneuvers in Cluttered Environments","J. Zhang; R. G. Chadha; V. Velivela; S. Singh","Carnegie Mellon University; Carnegie Mellon University; Near Earth Autonomy, Inc.; Near Earth Autonomy, Inc.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8456","8463","We propose a novel method to enable fast autonomous flight in cluttered environments. Typically, autonomous navigation through a complex environment requires a continuous heuristic search on a graph generated by a k-connected grid or a probabilistic scheme. As the vehicle progresses, modification of the graph with data from onboard sensors is expensive as is search on the graph, especially if the paths must be kino-dynamically feasible. We suggest that computation needed to find safe paths during fast flight can be greatly reduced if we precompute and carefully arrange a dense set of alternative paths before the flight. Any prior map information can be used to prune the alternative paths to come up with a data structure that enables very fast online computation to deal with obstacles that are not on the map but only detected by onboard sensors. To test this idea, we have conducted a large number of flight experiments in structured (large industrial facilities) and unstructured (forests-like) environments. We show that even in the most unstructured environments, this method enables flight at a speed up to 10m/s while avoiding obstacles detected from onboard sensors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593826","","Navigation;Sensors;Switches;Collision avoidance;Forestry;Gold;Planning","autonomous aerial vehicles;collision avoidance;data structures;graph theory;mobile robots;navigation;probability;search problems","p-CAP;pre-computed alternative paths;cluttered environments;fast autonomous flight;autonomous navigation;complex environment;continuous heuristic search;k-connected grid;probabilistic scheme;onboard sensors;prior map information;data structure;flight experiments;unstructured environments;aggressive aerial maneuvers;graph;forests-like environments;obstacles avoidance","","","18","","","","","IEEE","IEEE Conferences"
"Solving Markov Decision Processes with Reachability Characterization from Mean First Passage Times","S. Debnath; L. Liu; G. Sukhatme","Shoubhik Debnath is with NVIDIA Corporation, Santa Clara, CA, 95051, USA; Indiana University, Intelligent Systems Engineering Department, Bloomington, Bloomington, IN, 47408, USA; The University of Southern, Department of Computer Science, California, Los Angeles, CA, 90089, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7063","7070","A new mechanism for efficiently solving the Markov decision processes (MDPs) is proposed in this paper. We introduce the notion of reachability landscape where we use the Mean First Passage Time (MFPT) as a means to characterize the reachability of every state in the state space. We show that such reachability characterization very well assesses the importance of states and thus provides a natural basis for effectively prioritizing states and approximating policies. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Value Iteration (MFPT-VI) and Mean First Passage Time based Policy Iteration (MFPT-PI) - that have been modified from the state-of-the-art solution methods. To validate our design, we have performed numerical evaluations in robotic decision-making scenarios, by comparing the proposed new methods with corresponding classic baseline mechanisms. The evaluation results showed that MFPT-VI and MFPT-PI have outperformed the state-of-the-art solutions in terms of both practical runtime and number of iterations. Aside from the advantage of fast convergence, this new solution method is intuitively easy to understand and practically simple to implement.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594383","","Convergence;Markov processes;Mathematical model;Approximation algorithms;Planning;Linear systems;Standards","decision making;decision theory;iterative methods;Markov processes;reachability analysis;robots","Markov decision processes;reachability characterization;reachability landscape;MFPT-VI;MFPT-PI;mean first passage time based value iteration;mean first passage time based policy iteration;robotic decision-making;numerical evaluation","","","21","","","","","IEEE","IEEE Conferences"
"Embedded and controllable shape morphing with twisted-and-coiled actuators*","J. Sun; B. Pawlowski; J. Zhao","Colorado State University, Department of Mechanical Engineering, Fort Collins, CO, 80523, USA; Colorado State University, Department of Mechanical Engineering, Fort Collins, CO, 80523, USA; Colorado State University, Department of Mechanical Engineering, Fort Collins, CO, 80523, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5912","5917","Shape morphing, meaning a structure can first morph and then lock into another shape, can be applied to robot designs to endow robots with adaptive morphology for increased functionality and adaptivity. In this paper, we introduce a novel shape morphing scheme enabled by a new artificial muscle: twisted and coiled actuators (TCAs). This new actuator is purely soft, low cost, and electrically driven. Embedding a TCA and a thermoplastic material with variable stiffness into soft materials, we create a miniature shape-morphing link. We also establish a general model to predict the steady-state shape of the link given an input power applied to the TCA. Experiments are conducted to characterize parameters and verify the proposed model. Finally, we demonstrate this shape-morphing link can serve as a link in a mechanism to change the trajectory of its foot or endpoint. We envision that such a new shape-morphing scheme can enable robots to leverage the same mechanical design for different functions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593651","","Shape;Programmable logic arrays;Actuators;Strain;Force;Mathematical model;Robots","actuators;muscle;prosthetics","robot designs;adaptive morphology;soft materials;steady-state shape;embedded shape morphing;controllable shape morphing;twisted-and-coiled actuators;thermoplastic material;variable stiffness;mechanical design;artificial muscle","","1","22","","","","","IEEE","IEEE Conferences"
"Projection-Aware Task Planning and Execution for Human-in-the-Loop Operation of Robots in a Mixed-Reality Workspace","T. Chakraborti; S. Sreedharan; A. Kulkarni; S. Kambhampati","Department of Computer Science, Arizona State University, Tempe, AZ, USA; Department of Computer Science, Arizona State University, Tempe, AZ, USA; Department of Computer Science, Arizona State University, Tempe, AZ, USA; Department of Computer Science, Arizona State University, Tempe, AZ, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4476","4482","Recent advances in mixed-reality technologies have renewed interest in alternative modes of communication for human-robot interaction. However, most of the work in this direction has been confined to tasks such as teleoperation, simulation or explication of individual actions of a robot. In this paper, we will discuss how the capability to project intentions affect the task planning capabilities of a robot. Specifically, we will start with a discussion on how projection actions can be used to reveal information regarding the future intentions of the robot at the time of task execution. We will then pose a new planning paradigm - projection-aware planning - whereby a robot can trade off its plan cost with its ability to reveal its intentions using its projection actions. We will demonstrate each of these scenarios with the help of a joint human-robot activity using the HoloLens.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593830","","Robots;Task analysis;Planning;Virtual reality;Observers;Vocabulary;Natural languages","control engineering computing;human-robot interaction;planning (artificial intelligence);virtual reality","mixed-reality technologies;human-robot interaction;HoloLens;human-in-the-loop operation;projection-aware task planning capabilities","","","36","","","","","IEEE","IEEE Conferences"
"Multibeam Data Processing for Underwater Mapping","P. V. Teixeira; F. S. Hover; J. J. Leonard; M. Kaess","Department of Mechanical Engineering, MIT, 77 Massachusetts Ave, Cambridge, MA, 02139, USA; Department of Mechanical Engineering, MIT, 77 Massachusetts Ave, Cambridge, MA, 02139, USA; Department of Mechanical Engineering, MIT, 77 Massachusetts Ave, Cambridge, MA, 02139, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1877","1884","From archaeology to the inspection of subsea structures, underwater mapping has become critical to many applications. Because of the balanced trade-off between range and resolution, multibeam sonars are often used as the primary sensor in underwater mapping platforms. These sonars output an image representing the intensity of the received acoustic echos over space, which must be classified into free and occupied regions before range measurements are determined and spatially registered. Most classifiers found in the underwater mapping literature use local thresholding techniques, which are highly sensitive to noise, outliers, and sonar artifacts typically found in these images. In this paper we present an overview of some of the techniques developed in the scope of our work on sonar-based underwater mapping, with the aim of improving map accuracy through better segmentation performance. We also provide experimental results using data collected with a DIDSON imaging sonar that show that these techniques improve both segmentation accuracy and robustness to outliers.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594128","","Sonar measurements;Robot sensing systems;Acoustic beams;Image segmentation;Mathematical model;Acoustics","image segmentation;oceanographic techniques;sonar;sonar detection;sonar imaging;underwater vehicles","balanced trade-off;underwater mapping literature;underwater mapping literature;local thresholding techniques;subsea structures;multibeam data processing;DIDSON imaging sonar;map accuracy;sonar-based underwater mapping;sonar artifacts;range measurements;occupied regions;free regions;received acoustic echos;sonars output;underwater mapping platforms;primary sensor;multibeam sonars","","","20","","","","","IEEE","IEEE Conferences"
"Uncertain Local Leader Selection in Distributed Formations","D. Rovinsky; N. Agmon","Department of Computer Science, Bar-Ilan University, Israel; Department of Computer Science, Bar-Ilan University, Israel","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4818","4824","Leader-Follower is a hierarchical form of multi-robot formation control, where each robot aims to maintain specific predefined angle and distance from one or more robots in the team (referred to as its local leaders), while a single robot is selected to lead the entire formation to a desired destination. When the robots are given a specific formation to maintain, their goal is usually to minimize the deviation from this desired formation (maximizing the accuracy) during their journey. Previous work has considered optimality in an uncertain environment only in centralized setting (or using perfect, or almost perfect communication). In this paper we examine the problem of optimal multi-robot formation control in a distributed setting, while accounting for two challenges: sensory uncertainty and absence of communication. Specifically, we present an algorithm that allows each individual robot to estimate the overall formation accuracy of the other robots in their field of view via a tree reconstruction algorithm. The algorithm is used to select the most accurate local leader, or to generate virtual local leader via a weighted average of all visible robots. We provide both theoretical analysis and an extensive empirical evaluation (in ROS/Gazebo simulated environment) showing the effectiveness of the two approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594307","","Robot sensing systems;Reliability;Shape;Uncertainty;Task analysis","collision avoidance;control engineering computing;mobile robots;multi-robot systems","virtual local leader;accurate local leader;formation accuracy;individual robot;sensory uncertainty;distributed setting;optimal multirobot formation control;uncertain environment;desired formation;specific formation;desired destination;single robot;local leaders;specific predefined angle;hierarchical form;Leader-Follower;distributed formations;uncertain local leader selection;visible robots","","","20","","","","","IEEE","IEEE Conferences"
"Optimizing Contextual Ergonomics Models in Human-Robot Interaction","A. G. Marin; M. S. Shourijeh; P. E. Galibarov; M. Damsgaard; L. Fritzsch; F. Stulp","Robotics and Mechatronics Center (RMC), German Aerospace Center (DLR), Wessling, Münchner Str. 20, Germany; AnyBody Technology A/S, Aalborg, Niels Jernes Vej 10, Denmark; AnyBody Technology A/S, Aalborg, Niels Jernes Vej 10, Denmark; AnyBody Technology A/S, Aalborg, Niels Jernes Vej 10, Denmark; IMK automotive GmbH, Chemnitz, Amselgrund 30, Germany; Robotics and Mechatronics Center (RMC), German Aerospace Center (DLR), Wessling, Münchner Str. 20, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Current ergonomic assessment procedures require observation and manual annotation of postures by an expert, after which ergonomic scores are inferred from these annotations. Our aim is to automate this procedure and to enable robots to optimize their behavior with respect to such scores. A particular challenge is that ergonomic scoring requires accurate biomechanical simulations which are computationally too expensive to use in robot control loops or optimization. To address this, we learn Contextual Ergonomics Models, which are Gaussian Process Latent Variable Models that have been trained with full musculoskeletal simulations for specific tasks contexts. Contextual Ergonomics Models enable search in a low-dimensional latent space, whilst the cost function can be defined in terms of the full high-dimensional musculoskeletal model, which can be quickly reconstructed from the latent space. We demonstrate how optimizing Contextual Ergonomics Models leads to significantly reduced muscle activation in an experiment with eight subjects performing a drilling task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594132","","Ergonomics;Biological system modeling;Context modeling;Task analysis;Data models;Muscles","biomechanics;ergonomics;Gaussian processes;human-robot interaction;learning (artificial intelligence);muscle;physiological models","accurate biomechanical simulations;robot control loops;high-dimensional musculoskeletal model;human-robot interaction;current ergonomic assessment procedures;ergonomic scores;ergonomic scoring;Gaussian process latent variable models","","","22","","","","","IEEE","IEEE Conferences"
"Continuously Shaping Projections and Operational Space Tasks","N. Dehio; D. Kubus; J. J. Steil","Technical University, Research Institute for Robotics and Process Control, Braunschweig, Germany; Technical University, Research Institute for Robotics and Process Control, Braunschweig, Germany; Technical University, Research Institute for Robotics and Process Control, Braunschweig, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5995","6002","Projection operators are widely employed in multi-objective robot control. It is an open research question how to achieve continuous transitions between different idempotent projectors which is required for dynamic task priority rearrangement. We formalize projection shaping, providing a solution to deal with rank changes in a smooth fashion. Furthermore, we derive meaningful shaping operators and show that damped least squares is a special case of our general formulation. Finally, we extend the Stack-of-Tasks prioritization scheme for continuous priority rearrangement of single task dimensions. Simulation results validate our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593400","","Task analysis;Aerospace electronics;Jacobian matrices;Robots;Interference;Torque;Nickel","least squares approximations;robots","projection operators;multiobjective robot control;dynamic task priority rearrangement;projection shaping;damped least squares;idempotent projectors;shaping operators;stack-of-tasks prioritization scheme;single task dimensions continuous priority rearrangement","","1","34","","","","","IEEE","IEEE Conferences"
"Cognition-enabled Framework for Mixed Human-Robot Rescue Teams","F. Yazdani; G. Kazhoyan; A. K. Bozcuoğlu; A. Haidu; F. Bálint-Benczédi; D. Beßler; M. Pomarlan; M. Beetz","Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1421","1428","With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594311","","Cognition;Robot sensing systems;Geographic information systems;Task analysis;Lakes;Bridges","cognition;human-robot interaction;mobile robots;telerobotics","cognition-enabled framework;rescue missions;cognitive capabilities;robot behavior;human-robot rescue teams;human-robot interaction;visibility areas;robotic systems teleoperation;locomotion areas;belief state representations","","","31","","","","","IEEE","IEEE Conferences"
"Courteous Autonomous Cars","L. Sun; W. Zhan; M. Tomizuka; A. D. Dragan","Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","663","670","Typically, autonomous cars optimize for a combination of safety, efficiency, and driving quality. But as we get better at this optimization, we start seeing behavior go from too conservative to too aggressive. The car's behavior exposes the incentives we provide in its cost function. In this work, we argue for cars that are not optimizing a purely selfish cost, but also try to be courteous to other interactive drivers. We formalize courtesy as a term in the objective that measures the increase in another driver's cost induced by the autonomous car's behavior. Such a courtesy term enables the robot car to be aware of possible irrationality of the human behavior, and plan accordingly. We analyze the effect of courtesy in a variety of scenarios. We find, for example, that courteous robot cars leave more space when merging in front of a human driver. Moreover, we find that such a courtesy term can help explain real human driver behavior on the NGSIM dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593969","","Autonomous automobiles;Vehicles;Cost function;Planning;Robot kinematics;Safety","automobiles;road traffic;traffic engineering computing","courteous autonomous cars;driving quality;cost function;purely selfish cost;interactive drivers;autonomous car;courtesy term;robot car;human behavior;courteous robot cars;human driver behavior","","","21","","","","","IEEE","IEEE Conferences"
"Design of Robotic Gripper with Constant Transmission Ratio Based on Twisted String Actuator: Concept and Evaluation","S. Nedelchev; I. Gaponov; J. Ryu","School of Mechanical Engineering, Korea University of Technology and Education, Chungjeolno, Cheonan, Chungnam, 1600, Rep. of South Korea; School of Mechanical Engineering, Korea University of Technology and Education, Chungjeolno, Cheonan, Chungnam, 1600, Rep. of South Korea; School of Mechanical Engineering, Korea University of Technology and Education, Chungjeolno, Cheonan, Chungnam, 1600, Rep. of South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","967","972","Robotic systems for object handling and manipulation are hugely important for modern engineering and industry, with their efficiency, agility and robustness often depending on gripper design and performance. In this work, we investigate a gripper design that, when driven by a twisted string actuator, exhibits nearly-constant transmission ratio throughout its motion range. This allows for design of a highly-compact, modular and efficient robotic gripper driven by a low-power motor. We investigate kinematics of the device, experimentally verify developed models with a practical gripper testbed, and analyze transmission ratio and efficiency of the designed device. The resulting system has a nearly-constant transmission ratio of 550, with the constancy coefficient of 0.985.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593794","","Grippers;Force;Actuators;Kinematics;Mathematical model;Service robots","actuators;grippers;industrial robots;materials handling;mobile robots;robots","twisted string actuator;robotic systems;object handling;manipulation;modern engineering;robustness;gripper design;exhibits nearly-constant transmission ratio;efficient robotic gripper;practical gripper;designed device","","","12","","","","","IEEE","IEEE Conferences"
"On Muscle Activation for Improving Robotic Rehabilitation after Spinal Cord Injury","R. Cheng; Y. Sui; D. Sayenko; J. W. Burdick","Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, 91125, USA; Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, 91125, USA; Department of Integrative Biology and Physiology, University of California Los Angeles, Los Angeles, CA, 90095, USA; Division of Engineering and Applied Science, California Institute of Technology, Pasadena, CA, 91125, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","798","805","Spinal cord stimulation (SCS) has recently enabled humans with motor complete spinal cord injury (SCI) to independently stand and recover some lost autonomic function. However, the nature of the recovered motor activity and the interplay between SCS and motor training are not well understood. Understanding the effect of stand training and spinal stimulation on motor activity during bipedal standing is important for designing spinal rehabilitation therapies that seek to combine spinal stimulation and rehabilitative robots. In this study, we examined electromyography (EMG) data gathered from two SCI patients and six healthy subjects as they attempted standing. We analyzed the muscle activation patterns and EMG waveform shape to quantify both the changes in SCI patient motor activity with training, and the differences between healthy motor activity and SCI patient motor activity under stimulation. We also looked for correlations between the similarity in SCI patients' motor activity to healthy subjects and their overall standing ability. We found that good standing in SCI patients does not emulate healthy standing muscle activity. Furthermore, patient stand training heavily influenced motor activation patterns, but not in ways that improved standing ability. These results indicate that current training techniques do not optimally influence motor activity, and robotic rehabilitation strategies for SCI patients should target essential features of motor activity to optimize functional performance, rather than emulate healthy activity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593973","","Electromyography;Muscles;Training;Electrical stimulation;Robot sensing systems;Feature extraction","biomechanics;electromyography;injuries;medical robotics;neuromuscular stimulation;neurophysiology;patient rehabilitation;patient treatment","motor activation patterns;improved standing ability;SCI patients;healthy activity;improving robotic rehabilitation;spinal cord stimulation;motor complete spinal cord injury;recovered motor activity;motor training;spinal stimulation;bipedal standing;spinal rehabilitation therapies;healthy subjects;muscle activation patterns;SCI patient motor activity;healthy motor activity;healthy standing muscle activity;patient stand training","","","22","","","","","IEEE","IEEE Conferences"
"Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots","R. N. Haksar; M. Schwager","Department of Mechanical Engineering, Stanford University, Stanford, CA, 94305; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA, 94305","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1067","1074","This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593539","","Vegetation;Forestry;Sensors;Retardants;Monitoring;Lattices;Unmanned aerial vehicles","aerospace control;autonomous aerial vehicles;dynamic programming;fires;learning (artificial intelligence);Markov processes;Monte Carlo methods;optimal control;rescue robots","distributed deep reinforcement learning based strategy;UAVs;Markov decision process;deep RL approach;deep RL policy;forest sizes;simulated forest fire;unmanned aerial vehicles;aerial robots","","","29","","","","","IEEE","IEEE Conferences"
"Passive Compliance Control of Aerial Manipulators","M. J. Kim; R. Balachandran; M. De Stefano; K. Kondak; C. Ott","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4177","4184","This paper presents a passive compliance control for aerial manipulators to achieve stable environmental interactions. The main challenge is the absence of actuation along body-planar directions of the aerial vehicle which might be required during the interaction to preserve passivity. The controller proposed in this paper guarantees passivity of the manipulator through a proper choice of end-effector coordinates, and that of vehicle fuselage is guaranteed by exploiting time domain passivity technique. Simulation studies validate the proposed approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593718","","Manipulator dynamics;End effectors;Dynamics;Unmanned aerial vehicles;Mathematical model;Task analysis","aerospace components;compliance control;end effectors;force control;manipulators;position control","time domain passivity technique;passive compliance control;aerial manipulators;stable environmental interactions;body-planar directions;aerial vehicle;manipulator","","","26","","","","","IEEE","IEEE Conferences"
"Scale Correct Monocular Visual Odometry Using a LiDAR Altimeter","R. Giubilato; S. Chiodini; M. Pertile; S. Debei","University of Padova, CISAS, Padova, Italy; University of Padova, CISAS, Padova, Italy; University of Padova, CISAS, Padova, Italy; University of Padova, CISAS, Padova, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3694","3700","The inherent scale ambiguity in monocular vision is a well known issue that forces the integration of other sensory sources to obtain metric references. However, 2D or 3D LiDARs and RGB-D sensors, while guaranteeing metrological accuracy, impose a non negligible burden both in terms of computational load and power requirements limiting the feasibility of being implemented on small exploration vehicles. This paper presents a scale aware monocular Visual Odometry framework that fuses range data from a laser altimeter in order to recover and maintain a correct metric scale. The proposed Visual Odometry method consists of a keyframe based tracking and mapping algorithm using optical flow where range data serves as a scale constraint on a keyframe to keyframe basis. An optimization backend based on iSAM2 is employed in order to refine the trajectory and map estimates eliminating the scale drift without the need of performing loop closures. We demonstrate that our algorithm can obtain very similar performances to state of the art stereo visual SLAM and RGB-D methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594096","","Cameras;Laser radar;Measurement;Three-dimensional displays;Visual odometry;Visualization;Sensors","distance measurement;image sequences;mobile robots;optical radar;robot vision;SLAM (robots);stereo image processing","stereo visual SLAM;monocular vision;inherent scale ambiguity;LiDAR altimeter;scale correct monocular visual odometry;RGB-D methods;scale drift;keyframe basis;scale constraint;mapping algorithm;keyframe based tracking;Visual Odometry method;laser altimeter;range data;exploration vehicles;power requirements;computational load;metrological accuracy;RGB-D sensors;3D LiDARs;metric references;sensory sources","","","35","","","","","IEEE","IEEE Conferences"
"Soft Fabric Actuator for Robotic Applications","S. Y. Yang; K. H. Cho; Y. Kim; K. Kim; J. H. Park; H. S. Jung; J. U. Ko; H. Moon; J. C. Koo; H. Rodrigue; J. W. Suk; J. Nam; H. R. Choi","The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; The School of Mechanical Engineering; Department of Polymer Science and Engineering, Sungkyunkwan University, Chunchon-dong 300, Suwon, Korea; The School of Mechanical Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5451","5456","This paper presents a fabric actuator consisting of ordinary polymer fibers, conductive fibers, and twisted and coiled soft actuators (TCAs). Previous studies have developed a Spandex TCA (STCA) that is driven at a lower temperature than the conventional Nylon TCA and exhibits greater actuation strain. However, no method to drive STCAs via electrical joule-heating has been developed yet. The fabric actuator presented in this paper offers a solution to this problem by employing an STCA multiple fabrication method, a continuous fabrication method, bundling technology, and weaving technology. Two types of samples (cylindrical and planar) are fabricated and their performances are evaluated experimentally. From the actuation test according to the loads, the maximum contraction strain of 34.3% is measured. The repeatability is also verified through 200 cycles of actuation. Using a linearized model, the dynamic performance of the fabric actuator is predicted and compared with experimental results. An actual human arm size mannequin is driven by applying the fabric actuator, and angle control can be achieved with an encoder mounted on the joint. In addition, fabric actuator is weaved to sweater showing the possibility of wearable assistive robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594275","","Actuators;Fabrics;Fabrication;Strain;Weaving;Yarn;Connectors","electroactive polymer actuators;fabrics;microactuators;polymer fibres;polymers;wearable robots;weaving","coiled soft actuators;STCA multiple fabrication method;continuous fabrication method;actuation test;soft fabric actuator;actuation strain;robotic applications;twisted and coiled soft actuators;Spandex TCA;Nylon TCA;human arm size mannequin;angle control","","","20","","","","","IEEE","IEEE Conferences"
"A Unified Controller for Region-reaching and Deforming of Soft Objects","Z. Wang; X. Li; D. Navarro-Alarcon; Y. Liu","Department of Mechanical and Automation Engineering, The T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR; Department of Mechanical and Automation Engineering, The T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR; Department of Mechanical Engineering, Hong Kong Polytechnic University, HKSAR; Department of Mechanical and Automation Engineering, The T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","472","478","Emerging applications of robotic manipulation of deformable objects have opened up new challenges in robot control. While several control techniques have been developed to manipulate deformable objects, the performance of existing methods is commonly limited by two issues: 1) implicit assumption that the physical contact between the end-effector and the object is always maintained, and 2) requirements of exact parameters of deformation model, which are difficult to obtain. This paper presents a new control scheme for robotic manipulation of deformable objects, which allows the robot to automatically contact then actively deform the deformable object by assessing the status of deformation in real time. Instead of designing multiple controllers and switching among them, the proposed method smoothly and stably integrates two control phases (i.e. region reaching and active deforming) into a single controller. The stability of the closed-loop system is rigorously proved with the consideration of the uncertain deformation model and uncalibrated cameras. Hence, the proposed control scheme enhances the autonomous capability of active deformable object manipulation. Experimental studies are conducted with different initial conditions to demonstrate the performance of the proposed controller.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593543","","Strain;Deformable models;Cameras;End effectors;Robot vision systems;Adaptation models","cameras;closed loop systems;deformation;end effectors;manipulators;mobile robots;robot vision;stability","uncertain deformation model;active deformable object manipulation;unified controller;soft objects;robotic manipulation;robot control;region reaching;region deforming;uncalibrated cameras;closed-loop system stability;end-effector","","","28","","","","","IEEE","IEEE Conferences"
"Faster Collision Checks for Car-Like Robot Motion Planning","B. C. Heinrich; D. Fassbender; H. Wuensche","The Universität der Bundeswehr, Institute for Autonomous Systems Technology (TAS), Munich, Neubiberg, Germany; The Universität der Bundeswehr, Institute for Autonomous Systems Technology (TAS), Munich, Neubiberg, Germany; The Universität der Bundeswehr, Institute for Autonomous Systems Technology (TAS), Munich, Neubiberg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7533","7538","In this paper, we describe how collision checking for car-like robots can be sped up utilizing system knowledge. Their non-holonomic motion, while being a challenge for motion planning, is utilized here to place discs which are used as an approximation of the robot's shape in a predictive manner. For ease of comparison, we assume the robot to be rectangular, i. e., we use bounding boxes. Our algorithm is compared to a widely-used baseline and shows similar performance in terms of under- and oversampling while being approximately 20-40 % faster. Another feature of the algorithm is its predictive nature: with the frontal disc, we already check for collisions that would occur with the rear disc in the next sample, assuming near-constant curvature. While this might be conservative in some cases where large steering rates are necessary, in our evaluation even tight corridors could be navigated without negative effects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594454","","Collision avoidance;Trajectory;Shape;Planning;Robot kinematics;Tuning","collision avoidance;geometry;mobile robots;motion control","rear disc;faster collision checks;system knowledge;nonholonomic motion;motion planning;frontal disc;car-like robot motion planning;predictive algorithm","","","11","","","","","IEEE","IEEE Conferences"
"Feedback Control For Cassie With Deep Reinforcement Learning","Z. Xie; G. Berseth; P. Clary; J. Hurst; M. van de Panne","Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Dynamic Robotics Laboratory, School of Mechanical, Industrial and Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; Dynamic Robotics Laboratory, School of Mechanical, Industrial and Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1241","1246","Bipedal locomotion skills are challenging to develop. Control strategies often use local linearization of the dynamics in conjunction with reduced-order abstractions to yield tractable solutions. In these model-based control strategies, the controller is often not fully aware of many details, including torque limits, joint limits, and other non-linearities that are necessarily excluded from the control computations for simplicity. Deep reinforcement learning (DRL) offers a promising model-free approach for controlling bipedal locomotion which can more fully exploit the dynamics. However, current results in the machine learning literature are often based on ad-hoc simulation models that are not based on corresponding hardware. Thus it remains unclear how well DRL will succeed on realizable bipedal robots. In this paper, we demonstrate the effectiveness of DRL using a realistic model of Cassie, a bipedal robot. By formulating a feedback control problem as finding the optimal policy for a Markov Decision Process, we are able to learn robust walking controllers that imitate a reference motion with DRL. Controllers for different walking speeds are learned by imitating simple time-scaled versions of the original reference motion. Controller robustness is demonstrated through several challenging tests, including sensory delay, walking blindly on irregular terrain and unexpected pushes at the pelvis. We also show we can interpolate between individual policies and that robustness can be improved with an interpolated policy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593722","","Legged locomotion;Reinforcement learning;Computational modeling;Aerospace electronics;Feedback control;Trajectory","feedback;learning (artificial intelligence);legged locomotion;Markov processes;motion control;robot dynamics;velocity control","Cassie;deep reinforcement learning;bipedal locomotion skills;local linearization;reduced-order abstractions;tractable solutions;model-based control strategies;torque limits;joint limits;nonlinearities;control computations;DRL;machine learning literature;ad-hoc simulation models;realizable bipedal robots;feedback control problem;robust walking controllers;controller robustness;model-free approach","","1","21","","","","","IEEE","IEEE Conferences"
"Incremental Semi-Supervised Learning from Streams for Object Classification","I. Chiotellis; F. Zimmermann; D. Cremers; R. Triebel","Dep. of Computer Science, TU Munich, Computer Vision Group, Garching, 85748, Germany; Dep. of Computer Science, TU Munich, Computer Vision Group, Garching, 85748, Germany; Dep. of Computer Science, TU Munich, Computer Vision Group, Garching, 85748, Germany; Dep. of Computer Science, TU Munich, Computer Vision Group, Garching, 85748, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5743","5749","The Label Propagation (LP) algorithm, first introduced by Zhu and Ghahramani [1], is a semi-supervised method used in transductive learning scenarios, where all data are available already in the beginning. In this work, we present a novel extension of the LP algorithm for applications where data samples are observed sequentially - as is the case in autonomous driving. Specifically, our “Incremental Label Propagation” algorithm efficiently approximates the so called harmonic solution on a nearest-neighbor graph that is regularly updated by new labeled and unlabeled nodes. We achieve this by reformulating the original algorithm based on an active set of nodes and by introducing a threshold to decide whether the label of a given node should be updated or not. Our method can also deal with graphs that are not fully connected, and we give a formal convergence proof for this general case. In experiments on the challenging KITTI benchmark data stream, we show superior performance in terms of both test accuracy and number of required training labels compared to state-of-the-art online learning methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593901","","Harmonic analysis;Convergence;Approximation algorithms;Semisupervised learning;Benchmark testing;Training data;Clustering algorithms","graph theory;image classification;nearest neighbour methods;supervised learning","object classification;Zhu;transductive learning scenarios;LP algorithm;data samples;autonomous driving;nearest-neighbor graph;labeled nodes;unlabeled nodes;harmonic solution;KITTI benchmark data stream;label propagation algorithm;Ghahramani;formal convergence;incremental semisupervised learning","","","21","","","","","IEEE","IEEE Conferences"
"Octree map based on sparse point cloud and heuristic probability distribution for labeled images","J. S. Berrio; W. Zhou; J. Ward; S. Worrall; E. Nebot","Australian Centre for Field Robotics (ACFR), University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), University of Sydney, NSW, Australia; Australian Centre for Field Robotics (ACFR), University of Sydney, NSW, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3174","3181","To navigate through urban roads, an automated vehicle must be able to perceive and recognize objects in a three-dimensional environment. A high level contextual understanding of the surroundings is necessary to execute accurate driving maneuvers. This paper presents a novel approach to build three dimensional semantic octree maps from lidar scans and the output of a convolutional neural network (CNN) to obtain the labels of the environment. We present a heuristic method to associate uncertainties to the labels from the images based on a combination of the labels themselves, score maps retrieved by the CNN and the raw images. These uncertainties and the camera-lidar calibration parameters for multiple cameras are considered in the projection of the labels and their uncertainties into the point cloud. Every labeled lidar scan works as an input to an octree map building algorithm that calculates and updates the label probabilities of the voxels in the map. This paper also presents a qualitative and quantitative evaluation of accuracy, analyzing projection in single lidar scans and complete maps built with our probabilistic octree framework.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594024","","Three-dimensional displays;Semantics;Laser radar;Uncertainty;Octrees;Cameras;Buildings","calibration;cameras;convolutional neural nets;image recognition;object recognition;octrees;probability;stereo image processing","semantic octree maps;probabilistic octree framework;single lidar scans;octree map building algorithm;labeled lidar scan;camera-lidar calibration parameters;convolutional neural network;accurate driving maneuvers;automated vehicle;urban roads;labeled images;heuristic probability distribution;sparse point cloud","","","37","","","","","IEEE","IEEE Conferences"
"An Analytical Study on Trotting at Constant Velocity and Height","K. Machairas; E. Papadopoulos","National Technical University of Athens, School of Mechanical Engineering; National Technical University of Athens, School of Mechanical Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3279","3284","Quadrupedal trotting gaits of constant forward velocity and body height are studied. A method is developed, which is structured upon analytical expressions derived from the dynamics of a reduced single-legged model comprised of a point mass, and two actuated rotational joints. The inputs of the method include the robot mass, the leg and actuator properties, and the desired forward velocity, yielding all robot body feasible trajectories and their energy footprints. Thus, the method predicts the maximum forward velocity of a trotting quadruped; it also suggests energetically optimal combinations of body height and step length for a given forward velocity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593686","","Legged locomotion;Actuators;Trajectory;Knee;Torque;Task analysis","legged locomotion;motion control;robot dynamics","body height;quadrupedal trotting gaits;single-legged model;point mass;actuated rotational joints;robot mass;actuator properties;robot body feasible trajectories;forward velocity;leg properties","","","10","","","","","IEEE","IEEE Conferences"
"Modeling Supervisor Safe Sets for Improving Collaboration in Human-Robot Teams","D. L. McPherson; D. R. R. Scobee; J. Menke; A. Y. Yang; S. S. Sastry","Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","861","868","When a human supervisor collaborates with a team of robots, the human's attention is divided, and cognitive resources are at a premium. We aim to optimize the distribution of these resources and the flow of attention. To this end, we propose the model of an idealized supervisor to describe human behavior. Such a supervisor employs a potentially inaccurate internal model of the the robots' dynamics to judge safety. We represent these safety judgements by constructing a safe set from this internal model using reachability theory. When a robot leaves this safe set, the idealized supervisor will intervene to assist, regardless of whether or not the robot remains objectively safe. False positives, where a human supervisor incorrectly judges a robot to be in danger, needlessly consume supervisor attention. In this work, we propose a method that decreases false positives by learning the supervisor's safe set and using that information to govern robot behavior. We prove that robots behaving according to our approach will reduce the occurrence of false positives for our idealized supervisor model. Furthermore, we empirically validate our approach with a user study that demonstrates a significant (p = 0.0328) reduction in false positives for our method compared to a baseline safety controller.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593865","","Robots;Safety;Trajectory;Level set;Noise measurement;Optimal control;Optimization","cognition;human-robot interaction;mobile robots;multi-robot systems;optimisation;reachability analysis","human-robot teams;human supervisor collaborates;optimization;reachability theory;robots dynamic;robot behavior;human behavior;cognitive resources","","","20","","","","","IEEE","IEEE Conferences"
"Instance Segmentation of Visible and Occluded Regions for Finding and Picking Target from a Pile of Objects","K. Wada; S. Kitagawa; K. Okada; M. Inaba","University of Tokyo, JSK Laboratory; University of Tokyo, JSK Laboratory; University of Tokyo, JSK Laboratory; University of Tokyo, JSK Laboratory","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2048","2055","We present a robotic system for picking a target from a pile of objects that is capable of finding and grasping the target object by removing obstacles in the appropriate order. The fundamental idea is to segment instances with both visible and occluded masks, which we call `instance occlusion segmentation'. To achieve this, we extend an existing instance segmentation model with a novel `relook' architecture, in which the model explicitly learns the inter-instance relationship. Also, by using image synthesis, we make the system capable of handling new objects without human annotations. The experimental results show the effectiveness of the relook architecture when compared with a conventional model and of the image synthesis when compared to a human-annotated dataset. We also demonstrate the capability of our system to achieve picking a target in a cluttered environment with a real robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593690","","Image segmentation;Robots;Feature extraction;Object segmentation;Image generation;Task analysis;Predictive models","image motion analysis;image segmentation;learning (artificial intelligence);object detection","target object;robotic system;human-annotated dataset;human annotations;image synthesis;inter-instance relationship;novel relook architecture;instance occlusion segmentation;occluded masks","","","25","","","","","IEEE","IEEE Conferences"
"Registering Reconstructions of the Two Sides of Fruit Tree Rows","P. Roy; W. Dong; V. Isler","University of Minnesota, Department of Computer Science and Engineering, Minneapolis, MN, USA; University of Minnesota, Department of Computer Science and Engineering, Minneapolis, MN, USA; University of Minnesota, Department of Computer Science and Engineering, Minneapolis, MN, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We consider the problem of building accurate three dimensional (3D)reconstructions of orchard rows. This problem arises in many applications including yield mapping and measuring traits (e.g. trunk diameters)for phenotyping. While 3D reconstructions of side views can be obtained using standard methods, merging the two side-views is difficult due to the lack of overlap between the two partial reconstructions. We present a novel method that utilizes global features to constrain the solution. Specifically, we use information from the silhouettes and the ground plane for alignment. The method is evaluated using multiple simulated and real datasets. For additional information and demonstration of experimental results please see https://www.youtube.com/watch?v=6mGMF2gFv4M.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594167","","Image reconstruction;Three-dimensional displays;Vegetation;Principal component analysis;Shape;Semantics;Cameras","agricultural products;feature extraction;image reconstruction;image registration","three dimensionalreconstructions;reconstruction registeration;partial reconstructions;side-views;measuring traits;yield mapping;orchard rows;fruit tree","","","15","","","","","IEEE","IEEE Conferences"
"Egocentric Spatial Memory","M. Zhang; K. T. Ma; S. Yen; J. H. Lim; Q. Zhao; J. Feng","National University of Singapore (NUS), Singapore; A*AI, SCEI, I2R, A*STAR, Singapore; NUS, Singapore; A*AI, SCEI, I2R, A*STAR, Singapore; University of Minnesota, USA; NUS, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","137","144","Egocentric spatial memory (ESM) defines a memory system with encoding, storing, recognizing and recalling the spatial information about the environment from an egocentric perspective. We introduce an integrated deep neural network architecture for modeling ESM. It learns to estimate the occupancy state of the world and progressively construct top-down 2D global maps from egocentric views in a spatially extended environment. During the exploration, our proposed ESM model updates belief of the global map based on local observations using a recurrent neural network. It also augments the local mapping with a novel external memory to encode and store latent representations of the visited places over longterm exploration in large environments which enables agents to perform place recognition and hence, loop closure. Our proposed ESM network contributes in the following aspects: (1) without feature engineering, our model predicts free space based on egocentric views efficiently in an end-to-end manner; (2) different from other deep learning-based mapping system, ESMN deals with continuous actions and states which is vitally important for robotic control in real applications. In the experiments, we demonstrate its accurate and robust global mapping capacities in 3D virtual mazes and realistic indoor environments by comparing with several competitive baselines.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593435","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593435","","Computer architecture;Cameras;Navigation;Microprocessors;Sensors;Task analysis;Motion measurement","learning (artificial intelligence);mobile robots;neurophysiology;recurrent neural nets;robot vision","place recognition;robotic control;3D virtual mazes;deep learning based mapping system;ESM network;external memory;recurrent neural network;spatially extended environment;2D global maps;integrated deep neural network architecture;egocentric perspective;spatial information;memory system;egocentric spatial memory","","","34","","","","","IEEE","IEEE Conferences"
"Soft-obstacle Avoidance for Redundant Manipulators with Recurrent Neural Network","Y. Li; B. Hannaford","Department of Electrical Engineering, University of Washington, BioRobotics Lab, Seattle, WA, 98195, USA; Department of Electrical Engineering, University of Washington, BioRobotics Lab, Seattle, WA, 98195, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3022","3027","Compressing soft-obstacles secondary to a controlled motion task is common for human beings. While these tasks are nearly trivial for teleoperated robots, they remain a challenging problem in robotic autonomy. Addressing the problem is significant. For example, in Minimally Invasive Surgeries (MISs), safely compressing soft tissues ensures the surgical safety and decreases tissue removal, thus dramatically decreases surgical trauma and operating room time, and leads to improved surgical outcomes. In this work, we define the problem of soft-obstacle avoidance and project the safety motion constraints into the task space and the velocity space. We illustrate the significance of addressing this problem in the robotic surgery scenario. We present a Recurrent Neural Networks (RNNs) based solution, which formulates the problem as an inequality constrained optimization problem and solves it in its dual space. The application of the proposed method was demonstrated in the Raven II surgical robot. Experimental results demonstrated that the proposed method is effective in addressing the soft-obstacle avoidance problem.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594346","Soft Obstacle Avoidance;Autonomous Robotic Surgery;Robot Arm;Recurrent Neural Network","Surgery;Manipulators;Task analysis;Collision avoidance;Recurrent neural networks;Optimization","biological tissues;collision avoidance;medical robotics;motion control;optimisation;recurrent neural nets;redundant manipulators;surgery;telerobotics","surgical trauma;safety motion constraints;soft-obstacle avoidance problem;redundant manipulators;recurrent neural network;human beings;teleoperated robots;robotic autonomy;soft tissues;surgical safety;robotic surgery;optimization problem;minimally invasive surgeries;Raven-II surgical robot;RNNs","","1","35","","","","","IEEE","IEEE Conferences"
"Interactive Training of Object Detection Without ImageNet","E. Martinson","Soar Technologies, Ann Arbor, MI 48105, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","For many robotic tasks, particularly those of service robots operating in human environments, the scope of object detection needs is greater than the available data. Either public datasets do not contain the entire set of objects needed for the task, and/or it is a commercial application that cannot use public datasets for training. Instead of hiring people to hand-label more data to support the integration of new objects into robot perception, we propose an interactive training process requiring zero hand labeling. With as little as 4 minutes of interaction with the robot per object, we demonstrate 99% precision and 57% recall in stationary object detection tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593614","","Robots;Training;Labeling;Object detection;Task analysis;Image segmentation;Cameras","human computer interaction;interactive systems;object detection;robot vision;service robots","ImageNet;robotic tasks;service robots operating;robot perception;interactive training process;zero hand labeling;object detection","","","16","","","","","IEEE","IEEE Conferences"
"Pulleys and Force Sensors Influence on Payload Estimation of Cable-Driven Parallel Robots","É. Picard; S. Caro; F. Claveau; F. Plestan","IRT Jules Verne, Chemin du Chaffault, Bouguenais, 44340, France; UMR CNRS 6004, Laboratoire des Sciences du Numérique de Nantes, 1, rue de la Noë, Nantes, 44321, France; UMR CNRS 6004, Laboratoire des Sciences du Numérique de Nantes, 1, rue de la Noë, Nantes, 44321, France; UMR CNRS 6004, Laboratoire des Sciences du Numérique de Nantes, 1, rue de la Noë, Nantes, 44321, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1429","1436","The subject of this paper is about the use of a suspended Cable-Driven Parallel Robot (CDPR) for pick-and-place operations of heavy and heterogeneous objects. The knowledge of the payload mass and its center of mass in realtime is an asset for robust control of the device, which is required to ensure a good stability, especially when the objects have different shapes, sizes and masses. Accordingly, this paper aims at experimentally evaluating the effects of (i) the pulleys modeling and (ii) the use of force sensors for the payload estimation. It turns out that the consideration of the pulleys into the geometric model of the robot improves the mass and center of mass estimations of the payload. A comparison is made between the estimation of cable tensions from force sensors and from motor currents. Finally, a torque controller with a feedforward term for real-time mass compensation is proposed and implemented on a CDPR prototype.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594171","","Pulleys;Payloads;Mechanical cables;Estimation;Robots;Prototypes;Trajectory","cables (mechanical);feedforward;force sensors;manipulators;motion control;pulleys;robot kinematics;robust control;torque control","Cable-Driven Parallel robots;suspended Cable-Driven Parallel Robot;heavy objects;heterogeneous objects;payload mass;robust control;pulleys;payload estimation;geometric model;mass estimations;cable tensions;torque controller;real-time mass compensation;CDPR prototype;force sensors influence;pick-and-place operations","","1","18","","","","","IEEE","IEEE Conferences"
"Automated Tuning of Nonlinear Model Predictive Controller by Reinforcement Learning","M. Mehndiratta; E. Camci; E. Kayacan","School of Mechanical and Aerospace Engineering (MAE), Nanyang Technological University (NTU), 50 Nanyang Avenue, 639798, Singapore; School of Mechanical and Aerospace Engineering (MAE), Nanyang Technological University (NTU), 50 Nanyang Avenue, 639798, Singapore; Department of Engineering, Aarhus University, Aarhus, 8200, Denmark","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3016","3021","One of the major challenges of model predictive control (MPC) for robotic applications is the non-trivial weight tuning process while crafting the objective function. This process is often executed using the trial-and-error method by the user. Consequently, the optimality of the weights and the time required for the process become highly dependent on the skill set and experience of the user. In this study, we present a generic and user-independent framework which automates the tuning process by reinforcement learning. The proposed method shows competency in tuning a nonlinear MPC (NMPC) which is employed for trajectory tracking control of aerial robots. It explores the desirable weights within less than an hour in iterative Gazebo simulations running on a standard desktop computer. The real world experiments illustrate that the NMPC weights explored by the proposed method result in a satisfactory trajectory tracking performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594350","","Tuning;Rotors;Computational modeling;Optimization;Aerodynamics;Iron;Reinforcement learning","autonomous aerial vehicles;control engineering computing;iterative methods;learning (artificial intelligence);nonlinear control systems;predictive control;trajectory control","nonlinear MPC;trajectory tracking control;aerial robots;NMPC weights;automated tuning;nonlinear model predictive controller;reinforcement learning;nontrivial weight tuning process;generic user-independent framework;trial-and-error method;iterative Gazebo simulations;standard desktop computer","","","18","","","","","IEEE","IEEE Conferences"
"Contact Detection and Size Estimation Using a Modular Soft Gripper with Embedded Flex Sensors","K. Elgeneidy; G. Neumann; S. Pearson; M. Jackson; N. Lohse","Lincoln Institute for Agri-Food Technology, University of Lincoln, United Kingdom; Lincoln Centre for Autonomous Systems, School of Computer Science, University of Lincoln, United Kingdom; Lincoln Institute for Agri-Food Technology, University of Lincoln, United Kingdom; Electrical and Manufacturing Engineering, Loughborough University, Wolfson School of Mechanical, United Kingdom; Electrical and Manufacturing Engineering, Loughborough University, Wolfson School of Mechanical, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","498","503","Grippers made from soft elastomers are able to passively and gently adapt to their targets allowing deformable objects to be grasped safely without causing bruise or damage. However, it is difficult to regulate the contact forces due to the lack of contact feedback for such grippers. In this paper, a modular soft gripper is presented utilizing interchangeable soft pneumatic actuators with embedded flex sensors as fingers of the gripper. The fingers can be assembled in different configurations using 3D printed connectors. The paper investigates the potential of utilizing the simple sensory feedback from the flex and pressure sensors to make additional meaningful inferences regarding the contact state and grasped object size. We study the effect of the grasped object size and contact type on the combined feedback from the embedded flex sensors of opposing fingers. Our results show that a simple linear relationship exists between the grasped object size and the final flex sensor reading at fixed input conditions, despite the variation in object weight and contact type. Additionally, by simply monitoring the time series response from the flex sensor, contact can be detected by comparing the response to the known free-bending response at the same input conditions. Furthermore, by utilizing the measured internal pressure supplied to the soft fingers, it is possible to distinguish between power and pinch grasps, as the contact type affects the rate of change in the flex sensor readings against the internal pressure.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593399","","Grippers;Sensors;Flexible printed circuits;Grasping;Thumb;Three-dimensional displays","bending;biomechanics;deformation;elastomers;feedback;grippers;mechanical contact;pneumatic actuators;pressure sensors;sensors;time series","modular soft gripper;utilizing interchangeable soft pneumatic actuators;embedded flex sensors;simple sensory feedback;pressure sensors;contact state;grasped object size;contact type;final flex sensor;object weight;soft fingers;flex sensor readings;soft elastomers;deformable objects;contact forces;contact feedback","","","24","","","","","IEEE","IEEE Conferences"
"Machine Learning Based Skill-Level Classification for Personal Mobility Devices Using Only Operational Characteristics","Y. Huang; T. Mori; U. E. Manawadu; M. Kamezaki; T. Ishihara; M. Nakano; K. Koshiji; N. Higo; T. Tubaki; S. Sugano","Depart. Modern Mechanical Engineering Waseda Univ, Graduate School of Creative Science and Engineering, 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Depart. Modern Mechanical Engineering Waseda Univ, Graduate School of Creative Science and Engineering, 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Depart. Modern Mechanical Engineering Waseda Univ, Graduate School of Creative Science and Engineering, 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Waseda University, Research Institute for Science and Engineering (RISE), 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Network Robot & Gadget Project NTT Corporation, NTT Service Evolution Laboratories, 1–1 Hikarinooka, Yokosuka-Shi, Kanacawa, 219-0847, Japan; Network Robot & Gadget Project NTT Corporation, NTT Service Evolution Laboratories, 1–1 Hikarinooka, Yokosuka-Shi, Kanacawa, 219-0847, Japan; Network Architecture Innovation Project NTT Corporation, NTT Network Technology Laboratories, 3-9-11 Midori-cho, Musashino-shi, Tokyo, 180-8585, Japan; Network Architecture Innovation Project NTT Corporation, NTT Network Technology Laboratories, 3-9-11 Midori-cho, Musashino-shi, Tokyo, 180-8585, Japan; Network Architecture Innovation Project NTT Corporation, NTT Network Technology Laboratories, 3-9-11 Midori-cho, Musashino-shi, Tokyo, 180-8585, Japan; Department of Modern Mechanical Engineering Waseda University, School of Creative Science and Engineering, 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5469","5476","Some electric-powered wheelchairs are recently redefined as personal mobility devices. Their users are not only elderly or handicapped people, but also passengers with large baggage or pedestrians going from station to destination, i.e., last-mile transport. Consequently, people with different operation skills and expectations on personal mobility would become new users of this kind of devices. Safe and comfort travel in human co-existing environment such as sidewalks and airports is a social expectation for personal mobility. In order to realize this, understanding the operation skill of each user by a practical and simple method is essential. This paper thus introduced a skill level classification method by machine learning using only joystick data as input. In order to determine the number of skill level clusters, basic 26 features of joystick operation data are used for unsupervised clustering (single-linkage). We then made evaluation indexes by using speed, speed control, and direction control. For a five-level classification by using gradient boosting as supervised learning, we achieved a 67% accuracy (tolerance: 0) and a 98% accuracy (tolerance: 1). Further analysis of the feature importance of gradient boosting revealed key features to a good operation. Results also show that skill level differed among people with different driving experiences.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593578","","Boosting;Vehicles;Sensors;Feature extraction;Acceleration","electric vehicles;handicapped aids;learning (artificial intelligence);pattern classification;wheelchairs","machine learning;skill-level classification;personal mobility devices;operational characteristics;electric-powered wheelchairs;handicapped people;comfort travel;skill level classification method;skill level clusters;joystick operation data;five-level classification;supervised learning;user operation skills;unsupervised clustering;speed control;direction control;gradient boosting","","","25","","","","","IEEE","IEEE Conferences"
"Imitation Learning for Object Manipulation Based on Position/Force Information Using Bilateral Control","T. Adachi; K. Fujimoto; S. Sakaino; T. Tsuji","Department of Electronic Information System, School of Science and Technology, Saitama University, Saitama, 338-8570, Japan; Faculty of Engineering, Department of Electrical and Electonic Engineering, Saitama University, Saitama, 338-8570, Japan; Department of Electronic Information System, School of Science and Technology, Saitama University, Saitama, 338-8570, Japan; Department of Electronic Information System, School of Science and Technology, Saitama University, Saitama, 338-8570, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3648","3653","This study proposes an imitation learning method based on force and position information. Force information is required for precise object manipulation but is difficult to obtain because the acting and reaction forces cannot be separated. To separate the forces, we proposed to introduce bilateral control, in which the acting and reaction forces are divided using two robots. In the proposed method, two models of neural networks learn a task; to draw a line along a ruler. We verify the possibility that force information is essential to imitate the human skill of object manipulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594489","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594489","","Force;Torque;Predictive models;Manipulators;Angular velocity;Control systems","control engineering computing;force control;learning (artificial intelligence);manipulators;neural nets;position control","bilateral control;imitation learning method;position information;precise object manipulation;neural networks;robots;position-force information","","","22","","","","","IEEE","IEEE Conferences"
"An Adjustable Force Sensitive Sensor with an Electromagnet for a Soft, Distributed, Digital 3-axis Skin Sensor","A. C. Holgado; J. A. Alvarez Lopez; A. Schmitz; T. P. Tomo; S. Somlor; L. Jamone; S. Sugano","Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, Tokyo, Japan; Lorenzo Jamone is with ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, London, E14NS, UK; Faculty of Science and Engineering, Modern Mechanical Engineering, Waseda University, Tokyo, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2582","2588","Typically, the range and sensitivity of force sensors are determined during production. However, to be able to do both delicate and high-force demanding work, adjustable force sensitivity would be beneficial. The current paper proposes such a sensor by implementing a planar electromagnet above a 3-axis magnetic sensor, separated by soft foam. Furthermore, the sensor has digital output with an integrated microcontroller. The magnetic field strength with varying currents is examined in simulation, and the field changes according to displacements are investigated both in simulation and with the actual sensor. A prototype 3-axis force sensor is implemented and the relationship between the magnetic field change and the corresponding applied force is also investigated. It could be shown that the sensitivity of the sensor to displacements, as well as force, can indeed be adjusted.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593757","","Robot sensing systems;Sensitivity;Magnetometers;Magnetic separation;Coils;Force","distributed sensors;electromagnets;foams;force measurement;force sensors;magnetic field measurement;magnetic sensors;microcontrollers;microsensors;skin","3-axis force sensor;soft distributed digital 3-axis skin sensor;integrated microcontroller;adjustable force sensitive sensor;magnetic field strength;soft foam;3-axis magnetic sensor;planar electromagnet","","","24","","","","","IEEE","IEEE Conferences"
"Adaptive Baseline Monocular Dense Mapping with Inter-Frame Depth Propagation","K. Wang; S. Shen","Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3225","3232","State-of-the-art monocular dense mapping methods usually divide the image sequence into several separate multi-view stereo problems thus have limited utilization of the information in multi-baseline observations and sequential depth estimations. In this paper, two core contributions are proposed to improve the mapping performance by exploiting the information. The first is an adaptive baseline matching cost computation that uses the sequential input images to provide each pixel with wide-baseline observations. The second is a frame-to-frame propagated depth filter which integrates the sequential depth estimation of the same physical point in a robust probabilistic manner. Two contributions are integrated into a monocular dense mapping system that generates the depth maps in real-time for both pinhole and fisheye cameras. Our system is fully parallelized and can run at more than 25 fps on a Nvidia Jetson TX2. We compare our work with state-of-the-art methods on the public dataset. Onboard UAV mapping and handhold experiments are also used to demonstrate the performance of our method. For the benefit of the community, we make the implementation open source.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593936","","Estimation;Cameras;Probabilistic logic;Adaptive systems;Image sequences;Real-time systems;Robot vision systems","image matching;image reconstruction;image sequences;stereo image processing","monocular dense mapping methods;frame-to-frame propagated depth filter;wide-baseline observations;sequential input images;adaptive baseline matching cost computation;sequential depth estimation;multibaseline observations;separate multiview stereo problems;image sequence;inter-frame depth propagation;adaptive baseline monocular dense mapping","","","18","","","","","IEEE","IEEE Conferences"
"Development of MR Clutch for a Prospective 5 DOF Robot* This work was supported in part by Canada Foundation for Innovation (CFI) and Natural Sciences and Engineering Research Council (NSERC) of Canada under grant No.25031 and RGPIN-346166.","S. Pisetskiy; M. R. Kermani","University of Western, Electrical and Computer Engineering Department, London, ON, N6A 5B9, Canada; University of Western, Electrical and Computer Engineering Department, London, ON, N6A 5B9, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5900","5905","This paper presents an improved design approach for the construction of a Magneto-Rheological (MR) clutch intended to be used in a prospective 5 degrees of freedom robot. The MR clutch features embedded Hall sensors for intrinsic torque control. After a brief description of the MR clutch principles, the details of the mechanical design are discussed. Simulation and preliminary experimental results demonstrate the main characteristics and advantages of the proposed MR clutch.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593582","","Torque;Magnetic sensors;Stators;Rotors;Robots;Wires","clutches;design engineering;Hall effect transducers;intelligent sensors;machine control;magnetorheology;torque control","intrinsic torque control;mechanical design;prospective 5 DOF robot;MR clutch;magneto-rheological clutch;prospective 5 degrees of freedom robot;embedded Hall sensors","","","25","","","","","IEEE","IEEE Conferences"
"Temporally Smooth Privacy-Protected Airborne Videos","O. Sarwar; A. Cavallaro; B. Rinner","Alpen-Adria-Universität Klagenfurt, Institute of Networked and Embedded Systems, Austria; Queen Mary University of London, Centre for Intelligent Sensing, United Kingdom; Alpen-Adria-Universität Klagenfurt, Institute of Networked and Embedded Systems, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6728","6733","Recreational videography from small drones can capture bystanders who may be uncomfortable about appearing in those videos. Existing privacy filters, such as scrambling and hopping blur, address this issue through de-identification but generate temporal distortions that manifest themselves as flicker. To address this problem, we present a robust spatiotemporal hopping blur filter that protects privacy through de-identification of face regions. The proposed filter is meant for on-board installation and produces temporally smooth and pleasant videos. We apply hopping blur to protect each frame against identification attacks, and minimise artefacts and flicker introduced by the hopping blur. We evaluate the proposed filter against different identification attacks and by assessing the quality of the resulting videos using a subjective test and objective measures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594493","","Face;Privacy;Videos;Probes;Distortion;Detectors;Smoothing methods","data privacy;image restoration;spatiotemporal phenomena;video signal processing","recreational videography;drones;privacy filters;flicker;privacy-protected airborne videos;identification attacks;spatiotemporal hopping blur filter","","","19","","","","","IEEE","IEEE Conferences"
"OpenSeqSLAM2.0: An Open Source Toolbox for Visual Place Recognition Under Changing Conditions","B. Talbot; S. Garg; M. Milford","Queensland University of Technology (QUT), School of Electrical Engineering and Computer Science, Brisbane, Australia; Queensland University of Technology (QUT), ARC Centre of Excellence for Robotic Vision, Brisbane, Australia; Queensland University of Technology (QUT), ARC Centre of Excellence for Robotic Vision, Brisbane, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7758","7765","Visually recognising a traversed route - regardless of whether seen during the day or night, in clear or inclement conditions, or in summer or winter - is an important capability for navigating robots. Since SeqSLAM was introduced in 2012, a large body of work has followed exploring how robotic systems can use the algorithm to meet the challenges posed by navigation in changing environmental conditions. The following paper describes OpenSeqSLAM2.0, a fully open-source toolbox for visual place recognition under changing conditions. Beyond the benefits of open access to the source code, OpenSeqSLAM2.0 provides a number of tools to facilitate exploration of the visual place recognition problem and interactive parameter tuning. Using the new open source platform, it is shown for the first time how comprehensive parameter characterisations provide new insights into many of the system components previously presented in ad hoc ways and provide users with a guide to what system component options should be used under what circumstances and why.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593761","","Visualization;Robots;Tools;Open source software;Search methods;Trajectory;Heuristic algorithms","image recognition;mobile robots;navigation;object recognition;public domain software;robot vision;SLAM (robots)","open source toolbox;changing conditions;traversed route;inclement conditions;navigating robots;robotic systems;environmental conditions;fully open-source toolbox;open access;source code;visual place recognition problem;open source platform;OpenSeqSLAM2.0","","","39","","","","","IEEE","IEEE Conferences"
"Dolphin: A Task Orchestration Language for Autonomous Vehicle Networks","K. Lima; E. R. B. Marques; J. Pinto; J. B. Sousa","Faculdade de Engenharia da Universidade do Porto, Laboratório de Sistemas e Tecnologia Subaquática, Portugal; Faculdade de Ciências da Universidade do Porto, CRACS/INESC-TEC, Portugal; Faculdade de Engenharia da Universidade do Porto, Laboratório de Sistemas e Tecnologia Subaquática, Portugal; Faculdade de Engenharia da Universidade do Porto, Laboratório de Sistemas e Tecnologia Subaquática, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","603","610","We present Dolphin, an extensible programming language for autonomous vehicle networks. A Dolphin program expresses an orchestrated execution of tasks defined compositionally for multiple vehicles. Building upon the base case of elementary one-vehicle tasks, the built-in operators include support for composing tasks in several forms, for instance according to concurrent, sequential, or event-based task flow. The language is implemented as a Groovy DSL, facilitating extension and integration with external software packages, in particular robotic toolkits. The paper describes the Dolphin language, its integration with an open-source toolchain for autonomous vehicles, and results from field tests using unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594059","","Task analysis;Dolphins;DSL;Autonomous vehicles;Engines;Runtime;Java","autonomous aerial vehicles;autonomous underwater vehicles;control engineering computing;public domain software;software packages;specification languages","unmanned aerial vehicles;task orchestration language;autonomous vehicle networks;extensible programming language;Dolphin program;orchestrated execution;multiple vehicles;one-vehicle tasks;event-based task flow;Dolphin language;autonomous vehicles;unmanned underwater vehicles;Groovy DSL;software packages;robotic toolkits;open-source toolchain","","","29","","","","","IEEE","IEEE Conferences"
"Lightweight and Compliant Long Reach Aerial Manipulator for Inspection Operations","A. Suarez; P. Sanchez-Cuevas; M. Fernandez; M. Perez; G. Heredia; A. Ollero","University of Seville, Robotics, Vision and Control Group, Spain; University of Seville, Robotics, Vision and Control Group, Spain; University of Seville, Robotics, Vision and Control Group, Spain; University of Seville, Robotics, Vision and Control Group, Spain; University of Seville, Robotics, Vision and Control Group, Spain; University of Seville, Robotics, Vision and Control Group, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6746","6752","The proximity between the multirotor blades and the environmental obstacles restricts the application of aerial manipulators in inspection tasks due to the risk of impacts, the limitation in the reach of the arm, and the physical interactions. This paper presents a long reach aerial manipulator consisting of a hexarotor platform equipped with a 2-DOF compliant joint arm attached at the tip of a one-meter-length link in passive pendulum configuration. The arm integrates magnetic encoders for force/torque estimation-control based on joint deflection, a range sensor in the forearm link for measuring the distance to the contact point, and a camera for visual inspection. A 2-DOF wearable exoskeleton interface has been developed, allowing the teleoperation of the arm with visual feedback in a more intuitive way. The paper also covers the kinematics and dynamics of the aerial manipulator, including the dynamics of the flexible long reach link. The developed system has been evaluated in test-bench and in outdoor flight tests.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593940","","Manipulator dynamics;Inspection;Robot sensing systems;Visualization;Exoskeletons;Cameras","actuators;autonomous aerial vehicles;feedback;industrial manipulators;inspection;manipulator dynamics;manipulator kinematics;mobile robots;motion control;pendulums;position control;torque control","inspection operations;multirotor blades;environmental obstacles;inspection tasks;long reach aerial manipulator;hexarotor platform;compliant joint arm;one-meter-length link;passive pendulum configuration;force/torque estimation-control;joint deflection;visual inspection;wearable exoskeleton interface;aerial manipulator kinematics;aerial manipulator dynamics","","","20","","","","","IEEE","IEEE Conferences"
"Obstacle Detection for USVs by Joint Stereo-View Semantic Segmentation","B. Bovcon; M. Kristan","Faculty of Computer and Information Science, University of Ljubljana, Slovenia; Faculty of Computer and Information Science, University of Ljubljana, Slovenia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5807","5812","We propose a stereo-based obstacle detection approach for unmanned surface vehicles. Obstacle detection is cast as a scene semantic segmentation problem in which pixels are assigned a probability of belonging to water or non-water regions. We extend a single-view model to a stereo system by adding a constraint which prefers consistent class labels assignment to pixels in the left and right camera images corresponding to the same parts of a 3D scene. Our approach jointly fits a semantic model to both images, leading to an improved class-label posterior map from which obstacles and water edge are extracted. In overall F-measure, our approach outperforms the current state-of-the-art monocular approach by 0.495, a monocular CNN by 0.798 and their stereo extensions by 0.059 and 0.515, respectively on the task of obstacle detection while running real-time on a single CPU.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594238","","Semantics;Image segmentation;Cameras;Image edge detection;Sea surface;Graphical models;Three-dimensional displays","cameras;collision avoidance;control engineering computing;convolutional neural nets;edge detection;image segmentation;mobile robots;remotely operated vehicles;robot vision;stereo image processing","water edge;stereo extensions;joint stereo-view semantic segmentation;unmanned surface vehicles;scene semantic segmentation problem;single-view model;consistent class labels assignment;monocular CNN;class-label posterior map;stereo-based obstacle detection","","","21","","","","","IEEE","IEEE Conferences"
"Design of Extra Robotic Legs for Augmenting Human Payload Capabilities by Exploiting Singularity and Torque Redistribution","D. J. Gonzalez; H. H. Asada","Department of Mechanical Engineering, D'Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Department of Mechanical Engineering, D'Arbeloff Laboratory for Information Systems and Technology, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4348","4354","We present the design of a new robotic human augmentation system that will assist the operator in carrying a heavy payload, reaching and maintaining difficult postures, and ultimately better performing their job. The Extra Robotic Legs (XRL) system is worn by the operator and consists of two articulated robotic legs that move with the operator to bear a heavy payload. The design was driven by a need to increase the effectiveness of hazardous material emergency response personnel who are encumbered by their personal protective equipment (PPE). The legs will ultimately walk, climb stairs, crouch down, and crawl with the operator while eliminating all external PPE loads on the operator. The forces involved in the most extreme loading cases were analyzed to find an effective strategy for reducing actuator loads. The analysis reveals that the maximum torque is exerted during the transition from the crawling to standing mode of motion. Peak torques are significantly reduced by leveraging redundancy in force application resulting from a closed-loop kinematic chain formed by a particular posture of the XRL. The actuators, power systems, and transmission elements were designed from the results of these analyses. Using differential mechanisms to combine the inputs of multiple actuators into a single degree of freedom, the gear reductions needed to bear the heavy loads could be kept at a minimum, enabling high bandwidth force control due to the near-direct-drive transmission. A prototype was fabricated utilizing the insights gained from these analyses and initial tests indicate the feasibility of the XRL system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593506","Human Augmentation;Supernumerary Robotic Limbs;Exoskeletons;Mechanism Design;Industrial Robotics","Legged locomotion;Payloads;Kinematics;Force;Torque;Actuators","actuators;closed loop systems;design engineering;force control;gears;industrial robots;legged locomotion;manipulator kinematics;motion control;torque control;wearable robots","force control;PPE loads;extra robotic legs system;hazardous material emergency;gear reductions;XRL system;power systems;closed-loop kinematic chain;actuator loads;personal protective equipment;robotic human augmentation system;torque redistribution","","1","18","","","","","IEEE","IEEE Conferences"
"SEAR: A Polynomial- Time Multi-Robot Path Planning Algorithm with Expected Constant-Factor Optimality Guarantee","S. D. Han; E. J. Rodriguez; J. Yu","Department of Computer Science’ Rutgers, The State University of New Jersey, Piscataway, NJ, USA; Department of Mathematics, University of California Berkeley, Berkeley, CA, USA; Department of Computer Science’ Rutgers, The State University of New Jersey, Piscataway, NJ, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We study the labeled multi-robot path planning problem in continuous 2D and 3D domains in the absence of obstacles where robots must not collide with each other. For an arbitrary number of robots in arbitrary initial and goal arrangements, we derive a polynomial time, complete algorithm that produces solutions with constant-factor optimality guarantees on both makespan and distance optimality, in expectation, under the assumption that the robot labels are uniformly randomly distributed. Our algorithm only requires a small constant-factor expansion of the initial and goal configuration footprints for solving the problem, i.e., the problem can be solved in a fairly small bounded region. Beside theoretical guarantees, we present a thorough computational evaluation of the proposed solution. In addition to the baseline implementation, adapting an effective (but non-polynomial time) routing subroutine, we also provide a highly efficient implementation that quickly computes near-optimal solutions. Hardware experiments on the microMVP platform composed of non-holonomic robots confirms the practical applicability of our algorithmic pipeline.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594417","","Robots;Path planning;Collision avoidance;Labeling;Routing;Pipelines;Planning","computational complexity;graph theory;mobile robots;multi-robot systems;optimisation;path planning;statistical distributions","polynomial-time multirobot path planning algorithm;expected constant-factor optimality guarantee;arbitrary initial goal arrangements;continuous 2D domains;continuous 3D domains;uniformly randomly distributed;microMVP platform;nonholonomic robots;near-optimal solutions;nonpolynomial time;initial goal configuration footprints;constant-factor expansion","","","54","","","","","IEEE","IEEE Conferences"
"An Ungrounded Master Device for Tele-Microassembly","S. Sakr; T. Daunizeau; D. Reversat; S. Régnier; S. Haliyo","Institut des Systemes Intelligents et de Robotique, ASorbonne Université, CNRS, ISIR, Paris, F-75005, France; Institut des Systemes Intelligents et de Robotique, ASorbonne Université, CNRS, ISIR, Paris, F-75005, France; Institut des Systemes Intelligents et de Robotique, ASorbonne Université, CNRS, ISIR, Paris, F-75005, France; Institut des Systemes Intelligents et de Robotique, ASorbonne Université, CNRS, ISIR, Paris, F-75005, France; Institut des Systemes Intelligents et de Robotique, ASorbonne Université, CNRS, ISIR, Paris, F-75005, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Micro-assembly is a challenging issue for automation due to particularities of micro-world physics and limitations on sensors. Consequently, most applications are human-operated often with basic joystick-like interfaces. Beside being nonintuitive, these solutions do not provide their users with a meaningful insight into the microworld. This paper proposes a novel intuitive remote handling interface, using a classical hand-held assembly tool as a paradigm. The master device is a portable instrumented tweezers with one active degree of freedom. Its spatial motion, tracked by optical means, controls the slave kinematics while its pinch commands the slave robot's microgripper and provides haptic feedback. Different coupling strategies using position or speed variables are demonstrated.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594063","","Tracking;Haptic interfaces;Robot sensing systems;Force;Tools","grippers;haptic interfaces;manipulator kinematics;microassembling;micromanipulators;position control;robotic assembly;telerobotics;velocity control","ungrounded master device;tele-microassembly;intuitive remote handling interface;portable instrumented tweezers;spatial motion;slave kinematics;slave robot;hand-held assembly tool;joystick-like interfaces;microgripper;haptic feedback;position variables;speed variables","","","18","","","","","IEEE","IEEE Conferences"
"Accelerating Learning in Constructive Predictive Frameworks with the Successor Representation","C. Sherstan; M. C. Machado; P. M. Pilarskir","University of Alberta, Canada; University of Alberta, Canada; University of Alberta, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2997","3003","We propose using the Successor Representation (SR) to accelerate learning in a constructive knowledge system based on General Value Functions (GVFs). In real-world settings, like robotics for unstructured and dynamic environments, it is impossible to model all meaningful aspects of a system and its environment by hand. Instead, robots must learn and adapt to changes in their environment and task, incrementally constructing models from their own experience. GVFs, taken from the field of reinforcement learning (RL), are a way of modeling the world as predictive questions. One approach to such models proposes a massive network of interconnected and interdependent GVFs, which are incrementally added over time. It is reasonable to expect that new, incrementally added predictions can be learned more swiftly if the learning process leverages knowledge gained from past experience. The SR provides a means of capturing regularities that can be reused across multiple GVFs by separating the dynamics of the world from the prediction targets. As a primary contribution of this work, we show that using the SR can improve sample efficiency and learning speed of GVFs in a continual learning setting where new predictions are incrementally added and learned over time. We analyze our approach in a grid-world and then demonstrate its potential on data from a physical robot arm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594242","","Robots;Prediction algorithms;Function approximation;Acceleration;Approximation algorithms;Standards;Adaptation models","computer aided instruction;learning (artificial intelligence);mobile robots;robot programming","unstructured environments;dynamic environments;reinforcement learning;predictive questions;massive network;interconnected GVFs;interdependent GVFs;SR;continual learning;physical robot arm;constructive predictive frameworks;constructive knowledge system;general value functions;successor representation;accelerated learning","","","30","","","","","IEEE","IEEE Conferences"
"ArduSoar: An Open-Source Thermalling Controller for Resource-Constrained Autopilots","S. Tabor; I. Guilliard; A. Kolobov","Australian National University, Glasgow, Scotland; Australian National University, Canberra, Australia; Microsoft Research, Redmond, WA, 98052","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6255","6262","Autonomous soaring capability has the potential to significantly increase time aloft for fixed-wing UAVs. In this paper, we introduce ArduSoar, the first soaring controller integrated into a major autopilot software suite for small UAVs. We describe ArduSoar from the algorithmic standpoint, outline its integration with the ArduPlane autopilot, discuss parameter tuning for it, and conduct a series of flight tests on real sUAVs that show ArduSoar's robustness even in highly nonideal atmospheric conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593510","","Aircraft;Atmospheric modeling;Computational modeling;Kalman filters;Mathematical model;Heating systems;Earth","aerospace components;aerospace simulation;aircraft control;autonomous aerial vehicles","resource-constrained autopilots;autonomous soaring capability;soaring controller;autopilot software suite;algorithmic standpoint;ArduPlane autopilot;parameter tuning;open-source thermalling controller;fixed-wing UAV;ArduSoars robustness","","","18","","","","","IEEE","IEEE Conferences"
"Sliding-Layer Laminates: A Robotic Material Enabling Robust and Adaptable Undulatory Locomotion","M. Jiang; N. Gravish","Department of Mechanical and Aerospace Engineering, University of California at San Diego, La Jolla, 9500 Gilman Dr, CA 92093, USA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5944","5951","Continuum robots that move through undulatory actuation must be composed of body materials that can enable flexible movement yet also provide resistive forces to the surrounding fluid, granular, or solid environments. This need for “f1exible-yet-stiff” materials is notably important in robot designs that use passive propulsive elements such as tails and wings. Here we explore a laminate design paradigm for “f1exible-yet-stiff” robotic materials through sliding layer laminates (SLLs). We present design principles motivated by theory and experiment and illustrate a taxonomy of SLL enabled morphable materials capable of up to 7 fold change in stiffness. Lastly, we demonstrate the applicability of SLLs to undulatory continuum robots: a swimming robot with a passive tail. We target two desired robot locomotor behaviors: fast open water swimming, and steady swimming through narrow channels emulating underwater caverns and pipes. We demonstrate how tuning the stiffness of the robot tail maximizes thrust generation in these two locomotion modes. Soft tails are optimal in confined swimming because they generate short amplitude high wavenumber oscillations, while stiff tails in confined environments either collide with the walls or do not generate sufficient thrust. However, stiff tails are far better in unconfined environments which enable large stroke amplitudes requiring high stiffness. Through this demonstration we show that stiff or soft tail designs alone are incapable of effective locomotion in complex underwater environments challenge.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594421","","Laminates;Structural beams;Springs;Jamming;Service robots;Laser beams","elasticity;hydrodynamics;marine control;mobile robots;motion control","sliding-layer laminates;robotic material enabling robust;adaptable undulatory locomotion;continuum robots;undulatory actuation;body materials;flexible movement;resistive forces;surrounding fluid;solid environments;robot designs;passive propulsive elements;wings;laminate design paradigm;f1exible-yet-stiff robotic materials;SLLs;design principles;morphable materials;swimming robot;passive tail;water swimming;steady swimming;robot tail;locomotion modes;confined swimming;confined environments;high stiffness;stiff tail designs;soft tail designs;complex underwater environments;robot locomotor;flexible-yet-stiff materials","","","30","","","","","IEEE","IEEE Conferences"
"Establishing Appropriate Trust via Critical States","S. H. Huang; K. Bhatia; P. Abbeel; A. D. Dragan","ECS, University of California, Berkeley; ECS, University of California, Berkeley; ECS, University of California, Berkeley; ECS, University of California, Berkeley","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3929","3936","In order to effectively interact with or supervise a robot, humans need to have an accurate mental model of its capabilities and how it acts. Learned neural network policies make that particularly challenging. We propose an approach for helping end-users build a mental model of such policies. Our key observation is that for most tasks, the essence of the policy is captured in a few critical states: states in which it is very important to take a certain action. Our user studies show that if the robot shows a human what its understanding of the task's critical states is, then the human can make a more informed decision about whether to deploy the policy, and if she does deploy it, when she needs to take control from it at execution time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593649","","Autonomous automobiles;Cognitive science;Task analysis;Automobiles;Reinforcement learning;Entropy","learning (artificial intelligence);neural nets;robots;trusted computing","appropriate trust;critical states;learned neural network policies;end-users;mental model;robot learning","","2","26","","","","","IEEE","IEEE Conferences"
"Semantic Monocular SLAM for Highly Dynamic Environments","N. Brasch; A. Bozic; J. Lallemand; F. Tombari","BMW AG, Munich, 80788, Germany; Department of Computer Science, Technical University Munich, Boltzmannstr.3, Garching, 85748, Germany; BMW AG, Munich, 80788, Germany; Department of Computer Science, Technical University Munich, Boltzmannstr.3, Garching, 85748, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","393","400","Recent advances in monocular SLAM have enabled real-time capable systems which run robustly under the assumption of a static environment, but fail in presence of dynamic scene changes and motion, since they lack an explicit dynamic outlier handling. We propose a semantic monocular SLAM framework designed to deal with highly dynamic environments, combining feature-based and direct approaches to achieve robustness under challenging conditions. The proposed approach exploits semantic information extracted from the scene within an explicit probabilistic model, which maximizes the probability for both tracking and mapping to rely on those scene parts that do not present a relative motion with respect to the camera. We show more stable pose estimation in dynamic environments and comparable performance to the state of the art on static sequences on the Virtual KITTI and Synthia datasets.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593828","","Semantics;Simultaneous localization and mapping;Feature extraction;Dynamics;Cameras;Pose estimation;Probabilistic logic","cameras;feature extraction;image motion analysis;image sequences;mobile robots;object detection;object tracking;pose estimation;probability;robot vision;SLAM (robots)","static environment;semantic monocular SLAM framework;semantic information;explicit probabilistic model;dynamic environments;Virtual KITTI;Synthia datasets;pose estimation","","","26","","","","","IEEE","IEEE Conferences"
"Towards Real-Time Physical Human-Robot Interaction Using Skeleton Information and Hand Gestures","O. Mazhar; S. Ramdani; B. Navarro; R. Passama; A. Cherubini","CNRS, LIRMM Université de Montpellier, Montpellier, France; CNRS, LIRMM Université de Montpellier, Montpellier, France; CNRS, LIRMM Université de Montpellier, Montpellier, France; CNRS, LIRMM Université de Montpellier, Montpellier, France; CNRS, LIRMM Université de Montpellier, Montpellier, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","For successful physical human-robot interaction, the capability of a robot to understand its environment is imperative. More importantly, the robot should extract from the human operator as much information as possible. A reliable 3D skeleton extraction is essential for a robot to predict the intentions of the operator while s/he moves toward the robot or performs a meaningful gesture. For this purpose, we have integrated a time-of-flight depth camera with a state-of-the-art 2D skeleton extraction library namely Openpose, to obtain 3D skeletal joint coordinates reliably. We have also developed a robust and rotation invariant (in the coronal plane)hand gesture detector using a convolutional neural network. At run time (after having been trained)the detector does not require any pre-processing of the hand images. A complete pipeline for skeleton extraction and hand gesture recognition is developed and employed for real-time physical human-robot interaction, demonstrating the promising capability of the designed framework. This work establishes a firm basis and will be extended for the development of intelligent human intention detection in physical human-robot interaction scenarios, to efficiently recognize a variety of static as well as dynamic gestures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594385","","Robot sensing systems;Skeleton;Robot kinematics;Gesture recognition;Human-robot interaction;Three-dimensional displays","cameras;feature extraction;feedforward neural nets;gesture recognition;human-robot interaction;robot vision","l physical human-robot interaction;dynamic gestures;human-robot interaction scenarios;intelligent human intention detection;hand gesture recognition;hand images;3D skeletal joint coordinates;state-of-the-art 2D skeleton extraction library;time-of-flight depth camera;meaningful gesture;reliable 3D skeleton extraction;human operator;skeleton information;towards real-time physical human-robot interaction","","1","17","","","","","IEEE","IEEE Conferences"
"TacWhiskers: Biomimetic Optical Tactile Whiskered Robots","N. F. Lepora; M. Pearson; L. Cramphorn","Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, Bristol, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7628","7634","Here we propose and investigate a novel vibrissal tactile sensor - the Tac Whisker array - based on modifying a 3D-printed optical cutaneous (fingertip) tactile sensor - the TacTip. Two versions are considered: a static Tac Whisker array analogous to immotile tactile vibrissae (e.g. rodent microvib-rissae) and a dynamic Tac Whisker array analogous to motile tactile vibrissae (e.g. rodent macrovibrissae). Performance is assessed on an active object localization task. The whisking motion of the dynamic Tac Whisker leads to millimetre-scale location perception, whereas perception with the static Tac Whisker array is relatively poor when making dabbing contacts. The dynamic sensor output is dominated by a self-generated motion signal, which can be compensated by comparing to a reference signal. Overall, the Tac Whisker arrays give a new class of tactile whiskered robots that benefit from being relatively inexpensive and customizable. Furthermore, the biomimetic basis for the Tac Whiskers fits well with building an embodied model of the rodent sensory system for investigating animal perception.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593653","","Pins;Rodents;Tendons;Dynamics;Tactile sensors","biomimetics;mobile robots;tactile sensors","optical cutaneous tactile sensor;static Tac Whisker array;immotile tactile vibrissae;dynamic Tac Whisker array;dynamic sensor output;Tac Whiskers;biomimetic optical tactile whiskered robots;vibrissal tactile sensor;3D-printed optical cutaneous tactile sensor;TacTip;active object localization task","","","20","","","","","IEEE","IEEE Conferences"
"Kinematic Morphing Networks for Manipulation Skill Transfer","P. Englert; M. Toussaint","Machine Learning & Robotics Lab, University of Stuttgart, Germany; Machine Learning & Robotics Lab, University of Stuttgart, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2517","2523","The transfer of a robot skill between different geometric environments is non-trivial since a wide variety of environments exists, sensor observations as well as robot motions are high-dimensional, and the environment might only be partially observed. We consider the problem of extracting a low-dimensional description of the manipulated environment in form of a kinematic model. This allows us to transfer a skill by defining a policy on a prototype model and morphing the observed environment to this prototype. A deep neural network is used to map depth image observations of the environment to morphing parameter, which include transformations and configurations of the prototype model. Using the concatenation property of affine transformations and the ability to convert point clouds to depth images allows to apply the network in an iterative manner. The network is trained on data generated in a simulator and on augmented data that is created with its own predictions. The algorithm is evaluated on different tasks, where it is shown that iterative predictions lead to a higher accuracy than one-step predictions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593832","","Kinematics;Three-dimensional displays;Robot sensing systems;Prototypes;Neural networks;Solid modeling","affine transforms;image morphing;iterative methods;manipulators;motion control;neural nets;robot vision","kinematic model;robot motions;robot skill;manipulation skill transfer;kinematic morphing networks;affine transformations;map depth image observations;deep neural network","","","21","","","","","IEEE","IEEE Conferences"
"An Improved Formulation for Model Predictive Control of Legged Robots for Gait Planning and Feedback Control","K. Yuan; Z. Li","The University of Edinburgh, School of Informatics, UK; The University of Edinburgh, School of Informatics, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Predictive control methods for walking commonly use low dimensional models, such as a Linear Inverted Pendulum Model (LIPM), for simplifying the complex dynamics of legged robots. This paper identifies the physical limitations of the modeling methods that do not account for external disturbances, and then analyzes the issues of numerical stability of Model Predictive Control (MPC)using different models with variable receding horizons. We propose a new modeling formulation that can be used for both gait planning and feedback control in an MPC scheme. The advantages are the improved numerical stability for long prediction horizons and the robustness against various disturbances. Benchmarks were rigorously studied to compare the proposed MPC scheme with the existing ones in terms of numerical stability and disturbance rejection. The effectiveness of the controller is demonstrated in both MATLAB and Gazebo simulations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594309","","Optimization;Legged locomotion;Numerical models;Acceleration;Planning;Numerical stability","feedback;legged locomotion;numerical stability;pendulums;predictive control;robot dynamics;robust control","gait planning;feedback control;MPC scheme;long prediction horizons;low dimensional models;model predictive control scheme;numerical stability;linear inverted pendulum model;LIPM;legged robots dynamics;external disturbance;robustness","","2","24","","","","","IEEE","IEEE Conferences"
"Series Elastic Tether Management for Rappelling Rovers","T. Brown; A. Stefanini; J. Sawoniewicz; I. Nesnas; N. Georgiev","Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr., Pasadena, CA, 91109; Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr., Pasadena, CA, 91109; Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr., Pasadena, CA, 91109; Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr., Pasadena, CA, 91109; Department of Mechanical Engineering, California Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2893","2900","The Axel rappelling rover was designed to enable access to intriguing and important science sites that lie in difficult terrains that are inaccessible to conventional rovers. Extended autonomous rappelling calls for careful control of tether tension, precise management of tether spooling, and some measure of shock tolerance. This paper covers the design and testing of a first-generation tether management system (TMS) for Axel. The system uses a double bull-wheel capstan driven by a low-stiffness series elastic actuator (SEA) to provide tension control and decouple internal spooling tension from external tether tension. A series elastic actuator was chosen for this application to permit closed-loop tether tension control and to provide shock/drop tolerance of the rappelling system both while moving and when the system is inactive with the motors locked. Experiments on the new TMS show that this design performs well in keeping nearly constant spooling tension while rejecting large dynamic disturbances at the output. While the SEA is very effective at maintaining a given tension contribution, the additional effects of friction and the unique mechanical properties of the tether result in substantial errors in the measured output tension. Upcoming field trials will be used to evaluate the effectiveness and sufficiency of this system when integrated in Axel.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594134","","Springs;Bandwidth;Sea measurements;Actuators;Electric shock;Robots;Friction","actuators;closed loop systems;design engineering;elasticity;force control;mobile robots;position control;robot kinematics;wheels","series elastic tether management;Axel rappelling rover;intriguing science sites;important science sites;difficult terrains;conventional rovers;extended autonomous rappelling;tether spooling;shock tolerance;first-generation tether management system;double bull-wheel capstan;low-stiffness series elastic actuator;SEA;decouple internal spooling tension;external tether tension;closed-loop tether tension control;rappelling system;constant spooling tension;measured output tension;tension contribution;shock-drop tolerance","","","17","","","","","IEEE","IEEE Conferences"
"Real-Time Feature Depth Estimation for Image-Based Visual ServOing","X. Li; H. Zhao; H. Ding","Huazhong University of Science and Technology, State Key Laboratory of Digital Manufacturing Equipment and Technology, Wuhan, Hubei, 430074, P.R. China; Huazhong University of Science and Technology, State Key Laboratory of Digital Manufacturing Equipment and Technology, Wuhan, Hubei, 430074, P.R. China; Huazhong University of Science and Technology, State Key Laboratory of Digital Manufacturing Equipment and Technology, Wuhan, Hubei, 430074, P.R. China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7314","7320","Without the 3-D geometry of the target and robust to camera calibration error, image-based visual servoing schemes have gained a lot of attention. However, the depth of the selected feature, which is involved in the interaction matrix relating the time variation of the feature to the velocity twist of the camera, must be estimated correctly to guarantee the stability of the controller. To this end, this paper proposes a new nonlinear reduced-order observer structure to recover the feature depth in real time. Compared with the existing works, the proposed observer has a global asymptotic convergence property and fast convergence rate, and the convergence rate can be easily adjusted only using a single gain parameter. In addition, the proposed observer has a less restrictive observability condition and stronger robustness to noisy measurements. Extensive comparative numerical simulations are carried out to validate the effectiveness of the proposed depth observer.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593402","","Observers;Cameras;Convergence;Visual servoing;Acceleration","cameras;feature selection;nonlinear control systems;observability;observers;reduced order systems;robot vision;stability;visual servoing","nonlinear reduced-order observer structure;global asymptotic convergence property;restrictive observability condition;depth observer;camera calibration error;image-based visual servoing schemes;interaction matrix;real-time feature depth estimation","","","24","","","","","IEEE","IEEE Conferences"
"Learning Symbolic Representations for Planning with Parameterized Skills","B. Ames; A. Thackston; G. Konidaris","Duke University Computer Science; Toyota Research Institute; Brown University Computer Science","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","526","533","A critical capability required for generally intelligent robot behavior is the ability to sequence motor skills to reach a goal. This requires a (typically abstract) representation that supports goal-directed planning, which raises the question of how to construct such a representation. Previous work has addressed this question in the context of simple black-box motor skills, which are insufficiently flexible to support the wide range of behavior required of intelligent robots. We now extend that work to include parametrized motor skills, where a robot must both select an action to execute and also decide how to parametrize it. We show how to construct a representation suitable for planning with parametrized motor skills, and specify conditions which are sufficient to separate the selection of motor skills from the parametrization of those skills. Our method results in a simple discrete abstract representation for planning followed by a parameter selection process that operates on a fixed plan. We first demonstrate learning this representation in a virtual domain based on Angry Birds and then learn an abstract symbolic representation for a robot manipulation task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594313","","Planning;Task analysis;Probabilistic logic;Intelligent robots;Birds;Computer science","control engineering computing;humanoid robots;intelligent robots;learning (artificial intelligence);manipulators","critical capability;generally intelligent robot behavior;goal-directed planning;black-box motor skills;intelligent robots;parametrized motor skills;simple discrete abstract representation;fixed plan;abstract symbolic representation;robot manipulation task;angry birds;virtual domain","","","25","","","","","IEEE","IEEE Conferences"
"Reachset Conformance of Forward Dynamic Models for the Formal Analysis of Robots","S. B. Liu; M. Althoff","Department of Informatics, Technical University of Munich, Germany; Department of Informatics, Technical University of Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","370","376","Model-based design of robotic systems has many advantages, among them faster development cycles and reduced costs due to early detections of design flaws. Approximate models are sufficient for many classical robotic applications; however, they no longer suffice for safety-critical applications. For instance, a dangerous situation which has not been detected by model-based testing might occur in a human-robot co-existence scenario since models do not exactly replicate behaviors of real systems-this problem arises no matter how accurate a model is, since even disturbances and sensor noise can cause a mismatch. We address this issue by adding non-determinism to robotic models and by computing the whole set of possible behaviors using reachability analysis. By using reachset conformance, we automatically adjust the required non-determinism so that all recorded behaviors are captured. For the first time this approach is demonstrated for a real robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593975","","Friction;Uncertainty;Manipulators;Mathematical model;Computational modeling;Robot sensing systems","control engineering computing;human-robot interaction;program testing;reachability analysis;safety-critical software","human-robot co-existence scenario;robots;formal analysis;forward dynamic models;reachset conformance;reachability analysis;robotic models;model-based testing;safety-critical applications;classical robotic applications;design flaws;robotic systems;model-based design","","","33","","","","","IEEE","IEEE Conferences"
"Miniature Robot Finger Using a Micro Linear Ultrasonic Motor and a Closed-Loop Linkage","S. Izuhara; T. Mashimo","Department of Mechanical Engineering, Toyohashi University of Technology, 1-1 Hiragigaoka, Tenpaku-cho, Toyohashi, Aichi, 441-8580, Japan; Department of Mechanical Engineering, Toyohashi University of Technology, 1-1 Hiragigaoka, Tenpaku-cho, Toyohashi, Aichi, 441-8580, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","To prioritize miniaturization, the actuators of micro robot hands are placed far from the end effectors, but such mechanisms restrict controllability and dexterity. We propose a miniature robot finger driven by a new micro linear ultrasonic motor as a key component for micro robot hands. It enables dexterous and multiple motions for micro hands used in limited spaces. In this paper, we build a new micro linear ultrasonic motor involving a cuboid stator with a side length of approximately 2 mm, making it one of the smallest linear motors. The micro linear ultrasonic motor prototype shows an output torque of approximately 7.75 mN at low voltage operation, which is sufficient force to handle tiny objects. The miniature finger, a closed-loop six-bar-linkage mechanism, is built by micro fabrication and connected to the motor prototype. The first demonstration of the miniature finger is shown under a high-speed camera with a high power lens.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594098","","Acoustics;Stators;Robots;Couplings;Actuators;Electrodes;Vibrations","closed loop systems;controllability;dexterous manipulators;end effectors;force control;linear motors;microactuators;microrobots;ultrasonic motors","miniature robot finger;microrobot hands;microlinear ultrasonic motor prototype;closed-loop six-bar-linkage mechanism;microfabrication","","","27","","","","","IEEE","IEEE Conferences"
"Optimized Contrast Enhancements to Improve Robustness of Visual Tracking in a SLAM Relocalisation Context","X. Wang; M. Christie; E. Marchand","Inria, CNRS, IRISA, Univ Rennes, France; Inria, CNRS, IRISA, Univ Rennes, France; Inria, CNRS, IRISA, Univ Rennes, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","103","108","Robustness of indirect SLAM techniques to light changing conditions remains a central issue in the robotics community. With the change in the illumination of a scene, feature points are either not extracted properly due to low contrasts, or not matched due to large differences in descriptors. In this paper, we propose a multi-layered image representation (MLI) in which each layer holds a contrast enhanced version of the current image in the tracking process in order to improve detection and matching. We show how Mutual Information can be used to compute dynamic contrast enhancements on each layer. We demonstrate how this approach dramatically improves the robustness in dynamic light changing conditions on both synthetic and real environments compared to default ORB-SLAM. This work focalises on the specific case of SLAM relocalisation in which a first pass on a reference video constructs a map, and a second pass with a light changed condition relocalizes the camera in the map.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593366","","Mutual information;Lighting;Robustness;Simultaneous localization and mapping;Cameras;Entropy;Visualization","cameras;feature extraction;image colour analysis;image enhancement;image representation;mobile robots;robot vision;SLAM (robots);video signal processing","optimized contrast enhancements;visual tracking;SLAM relocalisation context;indirect SLAM techniques;robotics community;feature points;multilayered image representation;contrast enhanced version;tracking process;detection;matching;dynamic contrast enhancements;dynamic light changing conditions;ORB-SLAM;light changed condition;reference video","","","19","","","","","IEEE","IEEE Conferences"
"A Control Architecture with Online Predictive Planning for Position and Torque Controlled Walking of Humanoid Robots","S. Dafarra; G. Nava; M. Charbonneau; N. Guedelha; F. Andradel; S. Traversaro; L. Fiorio; F. Romano; F. Nori; G. Metta; D. Pucci","Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Google DeepMin, London, UK; Google DeepMin, London, UK; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, icub Facility Department, Genova, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","A common approach to the generation of walking patterns for humanoid robots consists in adopting a layered control architecture. This paper proposes an architecture composed of three nested control loops. The outer loop exploits a robot kinematic model to plan the footstep positions. In the mid layer, a predictive controller generates a Center of Mass trajectory according to the well-known table-cart model. Through a whole-body inverse kinematics algorithm, we can define joint references for position controlled walking. The outcomes of these two loops are then interpreted as inputs of a stack-of-task QP-based torque controller, which represents the inner loop of the presented control architecture. This resulting architecture allows the robot to walk also in torque control, guaranteeing higher level of compliance. Real world experiments have been carried on the humanoid robot iCub.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594277","","Legged locomotion;Trajectory;Computer architecture;Mathematical model;Humanoid robots;Robot kinematics","gait analysis;humanoid robots;legged locomotion;path planning;position control;predictive control;robot kinematics;torque control","inverse kinematics algorithm;iCub;center of mass trajectory;table-cart model;predictive controller;footstep positions;robot kinematic model;control loops;layered control architecture;humanoid robots;torque controlled walking;online predictive planning;stack-of-task QP-based torque controller;position controlled walking","","2","38","","","","","IEEE","IEEE Conferences"
"3D Human Pose Estimation on a Configurable Bed from a Pressure Image","H. M. Clever; A. Kapusta; D. Park; Z. Erickson; Y. Chitalia; C. C. Kemp","Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","54","61","Robots have the potential to assist people in bed, such as in healthcare settings, yet bedding materials like sheets and blankets can make observation of the human body difficult for robots. A pressure-sensing mat on a bed can provide pressure images that are relatively insensitive to bedding materials. However, prior work on estimating human pose from pressure images has been restricted to 2D pose estimates and flat beds. In this work, we present two convolutional neural networks to estimate the 3D joint positions of a person in a configurable bed from a single pressure image. The first network directly outputs 3D joint positions, while the second outputs a kinematic model that includes estimated joint angles and limb lengths. We evaluated our networks on data from 17 human participants with two bed configurations: supine and seated. Our networks achieved a mean joint position error of 77 mm when tested with data from people outside the training set, outperforming several baselines. We also present a simple mechanical model that provides insight into ambiguity associated with limbs raised off of the pressure mat, and demonstrate that Monte Carlo dropout can be used to estimate pose confidence in these situations. Finally, we provide a demonstration in which a mobile manipulator uses our network's estimated kinematic model to reach a location on a person's body in spite of the person being seated in a bed and covered by a blanket.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593545","","Three-dimensional displays;Pose estimation;Kinematics;Skeleton;Robot sensing systems;Two dimensional displays","convolutional neural nets;manipulators;Monte Carlo methods;pose estimation;stereo image processing","single pressure image;convolutional neural networks;flat beds;pressure-sensing mat;bedding materials;robots;configurable bed;3D human pose estimation;estimated kinematic model;pressure mat;mean joint position error;bed configurations;limb lengths;3D joint positions;size 77.0 mm","","","29","","","","","IEEE","IEEE Conferences"
"A B-Spline Mapping Framework for Long-Term Autonomous Operations","R. T. Rodrigues; A. P. Aguiar; A. Pascoal","Faculty of Engineering, University of Porto, Portugal; Faculty of Engineering, University of Porto, Portugal; ISR/IST, University of Lisbon, Laboratory of Robotics and Engineering Systems (LARSyS), Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3204","3209","This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594456","","Splines (mathematics);Simultaneous localization and mapping;Three-dimensional displays;Robot kinematics;Two dimensional displays","image representation;image sensors;mobile robots;navigation;path planning;robot vision;SLAM (robots);splines (mathematics)","landmark-based maps;robotics community;high frequency sensor;B-spline curves;B-spline maps;mapping algorithm;2D B-spline mapping framework;outdoor long-term autonomous operations;simultaneous localization and mapping;SLAM algorithm;software-in-the-loop simulations","","","17","","","","","IEEE","IEEE Conferences"
"Robot Imitation Through Vision, Kinesthetic and Force Features with Online Adaptation to Changing Environments","R. Fernandez-Fernandez; J. G. Victores; D. Estevez; C. Balaguer","The Department of Systems Engineering and Automation Universidad Carlos III de Madrid (UC3M), The Robotics Lab research group; The Department of Systems Engineering and Automation Universidad Carlos III de Madrid (UC3M), The Robotics Lab research group; The Department of Systems Engineering and Automation Universidad Carlos III de Madrid (UC3M), The Robotics Lab research group; The Department of Systems Engineering and Automation Universidad Carlos III de Madrid (UC3M), The Robotics Lab research group","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Continuous Goal-Directed Actions (CGDA)is a robot imitation framework that encodes actions as the changes they produce on the environment. While it presents numerous advantages with respect to other robot imitation frameworks in terms of generalization and portability, final robot joint trajectories for the execution of actions are not necessarily encoded within the model. This is studied as an optimization problem, and the solution is computed through evolutionary algorithms in simulated environments. Evolutionary algorithms require a large number of evaluations, which had made the use of these algorithms in real world applications very challenging. This paper presents online evolutionary strategies, as a change of paradigm within CGDA execution. Online evolutionary strategies shift and merge motor execution into the planning loop. A concrete online evolutionary strategy, Online Evolved Trajectories (OET), is presented. OET drastically reduces computational times between motor executions, and enables working in real world dynamic environments and/or with human collaboration. Its performance has been measured against Full Trajectory Evolution (FTE)and Incrementally Evolved Trajectories (IET), obtaining the best overall results. Experimental evaluations are performed on the TEO full-sized humanoid robot with “paint” and “iron” actions that together involve vision, kinesthetic and force features.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593724","","Trajectory;Robot sensing systems;Feature extraction;Force;Planning;Paints","evolutionary computation;humanoid robots;human-robot interaction;optimisation;robot vision;trajectory control","optimization problem;continuous goal-directed actions;robot joint trajectories;online evolved trajectories;force features;iron actions;TEO full-sized humanoid robot;motor execution;CGDA execution;online evolutionary strategies;evolutionary algorithms;robot imitation framework","","","16","","","","","IEEE","IEEE Conferences"
"CLASH: Compliant Low Cost Antagonistic Servo Hands","W. Friedl; H. Höppner; F. Schmidt; M. A. Roa; M. Grebenstein","German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6469","6476","This paper presents the first two members of the new generation of CLASH hands, which exploit low cost actuation and rapid prototyping to create antagonistic modular and lightweight hands and grippers. The hands approach the robustness of the DLR Awiwi hand with a much lower complexity and cost. To reduce the number of required actuators, a differential coupling mechanism for underactuated fingers was developed, along with a new mechanism that uses variable stiffness actuation in order to increase the workspace of underactuated fingers. The hands provide a research platform for both hand-in-hand and robotic grasping. Design aspects are discussed, and an initial experimental validation verifies the hands' performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593903","","Tendons;Thumb;Force;Servomotors;Grasping;Couplings;Kinematics","actuators;dexterous manipulators;grippers","actuators;grippers;hand-in-hand grasping;variable stiffness actuation;underactuated fingers;differential coupling mechanism;DLR Awiwi hand;lightweight hands;antagonistic modular hands;rapid prototyping;CLASH hands;compliant low cost antagonistic servo hands","","","20","","","","","IEEE","IEEE Conferences"
"Coverage Optimization with Non-Actuated, Floating Mobile Sensors using Iterative Trajectory Planning in Marine Flow Fields","J. Hansen; G. Dudek","Mobile Robotics Lab at the Centre for Intelligent Machines at McGill University, Montreal, QC, Canada; Mobile Robotics Lab at the Centre for Intelligent Machines at McGill University, Montreal, QC, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1906","1912","This paper considers a spatial coverage problem in which a network of passive floating sensors is used to collect samples in a body of water. We employ an iterative measurement and modeling scheme to incrementally deploy sensors so as to achieve spatial coverage, despite only controlling the initial sample point. Once deployed, sensors are moved about a survey area by ambient surface currents. We demonstrate our results in simulation on 40 different ocean flow fields and compare against several baselines. This work provides a computational tool for scientists seeking a low-cost, autonomous marine surveying system. Although in this paper, we concentrate on ocean drifters, our approach can be extended to other domains where a spatial distribution of passive nodes in a flow field can be modeled.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594281","","Trajectory;Sensors;Oceans;Planning;Sea measurements;Computational modeling;Robots","oceanographic equipment;oceanographic techniques","passive nodes;coverage optimization;mobile sensors;iterative trajectory planning;marine flow fields;spatial coverage problem;passive floating sensors;iterative measurement;modeling scheme;initial sample point;survey area;ambient surface currents;computational tool;autonomous marine surveying system;ocean drifters;spatial distribution;ocean flow fields","","","41","","","","","IEEE","IEEE Conferences"
"Re-Establishing Communication in Teams of Mobile Robots","I. Vandermeulen; R. Groß; A. Kolling","University of Sheffield, Department of Automatic Control and Systems Engineering, Sheffield, UK; University of Sheffield, Department of Automatic Control and Systems Engineering, Sheffield, UK; iRobot, Pasadena, California, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7947","7954","As communication is important for cooperation, teams of mobile robots need a way to re-establish a wireless connection if they get separated. We develop a method for mobile robots to maintain a belief of each other's positions using locally available information. They can use their belief to plan paths with high probabilities of reconnection. This approach also works for subteams cooperatively searching for a robot or group of robots that they would like to reconnect with. The problem is formulated as a constrained optimization problem which is solved using a branch-and-bound approach. We present simulation results showing the effectiveness of this strategy at reconnecting teams of up to five robots and compare the results to two other strategies.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594460","","Task analysis;Robot kinematics;Search problems;Mobile robots;Markov processes","mobile robots;multi-robot systems;optimisation;path planning;probability;tree searching","wireless connection;constrained optimization problem;branch-and-bound approach;locally available information;belief;mobile robots","","","23","","","","","IEEE","IEEE Conferences"
"Development of Stone Throwing Robot and High Precision Driving Control for Curling","J. H. Choi; C. Song; K. Kim; S. Oh","Department of Robotis Engineering, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, Korea; NT Robot. Co., Seoul, 08514, Korea; NT Robot. Co., Seoul, 08514, Korea; Department of Robotis Engineering, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2434","2440","In this paper, a novel mobile robot developed to perform Curling sports is introduced. The developed robot is a Stone Throwing Robot (STR) for Curling that can travel on the ice with wheels and throw a stone as well as make curls of the stone. The STR is developed as a robot component of an Artificial Intelligence(AI) system that can autonomously play the curling sport. The proposed STR can throw a stone at any desired speed and in any desired direction, which are determined by the AI system. To achieve this precise driving of the STR and throwing of the stone, two dimensional drive control is developed for the STR, which consists of 1) anti-slip control for high traction, 2) precise velocity control and 3) high accuracy heading angle control. In addition to the conventional PID controller, model-based feedforward control, Model Following Control (MFC) for the anti-slip control of the wheel on the ice and Yaw Moment Observer (YMO) for the robust heading angle control are applied as key technologies for the STR driving. The design configurations of the STR to achieve the detection of its own location and throwing/curling of the stone is proposed in this paper as well as the detail of the precise driving control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594026","","Mobile robots;Wheels;Cameras;Artificial intelligence;Ice;Servers","artificial intelligence;control engineering computing;control system synthesis;feedforward;mobile robots;motion control;observers;position control;three-term control;velocity control;wheels","AI system;stone throwing robot;curling sports;throwing-curling;artificial intelligence system;precise driving control;STR driving;robust heading angle control;model-based feedforward control;conventional PID controller;anti-slip control;dimensional drive control;curling sport;robot component;developed robot;novel mobile robot;high precision driving Control","","","19","","","","","IEEE","IEEE Conferences"
"Semantic Mapping with Simultaneous Object Detection and Localization","Z. Zeng; Y. Zhou; O. C. Jenkins; K. Desingh","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, 48109-2121, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, 48109-2121, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, 48109-2121, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, 48109-2121, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","911","918","We present a filtering-based method for semantic mapping to simultaneously detect objects and localize their 6 degree-of-freedom pose. For our method, called Contextual Temporal Mapping (or CT-Map), we represent the semantic map as a belief over object classes and poses across an observed scene. Inference for the semantic mapping problem is then modeled in the form of a Conditional Random Field (CRF). CT-Map is a CRF that considers two forms of relationship potentials to account for contextual relations between objects and temporal consistency of object poses, as well as a measurement potential on observations. A particle filtering algorithm is then proposed to perform inference in the CT-Map model. We demonstrate the efficacy of the CT-Map method with a Michigan Progress Fetch robot equipped with a RGB-D sensor. Our results demonstrate that the particle filtering based inference of CT-Map provides improved object detection and pose estimation with respect to baseline methods that treat observations as independent samples of a scene.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594205","","Semantics;Object detection;Context modeling;Three-dimensional displays;Pose estimation;Simultaneous localization and mapping","image sensors;mobile robots;object detection;particle filtering (numerical methods);pose estimation","semantic mapping problem;CT-Map method;six degree-of-freedom pose;pose estimation;RGB-D sensor;Michigan progress fetch robot;particle filtering algorithm;CRF;conditional random field;contextual temporal mapping;object localization;object detection","","","44","","","","","IEEE","IEEE Conferences"
"User Evaluation of a Haptic-Enabled Shared-Control Approach for Robotic Telemanipulation","F. Abi-Farraj; C. Pacchierotti; P. R. Giordano","CNRS at Irisa and Inria Rennes Bretagne Atlantique, Campus de Beaulieu, Rennes Cedex, 35042, France; CNRS at Irisa and Inria Rennes Bretagne Atlantique, Campus de Beaulieu, Rennes Cedex, 35042, France; CNRS at Irisa and Inria Rennes Bretagne Atlantique, Campus de Beaulieu, Rennes Cedex, 35042, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Robotic telemanipulators are already widely used in nuclear decommissioning sites for handling radioactive waste. However, currently employed systems are still extremely primitive, making the handling of these materials prohibitively slow and ineffective. As the estimated cost for the decommissioning and clean-up of nuclear sites keeps rising, it is clear that one would need faster and more effective approaches. Towards this goal, in this paper we present the user evaluation of a recently proposed haptic-enabled shared-control architecture for telemanipulation. An autonomous algorithm regulates a subset of the slave manipulator degrees of freedom (DoF) in order to help the human operator in grasping an object of interest. The human operator can then steer the manipulator along the remaining null-space directions with respect to the main task by acting on a grounded haptic interface. The haptic cues provided to the operator are designed in order to inform about the feasibility of the user's commands with respect to possible constraints of the robotic system. In this paper we compared this shared-control architecture against a classical 6-DOF teleoperation approach in a real scenario by running experiments with 10 subjects. The results clearly show that the proposed shared-control approach is a viable and effective solution for improving currently-available teleoperation systems in remote telemanipulation tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594030","","Task analysis;Manipulators;Grippers;Force;Grasping","haptic interfaces;manipulators;telerobotics","grounded haptic interface;remaining null-space directions;human operator;slave manipulator degrees;effective approaches;nuclear sites;estimated cost;currently employed systems;handling radioactive waste;nuclear decommissioning sites;robotic telemanipulators;robotic telemanipulation;user evaluation;remote telemanipulation tasks;currently-available teleoperation systems;shared-control approach;6-DOF teleoperation approach;shared-control architecture;robotic system;haptic cues","","","19","","","","","IEEE","IEEE Conferences"
"A New Manufacturing Process for Soft Robots and Soft/Rigid Hybrid Robots","H. D. Yang; A. T. Asbeck","Virginia Tech, Department of Mechanical Engineering, Blacksburg, VA, 24061, USA; Virginia Tech, Department of Mechanical Engineering, Blacksburg, VA, 24061, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8039","8046","We present a novel manufacturing process for creating monolithic, multi-chambered inflatable structures including both soft and rigid components. Specifically, our process involves stacking layers of textiles or plastics and thermal adhesive film, then bonding the structure with a heat press or in an oven. Several different ways of arranging textiles and thermal adhesive film in order to achieve airtight structures are presented. Since this process only uses materials that bend, but do not stretch, it permits the easy inclusion of rigid structures such as circuit boards, plates that constrain inflatable chambers to bend in specified locations, and rigid pieces that enable sections of a robot to be connected in a modular fashion. Additionally, the process permits folding layers before their assembly, leading to more complex geometries. We present three different possible seam types, and enumerate the different types of corners that can be constructed without leaking. We present measurements of the ability of these structures to support pressure and measurements of the strength of bonds between textiles and other materials. Finally, we present two examples of robots constructed using this manufacturing method, including a hybrid soft/rigid robotic arm and a soft robot that can roll along the ground.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593688","","Conferences;Intelligent robots","adhesion;adhesives;design engineering;inflatable structures;robots;textiles","multichambered inflatable structures;thermal adhesive film;heat press;bond strength;soft-rigid hybrid robotic arm","","","33","","","","","IEEE","IEEE Conferences"
"Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model","T. Ohashi; Y. Ikegami; K. Yamamoto; W. Takano; Y. Nakamura","Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Osaka University, Center for Mathematical Modeling and Data Science, 1-3 Machikaneyamacho, Toyonaka-shi, Osaka, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4226","4231","This paper discusses video motion capture, namely, 3D reconstruction of human motion from multi-camera images. After the Part Confidence Maps are computed from each camera image, the proposed spatiotemporal filter is applied to deliver the human motion data with accuracy and smoothness for human motion analysis. The spatiotemporal filter uses the human skeleton and mixes temporal smoothing in two-time inverse kinematics computations. The experimental results show that the mean per joint position error was 26.1mm for regular motions and 38.8mm for inverted motions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593867","","Phase change materials;Three-dimensional displays;Cameras;Computational modeling;Optical imaging;Adaptive optics;Spatiotemporal phenomena","cameras;image filtering;image motion analysis;image reconstruction;image sequences;spatiotemporal phenomena;video signal processing","video motion capture;part confidence maps;inverted motions;two-time inverse kinematics computations;human skeleton;human motion analysis;human motion data;spatiotemporal filter;camera image;human skeletal model;spatiotemporal filtering;multicamera images","","1","19","","","","","IEEE","IEEE Conferences"
"Quadrupedal walking motion and footstep placement through Linear Model Predictive Control","A. Laurenzi; E. M. Hoffman; N. G. Tsagarakis","Advanced Robotics Department (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Advanced Robotics Department (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Advanced Robotics Department (ADVR), Istituto Italiano di Tecnologia, Genova, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2267","2273","The present work addresses the generation of a walking gait with automatic footstep placement for a quadrupedal robot, within a Linear Model Predictive Control framework. Existing work has shown how this is only possible within a non-convex programming framework, finding a solution of which is well-known to be very hard. We propose a way to formulate the joint optimization problem as an approximate QP with linear constraints, whose global optimum can be quickly found with off-the-shelf solvers. More specifically, this is done by introducing auxiliary states and control inputs, each of which is subject to linear constraints that are inspired from the literature on bipedal locomotion. Finally, we validate our method on the CENTAURO robot, a hybrid wheeled-legged quadruped with a humanoid upper-body.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593692","","Legged locomotion;Robot kinematics;Optimization;Stability analysis;Planning","convex programming;gait analysis;humanoid robots;legged locomotion;motion control;predictive control;robot dynamics","linear model predictive control framework;quadrupedal walking motion;auxiliary states;bipedal locomotion;hybrid wheeled-legged quadruped;humanoid upper-body;joint optimization problem;nonconvex programming framework;quadrupedal robot;automatic footstep placement;walking gait;CENTAURO robot;control inputs;linear constraints;approximate QP","","2","25","","","","","IEEE","IEEE Conferences"
"Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning","M. Everett; Y. F. Chen; J. P. How","Aerospace Controls Laboratory, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA, USA; Oculus Research, Redmond, WA, USA; Aerospace Controls Laboratory, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3052","3059","Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593871","","Collision avoidance;Robots;Training;Decision making;Heuristic algorithms;Sensors;Navigation","collision avoidance;learning (artificial intelligence);mobile robots;path planning","safe operation;deep reinforcement learning;complex interactions;environment increases;dynamic agents;particular behavior rules;arbitrary number;motion planning;decision-making agents;collision avoidance algorithms","","2","23","","","","","IEEE","IEEE Conferences"
"Failure Detection Using Proprioceptive, Auditory and Visual Modalities","A. Inceoglu; G. Ince; Y. Yaslan; S. Sariel","Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey; Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey; Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey; Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2491","2496","Handling safety is crucial to achieve lifelong autonomy for robots. Unsafe situations might arise during manipulation in unstructured environments due to noises in sensory feedback, improper action parameters, hardware limitations or external factors. In order to assure safety, continuous execution monitoring and failure detection procedures are mandatory. To this end, we present a multimodal failure monitoring and detection system to detect manipulation failures. Rather than relying only on a single sensor modality, we consider integration of different modalities to get better detection performance in different failure cases. In our system, high level proprioceptive, auditory and visual predicates are extracted by processing each modality separately. Then, the extracted predicates are fused. Experiments on a humanoid robot for tabletop manipulation scenarios indicate that the contribution of each modality is different depending on the action in execution and multimodal fusion results in an overall performance increase in detecting failures compared to the performance attained by unimodal processing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594169","","Robot sensing systems;Hidden Markov models;Monitoring;Visualization;Task analysis;Grasping","computerised monitoring;humanoid robots;manipulators;robot vision;sensor fusion","failure detection;continuous execution monitoring;multimodal failure monitoring;single sensor modality;high level proprioceptive;auditory predicates;visual predicates;humanoid robot;tabletop manipulation scenarios;safety handling;multimodal fusion","","","35","","","","","IEEE","IEEE Conferences"
"Continuum Manipulator with Redundant Backbones and Constrained Bending Curvature for Continuously Variable Stiffness","B. Zhao; W. Zhang; Z. Zhang; X. Zhu; K. Xu","Shanghai Jiao Tong University, The RII Lab (Lab of Robotics Innovation and Intervention), UM-SJTU Joint Institute, Shanghai, China; Shanghai Jiao Tong University, School of Mechanical Engineering, Shanghai, China; Shanghai Jiao Tong University, The RII Lab (Lab of Robotics Innovation and Intervention), UM-SJTU Joint Institute, Shanghai, China; Shanghai Jiao Tong University, School of Mechanical Engineering, Shanghai, China; Shanghai Jiao Tong University, School of Mechanical Engineering, Shanghai, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7492","7499","Snake-like manipulators can navigate and perform manipulation in confined spaces. Their recent implementations in surgical robots attracted a lot of attentions. These slender manipulators usually possess either a hyper-redundant articulated vertebrate structure or a continuum one. Primary design considerations usually converge to a balance between proper workspace and acceptable stiffness. Efforts have hence been constantly made to achieve higher or adjustable stiffness for a manipulator to widen its applications. This paper presents a simple continuum manipulator design with variable stiffness based on redundantly arranged elastic backbones and continuously constrained bending curvature. The design concepts, kinematics, a preliminary formulation for stiffness adjustment, system construction and experimental characterizations are elaborated. The results showed that the manipulator's stiffness can be increased up to 4.71 times of the value without the curvature constraining rod, indicating the efficacy of the proposed idea.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593437","","Manipulators;Electron tubes;Kinematics;Friction;Tendons;Strips;Lead","bending;design engineering;elasticity;medical robotics;redundant manipulators","continuously constrained bending curvature;hyper-redundant articulated vertebrate structure;slender manipulators;surgical robots;snake-like manipulators;continuously variable stiffness;redundant backbones;redundantly arranged elastic backbones;simple continuum manipulator design","","","33","","","","","IEEE","IEEE Conferences"
"Identifying Driver Behaviors Using Trajectory Features for Vehicle Navigation","E. Cheung; A. Bera; E. Kubin; K. Gray; D. Manocha","Department of Computer Science, University of North Carolina at Chapel Hill, USA; Department of Computer Science, University of North Carolina at Chapel Hill, USA; Department of Psychology and Neuroscience, University of North Carolina at Chapel Hill, USA; Department of Psychology and Neuroscience, University of North Carolina at Chapel Hill, USA; Department of Computer Science and Electrical Computer Engg, University of Maryland at College Park","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3445","3452","We present a novel approach to automatically identify driver behaviors from vehicle trajectories and use them for safe navigation of autonomous vehicles. We propose a novel set of features that can be easily extracted from car trajectories. We derive a data-driven mapping between these features and six driver behaviors using an elaborate web-based user study. We also compute a summarized score indicating a level of awareness that is needed while driving next to other vehicles. We also incorporate our algorithm into a vehicle navigation simulation system and demonstrate its benefits in terms of safer realtime navigation, while driving next to aggressive or dangerous drivers.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594348","","Trajectory;Navigation;Automobiles;Feature extraction;Measurement;Acceleration","automobiles;behavioural sciences computing;driver information systems;feature extraction;Internet;mobile robots","vehicle trajectories;autonomous vehicles;car trajectories;data-driven mapping;vehicle navigation simulation system;driver behavior identification;Web-based user study","","","47","","","","","IEEE","IEEE Conferences"
"Inertial Velocity and Attitude Estimation for Quadrotors","J. Svacha; K. Mohta; M. Watterson; G. Loianno; V. Kumar","University of Pennsylvania, The authors are with the GRASP Lab, Philadelphia, 3330 Walnut Street, PA, 19104, USA; University of Pennsylvania, The authors are with the GRASP Lab, Philadelphia, 3330 Walnut Street, PA, 19104, USA; University of Pennsylvania, The authors are with the GRASP Lab, Philadelphia, 3330 Walnut Street, PA, 19104, USA; Tandon School of Engineering, the New York University, Brooklyn, 6 MetroTech Center, NY, 11201, USA; University of Pennsylvania, The authors are with the GRASP Lab, Philadelphia, 3330 Walnut Street, PA, 19104, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This work addresses the design and implementation of a filter that estimates the orientation of the body-fixed z axis and the velocity of a quadrotor UAV from the inertial measurement unit (IMU) given a known yaw. The velocity and attitude estimation is possible since the filter employs a linear drag model measuring the drag forces on the quadrotor through the IMU. These forces are functions of the robot's velocity and attitude. In addition, the filter estimates the linear drag parameters and thrust coefficient for the propellers. These parameters may be fed back into a controller to improve tracking performance. Experimental results are used to validate the proposed approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593616","","Aerodynamics;Sensors;Accelerometers;Estimation;Magnetometers;Kalman filters;Velocity measurement","aircraft control;attitude control;autonomous aerial vehicles;drag;helicopters;inertial navigation;Kalman filters","linear drag parameters;drag forces;linear drag model;IMU;inertial measurement unit;quadrotor UAV;body-fixed z axis;attitude estimation;inertial velocity","","1","19","","","","","IEEE","IEEE Conferences"
"Hybrid Approach for Human Activity Recognition by Ubiquitous Robots","R. Mojarad; F. Attal; A. Chibani; S. R. Fiorini; Y. Amirat","University of Paris-Est Créteil (UPEC), LISSI Laboratory, Vitry-sur-Seine, France; University of Paris-Est Créteil (UPEC), LISSI Laboratory, Vitry-sur-Seine, France; University of Paris-Est Créteil (UPEC), LISSI Laboratory, Vitry-sur-Seine, France; University of Paris-Est Créteil (UPEC), LISSI Laboratory, Vitry-sur-Seine, France; University of Paris-Est Créteil (UPEC), LISSI Laboratory, Vitry-sur-Seine, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5660","5665","One of the main objectives of ubiquitous robots is to proactively provide context-aware intelligent services to assist humans in their professional or daily living activities. One of the main challenges is how to automatically obtain a consistent and correct description of human context such as location, activities, emotions, etc. In this paper, a new hybrid approach for reasoning on the context is proposed. This approach focuses on human activity recognition and consists of machine-learning algorithms, an expressive ontology representation, and a reasoning system. The latter allows detecting the inconsistencies that may appear during the machine learning phase. The proposed approach can also correct automatically these inconsistencies by considering the context of the ongoing activity. The obtained results on the Opportunity dataset demonstrate the feasibility of the proposed method to enhance the performance of human activity recognition.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594173","","Ontologies;Activity recognition;Machine learning;Dairy products;Robot sensing systems","image recognition;learning (artificial intelligence);mobile robots;ontologies (artificial intelligence);ubiquitous computing","human activity recognition;ubiquitous robots;context-aware intelligent services;humans;professional living activities;daily living activities;consistent description;correct description;human context","","","21","","","","","IEEE","IEEE Conferences"
"Distributed Deep Reinforcement Learning based Indoor Visual Navigation","S. Hsu; S. Chan; P. Wu; K. Xiao; L. Fu","Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Director of NTU Center for Artificial Intelligence & Advanced Robotics, Taipei, Taiwan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2532","2537","Recently, as the rise of deep reinforcement learning, it not only can help the robot to convert the complicated environment scene to motor control command directly but also can accomplish the navigation task properly. In this paper, we propose a novel structure, where the objective is to achieve navigation in large-scale indoor complex environment without pre-constructed map. Generally, it requires good understanding of such indoor environment to make complex spatial perception possible, especially when the indoor space consists of many walls and doors which might block the view of robot leading to complex navigation path. By the proposed distributed deep reinforcement learning in different local regions, our method can achieve indoor visual navigation in the aforementioned large-scale environment without extra map information and human instruction. In the experiments, we validate our proposed method by conducting highly promising navigation tasks both in simulation and real environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594352","deep reinforcement learning;visual navigation","Navigation;Visualization;Task analysis;Training;Reinforcement learning;Robots;Indoor environments","indoor environment;indoor navigation;learning (artificial intelligence);mobile robots;object detection;path planning;robot vision","complicated environment scene;motor control command;navigation task;large-scale indoor complex environment;pre-constructed map;indoor environment;complex spatial perception possible;indoor space;complex navigation path;aforementioned large-scale environment;real environments;distributed deep reinforcement learning based indoor visual navigation","","","18","","","","","IEEE","IEEE Conferences"
"Quadtree-Accelerated Real-Time Monocular Dense Mapping","K. Wang; W. Ding; S. Shen","The Hong Kong University of Science and Technology, The Department of Electronic and Computer Engineering, Hong Kong, SAR China; The Hong Kong University of Science and Technology, The Department of Electronic and Computer Engineering, Hong Kong, SAR China; The Hong Kong University of Science and Technology, The Department of Electronic and Computer Engineering, Hong Kong, SAR China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594101","","Cameras;Three-dimensional displays;Belief propagation;Estimation;Optimization;Real-time systems;Image resolution","autonomous aerial vehicles;image fusion;image motion analysis;image reconstruction;image resolution;mobile robots;path planning;quadtrees;robot vision;stereo image processing","real-time monocular dense mapping;truncated signed distance function;dense 3D maps;resolution depth maps;pixels;dynamic belief propagation;pixel selection;depth map;intensity image;quadtree structure;single localized moving camera;high-quality dense depth maps;robotic navigation","","","23","","","","","IEEE","IEEE Conferences"
"A Model Predictive Control Approach for Vision-Based Object Grasping via Mobile Manipulator","M. Logothetis; G. C. Karras; S. Heshmati-Alamdari; P. Vlantis; K. J. Kyriakopoulos","Department of Mechanical Engineering, Control Systems Lab National Technical University of Athens, 9 Heroon Polytechniou Street, Zografou, 15780, Greece; Department of Mechanical Engineering, Control Systems Lab National Technical University of Athens, 9 Heroon Polytechniou Street, Zografou, 15780, Greece; Department of Mechanical Engineering, Control Systems Lab National Technical University of Athens, 9 Heroon Polytechniou Street, Zografou, 15780, Greece; Department of Mechanical Engineering, Control Systems Lab National Technical University of Athens, 9 Heroon Polytechniou Street, Zografou, 15780, Greece; Department of Mechanical Engineering, Control Systems Lab National Technical University of Athens, 9 Heroon Polytechniou Street, Zografou, 15780, Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","This paper presents the design of a vision-based object grasping and motion control architecture for a mobile manipulator system. The optimal grasping areas of the object are estimated using the partial point cloud acquired from an onboard RGB-D sensor system. The reach-to-grasp motion of the mobile manipulator is handled via a Nonlinear Model Predictive Control scheme. The controller is formulated accordingly in order to allow the system to operate in a constrained workspace with static obstacles. The goal of the proposed scheme is to guide the robot's end-effector towards the optimal grasping regions with guaranteed input and state constraints such as occlusion and obstacle avoidance, workspace boundaries and field of view constraints. The performance of the proposed strategy is experimentally verified using an 8 Degrees of Freedom KUKA Youbot in different reach-to-grasp scenarios.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593759","","Grasping;Three-dimensional displays;Manipulators;Grippers;Robot sensing systems;Predictive control","collision avoidance;dexterous manipulators;end effectors;grippers;image colour analysis;image sensors;mobile robots;motion control;nonlinear control systems;path planning;predictive control;robot vision","reach-to-grasp motion;optimal grasping regions;vision-based object grasping;motion control architecture;mobile manipulator system;partial point cloud;onboard RGB-D sensor system;KUKA Youbot;static obstacles;reach-to-grasp scenarios;model predictive control approach;nonlinear model predictive control scheme","","","23","","","","","IEEE","IEEE Conferences"
"Learning to Grasp by Extending the Peri-Personal Space Graph","J. Juett; B. Kuipers","University of Michigan, Division of Computer Science and Engineering, Ann Arbor, 2260 Hayward St, MI, 48109; University of Michigan, Division of Computer Science and Engineering, Ann Arbor, 2260 Hayward St, MI, 48109","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8695","8700","We present a robot model of early reach and grasp learning, inspired by infant learning without prior knowledge of the geometry, kinematics, or dynamics of the arm. Human infants at reach onset are capable of using a sequence of jerky submotions to bring the hand to the position of a nearby object. A robotic learning agent can produce qualitatively similar behavior by using a graph representation to encode a set of safe, potentially useful arm states and feasible moves between them. These observations show that the Peri-Personal Space (PPS) Graph model is sufficient for early reaching and suggest that infants may use analogous models during this phase. In this paper, we show that the PPS Graph, with a simulated Palmar reflex (a reflex in infants that closes the fingers when the palm is touched), allows accidental grasps to occur during continued reaching practice. Given these occasional events, the agent can bootstrap to a simple deliberate grasp action. In particular, the agent must learn three new necessary conditions for a grasp: the hand should be open as the grasp begins, the final motion of the hand should be led by the gripper opening so that it reaches the target first, and the wrist must be oriented such that the gripper fingers may close around the target object, often requiring the opening to be perpendicular to the object's major axis. Combined with the existing capability to reach and interact with target objects, knowledge of these conditions allows the agent to learn increasingly reliable purposeful grasps. The first two conditions are addressed in this paper, and allow 45% of grasps to succeed. This work contributes toward the larger goal of foundational robot learning after the model of infant learning, with minimal prior knowledge of its own anatomy or its environment. The ability to grasp will allow the agent to control the motion and position of objects, providing a richer representation for its environment and new experiences to learn from.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593938","","Manipulators;Reliability;Grippers;Robot sensing systems;Visualization;Trajectory","dexterous manipulators;graph theory;grippers;learning (artificial intelligence);mobile robots;motion control;position control;robot vision","robot model;infant learning;human infants;robotic learning agent;analogous models;deliberate grasp action;Palmar reflex;PPS graph;peri-personal space graph model;grasp learning;jerky submotions;gripper fingers","","","12","","","","","IEEE","IEEE Conferences"
"Integrating Path Planning and Pivoting","S. Cruciani; C. Smith","EECS at KTH Royal Institute of Technology, Robotics Perception and Learning Lab, Stockholm, Sweden; EECS at KTH Royal Institute of Technology, Robotics Perception and Learning Lab, Stockholm, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6601","6608","In this work we propose a method for integrating motion planning and in-hand manipulation. Commonly addressed as a separate step from the final execution, in-hand manipulation allows the robot to reorient an object within the end-effector for the successful outcome of the goal task. A joint achievement of repositioning the object and moving the manipulator towards its desired final pose saves time in the execution and introduces more flexibility in the system. We address this problem using a pivoting strategy (i.e. in-hand rotation)for repositioning the object and we integrate this strategy with a path planner for the execution of a complex task. This method is applied on a Baxter robot and its efficacy is shown by experimental results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593584","","Grippers;Task analysis;Friction;End effectors;Trajectory","end effectors;path planning","manipulator;pivoting strategy;Baxter robot;path planning;motion planning;in-hand manipulation;end-effector","","","22","","","","","IEEE","IEEE Conferences"
"The RobotriX: An Extremely Photorealistic and Very-Large-Scale Indoor Dataset of Sequences with Robot Trajectories and Interactions","A. Garcia-Garcia; P. Martinez-Gonzalez; S. Oprea; J. A. Castro-Vargas; S. Orts-Escolano; J. Garcia-Rodriguez; A. Jover-Alvarez","University of Alicante, 3D Perception Lab, Spain; University of Alicante, 3D Perception Lab, Spain; University of Alicante, 3D Perception Lab, Spain; University of Alicante, 3D Perception Lab, Spain; University of Alicante, 3D Perception Lab, Spain; University of Alicante, 3D Perception Lab, Spain; University of Alicante, 3D Perception Lab, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6790","6797","Enter the RobotriX, an extremely photorealistic indoor dataset designed to enable the application of deep learning techniques to a wide variety of robotic vision problems. The RobotriX consists of hyperrealistic indoor scenes which are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline using UnrealCV to generate raw data and ground truth labels. By taking this approach, we were able to generate a dataset of 38 semantic classes across 512 sequences totaling 8M stills recorded at +60 frames per second with full HD resolution. For each frame, RGB-D and 3D information is provided with full annotations in both spaces. Thanks to the high quality and quantity of both raw information and annotations, the RobotriX will serve as a new milestone for investigating 2D and 3D robotic vision tasks with large-scale data-driven techniques.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594495","","Robots;Three-dimensional displays;Trajectory;Deep learning;Image resolution;Rendering (computer graphics);Layout","control engineering computing;image colour analysis;image resolution;learning (artificial intelligence);rendering (computer graphics);robot vision;trajectory control;virtual reality","RobotriX;extremely photorealistic indoor dataset;very-large-scale indoor dataset;robot trajectories;deep learning techniques;robotic vision problems;hyperrealistic indoor scenes;robot agents;Unreal Engine;virtual reality headset;robotic hands;ground truth labels;3D robotic vision tasks;large-scale data-driven techniques;UnrealCV;full HD resolution;RGB-D;2D robotic vision tasks","","","30","","","","","IEEE","IEEE Conferences"
"Relative and inertial attitude determination in three-vehicle long formations","P. Cruz; P. Batista","Institute for Systems and Robotics, Laboratory for Robotics and Engineering Systems, Portugal; Institute for Systems and Robotics, Laboratory for Robotics and Engineering Systems, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2880","2885","This paper addresses a new attitude determination problem for formations. It considers a three-vehicle formation with relative and inertial measurements from sensors, where Constraints limit the relative measurements, which are not available between two of the vehicles, also known as deputies. The other vehicle is called the chief and does not have any limitation. Furthermore, each of the vehicles has an independent inertial measurement, whose references are known. The goal is to determine all attitude relations, both inertial and relative. The solution for this problem is divided into different stages. First, the relative attitude between the chief and the deputies is assessed, which results in two candidates for each of these relations. Then, each candidate yields a candidate for the inertial attitude of the chief. Next, comparing the four inertial candidates gives the solution for their respective relations and consequently for the relative relations as well. The remaining relations derive directly from those already known. The paper also provides some early insights about degeneracies, possible particular cases of the solution, and the effect of sensor noise. Finally, the solution is validated with a simulation, whose results are similar to attitude determination problems in constrained formations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593763","","Position measurement;Sensors;Extraterrestrial measurements;Visualization;Estimation;Space vehicles;Navigation","attitude control;attitude measurement;inertial navigation;mobile robots;multi-robot systems","inertial attitude;three-vehicle long formations;attitude determination problem;three-vehicle formation;independent inertial measurement;attitude relations;relative attitude;inertial candidates;constrained formations;sensor noise","","","12","","","","","IEEE","IEEE Conferences"
"Situated Human–Robot Collaboration: predicting intent from grounded natural language","J. Brawer; O. Mangin; A. Roncone; S. Widder; B. Scassellati","Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","827","833","Research in human teamwork shows that a key element of fluid and fluent interactions is the interpretation of implicit verbal and non-verbal cues in context. This poses an issue to robotic platforms, however, as they have historically worked best when controlled through explicit commands that have employed structured, unequivocal representations of the external world and their human partners. In this work, we present a framework for effectively grounding situated and naturalistic speech to action selection during human-robot collaborative activities. This is accomplished by maintaining and incrementally updating separate “speech” and “context” models that jointly classify a collaborator's utterance. We evaluate the efficacy of the system on a collaborative construction task with an autonomous robot and human participants. We first demonstrate that our system is capable of acquiring and deploying new task representations from limited and naturalistic data sets, and without any prior domain knowledge of language or the task itself. Finally, we show that our system is capable of significantly improving performance on an unfamiliar task after a one-shot exposure.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593942","","Task analysis;Collaboration;Context modeling;Natural languages;Tools;Robot kinematics","human-robot interaction;interactive systems;mobile robots;natural language processing","context models;collaborator;collaborative construction task;autonomous robot;task representations;naturalistic data sets;human-robot collaboration;grounded natural language;human teamwork;fluent interactions;nonverbal cues;robotic platforms;explicit commands;unequivocal representations;human partners;naturalistic speech;action selection;human-robot collaborative activities;separate speech","","","34","","","","","IEEE","IEEE Conferences"
"Persistent Monitoring with Refueling on a Terrain Using a Team of Aerial and Ground Robots","P. Maini; K. Yu; P. B. Sujit; P. Tokekar","Indraprastha Institute of Information Technology, India; Indraprastha Institute of Information Technology, India; Indraprastha Institute of Information Technology, India; Virginia Tech, Department of Electrical & Computer Engineering, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8493","8498","There are many applications such as surveillance and mapping that require persistent monitoring of terrains. In this work, we consider a heterogeneous team of aerial and ground robots that are tasked with monitoring a terrain along a given path. Both types of robots are equipped with cameras that can monitor the terrain within their fields-of-view. We also consider the ability of the aerial robots to land occasionally on the terrain to recharge. The objective is to find a path for all the robots to reduce the time required. Determining optimal routes for the robots is a challenging problem because of constrained visibility due to the terrain and fuel limitations of the robots. We devise an MILP formulation for the problem using a 1.5 dimensional representation model. A branch-and-cut framework is used to implement the MILP and involves the design of a separation algorithm to compute valid inequalities. We report results from extensive simulations and proof-of-concept field experiments to show the efficacy of our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593508","","Fuels;Monitoring;Unmanned aerial vehicles;Routing;Robot sensing systems;Kernel","aerospace robotics;integer programming;linear programming;multi-robot systems;path planning;tree searching","terrain;persistent monitoring;heterogeneous team;aerial robots;ground robots;MILP formulation;branch-and-cut framework;separation algorithm","","","16","","","","","IEEE","IEEE Conferences"
"Energy-Efficient Trajectory Generation for a Hexarotor with Dual- Tilting Propellers","F. Morbidi; D. Bicego; M. Ryll; A. Franchi","MIS laboratory, Université de Picardie Jules Verne, Amiens, 80039, France; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, 31400, France; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, 02139, USA; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, 31400, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6226","6232","In this paper, we consider a non-conventional hexarotor whose propellers can be simultaneously tilted about two orthogonal axes: in this way, its underactuation degree can be easily adapted to the task at hand. For a given tilt profile, the minimum-energy trajectory between two prescribed boundary states is explicitly determined by solving an optimal control problem with respect to the angular accelerations of the six brushless motors. We also perform, for the first time, a systematic study of the singularities of the control allocation matrix of the hexarotor, showing the presence of subtle singular configurations that should be carefully avoided in the design phase. Numerical experiments conducted with the FAST-Hex platform illustrate the theory and delineate the pros and cons of dual-tilting paradigm in terms of maneuverability and energy efficiency.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594419","","Propellers;Trajectory;Brushless motors;Batteries;Silicon;Force;Resource management","autonomous aerial vehicles;matrix algebra;optimal control;propellers;trajectory control","hexarotor;maneuverability;control allocation matrix;brushless motors;angular accelerations;optimal control problem;underactuation degree;dual- tilting propellers;energy-efficient trajectory generation","","","23","","","","","IEEE","IEEE Conferences"
"Composable Learning with Sparse Kernel Representations","E. Tolstaya; E. Stump; A. Koppel; A. Ribeiro","Department of ESE, University of Pennsylvania, Philadelphia, PA, 19104, USA; Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, MD, 20783, USA; Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, MD, 20783, USA; Department of ESE, University of Pennsylvania, Philadelphia, PA, 19104, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4622","4628","We present a reinforcement learning algorithm for learning sparse non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve the sample complexity of this approach by imposing a structure of the state-action function through a normalized advantage function (NAF). This representation of the policy enables efficiently composing multiple learned models without additional training samples or interaction with the environment. We demonstrate the performance of this algorithm on learning obstacle-avoidance policies in multiple simulations of a robot equipped with a laser scanner while navigating in a 2D environment. We apply the composition operation to various policy combinations and test them to show that the composed policies retain the performance of their components. We also transfer the composed policy directly to a physical platform operating in an arena with obstacles in order to demonstrate a degree of generalization.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594065","","Kernel;Stochastic processes;Hilbert space;Data models;Training;Complexity theory;Robots","collision avoidance;Hilbert spaces;learning (artificial intelligence);mobile robots;sparse matrices;stochastic processes","obstacle-avoidance policies;Reproducing kernel Hilbert space;NAF;2D environment;sparse kernel representations;normalized advantage function;state-action function;nonparametric controllers;reinforcement learning algorithm;composable learning","","","22","","","","","IEEE","IEEE Conferences"
"An Assist-as-Needed Velocity Field Control Scheme for Rehabilitation Robots","H. J. Asl; T. Narikiyo; M. Kawanishi","Department of Advanced Science and Technology, Control System Laboratory, Toyota Technological Institute, Tempaku-ku, 2-12-1 Hisakata, Nagoya, 468-8511, japan; Department of Advanced Science and Technology, Control System Laboratory, Toyota Technological Institute, Tempaku-ku, 2-12-1 Hisakata, Nagoya, 468-8511, japan; Department of Advanced Science and Technology, Control System Laboratory, Toyota Technological Institute, Tempaku-ku, 2-12-1 Hisakata, Nagoya, 468-8511, japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3322","3327","This paper addresses the problem of assist-as-needed (AAN) control for rehabilitation robots. To achieve a motion which is not explicitly a function of time, the velocity field control is considered in this paper. The proposed new controller consists of a proportional-like feedback term and a neural network (NN) term, where the later is exploited to compensate for the dynamic uncertainties of the system. The AAN property is facilitated by means of a dead-zone function in the feedback control term and a forgetting factor in the adaptation law of NN component. The designed controller guarantees the stability of the system with a bounded control command. The performance of the proposed AAN scheme is validated through the simulation and experiment conducted on a lower-limb exoskeleton.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594244","Rehabilitation robots;assist-as-need control;neural network;exoskeleton","Artificial neural networks;Timing;Aerospace electronics;Rehabilitation robotics;Stability analysis;Exoskeletons","control system synthesis;feedback;medical robotics;neural nets;patient rehabilitation;stability;velocity control","rehabilitation robots;neural network term;dead-zone function;feedback control term;bounded control command;AAN scheme;controller design;assist-as-needed velocity field control scheme;proportional-like feedback term;forgetting factor;lower-limb exoskeleton;NN component;system stability","","","21","","","","","IEEE","IEEE Conferences"
"FEM-Based Deformation Control for Dexterous Manipulation of 3D Soft Objects","F. Ficuciello; A. Migliozzi; E. Coevoet; A. Petit; C. Duriez","PRISMA Lab, University of Naples Federico II, via Claudio 21, Naples, 80125, Italy; PRISMA Lab, University of Naples Federico II, via Claudio 21, Naples, 80125, Italy; Defrost team: INRIA, CNRS, University of Lille and Ecole Centrale de Lille, France; Mimesis team: INRIA, 1, place de l'Hopital, Strasbourg, 67000, France; Defrost team: INRIA, CNRS, University of Lille and Ecole Centrale de Lille, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4007","4013","In this paper, a method for dexterous manipulation of 3D soft objects for real-time deformation control is presented, relying on Finite Element modelling. The goal is to generate proper forces on the fingertips of an anthropomorphic device during in-hand manipulation to produce desired displacements of selected control points on the object. The desired motions of the fingers are computed in real-time as an inverse solution of a Finite Element Method (FEM), the forces applied by the fingertips at the contact points being modelled by Lagrange multipliers. The elasticity parameters of the model are preliminarly estimated using a vision system and a force sensor. Experimental results are shown with an underactuated anthropomorphic hand that performs a manipulation task on a soft cylindrical object.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593512","","Strain;Finite element analysis;Robots;Deformable models;Three-dimensional displays;Biological system modeling;Estimation","control engineering computing;dexterous manipulators;elasticity;finite element analysis;force sensors;mobile robots;robot vision;solid modelling","finite element method;Lagrange multipliers;elasticity parameters;3D soft objects;dexterous manipulation;FEM-based deformation control;soft cylindrical object;manipulation task;underactuated anthropomorphic hand;force sensor;contact points;in-hand manipulation;anthropomorphic device","","","33","","","","","IEEE","IEEE Conferences"
"Artificial Invariant Subspace for Humanoid Robot Balancing in Locomotion","X. Deng; D. D. Lee","Department of Computer Science, ETH Zurich, Zurich, 8092, Switzerland; Department of Electrical and Computer Engineering, Cornell Tech, New York, NY, 10044, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","185","192","Legged robots that make use of compliant actuators have demonstrated greater robustness of locomotion than their rigid counterparts. Stiffness and damping are key parameters that characterize the adaptation to perturbations. In this work, by drawing inspirations from controllable compliance and damping in existing soft and bio-inspired legged robots, we propose an approach to design a nonlinear controller for the balancing of humanoid robots with rigid bodies. Existing literature has proposed simplified dynamical models of biped robots in order to predict the timing and placement of swing foot for walking without falling. We further employ the properties of invariance to perturbations in damped harmonic oscillators and formulate continuous feedback control in combination with predictive foot stepping in order to achieve continuous adaptive recoveries of the nominal walking cycle from unexpected physical disturbances. Our method allows asymptotic convergence of the rigid body dynamics to a subspace with the desired energy level. We demonstrate the robustness of the proposed algorithm base on extensive push recovery experiments on a NAO robot on flat terrains.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594423","","Legged locomotion;Foot;Humanoid robots;Orbits;Perturbation methods;Robustness","damping;feedback;humanoid robots;legged locomotion;motion control;nonlinear control systems;robot dynamics;stability","humanoid robots;biped robots;swing foot;damped harmonic oscillators;continuous feedback control;nominal walking cycle;rigid body dynamics;NAO robot;artificial invariant subspace;locomotion;compliant actuators;damping;nonlinear controller;robustness;bio-inspired legged robots;predictive foot stepping;asymptotic convergence;flat terrains","","","20","","","","","IEEE","IEEE Conferences"
"Learning-based Path Tracking Control of a Flapping-wing Micro Air Vehicle","J. Lee; S. Ryu; T. Kim; W. Kim; H. Jin Kim","Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7096","7102","Flapping-wing micro air vehicles (FWMAVs) become promising research platforms due to their advantages such as various maneuverability, and concealment. However, unsteady flow at low Reynolds number around the wings makes their dynamics time-varying and highly non-linear. It makes autonomous flight of FWMAV as a big challenge. In this paper, we suggest a model-based control strategy for FWMAV using learning architecture. For this task, we construct a ground station for logging flight data and control inputs, and train dynamics with a neural network. Then, we apply model predictive control (MPC) to the trained model. We validate our method by hardware experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594387","","Batteries;Training;Neural networks;Dynamics;Data models;Trajectory;Vehicle dynamics","aerodynamics;aerospace simulation;autonomous aerial vehicles;learning (artificial intelligence);mobile robots;neurocontrollers;predictive control;vehicle dynamics","autonomous flight;neural network;MPC;Reynolds number;model predictive control;model-based control strategy;FWMAV;flapping-wing microair vehicle;path tracking control","","","24","","","","","IEEE","IEEE Conferences"
"Improving Grasping Forces During the Manipulation of Unknown Objects","A. Montaño; R. Suárez","Universitat Politècnica de Catalunya (UPC), Institute of Industrial and Control Engineering (IOC), Barcelona, Spain; Universitat Politècnica de Catalunya (UPC), Institute of Industrial and Control Engineering (IOC), Barcelona, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3490","3495","Many of the solutions proposed for the object manipulation problem are based on the knowledge of the object features. The approach proposed in this paper intends to provide a simple geometrical approach to securely manipulate an unknown object based only on tactile and kinematic information. The tactile and kinematic data obtained during the manipulation is used to recognize the object shape (at least the local object curvature), allowing to improve the grasping forces when this information is added to the manipulation strategy. The approach has been fully implemented and tested using the Schunk Dexterous Hand (SDH2). Experimental results are shown to illustrate the efficiency of the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593655","","Shape;Tactile sensors;Force;Kinematics;Grasping","dexterous manipulators;manipulator kinematics;object recognition","simple geometrical approach;kinematic information;local object curvature;object manipulation problem;tactile information;object shape recognition;grasping forces;Schunk dexterous hand;SDH2","","","20","","","","","IEEE","IEEE Conferences"
"Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility","H. Yang; N. Staub; A. Franchi; D. Lee","Seoul National University, Department of Mechanical & Aerospace Engineering and IAMD, Seoul, Republic of Korea; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, France; Université de Toulouse, CNRS, LAAS-CNRS, Toulouse, France; Seoul National University, Department of Mechanical & Aerospace Engineering and IAMD, Seoul, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593834","","Unmanned aerial vehicles;Manipulators;Load modeling;Vibrations;Mathematical model;Shape","aerospace robotics;manipulators;mobile robots;multi-robot systems;vibration control","MAGMaS;load flexibility;heterogeneous system;aerial robot;rigid load manipulation;load weight holding;long-slender object manipulation;multiple aerial-ground manipulator system;flexible load-tip pose tracking;vibration suppression controllability","","","23","","","","","IEEE","IEEE Conferences"
"Incremental Object Database: Building 3D Models from Multiple Partial Observations","F. Furrer; T. Novkovic; M. Fehr; A. Gawel; M. Grinvald; T. Sattler; R. Siegwart; J. Nieto","ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland; ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland; ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland; ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland; ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland; Deparment of Computer Science, Computer Vision Group, ETH, Zurich, 8092, Switzerland; ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland; ETH, Autonomous Systems Lab, Zurich, 8092, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6835","6842","Collecting 3D object data sets involves a large amount of manual work and is time consuming. Getting complete models of objects either requires a 3D scanner that covers all the surfaces of an object or one needs to rotate it to completely observe it. We present a system that incrementally builds a database of objects as a mobile agent traverses a scene. Our approach requires no prior knowledge of the shapes present in the scene. Object-like segments are extracted from a global segmentation map, which is built online using the input of segmented RGB-D images. These segments are stored in a database, matched among each other, and merged with other previously observed instances. This allows us to create and improve object models on the fly and to use these merged models to reconstruct also unobserved parts of the scene. The database contains each (potentially merged) object model only once, together with a set of poses where it was observed. We evaluate our pipeline with one public dataset, and on a newly created Google Tango dataset containing four indoor scenes with some of the objects appearing multiple times, both within and across scenes.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594391","","Image segmentation;Databases;Three-dimensional displays;GSM;Shape;Image reconstruction;Solid modeling","feature extraction;image colour analysis;image reconstruction;image representation;image segmentation;mobile agents;object detection;solid modelling","multiple partial observations;incremental object database;indoor scenes;merged models;object model;observed instances;segmented RGB-D images;global segmentation map;3D models;mobile agent","","","34","","","","","IEEE","IEEE Conferences"
"Classification of EEG signals for a hypnotrack BCI system","M. Alimardani; S. Keshmiri; H. Sumioka; K. Hiraki","Department of Cognitive Science and Artificial Intelligence, Tilburg University, Netherlands; Lab Advanced Telecommunication Research Institute International (ATR), Japan; Lab Advanced Telecommunication Research Institute International (ATR), Japan; Department of General Systems Studies, Tokyo University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","240","245","People's responses to a hypnosis intervention is diverse and unpredictable. A system that predicts user's level of susceptibility from their electroencephalography (EEG) signals can be helpful in clinical hypnotherapy sessions. In this paper, we extracted differential entropy (DE) of the recorded EEGs from two groups of subjects with high and low hypnotic susceptibility and built a support vector machine on these DE features for the classification of susceptibility trait. Moreover, we proposed a clustering-based feature refinement strategy to improve the estimation of such trait. Results showed a high classification performance in detection of subjects' level of susceptibility before and during hypnosis. Our results suggest the usefulness of this classifier in development of future Bel systems applied in the domain of therapy and healthcare.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594136","","Electroencephalography;Entropy;Electrodes;Brain;Feature extraction;Support vector machines;Medical treatment","electroencephalography;feature extraction;medical signal processing;neurophysiology;patient treatment;signal classification;support vector machines","hypnotrack BCI system;EEG signals;clustering-based feature refinement strategy;support vector machine;clinical hypnotherapy sessions;electroencephalography signals;hypnosis intervention","","","26","","","","","IEEE","IEEE Conferences"
"Soft Snake Robots: Investigating the Effects of Gait Parameters on Locomotion in Complex Terrains","C. Branyan; Y. Menğüç","Oregon State University, Collaborative Robotics and Intelligent Systems Institute; Oregon State University, Collaborative Robotics and Intelligent Systems Institute","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Compliant materials used to create soft robots can better replicate biological structures than typical rigid materials. We can look to nature for developing locomotion strategies for these soft-bodied robots. In this work, snakes were used as inspiration to create an inextensible, soft robot which was used as a platform to test gaits in terrain composed of granular media ranging from fine sand to stone. Snakes vary the speed and amplitude of the traveling wave used in lateral undulation to navigate different environments. We used these gait parameters to develop and test a set of custom gaits that varied the phase offset of the sequence of waves as well as using the best performing gait to test how the amplitude of the wave effects locomotion over the selected terrains. These tests provide preliminary evidence that altering these parameters effects the robot's ability to traverse different terrains. The developed robot is also tested in environments specific to applications for snake robots to show how a soft snake robot can be potentially more effective in these environment. The highest performing gait-curvature combination was the half-activation gait (where the back actuator was activated half as long as the front)with a 135° swept angle. It reached a velocity of 2.2 mm/s or 0.011 body-lengths/s on paper, which was the best performing terrain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593404","","Actuators;Soft robotics;Snake robots;Navigation;Friction;Solenoids","mobile robots;motion control","gait-curvature combination;half-activation gait;soft robot;soft-bodied robots;locomotion strategies;compliant materials;complex terrains;gait parameters;soft snake robot","","","14","","","","","IEEE","IEEE Conferences"
"Inverse Error Function Trajectories for Image Reconstruction*This material is based upon work supported by the National Science Foundation under Grant No. 1662029","R. Katoch; B. Fusaro; J. Ueda","George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Bio-Robotics and Human Modeling Lab, Atlanta, GA, 30332, USA; George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Bio-Robotics and Human Modeling Lab, Atlanta, GA, 30332, USA; George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Bio-Robotics and Human Modeling Lab, Atlanta, GA, 30332, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7527","7532","Capturing clear images while a camera is moving fast, is integral to the development of mobile robots that can respond quickly and effectively to visual stimuli. This paper proposes to generate camera trajectories, with position and time constraints, that result in higher reconstructed image quality. The degradation in of an image captured during motion is known as motion blur. Three main methods exist for mitigating the effects of motion blur: (i) controlling optical parameters, (ii) controlling camera motion, and (iii) image reconstruction. Given control of a camera's motion, trajectories can be generated that result in an expected blur kernel or point-spread function. This work compares the motion blur effects and reconstructed image quality of three trajectories: (i) linear, (ii) polynomial, and (iii) inverse error. Where inverse error trajectories result in Gaussian blur kernels. Residence time analysis provides a basis for characterizing the motion blur effects of the trajectories.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594315","","Trajectory;Cameras;Image reconstruction;Robot vision systems;Optical imaging;Optical sensors","cameras;error analysis;Gaussian processes;image motion analysis;image restoration;mobile robots;optical transfer function","inverse error function trajectories;image reconstruction;mobile robots;visual stimuli;camera trajectories;camera motion;motion blur effects;image quality;Gaussian blur kernel;image capturing;linear error;polynomial error;time analysis;point-spread function","","","21","","","","","IEEE","IEEE Conferences"
"Human-Robot Cooperative Object Manipulation with Contact Changes","M. Gienger; D. Ruiken; T. Bates; M. Regaieg; M. MeiBner; J. Kober; P. Seiwald; A. Hildebrandt","Honda Research Institute Europe, Offenbach, Germany; Honda Research Institute Europe, Offenbach, Germany; Honda Research Institute Europe, Offenbach, Germany; Technical University of Munich, Arcisstraße 21, 80333, Germany; Honda Research Institute Europe, Offenbach, Germany; Technical University of Delft, Mekelweg 2, 2628CD, The Netherlands; Technical University of Munich, Arcisstraße 21, 80333, Germany; Technical University of Munich, Arcisstraße 21, 80333, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1354","1360","This paper presents a system for cooperatively manipulating large objects between a human and a robot. This physical interaction system is designed to handle, transport, or manipulate large objects of different shapes in cooperation with a human. Unique points are the bi-manual physical cooperation, the sequential characteristic of the cooperation including contact changes, and a novel architecture combining force interaction cues, interactive search-based planning, and online trajectory and motion generation. The resulting system implements a mixed initiative collaboration strategy, deferring to the human when his intentions are unclear, and driving the task once understood. This results in an easy and intuitive human-robot interaction. It is evaluated in simulations and on a bi-manual mobile robot with 32 degrees of freedom.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594140","","Robot sensing systems;Task analysis;Planning;Robot kinematics;Trajectory;Synchronization","cooperative systems;human-robot interaction;interactive systems;manipulators;mobile robots;path planning","physical interaction system;bi-manual physical cooperation;force interaction cues;interactive search-based planning;online trajectory;motion generation;mixed initiative collaboration strategy;human-robot cooperative object manipulation;human-robot interaction;bi-manual mobile robot","","","23","","","","","IEEE","IEEE Conferences"
"Development of the Research Platform of a Domestic Mobile Manipulator Utilized for International Competition and Field Test","T. Yamamoto; K. Terada; A. Ochiai; F. Saito; Y. Asahara; K. Murase","Frontier Research Center, TOYOTA MOTOR CORPORATION; Frontier Research Center, TOYOTA MOTOR CORPORATION; TOYOTA RESEARCH INSTITUTE; Frontier Research Center, TOYOTA MOTOR CORPORATION; Frontier Research Center, TOYOTA MOTOR CORPORATION; Frontier Research Center, TOYOTA MOTOR CORPORATION","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7675","7682","There has been an increasing interest in mobile manipulators that are capable of performing physical work in living spaces worldwide, corresponding to an aging population with declining birth rates with the expectation of improving quality of life (QoL). Research and development is a must in intelligent sensing and software which will enable advanced recognition, judgment, and motion to realize household work by robots. In order to accelerate this research, we have developed a compact and safe research platform, Human Support Robot (HSR), which can be operated in an actual home environment. We assume that overall R&D will accelerate by using a common robot platform among many researchers since that enables them to share their research results. Currently, the number of HSR users is expanding to 33 sites in 8 countries worldwide (as of February 15, 2018). Software and technical knowledge of all users is shared through a community website. HSR has been adopted as a standard platform for international robot competitions such as RoboCup@Home and World Robot Summit (WRS). HSR is provided to participants of those competitions through public offering. In this paper, we describe HSR's development background, and technical detail of its hardware and software. Specifically, we describe its omnidirectional mobile base using the dual-wheel caster-drive mechanism, which is the basis of HSR's operational movement and a novel whole body motion control system. Finally, we describe the results of utilization in RoboCup@Home and field tests in order to demonstrate the effect of introducing the platform.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593798","","Robot kinematics;Manipulators;Task analysis;Sensors;Software;Hardware","home computing;manipulators;mobile robots;motion control;multi-robot systems;wheels","international competition;aging population;intelligent sensing;household work;actual home environment;HSR users;technical knowledge;standard platform;international robot competitions;HSR's development background;omnidirectional mobile base;domestic mobile manipulator;human support robot;whole body motion control system;field test;quality of life;intelligent software;World Robot Summit;dual-wheel caster-drive mechanism;RoboCup@Home;HSR's operational movement","","","24","","","","","IEEE","IEEE Conferences"
"Leveraging Precomputation with Problem Encoding for Warm-Starting Trajectory Optimization in Complex Environments","W. Merkt; V. Ivan; S. Vijayakumar","The University of Edinburgh, Institute for Perception, Action, and Behaviour, School of Informatics, Informatics Forum 10 Crichton Street, Edinburgh, EH8 9AB, United Kingdom; The University of Edinburgh, Institute for Perception, Action, and Behaviour, School of Informatics, Informatics Forum 10 Crichton Street, Edinburgh, EH8 9AB, United Kingdom; The University of Edinburgh, Institute for Perception, Action, and Behaviour, School of Informatics, Informatics Forum 10 Crichton Street, Edinburgh, EH8 9AB, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5877","5884","Motion planning through optimization is largely based on locally improving the cost of a trajectory until an optimal solution is found. Choosing the initial trajectory has therefore a significant effect on the performance of the motion planner, especially when the cost landscape contains local minima. While multiple heuristics and approximations may be used to efficiently compute an initialization online, they are based on generic assumptions that do not always match the task at hand. In this paper, we exploit the fact that repeated tasks are similar according to some metric. We store solutions of the problem as a library of initial seed trajectories offline and employ a problem encoding to retrieve near-optimal warm-start initializations on-the-fly. We compare how different initialization strategies affect the global convergence and runtime of quasi-Newton and probabilistic inference solvers. Our analysis on the 38-DoF NASA Valkyrie robot shows that efficient and optimal planning in high-dimensional state spaces is possible despite the presence of globally non-smooth and discontinuous constraints, such as the ones imposed by collisions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593977","","Task analysis;Collision avoidance;Planning;Robots;Trajectory optimization","collision avoidance;convergence;humanoid robots;mobile robots;Newton method;trajectory control","problem encoding;warm-starting trajectory optimization;motion planner;local minima;motion planning;near-optimal warm-start initializations;global convergence;quasiNewton solvers;probabilistic inference solvers;NASA Valkyrie robot","","","29","","","","","IEEE","IEEE Conferences"
"Passive acoustic tracking for behavior mode classification between surface and underwater vehicles","E. M. Fischell; O. Viquez; H. Schmidt","Applied Ocean Physics and Engineering Department, Woods Hole Oceanographic Institution, 266 Woods Hole Rd., Woods Hole, MA, USA; Mechanical Engineering Department, MIT, 77 Massachusetts Avenue, Cambridge, MA, USA; Mechanical Engineering Department, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2383","2388","Autonomous underwater vehicles (AUVs) pose significant communication challenges: vehicles are submerged for periods of time in which speed-of-light communication is impossible. This is a particular problem on low-cost AUV platforms, on which acoustic modems are not available to get vehicle state or provide re-deploy commands. We investigate one possible method of providing operators with a communication line to these vehicles by using noise underwater to both classify behavior of submerged vehicles and to command them. In this scheme, processing of data from hydrophone arrays provide operators with AUV mode estimates and AUVs with surface vehicle behavior updates. Simulation studies were used to characterize trajectories for simple transect versus loiter behaviors based on the bearing and time to intercept (TTI). A classifier based on K-nearest-neighbor with dynamic time warping as a distance metric was used to classify simulation data. The simulation-based classifier was then applied to classify bearing tracking data from passive tracking of a loitering AUV and bearing and TTI data from passive tracking of a transecting boat based on field array data. Experiment data was classified with 76 % accuracy using bearing-only data, 96% accuracy for TTI -only data and 99 % accuracy for combined classification. The techniques developed here could be used for AUV cuing by surface vessels and monitoring of AUV behavior.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593981","","Boats;Acoustics;Sea surface;Trajectory;Arrays;Data models;Sonar equipment","autonomous underwater vehicles;hydrophones;mobile robots","acoustic modems;vehicle state;communication line;submerged vehicles;hydrophone arrays;AUV mode estimates;dynamic time;simulation data;simulation-based classifier;bearing tracking data;passive tracking;TTI data;field array data;experiment data;surface vessels;AUV behavior;passive acoustic tracking;behavior mode classification;autonomous underwater vehicles;speed-of-light communication;AUV platforms;surface vehicle behavior;K-nearest-neighbor","","","14","","","","","IEEE","IEEE Conferences"
"Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot","M. Zhao; F. Shi; T. Anzai; K. Chaudhary; X. Chen; K. Okada; M. Inaba","Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4735","4742","In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593368","","Unmanned aerial vehicles;Rotors;Collision avoidance;Path planning;Stability analysis;Robot sensing systems","aerospace control;aerospace robotics;aircraft control;autonomous aerial vehicles;collision avoidance;mobile robots;path planning;robot dynamics;stability","multilinked model;near-hover condition;motion sequence;improved dynamics derivation;flight control method;flight stability;small opening;flight motion;transformable multilinked aerial robot;multilinked robot;transformable aerial robot;under-actuated multirotors;aggressive maneuvering;necessary condition;crucial problems;unknown obstacle;multirotor;robot body","","","19","","","","","IEEE","IEEE Conferences"
"Towards Intelligent Arbitration of Diverse Active Learning Queries","K. Bullard; A. L. Thomaz; S. Chernova","Georgia Institute of Technology, School of Interactive Computing, Atlanta, Georgia, 30332-0250; The University of Texas at Austin, Department of Electrical & Computer Engineering, Austin, Texas, 78701; Georgia Institute of Technology, School of Interactive Computing, Atlanta, Georgia, 30332-0250","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6049","6056","Active learning literature has explored the selection of optimal queries by a learning agent with respect to given criteria, but prior work in classification has focused only on obtaining labels for queried samples. In contrast, proficient learners, like humans, integrate multiple forms of information during learning. This work seeks to enable an active learner to reason about multiple query types concurrently, aimed at soliciting both instance and feature information from the teacher, and to autonomously arbitrate between queries of different types. We contribute the design of rule-based and decision-theoretic arbitration strategies and evaluate all against baselines of more traditional passive and active learning. Our findings show that all arbitration strategies lead to more efficient learning, compared to the baselines. Moreover, given a dynamically changing environment and constrained questioning budget (typical in human settings), the decision-theoretic strategy statistically outperforms all other methods since it reasons about both what query to make and when to make a query, in order to most effectively utilize its questioning budget.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594279","","Task analysis;Training;Grounding;Robots;Feature extraction;Hafnium;Uncertainty","decision theory;learning (artificial intelligence);multi-agent systems;query processing","diverse active learning queries;optimal queries;learning agent;active learner;decision-theoretic arbitration strategies;decision-theoretic strategy;intelligent arbitration;rule-based arbitration strategies;passive learning","","1","22","","","","","IEEE","IEEE Conferences"
"Bipedal Hopping: Reduced-Order Model Embedding via Optimization-Based Control","X. Xiong; A. D. Ames","Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, 91125; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, 91125","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3821","3828","This paper presents the design and validation of controlling hopping on the 3D bipedal robot Cassie. A spring-mass model is identified from the kinematics and compliance of the robot. The spring stiffness and damping are encapsulated by the leg length, thus actuating the leg length can create and control hopping behaviors. Trajectory optimization via direct collocation is performed on the spring-mass model to plan jumping and landing motions. The leg length trajectories are utilized as desired outputs to synthesize a control Lyapunov function based quadratic program (CLF-QP). Centroidal angular momentum, taking as an addition output in the CLF-QP, is also stabilized in the jumping phase to prevent whole body rotation in the underactuated flight phase. The solution to the CLF-QP is a nonlinear feedback control law that achieves dynamic jumping behaviors on bipedal robots with compliance. The framework presented in this paper is verified experimentally on the bipedal robot Cassie.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593547","","Legged locomotion;Springs;Robot kinematics;Kinematics;Hip;Jacobian matrices","control system synthesis;feedback;legged locomotion;Lyapunov methods;nonlinear control systems;quadratic programming;robot dynamics;robot kinematics;springs (mechanical);stability","bipedal hopping;reduced-order model embedding;optimization-based control;spring-mass model;spring stiffness;damping;trajectory optimization;control Lyapunov function;CLF-QP;nonlinear feedback control law;dynamic jumping behaviors;bipedal robots;3D bipedal robot Cassie;quadratic program","","1","19","","","","","IEEE","IEEE Conferences"
"Inferring Semantic State Transitions During Telerobotic Manipulation","A. S. Bauer; P. Schmaus; A. Albu-Schäffer; D. Leidner","German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Human teleoperation of robots and autonomous operations go hand in hand in today's service robots. While robot teleoperation is typically performed on low to medium levels of abstraction, automated planning has to take place on a higher abstraction level, i.e. by means of semantic reasoning. Accordingly, an abstract state of the world has to be maintained in order to enable an operator to switch seamlessly between both operational modes. We propose a novel approach that combines simulation based geometric tracking and semantic state inference by means of so called State Inference Entities to overcome this issue. We also demonstrate how Evolutionary Strategies can be employed to refine simulation parameters. All experiments are demonstrated in real-world experiments conducted with the humanoid robot Rollin' Justin.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594458","","Semantics;Planning;Computational modeling;Physics;Robot sensing systems;Task analysis","control engineering computing;human-robot interaction;inference mechanisms;manipulators;mobile robots;service robots;telerobotics","telerobotic manipulation;autonomous operations;service robots;robot teleoperation;automated planning;higher abstraction level;semantic reasoning;abstract state;operational modes;simulation based geometric tracking;semantic state transitions inference;state inference entities","","","35","","","","","IEEE","IEEE Conferences"
"Ceiling Effects for Surface Locomotion of Small Rotorcraft","Y. H. Hsiao; P. Chirarattananon","City University of Hong Kong, Department of Mechanical and Biomedical Engineering, Hong Kong, SAR, China; City University of Hong Kong, Department of Mechanical and Biomedical Engineering, Hong Kong, SAR, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6214","6219","Motivated by the potential of bimodal aerial and surface locomotion as an energy saving strategy for small flying robots, we investigate the effects of a flat overhang surface in the vicinity of a spinning propeller. We employ the classical momentum theory and the blade element method to describe the “ceiling effects” in regards to the generated thrust, power, and rotational speed of the propeller in terms of a normalized distance between the ceiling and the propeller. Validating experiments were performed on a benchtop setup, and the results are in agreement with the proposed models. The presence of a ceiling was found to reduce the power consumption by more than a factor of three for the same thrust force. Overall, our findings show promise, paving the way for the use of perching maneuvers by small rotorcraft to extend their missions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593726","","Propellers;Robots;Blades;Rotors;Aerodynamics;Spinning;Mathematical model","aerodynamics;aerospace robotics;helicopters;mobile robots;propellers","small rotorcraft;ceiling effects;surface locomotion;energy saving strategy;flying robots;spinning propeller;classical momentum theory;blade element method;bimodal aerial locomotion","","","17","","","","","IEEE","IEEE Conferences"
"Down the CLiFF: Flow-Aware Trajectory Planning Under Motion Pattern Uncertainty","C. S. Swaminathan; T. P. Kucner; M. Magnusson; L. Palmieri; A. J. Lilienthal","AASS, Orebro University, Mobile Robots and Olfaction Lab, Sweden; AASS, Orebro University, Mobile Robots and Olfaction Lab, Sweden; AASS, Orebro University, Mobile Robots and Olfaction Lab, Sweden; Robert Bosch GmbH Corporate Research, Germany; AASS, Orebro University, Mobile Robots and Olfaction Lab, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7403","7409","In this paper we address the problem of flow-aware trajectory planning in dynamic environments considering flow model uncertainty. Flow-aware planning aims to plan trajectories that adhere to existing flow motion patterns in the environment, with the goal to make robots more efficient, less intrusive and safer. We use a statistical model called CLiFF-map that can map flow patterns for both continuous media and discrete objects. We propose novel cost and biasing functions for an RRT* planning algorithm, which exploits all the information available in the CLiFF-map model, including uncertainties due to flow variability or partial observability. Qualitatively, a benefit of our approach is that it can also be tuned to yield trajectories with different qualities such as exploratory or cautious, depending on application requirements. Quantitatively, we demonstrate that our approach produces more flow-compliant trajectories, compared to two baselines.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593905","","Trajectory;Robots;Planning;Cost function;Uncertainty;Vehicle dynamics;Aerospace electronics","mobile robots;path planning","flow-aware tralatory planning;motion pattern uncertainty;flow-aware trajectory;dynamic environments;flow model uncertainty;flow-aware planning;statistical model;map flow patterns;biasing functions;RRT* planning algorithm;CLiFF-map model;flow-compliant trajectories;flow motion patterns","","","10","","","","","IEEE","IEEE Conferences"
"Summarizing Large Scale 3D Mesh","I. B. Salah; S. Kramm; C. Demonceaux; P. Vasseur","UNIROUEN UNIHAVRE INSA Rouen LITIS, Laboratoire d'Informatique De Traitement de l'Information et des Systemes Normandie Univ, 76000 Rouen, France; UNIROUEN UNIHAVRE INSA Rouen LITIS, Laboratoire d'Informatique De Traitement de l'Information et des Systemes Normandie Univ, 76000 Rouen, France; ERL VIBOT CNRS 6000 Universite Bourgogne Franche-Comte, Laboratoire Le2i; ERL VIBOT CNRS 6000 Universite Bourgogne Franche-Comte, Laboratoire Le2i","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Recent progress in 3D sensor devices and in semantic mapping allows to build very rich HD 3D maps very useful for autonomous navigation and localization. However, these maps are particularly huge and require important memory capabilities as well computational resources. In this paper, we propose a new method for summarizing a 3D map (Mesh)as a set of compact spheres in order to facilitate its use by systems with limited resources (smartphones, robots, UAVs,...). This vision-based summarizing process is applied in a fully automatic way using jointly photometric, geometric and semantic information of the studied environment. The main contribution of this research is to provide a very compact map that maximizes the significance of its content while maintaining the full visibility of the environment. Experimental results in summarizing large-scale 3D map demonstrate the feasibility of our approach and evaluate the performance of the algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593372","","Three-dimensional displays;Navigation;Entropy;Semantics;Visualization;Optimization;Robots","mesh generation;mobile robots;robot vision;SLAM (robots);stereo image processing","vision-based summarizing process;HD 3D maps;large-scale 3D map;semantic information;geometric information;photometric information;autonomous navigation;semantic mapping;3D sensor devices","","","23","","","","","IEEE","IEEE Conferences"
"Cost Adaptation for Robust Decentralized Swarm Behaviour","P. Henderson; M. Vertescher; D. Meger; M. Coates","Department of Computer Science, McGill University, Montreal, Quebec, Canada; Department of Electrical, Computer, and Software Engineering, McGill University, Montreal, Quebec, Canada; Department of Computer Science, McGill University, Montreal, Quebec, Canada; Department of Electrical, Computer, and Software Engineering, McGill University, Montreal, Quebec, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4099","4106","Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multiagent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process - cost adaptation - which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594283","","Task analysis;Delays;Decision making;Cost function;Mesh networks;Control systems","computer games;control engineering computing;decentralised control;learning (artificial intelligence);multi-agent systems;multi-robot systems;optimisation;robot dynamics","cost adaptation;decentralized receding horizon control;multiagent settings;meta-learning process;mesh-networked swarm agents;adaptation mechanism;safer task completion;Unity3D game engine;D-RHC;robust decentralized swarm behaviour","","","23","","","","","IEEE","IEEE Conferences"
"Real-Time Edge Template Tracking via Homography Estimation","X. Qin; S. He; Z. Zhang; M. Dehghan; J. Jin; M. Jagersand","Dept. of Computing Science, University of Alberta, Canada; Dept. of Computing Science, University of Alberta, Canada; Dept. of Computing Science, University of Alberta, Canada; Dept. of Computing Science, University of Alberta, Canada; Dept. of Computing Science, University of Alberta, Canada; Dept. of Computing Science, University of Alberta, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","607","612","In this paper, we propose a novel real-time method for tracking planar edge templates. This method tracks an edge template by estimating its homography transformations with respect to the sampled edge pixels detected from the incoming frames. Particularly, we define a cost function based on a new feature map of the to-be-tracked edge template and optimize it by a Lucas-Kanade-like algorithm. The feature map is defined as the fourth root of the distance transform. Our method operates on just edges so that it is good at tracking those low textured targets, such as hollow targets (mug rim), thin targets (cable, ring) and non-Lambertian objects (disc). We validate and compare our method with four other methods on five newly collected real-world video sequences. The results achieves the lowest overall average error (1.58 pixels) and also outperforms others in terms of success rate. The per frame processing time of about 30 ms proves that our method is acceptable in realtime applications. The code and dataset are publicly available at: http://webdocs.cs.ualberta.ca/~xuebin/.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593551","","Image edge detection;Target tracking;Real-time systems;Video sequences;Cost function;Transforms","edge detection;feature extraction;image sampling;image sequences;image texture;target tracking;transforms;video signal processing","homography estimation;planar edge templates;homography transformations;sampled edge pixels;Lucas-Kanade-like algorithm;low textured targets;edge template tracking;nonLambertian objects;video sequences","","","18","","","","","IEEE","IEEE Conferences"
"Procedurally Provisioned Access Control for Robotic Systems","R. White; H. I. Christensen; G. Caiazza; A. Cortesi","Contextual Robotics Institute UC San Diego, California, USA; Contextual Robotics Institute UC San Diego, California, USA; Ca’ Foscari University of Venice Venezia VE, Italy; Ca’ Foscari University of Venice Venezia VE, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Security of robotics systems, as well as of the related middleware infrastructures, is a critical issue for industrial and domestic IoT, and it needs to be continuously assessed throughout the whole development lifecycle. The next generation open source robotic software stack, ROS2, is now targeting support for Secure DDS, providing the community with valuable tools for secure real world robotic deployments. In this work, we introduce a framework for procedural provisioning access control policies for robotic software, as well as for verifying the compliance of generated transport artifacts and decision point implementations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594462","","Service robots;Access control;Middleware;Tools;Cryptography","authorisation;Internet of Things;middleware;public domain software;robot programming","robotic systems;industrial IoT;domestic IoT;development lifecycle;ROS2;secure real world robotic deployments;procedural provisioning access control policies;secure DDS;middleware infrastructures;next generation open source robotic software stack","","1","22","","","","","IEEE","IEEE Conferences"
"Adaptive Modality Selection Algorithm in Robot-Assisted Cognitive Training","A. Taranović; A. Jevtić; C. Torras","CSIC-UPC, Institut de Robotica i Informatica Industrial, Barcelona, Spain; CSIC-UPC, Institut de Robotica i Informatica Industrial, Barcelona, Spain; CSIC-UPC, Institut de Robotica i Informatica Industrial, Barcelona, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4456","4461","Interaction of socially assistive robots with users is based on social cues coming from different interaction modalities, such as speech or gestures. However, using all modalities at all times may be inefficient as it can overload the user with redundant information and increase the task completion time. Additionally, users may favor certain modalities over the other as a result of their disability or personal preference. In this paper, we propose an Adaptive Modality Selection (AMS) algorithm that chooses modalities depending on the state of the user and the environment, as well as user preferences. The variables that describe the environment and the user state are defined as resources, and we posit that modalities are successful if certain resources possess specific values during their use. Besides the resources, the proposed algorithm takes into account user preferences which it learns while interacting with users. We tested our algorithm in simulations, and we implemented it on a robotic system that provides cognitive training, specifically Sequential memory exercises. Experimental results show that it is possible to use only a subset of available modalities without compromising the interaction. Moreover, we see a trend for users to perform better when interacting with a system with implemented AMS algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593730","","Shape;Training;Service robots;Manipulators;Task analysis;Market research","cognition;human-robot interaction;learning (artificial intelligence);medical robotics;patient rehabilitation;robot programming;service robots","robotic system;robot-assisted cognitive training;socially assistive robots;therapy;Alzheimer's disease;mild cognitive impairment;dementia;adaptive modality selection algorithm;interaction modalities;AMS algorithm","","","16","","","","","IEEE","IEEE Conferences"
"Learning Implicit Sampling Distributions for Motion Planning","C. Zhang; J. Huh; D. D. Lee","All authors are affiliated with the GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, 19104; All authors are affiliated with the GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, 19104; All authors are affiliated with the GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, 19104","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3654","3661","Sampling-based motion planners have experienced much success due to their ability to efficiently and evenly explore the state space. However, for many tasks, it may be more efficient to not uniformly explore the state space, especially when there is prior information about its structure. Previous methods have attempted to modify the sampling distribution using hand selected heuristics that can work well for specific environments but not universally. In this paper, a policy-search based method is presented as an adaptive way to learn implicit sampling distributions for different environments. It utilizes information from past searches in similar environments to generate better distributions in novel environments, thus reducing overall computational cost. Our method can be incorporated with a variety of sampling-based planners to improve performance. Our approach is validated on a number of tasks, including a 7DOF robot arm, showing marked improvement in number of collision checks as well as number of nodes expanded compared with baseline methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594028","","Planning;Task analysis;Probability distribution;Manipulators;Space exploration;Collision avoidance","learning (artificial intelligence);manipulators;mobile robots;path planning;sampling methods;search problems","implicit sampling distributions;motion planning;sampling-based motion planners;state space;sampling distribution;hand selected heuristics;policy-search based method;sampling-based planners;7DOF robot arm","","","28","","","","","IEEE","IEEE Conferences"
"Mechatronic fingernail with static and dynamic force sensing","R. Kõiva; T. Schwank; G. Walck; R. Haschke; H. J. Ritter","Neuroinformatics Group, Center of Excellence Cognitive Interaction Technology, Bielefeld University, Bielefeld, 33619, Germany; Neuroinformatics Group, Center of Excellence Cognitive Interaction Technology, Bielefeld University, Bielefeld, 33619, Germany; Neuroinformatics Group, Center of Excellence Cognitive Interaction Technology, Bielefeld University, Bielefeld, 33619, Germany; Neuroinformatics Group, Center of Excellence Cognitive Interaction Technology, Bielefeld University, Bielefeld, 33619, Germany; Neuroinformatics Group, Center of Excellence Cognitive Interaction Technology, Bielefeld University, Bielefeld, 33619, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2114","2119","Our fingernails help us to accomplish a variety of manual tasks, but surprisingly only a few robotic hands are equipped with nails. In this paper, we present a sensorized fingernail for mechatronic hands that can capture static and dynamic interaction forces with the nail. Over the course of several iterations, we have developed a very compact working prototype that fits together with our previously developed multi-cell tactile fingertip sensor into the cavity of the distal phalange of a human-sized robotic hand. We present the construction details, list the key performance characteristics and demonstrate an example application of finding the end of an adhesive tape roll using the signals captured by the sensors integrated in the nail. We conclude with a discussion about improvement ideas for future versions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594207","","Nails;Robot sensing systems;Force;Force measurement;Delays","force control;force sensors;manipulators;mechatronics;motion control","compact working prototype;multicell tactile fingertip sensor;distal phalange;robotic hand;mechatronic fingernail;static force sensing;dynamic force sensing;sensorized fingernail;mechatronic hands;static interaction forces;dynamic interaction forces","","1","16","","","","","IEEE","IEEE Conferences"
"Towards a Soft Fingertip with Integrated Sensing and Actuation","B. W. McInroe; C. L. Chen; K. Y. Goldberg; K. Y. Goldberg; R. Bajcsy; R. S. Fearing","B.W. McInroe is with the Biophysics Graduate Group, University of California, Berkeley, CA, 94720, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, 94720, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, 94720, USA; Department of Industrial Engineering and Operations Research, University of California, Berkeley, 94720, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, 94720, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6437","6444","Soft material robots are attractive for safe interaction with humans and unstructured environments due to their compliance and low intrinsic stiffness and mass. These properties enable new capabilities such as the ability to conform to environmental geometry for tactile sensing and to undergo large shape changes for actuation. Due to the complex coupling between sensing and actuation in high-dimensional nonlinear soft systems, prior work in soft robotics has primarily focused on either sensing or actuation. This paper presents SOFTcell, a novel controllable stiffness tactile device that incorporates both optical sensing and pneumatic actuation. We report details on the device's design and implementation and analyze results from characterization experiments on sensitivity and performance, which show that SOFTcell can controllably increase its effective modulus from 4.4kPa to 46.1kPa. Additionally, we demonstrate the utility of SOFTcell for grasping in a reactive control task in which tactile data is used to detect fingertip shear as a grasped object slips, and cell pressurization is used to prevent the slip without the need to adjust fingertip position.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594032","","Cameras;Tactile sensors;Optical sensors;Strain","biomechanics;dexterous manipulators;elasticity;force control;haptic interfaces;manipulator dynamics;pneumatic actuators;tactile sensors","tactile data;SOFTcell;pneumatic actuation;optical sensing;novel controllable stiffness tactile device;soft robotics;high-dimensional nonlinear soft systems;complex coupling;shape changes;tactile sensing;environmental geometry;low intrinsic stiffness;unstructured environments;safe interaction;soft material robots;integrated sensing;soft fingertip","","","38","","","","","IEEE","IEEE Conferences"
"Wearable Pediatric Gait Exoskeleton - A Feasibility Study","A. Ganguly; D. Sanz-Merodio; G. Puyuelo; A. Goñi; E. Garces; E. Garcia","Marsi Bionics SL, Av. Punto ES Alcala de Henares, Madrid, Spain; Marsi Bionics SL, Av. Punto ES Alcala de Henares, Madrid, Spain; Marsi Bionics SL, Av. Punto ES Alcala de Henares, Madrid, Spain; CSIC-UPM, Centre for Automation and Robotics, Arganda del Rey, Madrid, Spain; Marsi Bionics SL, Av. Punto ES, Alcala de Henares, Madrid, Spain; CSIC-UPM, Centre for Automation and Robotics, Arganda del Rey, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4667","4672","This study reports the initial testing of a gait exoskeleton for Spinal Muscular Atrophy (SMA) patients having variable muscle strength with no balance or ambulation capabilities. To improve the quality of life of such patients, a pediatric gait exoskeleton was developed. The ATLAS exoskeleton has 8 active degrees of freedom (DOF): 2 at the hip (adduction/abduction and flexion/extension), 1 at the knee and ankle joint for flexion and extension. A feasibility test was performed to gauge the initial response of the patients. This study demonstrates that the exoskeleton was able to provide gait assistance and sit-to-stand movements effectively to the subjects. This kind of wearable exoskeleton will play a key role in the rehabilitation of SMA patients and delay further metabolic degeneration in the future.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594211","","Exoskeletons;Pediatrics;Diseases;Force;Torque;Hip;Biomimetics","gait analysis;medical robotics;muscle;orthotics;paediatrics;patient rehabilitation","metabolic degeneration;SMA patient rehabilitation;sit-to-stand movements;degrees-of-freedom;flexion-extension;adduction-abduction;muscle strength;wearable exoskeleton;gait assistance;feasibility test;ATLAS exoskeleton;Spinal Muscular Atrophy patients;wearable pediatric gait exoskeleton","","","16","","","","","IEEE","IEEE Conferences"
"Positioning. Navigation and Awareness of the !VAMOS! Underwater Robotic Mining System","J. Almeida; A. Martins; C. Almeida; A. Dias; B. Matias; A. Ferreira; P. Jorge; R. Martins; M. Bleier; A. Nuchter; J. Pidgeon; S. Kapusniak; E. Silva","INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal; INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, Porto, Portugal; Zentrum fur Telematik e.V., Wurzburg, Germany; Informatics VII Robotics and Telematics, Julius Maximilian University of Wurzburg and Zentrum fur Telematik e. V., Wurzburg, Germany; BMT WBM Pty Ltd, Brisbane, Australia; Soil Machine Dynamics, Newcastle-Upon Tyne, United Kingdom; INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1527","1533","This paper presents the positioning, navigation and awareness (PNA) system developed for the Underwater Robotic Mining System of the !VAMOS! project [1]. It describes the main components of the !VAMOS! system, the PNA sensors in each of those components, the global architecture of the PNA system, and its main subsystems: Position and Navigation, Realtime Mine Modeling, 3D Virtual reality HMI and Real-time grade system. General results and lessons learn during the first mining field trial in Lee Moor, Devon, UK during the months of September and October 2017 are presented.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593869","","Three-dimensional displays;Sensor systems;Solid modeling;Presence network agents;Virtual reality;Real-time systems","control engineering computing;mining;mobile robots;position control;virtual reality","global architecture;real-time grade system;3D virtual reality HMI;realtime mine modeling;¡VAMOS!;underwater robotic mining system;navigation;mining field trial;PNA system;PNA sensors","","","15","","","","","IEEE","IEEE Conferences"
"Humanoid Navigation Planning in Large Unstructured Environments Using Traversability - Based Segmentation","Y. Lin; D. Berenson","Yu-Chi Lin and Dmitry Berenson are with the University of Michigan, Ann Arbor, MI, U.S.A.; Yu-Chi Lin and Dmitry Berenson are with the University of Michigan, Ann Arbor, MI, U.S.A.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7375","7382","Humanoids' abilities to navigate stairs and uneven terrain make them well-suited for disaster response efforts. However, humanoid navigation in such environments is currently limited by the capabilities of navigation planners. Such planners typically consider only footstep locations, but planning with palm contacts may be necessary to cross a gap, avoid an obstacle, or maintain balance. However, considering palm contacts greatly increases the branching factor of the search, leading to impractical planning times for large environments. In previous work we explored using library-based methods to address difficult navigation planning problems requiring palm contacts, but such methods are not efficient when navigating an easy-to-traverse part of the environment. To maximize planning efficiency, we would like to use discrete planners when an area is easy to traverse and switch to the library-based method only when traversal becomes difficult. Thus, in this paper we present a method that 1) Plans a guiding torso path which accounts for the difficulty of traversing the environment as predicted by learned regressors; and 2) Decomposes the guiding path into a set of segments, each of which is assigned a motion mode (i.e. a set of feet and hands to use) and a planning method. Easily-traversable segments are assigned a discrete-search planner, while other segments are assigned a library-based method that fits existing motion plans to the environment near the given segment. Our results suggest that this segmentation approach greatly outperforms standard discrete planning and that using the library-based method for more difficult segments gives a benefit over using discrete planning.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593694","","Planning;Motion segmentation;Torso;Navigation;Humanoid robots;Foot","collision avoidance;humanoid robots;image segmentation;learning (artificial intelligence);legged locomotion;motion control;planning (artificial intelligence);robot kinematics","humanoid navigation planning;unstructured environments;disaster response efforts;navigation planners;considering palm contacts;impractical planning times;library-based method;easy-to-traverse part;discrete planners;easily-traversable segments;discrete-search planner;motion plans;standard discrete planning;navigation planning problems;traversability -based segmentation","","","18","","","","","IEEE","IEEE Conferences"
"Identification of the User's Habits based on Activity Information","N. Melo; J. Lee; R. Suzuki","College of Engineering, Chubu University, 1200 Matsumoto-cho, Kasugai, Aichi, 487-8501, Japan; College of Engineering, Chubu University, 1200 Matsumoto-cho, Kasugai, Aichi, 487-8501, Japan; College of Engineering, Chubu University, 1200 Matsumoto-cho, Kasugai, Aichi, 487-8501, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2014","2019","This work proposes a system able to recognize the user habits based on his daily activities in a smart house. The habit estimation system uses the information provided by an activity recognition module, which provides the sequence and the duration of the activities performed by the user. Based on those parameters, the activities are represented as a signal by using Fourier series representation. Several output signals from different users are clustered into groups using the k-means method, where each cluster corresponds to a specific habit from a group of people. The proposed system was tested with dataset from the experiment that took place in an environment similar to a smart house. The users were asked to perform a set of 6 activities in any desired orders. In total, twenty-four subjects took part in the experiments. All activities were successfully recognized by the system and three different habits were found. The proposed system along with its habit representation can be potentially used to trace the relationships between the habits observed and some aspects of the user personality traits.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593873","","Activity recognition;Robot kinematics;TV;Radiofrequency identification;Receivers;Senior citizens","Fourier series;home automation;service robots","k-means method;Fourier series representation;activity recognition module;habit estimation system;smart house;user habits;activity information;user personality traits;habit representation","","","19","","","","","IEEE","IEEE Conferences"
"Circle Formation with Computation-Free Robots Shows Emergent Behavioural Structure","D. St-Onge; C. Pinciroli; G. Beltrame","Department of Computer and Software Engineering, Ècole Poly technique de Montréal, Quebec, CA; Department of Computer and Software Engineering, Ècole Poly technique de Montréal, Quebec, CA; Department of Computer Science, Worcester Polytechnic Institute, US","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5344","5349","In this paper, we demonstrate how behavioural structure, such as a finite state machine, can emerge in minimal robots without computation nor memory capabilities. As a case study we observe the ability of a group of non-holonomic robots to form robust, self-healing circle formations in a decentralized manner using only a limited frontal binary sensor. We present a grid-search method to find suitable parameters that promote the formation of a stable circle. We then examine how the parameters of the controllers affect the appearance of the behaviour, and provide theoretical proof for its emergence and self-healing properties. We validate the proposed model through a set of experiments with ten mobile real robots. Our results with real robots match the simulated experiments and provide insights on how a simple, computation-free behaviour can generate complex spatio-temporal dynamics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593439","","Robot sensing systems;Mobile robots;Robot kinematics;Apertures;Standards;Computational modeling","finite state machines;mobile robots;multi-robot systems;spatiotemporal phenomena","computation-free robots;emergent behavioural structure;finite state machine;minimal robots;nonholonomic robots;self-healing circle formations;frontal binary sensor;grid-search method;computation-free behaviour;spatio-temporal dynamics","","","12","","","","","IEEE","IEEE Conferences"
"Probabilistic Dense Reconstruction from a Moving Camera","Y. Ling; K. Wang; S. Shen","Tencent AI Lab, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6364","6371","This paper presents a probabilistic approach for online dense reconstruction using a single monocular camera moving through the environment. Compared to spatial stereo, depth estimation from motion stereo is challenging due to insufficient parallaxes, visual scale changes, pose errors, etc. We utilize both the spatial and temporal correlations of consecutive depth estimates to increase the robustness and accuracy of monocular depth estimation. An online, recursive, probabilistic scheme to compute depth estimates, with corresponding covariances and inlier probability expectations, is proposed in this work. We integrate the obtained depth hypotheses into dense 3D models in an uncertainty-aware way. We show the effectiveness and efficiency of our proposed approach by comparing it with state-of-the-art methods in the TUM RGB-D SLAM & ICL-NUIM dataset. Online indoor and outdoor experiments are also presented for performance demonstration.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593618","","Image reconstruction;Cameras;Estimation;Visualization;Robot vision systems;Probabilistic logic;Simultaneous localization and mapping","cameras;image colour analysis;image reconstruction;image sequences;probability;SLAM (robots);stereo image processing","TUM RGB-D SLAM;ICL-NUIM dataset;spatial correlations;visual scale changes;insufficient parallaxes;motion stereo;spatial stereo;single monocular camera;online dense reconstruction;probabilistic approach;moving camera;probabilistic dense reconstruction;outdoor experiments;dense 3D models;inlier probability expectations;depth estimates;probabilistic scheme;monocular depth estimation;temporal correlations","","","26","","","","","IEEE","IEEE Conferences"
"NDVI Point Cloud Generator Tool Using Low-Cost RGB-D Sensor","D. Calero; E. Fernández; M. E. Parés; E. Angelats","Pare Mediterrani de la Tecnologia (PMT), Geomatics division of the Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Castelldefels, Building B4, Av. Carl Friedrich Gauss 7, 08860, Spain; Pare Mediterrani de la Tecnologia (PMT), Geomatics division of the Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Castelldefels, Building B4, Av. Carl Friedrich Gauss 7, 08860, Spain; Pare Mediterrani de la Tecnologia (PMT), Geomatics division of the Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Castelldefels, Building B4, Av. Carl Friedrich Gauss 7, 08860, Spain; Pare Mediterrani de la Tecnologia (PMT), Geomatics division of the Centre Tecnològic de Telecomunicacions de Catalunya (CTTC/CERCA), Castelldefels, Building B4, Av. Carl Friedrich Gauss 7, 08860, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7860","7865","In this manuscript, a NDVI point cloud generator tool based on low-cost active RGB-D sensor is presented. Taking advantage of currently available ROS point cloud generation tools and RGB-D sensor technology (like Microsoft Kinect), that includes an inbuilt active IR camera and a RGB camera, 3D NDVI maps can be quickly and easily generated for vegetation monitoring purposes. When using low-cost sensors for vegetation index estimation, it is necessary to apply a rigorous methodology for extracting reliable information. In this paper, the methodology for NDVI generation using a low-cost sensor as well as experiments to evaluate its performance is presented. The experiments performed show that it is possible to obtain a reliable NDVI point cloud from a Kinect V2.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594175","","Conferences;Intelligent robots","cameras;geophysical image processing;image colour analysis;image sensors;vegetation mapping","vegetation index estimation;Microsoft Kinect V2;vegetation monitoring purposes;ROS point cloud generation tools;active IR camera;active RGB-D sensor technology;RGB camera;NDVI point cloud generator tool;3D NDVI maps","","","15","","","","","IEEE","IEEE Conferences"
"Transparency-Optimal Passivity Layer Design for Time-Domain Control of Multi-DoF Haptic-Enabled Teleoperation","O. A. Moreno Franco; J. Bimbo; C. Pacchierotti; D. Prattichizzo; D. Barcelli; G. Bianchini","Istituto Italiano di Tecnologia, Advanced Robotics Department, Genova, 16163, Italy; Istituto Italiano di Tecnologia, Advanced Robotics Department, Genova, 16163, Italy; CNRS IRISA, Univ Rennes, Inria, Rennes Cedex, 35042, France; Istituto Italiano di Tecnologia, Advanced Robotics Department, Genova, 16163, Italy; Dipartimento di Ingegneria dell’ Informazione e Scienze Matematiche, Università degli Studi di Siena, Siena, 53100, Italy; Dipartimento di Ingegneria dell’ Informazione e Scienze Matematiche, Università degli Studi di Siena, Siena, 53100, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4988","4994","This paper presents a novel optimization-based passivity control algorithm for haptic-enabled bilateral teleoperation systems involving multiple degrees of freedom. In particular, in the context of energy-bounding control, the contribution focuses on the implementation of a passivity layer for an existing time-domain scheme, ensuring optimal transparency of the interaction along subsets of the environment space which are preponderant for the given task, while preserving the energy bounds required for passivity. The involved optimization problem is convex and amenable to real-time implementation. The effectiveness of the proposed design is validated via an experiment performed on a virtual teleoperated environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593443","","Force;Task analysis;Computer architecture;Robots;Indexes;Time-domain analysis;Haptic interfaces","haptic interfaces;optimisation;telerobotics","time-domain scheme;optimization problem;optimization-based passivity control algorithm;virtual teleoperated environment;real-time implementation;optimal transparency;energy-bounding control;haptic-enabled bilateral teleoperation systems;multiDoF;time-domain control;transparency-optimal passivity layer design","","","23","","","","","IEEE","IEEE Conferences"
"Trifo-VIO: Robust and Efficient Stereo Visual Inertial Odometry Using Points and Lines","F. Zheng; G. Tsai; Z. Zhang; S. Liu; C. Chu; H. Hu","Trifo, Inc., Santa Clara, CA, 95054, USA; Trifo, Inc., Santa Clara, CA, 95054, USA; Trifo, Inc., Santa Clara, CA, 95054, USA; Trifo, Inc., Santa Clara, CA, 95054, USA; Trifo, Inc., Santa Clara, CA, 95054, USA; Trifo, Inc., Santa Clara, CA, 95054, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3686","3693","In this paper, we present the Trifo Visual Inertial Odometry (Trifo-VIO), a tightly-coupled filtering-based stereo VIO system using both points and lines. Line features help improve system robustness in challenging scenarios when point features cannot be reliably detected or tracked, e.g. low-texture environment or lighting change. In addition, we propose a novel lightweight filtering-based loop closing technique to reduce accumulated drift without global bundle adjustment or pose graph optimization. We formulate loop closure as EKF updates to optimally relocate the current sliding window maintained by the filter to past keyframes. We also present the Trifo Ironsides dataset, a new visual-inertial dataset, featuring high-quality synchronized stereo camera and IMU data from the Ironsides sensor [3] with various motion types and textures and millimeter-accuracy groundtruth. To validate the performance of the proposed system, we conduct extensive comparison with state-of-the-art approaches (OKVIS, VINS-MONO and S-MSCKF) using both the public EuRoC dataset and the Trifo Ironsides dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594354","","Cameras;Optimization;Visualization;Feature extraction;Image edge detection;Three-dimensional displays;Robot sensing systems","computer graphics;distance measurement;filtering theory;graph theory;image matching;Kalman filters;mobile robots;nonlinear filters;pose estimation;robot vision;SLAM (robots);stereo image processing","efficient stereo Visual Inertial Odometry;stereo VIO system;line features;system robustness;point features;low-texture environment;lightweight filtering-based loop closing technique;global bundle adjustment;graph optimization;current sliding window;Trifo Ironsides dataset;visual-inertial dataset;high-quality synchronized stereo camera","","","41","","","","","IEEE","IEEE Conferences"
"Cross-Scene Suture Thread Parsing for Robot Assisted Anastomosis based on Joint Feature Learning","Y. Gu; Y. Hu; L. Zhang; J. Yang; G. Yang","Institute of Image Processing, Pattern Recognition and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, CHINA; Hamlyn Centre for Robotic Surgery, Imperial College London, SW72AZ, UK; Institute of Image Processing, Pattern Recognition and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, CHINA; Institute of Image Processing, Pattern Recognition and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, CHINA; Hamlyn Centre for Robotic Surgery, Imperial College London, SW72AZ, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","769","776","Task autonomy is an important consideration for the development of future surgical robots. For robot-assisted anastomosis, suture thread detection is a prerequisite for subsequent robot manipulation. Previous works on automatic thread detection are focused on the learning of the models with specific surgical settings that are poorly generalisable to generic settings. In this paper, we propose a joint feature learning framework that caters for the foreground and background adaptation for surgical suture thread detection. The proposed method is developed in the context of semi-supervised and unsupervised domain adaptation, leveraging the labelled training data from the source domain to learn the detection model for unlabelled or partially labelled target domain, which can also be from different types of threads or organs. Based on adversarial learning, we further preserve the semantic identity and introduce curriculum adaptation to generate synthetic data. Experiments on four domain adaptation tasks for suture thread detection demonstrate the strength of the proposed method being able to generate good quality synthetic data and transfer between specific domains with limited or even no labelled data of the target domain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593622","","Yarn;Task analysis;Instruction sets;Adaptation models;Image segmentation;Surgery;Splines (mathematics)","feature extraction;manipulators;medical computing;medical robotics;object detection;surgery;unsupervised learning","joint feature learning framework;background adaptation;surgical suture thread detection;unsupervised domain adaptation;labelled training data;partially labelled target domain;organs;adversarial learning;cross-scene suture thread parsing;task autonomy;robot-assisted anastomosis;automatic thread detection;surgical robots;robot manipulation;surgical settings;foreground adaptation;semisupervised domain adaptation;detection model learning;semantic identity","","","18","","","","","IEEE","IEEE Conferences"
"Hybrid Contact Preintegration for Visual-Inertial-Contact State Estimation Using Factor Graphs","R. Hartley; M. G. Jadidi; L. Gan; J. Huang; J. W. Grizzle; R. M. Eustice","University of Michigan, College of Engineering, Ann Arbor, MI, 48109, USA; University of Michigan, College of Engineering, Ann Arbor, MI, 48109, USA; University of Michigan, College of Engineering, Ann Arbor, MI, 48109, USA; University of Michigan, College of Engineering, Ann Arbor, MI, 48109, USA; University of Michigan, College of Engineering, Ann Arbor, MI, 48109, USA; University of Michigan, College of Engineering, Ann Arbor, MI, 48109, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3783","3790","The factor graph framework is a convenient modeling technique for robotic state estimation where states are represented as nodes, and measurements are modeled as factors. When designing a sensor fusion framework for legged robots, one often has access to visual, inertial, joint encoder, and contact sensors. While visual-inertial odometry has been studied extensively in this framework, the addition of a preintegrated contact factor for legged robots has been only recently proposed. This allowed for integration of encoder and contact measurements into existing factor graphs, however, new nodes had to be added to the graph every time contact was made or broken. In this work, to cope with the problem of switching contact frames, we propose a hybrid contact preintegration theory that allows contact information to be integrated through an arbitrary number of contact switches. The proposed hybrid modeling approach reduces the number of required variables in the nonlinear optimization problem by only requiring new states to be added alongside camera or selected keyframes. This method is evaluated using real experimental data collected from a Cassie-series robot where the trajectory of the robot produced by a motion capture system is used as a proxy for ground truth. The evaluation shows that inclusion of the proposed preintegrated hybrid contact factor alongside visual-inertial navigation systems improves estimation accuracy as well as robustness to vision failure, while its generalization makes it more accessible for legged platforms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593801","","Kinematics;Legged locomotion;Optimization;Cameras;Robot vision systems","distance measurement;graph theory;inertial navigation;legged locomotion;motion estimation;optimisation;sensor fusion;state estimation","factor graphs;robotic state estimation;sensor fusion framework;legged robots;visual encoder;inertial encoder;visual-inertial odometry;visual-inertial navigation systems;cassie-series robot;nonlinear optimization;motion capture system;preintegration theory","","","28","","","","","IEEE","IEEE Conferences"
"Probabilistic Learning of Torque Controllers from Kinematic and Force Constraints","J. Silvério; Y. Huang; L. Rozo; S. Calinon; D. G. Caldwell","Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy; Idiap Research Institute, Martigny, Switzerland; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","When learning skills from demonstrations, one is often required to think in advance about the appropriate task representation (usually in either operational or configuration space). We here propose a probabilistic approach for simultaneously learning and synthesizing torque control commands which take into account task space, joint space and force constraints. We treat the problem by considering different torque controllers acting on the robot, whose relevance is learned probabilistically from demonstrations. This information is used to combine the controllers by exploiting the properties of Gaussian distributions, generating new torque commands that satisfy the important features of the task. We validate the approach in two experimental scenarios using 7- DoF torque-controlled manipulators, with tasks that require the consideration of different controllers to be properly executed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594103","","Task analysis;Torque;Aerospace electronics;Probabilistic logic;Force;End effectors","control engineering computing;force control;Gaussian distribution;learning (artificial intelligence);manipulators;motion control;position control;torque control","kinematic constraints;task representation;task space;Gaussian distributions;7- DoF torque-controlled manipulators;joint space;torque control commands;operational configuration space;force constraints;probabilistic learning","","2","23","","","","","IEEE","IEEE Conferences"
"Risk-Based Human-Aware Multi-Robot Coordination in Dynamic Environments Shared with Humans","Z. Talebpour; A. Martinoli","Ecole Polytechnique Fédérale de Lausanne (EPFL), Distributed Intelligent Systems and Algorithms Laboratory (DISAL) School of Architecture Civil and Environmental Engineering, Lausanne, 1015, Switzerland; Civil and Environmental Engineering Ecole Polytechnique Fédérale de Lausanne (EPFL), Distributed Intelligent Systems and Algorithms Laboratory (DISAL) School of Architecture, Lausanne, 1015, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3365","3372","In this paper, we propose a risk-based coordination method for the Multi-Robot Task Allocation (MRTA) problem in human-populated environments. We introduce risk-based bids that incorporate human trajectory prediction uncertainties and furthermore, social costs in their formulation. We demonstrate the effectiveness of including a predictive component in the risk formulation despite the lack of accurate position estimation for humans through an extensive suite of experiments. This is done by means of testing different levels of prediction error for known human trajectories and in a separate approach, using a Kalman filter for human trajectory estimation. Furthermore, we propose different risk formulations and evaluate their performance in a high-fidelity simulator. Additionally, a comparative study targeting human-agnostic planning at both navigation and planning levels, human-aware navigation and planning based on deterministic costs, and risk-based human-aware planning with no individual human-aware navigation has been conducted. Results confirm that risk-based bids lead to more socially acceptable team plans that reduce the need for the lower level individual human-aware navigation to be activated. Risk-based plans accounting for social costs prevent difficult social situations that can lead to less effective human-aware navigation, such as traversing narrow passages occupied by humans.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593586","","Robot kinematics;Task analysis;Navigation;Planning;Uncertainty;Estimation","human-robot interaction;Kalman filters;mobile robots;multi-robot systems;path planning;risk analysis;trajectory control","risk-based human-aware multirobot coordination;dynamic environments;human-populated environments;Kalman filter;position estimation;MRTA problem;human trajectory prediction;multirobot task allocation problem;human-aware navigation;risk-based bids;risk-based human-aware planning;human-agnostic planning;prediction error","","","29","","","","","IEEE","IEEE Conferences"
"A Framework for Dexterous Manipulation","L. Y. Ku; J. Rogers; P. Strawser; J. Badger; E. Learned-Mille; R. Grupen","College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, 01003, USA; Jonathan RogersPhilip Strawser, and Julia Badger are with the National Aeronautics and Space Administration, Houston, TX, USA; Jonathan RogersPhilip Strawser, and Julia Badger are with the National Aeronautics and Space Administration, Houston, TX, USA; Jonathan RogersPhilip Strawser, and Julia Badger are with the National Aeronautics and Space Administration, Houston, TX, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, 01003, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, 01003, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4131","4138","In this work, we introduce a framework for performing dexterous manipulations on the humanoid robot Robonaut-2. This framework memorizes how actions change perceptions and can learn a sequence of actions based on demonstrations. With the anthropomorphic Robonaut-2 hand and arm, a variety of manipulation tasks such as grasping novel objects, rotating a drill for grasping, and tightening a bolt with a ratchet can be accomplished. This framework was also used to compete in the IROS2018 Fan Robotic Challenge that requires manipulating a hand fan and was a winner of the phase I modality A competition.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594497","","Robots;Task analysis;Neurons;Brain modeling;Fans;Computational modeling;Grasping","dexterous manipulators;humanoid robots;learning (artificial intelligence);manipulator dynamics;motion control","dexterous manipulation;humanoid robot Robonaut-2;anthropomorphic Robonaut-2 hand;manipulation tasks;hand fan;IROS2018 fan robotic challenge;phase I modality A competition","","","46","","","","","IEEE","IEEE Conferences"
"A Rationale-Driven Team Plan Representation for Autonomous Intra-Robot Replanning*","P. Cooksey; M. Veloso","Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2389","2394","For autonomous multi-robot teams, the individual team members are tasked with completing their assigned tasks as defined by a team plan provided by a centralized team planner. However in complex dynamic domains, the team plans are generated by the team planner with assumptions due to the complexity of modeling the domain. Failures in execution are therefore inevitable for the team members, and as such, replanning will occur for the team. In this paper, we introduce a rationale-driven team plan representation that provides rationales on why actions were chosen by the team planner. During a failure, the individual team members autonomously use our described intra-robot replanning algorithm to select all applicable replan policies for a given rationale. We then describe a method to learn the predicted cost of each replan policy, given a state of the environment, in order for the individual robots to select the lowest costing replan policy to improve team performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593765","","Robots;Oceans;Task analysis;Prediction algorithms;Planning;Satellites;Global Positioning System","mobile robots;multi-robot systems;path planning","rationale-driven team plan representation;autonomous multirobot teams;autonomous intrarobot replanning;team planner;intrarobot replanning algorithm","","","14","","","","","IEEE","IEEE Conferences"
"Liquid Metal-Microelectronics Integration for a Sensorized Soft Robot Skin","T. Hellebrekers; K. B. Ozutemiz; J. Yin; C. Majidi","Carnegie Mellon University, Robotics Institute, School of Computer Science, Pittsburgh, 15123, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15123, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15123, USA; Carnegie Mellon University, Robotics Institute, School of Computer Science, Pittsburgh, 15123, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5924","5929","Progress in soft robotics depends on the integration of electronics for sensing, power regulation, and signal processing. Commercially available microelectronics satisfy these functions and are small enough to preserve the natural mechanics of the host system. Here, we present a method for incorporating microelectronic sensors and integrated circuits (ICs) into the elastomeric skin of a soft robot. The thin stretchable skin contains various solid-state electronics for orientation, pressure, proximity, and temperature sensing, and a microprocessor. The components are connected by thin-film copper traces wetted with eutectic gallium indium (EGaIn), a room temperature liquid metal alloy that allows the circuit to maintain conductivity as it deforms under mechanical loading. In this paper, we characterize the function of the individual sensors in air and water, discuss the integration of the microelectronic skin with a shape-memory actuated soft gripper, and demonstrate the sensorized soft gripper in conjunction with a 4 degree-of-freedom (DOF) robot arm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593944","","Grippers;Robot sensing systems;Temperature sensors;Skin;Liquids;Metals","actuators;elastomers;flexible electronics;gallium alloys;grippers;indium alloys;integrated circuits;liquid metals;microsensors;robots;sensors;shape memory effects;skin;tactile sensors;temperature sensors","robot arm;sensorized soft gripper;shape-memory actuated soft gripper;microelectronic skin;individual sensors;mechanical loading;room temperature liquid metal alloy;eutectic gallium indium;temperature sensing;solid-state electronics;stretchable skin;elastomeric skin;integrated circuits;microelectronic sensors;natural mechanics;signal processing;power regulation;sensorized soft robot skin;liquid metal-microelectronics integration;temperature 293 K to 298 K","","","36","","","","","IEEE","IEEE Conferences"
"Design of Compliant Mechanosensory Composite (CMC) and its Application Toward the Sensible Mesoscale Robotics","B. Kwak; J. Bae","Department of Mechanical Engineering, UNIST, Bio-Robotics and Control (BiRC) Laboratory, Ulsan, Korea; Department of Mechanical Engineering, UNIST, Bio-Robotics and Control (BiRC) Laboratory, Ulsan, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1470","1475","Sensed information greatly helps a robot to adjust its motion or modulate the locomotory behavior. While many sensing components have been developed for macroscale robots, such off-the-shelf sensors are hardly integrated with a mesoscale (i.e., 0.1 mm to 10 mm) robot due to the size limitation. In this work, we propose a Compliant Mechanosensory Composite (CMC) to fabricate a small compliant mechanism with embedded sensing ability. As the first demonstration of CMC, we directly print a conductive polymer PEDOT:PSS onto the flexible joint of a compliant mechanism to sense the motion of the flexible joint itself. Owing to the variation of electric contact resistance (ECR) upon bending, the CMC could estimate its bending angle. The performance of the CMC was verified by analyzing the cyclic bending, transient and stationary response. Overall, a sparsely printed serpentine pattern with thicker line exhibited consistent response without a noticeable hysteresis. To demonstrate the applicability of the CMC process, a small gripper actuated by a SMA (shape memory alloy) coil was fabricated, and its motion was successfully measured using the embedded sensors. We expect the proposed CMC will enable a small robot to become sensible at its self motion, external load, and physical contacts in future.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593590","","Robot sensing systems;Resistance;Fabrication;Contact resistance;Manufacturing processes","angular measurement;coils;composite materials;conducting polymers;contact resistance;grippers;intelligent sensors;mobile robots;motion measurement","embedded sensing ability;conductive polymer PEDOT:PSS;CMC process;sensible mesoscale robotics;macroscale robots;compliant mechanosensory composite design;locomotory modulation;electric contact resistance;ECR;bending angle estimation;cyclic bending analysis;sparsely printed serpentine pattern;SMA coil;shape memory alloy coil;embedded sensors;size 0.1 mm to 10.0 mm","","","22","","","","","IEEE","IEEE Conferences"
"Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots","J. Cartucho; R. Ventura; M. Veloso","Institute for Systems and Robotics, Instituto Superior Técnico, Lisboa, 1049-001, Portugal; Institute for Systems and Robotics, Instituto Superior Técnico, Lisboa, 1049-001, Portugal; Machine Learning Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2336","2341","Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594067","","Neural networks;Labeling;Training;Symbiosis;Service robots;Object recognition","human-robot interaction;learning (artificial intelligence);mobile robots;neural nets;object detection;object recognition;service robots","robust object recognition;symbiotic deep learning;mobile service robot;human environments;symbiotic autonomy approach;HHELP;RGB camera;onboard tablet;object detection;deep neural network;domestic environment;YOLOv2 neural network;bootstrap YOLOv2;CMU;Monarch Mbot;ISR-Lisbon","","","21","","","","","IEEE","IEEE Conferences"
"Constrained Motion Cueing for Driving Simulators Using a Real-Time Nonlinear MPC Scheme","A. Lamprecht; J. Haecker; K. Graichen","Control and Microtechnology, Ulm University, Institut of Measurement, Ulm, 89077, Germany; Daimler AG, Sindelfingen, 71059, Germany; Control and Microtechnology, Ulm University, Institut of Measurement, Ulm, 89077, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7466","7471","This contribution presents a motion cueing algorithm (MCA) for driving simulators using nonlinear model predictive control (MPC). The goal of the MCA is to generate a realistic motion feeling while keeping the simulator within its workspace limits. The approach relies on a realtime gradient algorithm in combination with the augmented Lagrangian method in order to directly incorporate the system constraints into the optimization. Simulation results for a reference trajectory with typical driving situations demonstrate the performance as well as the computational efficiency of the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594246","","Acceleration;Fasteners;Real-time systems;Trajectory;Vehicles;Software algorithms;Minimization","nonlinear control systems;optimisation;predictive control;road traffic control","real-time nonlinear MPC scheme;motion cueing algorithm;MCA;nonlinear model predictive control;realistic motion feeling;realtime gradient algorithm;augmented Lagrangian method;constrained motion cueing;driving simulators","","","15","","","","","IEEE","IEEE Conferences"
"Tree Species Identification from Bark Images Using Convolutional Neural Networks","M. Carpentier; P. Giguère; J. Gaudreault","NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1075","1081","Tree species identification using bark images is a challenging problem that could prove useful for many forestry related tasks. However, while the recent progress in deep learning showed impressive results on standard vision problems, a lack of datasets prevented its use on tree bark species classification. In this work, we present, and make publicly available, a novel dataset called BarkNet 1.0 containing more than 23,000 high-resolution bark images from 23 different tree species over a wide range of tree diameters. With it, we demonstrate the feasibility of species recognition through bark images, using deep learning. More specifically, we obtain an accuracy of 93.88% on single crop, and an accuracy of 97.81% using a majority voting approach on all of the images of a tree. We also empirically demonstrate that, for a fixed number of images, it is better to maximize the number of tree individuals in the training database, thus directing future data collection efforts.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593514","","Vegetation;Forestry;Deep learning;Feature extraction;Training;Cameras;Task analysis","feature extraction;forestry;geophysical image processing;image classification;learning (artificial intelligence);neural nets;vegetation mapping","bark images;tree individual number;high-resolution bark images;species recognition;tree diameters;tree bark species classification;standard vision problems;deep learning;forestry related tasks;convolutional neural networks;tree species identification","","","33","","","","","IEEE","IEEE Conferences"
"Efficient Model Identification for Tensegrity Locomotion","S. Zhu; D. Surovik; K. Bekris; A. Boularias","Department of Computer Science, Rutgers University, New Jersey, USA; Department of Computer Science, Rutgers University, New Jersey, USA; Department of Computer Science, Rutgers University, New Jersey, USA; Department of Computer Science, Rutgers University, New Jersey, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2985","2990","This paper aims to identify in a practical manner unknown physical parameters, such as mechanical models of actuated robot links, which are critical in dynamical robotic tasks. Key features include the use of an off-the-shelf physics engine and the Bayesian optimization framework. The task being considered is locomotion with a high-dimensional, compliant Tensegrity robot. A key insight, in this case, is the need to project the space of models into an appropriate lower dimensional space for time efficiency. Comparisons with alternatives indicate that the proposed method can identify the parameters more accurately within the given time budget, which also results in more precise locomotion control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594425","","Robots;Engines;Optimization;Physics;Predictive models;Dimensionality reduction;Task analysis","Bayes methods;legged locomotion;optimisation;robot dynamics","Tensegrity locomotion;mechanical models;actuated robot links;dynamical robotic tasks;Bayesian optimization framework;high-dimensional Tensegrity robot;compliant Tensegrity robot;precise locomotion control;model identification;unknown physical parameters;physics engine","","","40","","","","","IEEE","IEEE Conferences"
"A Novel OCR-RCNN for Elevator Button Recognition","D. Zhu; T. Li; D. Ho; T. Zhou; M. Q. Meng","Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong, SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong, SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong, SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong, SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong, SAR, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3626","3631","Autonomous elevator operation is considered an intelligent solution in handling the inter-floor navigation problem of service robots. As one of the most fundamental steps, elevator button recognition starts to receive more and more attention. However, due to the challenging image conditions and severe class imbalance problem, the performance of existing results is unsatisfying. In this paper, we propose to combine an optical character recognition (OCR) network and the Faster RCNN architecture into a single neural network, called OCR-RCNN to facilitate an end-to-end training and elevator button recognition procedure. To verify our method, we collect a large dataset of elevator panels and carry out extensive comparative experiments. The experiment results show that our method can greatly outperform the traditional recognition pipelines, yielding an accurate and robust performance on recognizing untrained elevator buttons.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594071","","Elevators;Optical character recognition software;Proposals;Task analysis;Feature extraction;Training;Pipelines","learning (artificial intelligence);neurocontrollers;optical character recognition;path planning;recurrent neural nets;robot vision;service robots","autonomous elevator operation;inter-floor navigation problem;elevator button recognition;severe class imbalance problem;optical character recognition network;Faster RCNN architecture;elevator panels;OCR-RCNN architecture;service robots;image conditions","","","22","","","","","IEEE","IEEE Conferences"
"A Novel Joint Torque Estimation Method and Sensory System for Assistive Lower Limb Exoskeletons","L. Saccares; I. Sarakoglou; N. G. Tsagarakis","Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This work presents a novel method for estimating online the torques at the ankle, knee and hip of a user with the goal of generating reference signals for torque controlled lower limb exoskeletons. In particular, this approach attempts to address difficulties arising in real life scenarios when noncyclic locomotion activity, unexpected terrain or unpredicted interactions with the surroundings occur. An advantage of the proposed method is that it does not require any information on the user's upper body (i.e. pose, weight and center of mass location)or on any interaction of the user's upper body with the environment (i.e. payload handling or pushing and pulling task). By monitoring the interaction of the user's feet with the ground through a novel sensorized shoe sensing system, the method applies an inverse static analysis on the user's lower limbs to estimate in real time the torque at each leg joint. The system is fully wearable, ergonomic and portable and uses a reduced number of body posture sensors. The design of the sensorized shoes permits plantar flexion, while measuring the toe and heel orientation and the interaction loads. This allows walking on irregular terrains and natural feet postures in different tasks. Trials were performed to validate the proposed approach under different tasks and terrains. Finally, the knee torques estimated online by the proposed strategy were used as reference signals to drive the iT-Knee Bipedal System in an assistive task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594250","","Sensors;Foot;Torque;Task analysis;Exoskeletons;Legged locomotion;Knee","biomechanics;gait analysis;legged locomotion;medical robotics;motion control;patient rehabilitation;torque;torque control","novel joint torque estimation method;sensory System;assistive lower limb exoskeletons;hip;reference signals;life scenarios;noncyclic locomotion activity;unexpected terrain;unpredicted interactions;upper body;mass location;sensorized shoe sensing system;inverse static analysis;lower limbs;leg joint;body posture sensors;sensorized shoes;interaction loads;irregular terrains;natural feet postures;knee torques;iT-Knee Bipedal System;assistive task","","","14","","","","","IEEE","IEEE Conferences"
"A Novel All-in-One Manufacturing Process for a Soft Sensor System and its Application to a Soft Sensing Glove","S. Kim; D. Jeong; J. Oh; W. Park; J. Bae","Department of Mechanical Engineering, Ulsan National Institute of Science and Technology (UNIST), Bio-Robotics and Control (BiRC) Laboratory, Ulsan, 44919, Korea; Department of Mechanical Engineering, Ulsan National Institute of Science and Technology (UNIST), Bio-Robotics and Control (BiRC) Laboratory, Ulsan, 44919, Korea; Department of Mechanical Engineering, Ulsan National Institute of Science and Technology (UNIST), Bio-Robotics and Control (BiRC) Laboratory, Ulsan, 44919, Korea; Department of Mechanical Engineering, Ulsan National Institute of Science and Technology (UNIST), Bio-Robotics and Control (BiRC) Laboratory, Ulsan, 44919, Korea; Department of Mechanical Engineering, Ulsan National Institute of Science and Technology (UNIST), Bio-Robotics and Control (BiRC) Laboratory, Ulsan, 44919, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7004","7009","A sensing glove is an attractive application of wearable devices. Soft sensors are emerging to replace rigid sensing units, especially for wearable sensor systems, due to its inherent softness, flexibility, and stretchability. However, the fabrication process for the soft sensors is usually complex, time-consuming, labor-intensive, and has low production rate. To integrate a sensor system, an assembly process is essential, which may make the system bulky. Moreover, a solution for the electrode parts has rarely been suggested, although a bulky electrode part may obstruct the user's movement and degrade performance of the sensor. Thus, in this study, a novel fabrication process is suggested based on direct ink writing (DIW) of eutectic gallium-indium (EGaIn), which forms all the items in the sensor system from the sensing units, wiring, and the electrode part. A sensing glove for 2D finger motions was fabricated, and its performance was verified in terms of linearity, dynamic response, and accuracy. The sensing glove can be used as an easily-wearable and an intuitive interface to the virtual reality environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594389","","Fabrication;Robot sensing systems;Electrodes;Sensor systems;Writing;Wiring","biomechanics;data gloves;gallium alloys;manufacturing processes;sensors;virtual reality;wearable computers","manufacturing process;soft sensor system;soft sensing glove;attractive application;wearable devices;soft sensors;rigid sensing units;wearable sensor systems;assembly process;bulky electrode part;novel fabrication process","","","46","","","","","IEEE","IEEE Conferences"
"On the Orientation Planning with Constrained Angular Velocity and Acceleration at Endpoints","M. Shahbazi; N. Kashiri; D. Caldwell; N. Tsagarakis","Istituto Italiano di Tecnologia (IIT), Department of Advanced Robotics, Genova, Via Morego 30, 16163, Italy; Istituto Italiano di Tecnologia (IIT), Department of Advanced Robotics, Genova, Via Morego 30, 16163, Italy; Istituto Italiano di Tecnologia (IIT), Department of Advanced Robotics, Genova, Via Morego 30, 16163, Italy; Istituto Italiano di Tecnologia (IIT), Department of Advanced Robotics, Genova, Via Morego 30, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7033","7038","This paper presents orientation planning algorithms respecting the requirements of task space trajectory generation, particularly in robotics applications. The proposed algorithms fulfill the following conditions: (i) permitting to impose constraints at angular velocity and acceleration in addition to orientation at endpoints; (ii) rendering continuous acceleration profiles even when interpolating multiple orientations; and (iii) being computationally fast enough for realtime implementation. The generated spline trajectories are essentially a concatenation of polynomial in time curves parameterized by quaternion coefficients. To impose the unitariness condition critically required for quaternion representation of orientation, we develop an on-line update mechanism which successively reparameterizes the polynomials constructing the spline, towards suppressing distortions that the normalization operation might incur. Experiments on an anthropomorphic robot upper-body are carried out to demonstrate the efficacy and real-time compatibility of the proposed algorithms in comparison with a standard spherical interpolation method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593657","","Quaternions;Interpolation;Acceleration;Robots;Splines (mathematics);Trajectory;Planning","humanoid robots;interpolation;path planning;polynomials;position control;splines (mathematics)","spline trajectories;time curves;quaternion coefficients;unitariness condition;quaternion representation;on-line update mechanism;anthropomorphic robot upper-body;real-time compatibility;constrained angular velocity;orientation planning algorithms;task space trajectory generation;robotics applications;continuous acceleration profiles;realtime implementation","","","22","","","","","IEEE","IEEE Conferences"
"Bidirectional Thrust for Multirotor MAVs with Fixed-Pitch Propellers","M. Maier","German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Münchener Straße 20, Weßling, 82234, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","This paper is devoted to the study of multirotor Micro Aerial Vehicles (MAVs) with fixed-pitch propellers and bidirectional thrust vector. The latter is realized by using dedicated motor controllers, which allow to invert the propellers' direction of rotation during flight (so-called 3D mode), and almost or fully symmetric propellers. We present a unified modeling, controller design, and control allocation approach that accounts for bidirectional thrust. Suitable propellers with the ability to produce thrust and torque in both directions are compared and their parameters are identified through a static thrust test. Furthermore, we discuss applications of bidirectional thrust, like inverted flight or surface slip reduction, which are impossible to realize with common unidirectional thrust vehicles. We generate suitable flight trajectories and evaluate our unified approach in experiments with a custom-built quadrotor.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593836","","Propellers;Rotors;Torque;Resource management;Force;Attitude control;Trajectory","aircraft control;autonomous aerial vehicles;control system synthesis;helicopters;propellers","fixed-pitch propellers;multirotor MicroAerial Vehicles;bidirectional thrust vector;dedicated motor controllers;controller design;control allocation approach;static thrust test;inverted flight;multirotor MAV;unidirectional thrust vehicles","","","20","","","","","IEEE","IEEE Conferences"
"Generative Modeling of Multimodal Multi-Human Behavior","B. Ivanovic; E. Schmerling; K. Leung; M. Pavone","Department of Computer Science, Stanford University, Stanford, CA, 94305, USA; Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA, 94305, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, 94305, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, 94305, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3088","3095","This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594393","","Trajectory;Predictive models;Analytical models;Deep learning;Ground penetrating radar;Data models;Robots","approximation theory;behavioural sciences computing;bin packing;human-robot interaction;learning (artificial intelligence);mobile robots;multi-agent systems;statistical distributions","deep learning approximations;probabilistic graphical models;candidate future agent behavior;crowded environments;human-driven vehicles;human-robot collaborative bin packing;multimodal probability distribution;multihuman interactions;basketball player trajectories;multimodal multihuman behavior;self-driving cars;warehouse;autoencoders;response dynamics;robotic applications;proxy","","","28","","","","","IEEE","IEEE Conferences"
"GelSlim: A High-Resolution, Compact, Robust, and Calibrated Tactile-sensing Finger","E. Donlon; S. Dong; M. Liu; J. Li; E. Adelson; A. Rodriguez","Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1927","1934","This work describes the development of a high-resolution tactile-sensing finger for robot grasping. This finger, inspired by previous GelSight sensing techniques (Johnson and Adelson 2009), features an integration that is slimmer, more robust, and with more homogeneous output than previous vision-based tactile sensors. To achieve a compact integration, we redesign the optical path from illumination source to camera by combining light guides and an arrangement of mirror reflections. We parameterize the optical path with geometric design variables and describe the tradeoffs between the finger thickness, camera depth of field, and size of the tactile sensing area. The sensor sustains the wear from continuous use - and abuse - in grasping tasks by combining tougher materials for the compliant gel, a textured fabric skin, a structurally rigid body, and a calibration process that maintains homogeneous illumination and contrast of the tactile images during use. Finally, we evaluate the sensor's durability along four metrics that track the signal quality during more than 3000 grasping experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593661","","Tactile sensors;Cameras;Three-dimensional displays;Grasping","calibration;dexterous manipulators;grippers;robot vision;tactile sensors","calibrated tactile-sensing finger;high-resolution tactile-sensing finger;robot grasping;previous GelSight sensing techniques;Adelson 2009;homogeneous output;previous vision-based tactile sensors;compact integration;optical path;illumination source;geometric design variables;finger thickness;tactile sensing area;grasping tasks;compliant gel;calibration process;homogeneous illumination;tactile images","","1","22","","","","","IEEE","IEEE Conferences"
"A Family of Iterative Gauss-Newton Shooting Methods for Nonlinear Optimal Control","M. Giftthaler; M. Neunert; M. Stäuble; J. Buchli; M. Diehl","ETH Zürich, Agile & Dexterous Robotics Lab, Switzerland; ETH Zürich, Agile & Dexterous Robotics Lab, Switzerland; ETH Zürich, Agile & Dexterous Robotics Lab, Switzerland; ETH Zürich, Agile & Dexterous Robotics Lab, Switzerland; Department of Microsystems Engineering (IMTEK), University of Freiburg, Systems Control and Optimization Laboratory, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper introduces a family of iterative algorithms for unconstrained nonlinear optimal control. We generalize the well-known iLQR algorithm to different multiple shooting variants, combining advantages like straightforward initialization and a closed-loop forward integration. All algorithms have similar computational complexity, i.e. linear complexity in the time horizon, and can be derived in the same computational framework. We compare the full-step variants of our algorithms and present several simulation examples, including a high-dimensional underactuated robot subject to contact switches. Simulation results show that our multiple shooting algorithms can achieve faster convergence, better local contraction rates and much shorter runtimes than classical iLQR, which makes them a superior choice for nonlinear model predictive control applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593840","Numerical Optimal Control;Trajectory Optimization;Multiple Shooting;Quadrupedal Robots;Nonlinear Model Predictive Control;Differential Dynamic Programming","Optimal control;Trajectory;Heuristic algorithms;Prediction algorithms;Robots;System dynamics;Convergence","closed loop systems;computational complexity;iterative methods;linear quadratic control;nonlinear control systems;predictive control","iterative algorithms;unconstrained nonlinear optimal control;iLQR algorithm;closed-loop forward integration;linear complexity;multiple shooting algorithms;nonlinear model predictive control applications;computational complexity;high-dimensional underactuated robot;iterative Gauss-Newton shooting methods","","","27","","","","","IEEE","IEEE Conferences"
"How do humans read robotics? The matter of the lexical ambiguity resolution","C. Pieters; E. Danblon; J. P. Laumond; L. ULB","LAAS-CNRS and the National Institute of Applied Sciences (INSA), Toulouse, France; FNRS professor of rhetoric at the Free, University of Brussels, Belgium; CNRS director of research in robotics at LAAS, Toulouse, France; CNRS director of research in robotics at LAAS, Toulouse, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2349","2354","The words used to describe robotic performances include a degree of ambiguity that the human brain should solve without difficulty. However, the language used in-and about-robotics seems to escape from the ordinary processing of lexical ambiguity resolution. In this paper, we argue that there is no lack of an adequate language for robotics but that the lexicon at hand is forced by our representations. We investigate the main representational issues of the notions that express robotic actions and dispositions (i.e. behaviors).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594138","","Robots;Linguistics;Rhetoric;Semantics;Task analysis;Psychology","human-robot interaction","robotic actions;lexical ambiguity resolution","","","31","","","","","IEEE","IEEE Conferences"
"A Series Elastic Brake Pedal to Preserve Conventional Pedal Feel under Regenerative Braking","U. Caliskan; A. Apaydin; A. Otaran; V. Patoglu","Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1367","1373","We propose a force-feedback brake pedal with series elastic actuation to preserve the conventional brake pedal feel during cooperative regenerative braking. The novelty of the proposed design is due to the deliberate introduction of a compliant element between the actuator and the brake pedal whose deflections are measured to estimate interaction forces and to perform closed-loop force control. Thanks to its series elasticity, the force-feedback brake pedal can utilize robust controllers to achieve high fidelity force control, possesses favorable output impedance characteristics over the entire frequency spectrum, and can be implemented in a compact package using low-cost components. The applicability and effectiveness of the proposed series elastic brake pedal have been tested through human subject experiments that evaluate simulated cooperative regenerative braking scenarios with and without pedal feel compensation. The experimental results and responses to the accompanying questionnaire indicate that pedal feel compensation through the series elastic brake pedal can significantly decrease hard braking instances, improving safety and driver experience.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594317","","Brakes;Force;Friction;Force control;Actuators;Vehicles;Couplings","actuators;brakes;closed loop systems;elasticity;force control;force feedback;regenerative braking;robust control","series elastic brake pedal;force-feedback brake pedal;series elastic actuation;closed-loop force control;pedal feel compensation;regenerative braking;robust controller;fidelity force control;impedance characteristic;frequency spectrum","","","28","","","","","IEEE","IEEE Conferences"
"Design and Development of a Slender Dual-Structure Continuum Robot for In-Situ Aeroengine Repair","M. Wang; D. Palmer; X. Dong; D. Alatorre; D. Axinte; A. Norton","University of Nottingham, Rolls-Royce UTC in Manufacturing and On-Wing Technology, Nottingham, NG8 1BB, UK; University of Nottingham, Rolls-Royce UTC in Manufacturing and On-Wing Technology, Nottingham, NG8 1BB, UK; University of Nottingham, Rolls-Royce UTC in Manufacturing and On-Wing Technology, Nottingham, NG8 1BB, UK; University of Nottingham, Rolls-Royce UTC in Manufacturing and On-Wing Technology, Nottingham, NG8 1BB, UK; University of Nottingham, Rolls-Royce UTC in Manufacturing and On-Wing Technology, Nottingham, NG8 1BB, UK; Rolls-Royce plc, Derby, DE24 8BJ, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5648","5653","In-situ aeroengine maintenance works (e.g. inspection, repair) are highly beneficial as it can significantly reduce currently accepted maintenance cycle which is extensive and costly due to the need to remove engines from the wing of an aircraft. However, feeding in/out via inspection ports and performing a multi-axis movement of an end-effector in a very constrained environment such as aeroengine combustion chamber is a fairly challenging task. This paper presents the design and development of a highly slender (i.e., low diameter-to-length ratio) dual-structure continuum robot with 16 degrees of freedom (DoFs) to provide the feeding motion needed to navigate into confined environments and then perform a required configuration shape for further repair operation. This continuum robot is a compact system and presents a set of innovative mechatronic solutions such as: (i) two-stage tendon-driven structure with bevelled disk design to perform required configuration shape and to provide selective stiffness for the ability of taking high payloads; (ii) various compliant joints to enable different flexibility requirement in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with a precise actuation. To be able to achieve the desired configuration shape, a kinematic model has been established and the configuration-cable kinematics has been implemented. Finally, the continuum robot has been built and tested for performing the predefined configuration shape.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594142","","Maintenance engineering;Kinematics;Inspection;Shape;End effectors;Task analysis","aerodynamics;aircraft maintenance;end effectors;industrial robots;inspection;mechatronics;suspensions (mechanical components)","slender dual-structure continuum robot;In-Situ Aeroengine Repair;in-situ aeroengine maintenance works;end-effector;aeroengine combustion chamber;configuration-cable kinematics","","","12","","","","","IEEE","IEEE Conferences"
"Composite Reinforcement Learning for Social Robot Navigation","P. Ciou; Y. Hsiao; Z. Wu; S. Tseng; L. Fu","Department of Electrical Engineering and Computer Science and Information Engineering, Graduate School of Engineering, National Taiwan University, 106 Taipei City, Da'an District, Roosevelt Rd. Sec. 4 No. 1, Taiwan (R.O.C.); Department of Electrical Engineering and Computer Science and Information Engineering, Graduate School of Engineering, National Taiwan University, 106 Taipei City, Da'an District, Roosevelt Rd. Sec. 4 No. 1, Taiwan (R.O.C.); Department of Electrical Engineering and Computer Science and Information Engineering, Graduate School of Engineering, National Taiwan University, 106 Taipei City, Da'an District, Roosevelt Rd. Sec. 4 No. 1, Taiwan (R.O.C.); Department of Electrical Engineering and Computer Science and Information Engineering, Graduate School of Engineering, National Taiwan University, 106 Taipei City, Da'an District, Roosevelt Rd. Sec. 4 No. 1, Taiwan (R.O.C.); Department of Electrical Engineering and Computer Science and Information Engineering, Graduate School of Engineering, National Taiwan University, 106 Taipei City, Da'an District, Roosevelt Rd. Sec. 4 No. 1, Taiwan (R.O.C.)","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2553","2558","For a service robot, it is not adequate to let its navigational movement be based only on a single metric, such as minimum distance path. In the environment where the robot and humans are coexisting, the robot should always perform social navigation whenever it is moving. However, to perform social navigation, the robot needs to follow certain “social norms” of the environment. Recently, deep reinforcement learning (DRL) technique is popularly applied to the robotics field; yet, it is rarely used to solve the mentioned social navigation problem, generally deemed as a high dimension complex problem. In this paper, we propose the composite reinforcement learning (CRL) framework under which the robot learns appropriate social navigation with sensor input and reward update based on human feedback. For learning the aspect of human robot interaction (HRI), we provide a method to facilitate the training of DRL in real environment by incorporating prior knowledge to the system. It turns out that our CRL system not only can incrementally learn how to set its velocity and to perform HRI but also keep collecting human feedback to synchronize the reward functions to the current social norms. The experiments show that the proposed CRL system can safely learn how to navigate in the environment and show that our system is able to perform HRI for social navigation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593410","","Navigation;Reinforcement learning;Legged locomotion;Task analysis;Collision avoidance;Robot kinematics","human-robot interaction;learning (artificial intelligence);mobile robots;path planning;service robots","minimum distance path;deep reinforcement learning technique;navigational movement;service robot;social robot navigation;CRL system;human robot interaction;human feedback;composite reinforcement learning framework;high dimension complex problem","","","18","","","","","IEEE","IEEE Conferences"
"Computing Cross-Sections of the Workspace of Suspended Cable-Driven Parallel Robot with Sagging Cables Having Tension Limitations","J. -. Merlet","HEPHAISTOS project, Université Côte d'Azur, Inria, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5042","5047","Although workspace is essential for the design and control of cable-driven parallel robots (CDPR) very few works have been devoted to this topic when sagging cables are considered, most probably because of the complexity of the cable model. In this paper we consider suspended CDPR with sagging cables that can support only a limited tension. We propose an algorithm to compute the border of horizontal cross-sections of the workspace for a given altitude and orientation of the platform. We show that singularities of the kinematics equations have to be taken into account for a proper determination of the border and that the workspace can be separated in several components according to the branch of the inverse kinematics on which the robot is evolving. We also compare the workspace obtained for ideal and sagging cables.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594321","","Kinematics;Parallel robots;Mathematical model;Legged locomotion;Mechanical cables;Robot kinematics","cables (mechanical);robot kinematics","suspended cable-driven parallel robot;sagging cables;horizontal cross-sections;tension limitations;CDPR;kinematics equations;inverse kinematics","","","25","","","","","IEEE","IEEE Conferences"
"Perspective Correcting Visual Odometry for Agile MAVs using a Pixel Processor Array","C. Greatwood; L. Bose; T. Richardson; W. Mayol-Cuevas; J. Chen; S. J. Carey; P. Dudek","Faculty of Engineering, Aerospace and Computer Science, University of Bristol, Bristol, England; Faculty of Engineering, Aerospace and Computer Science, University of Bristol, Bristol, England; Faculty of Engineering, Aerospace and Computer Science, University of Bristol, Bristol, England; Faculty of Engineering, Aerospace and Computer Science, University of Bristol, Bristol, England; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, England; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, England; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, England","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","987","994","This paper presents a visual odometry approach using a Pixel Processor Array (PPA) camera, specifically, the SCAMP-5 vision chip. In this device, each pixel is capable of storing data and performing computation, enabling a variety of computer vision tasks to be carried out directly upon the sensor itself. In this work the PPA performs HDR edge detection, perspective correction and image alignment based odometry, allowing the position and heading of a MAV to be tracked at several hundred frames per second. We evaluate our PPA based approach by direct comparison with a motion capture system for a variety of trajectories. These include rapid accelerations that would incur significant motion blur at low frame rates, and lighting conditions that would typically lead to under or over exposure of image detail. Such challenging conditions would often lead to unusable images when relying on traditional image sensors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594500","","Visual odometry;Cameras;Robot sensing systems;Arrays;Parallel processing;Visualization;Performance evaluation","cameras;computer vision;distance measurement;image motion analysis;image sensors;sensor arrays","SCAMP-5 vision chip;Pixel Processor Array camera;visual odometry approach;agile MAVs;traditional image sensors;low frame rates;significant motion blur;motion capture system;direct comparison;PPA based approach;MAV;image alignment based odometry;perspective correction;HDR edge detection;computer vision tasks","","","14","","","","","IEEE","IEEE Conferences"
"Determining Optimal Gait Parameters for a Statically Stable Walking Human Assistive Quadruped Robot","E. W. McClain; S. Meek","Department of Mechanical Engineering, University of Utah, SLC, UT, 84112, USA; Department of Mechanical Engineering, University of Utah, SLC, UT, 84112, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1751","1756","In this paper we propose a method to determine an optimal statically stable gait for a quadruped robot walking in the presence of an expected disturbance. There exists a tradeoff between a stable gait and an energy efficient gait. Our goal is to determine an energy efficient quadruped gait that will maintain stability while a human uses the device to stabilize themselves while walking. In order to determine an optimal gait, we present a cost function consisting of an energy term and a stability term. A method of evaluating the cost function using dynamics and quasi-static analysis is demonstrated. The optimization is implemented for a human assistive device currently being designed and the results are verified in simulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593979","","Legged locomotion;Foot;Cost function;Stability analysis;Gravity","legged locomotion;optimal control;optimisation;robot dynamics;stability","optimal gait parameters;statically stable walking human assistive quadruped robot;optimal statically stable gait;quadruped robot walking;energy efficient gait;energy efficient quadruped gait;cost function;energy term;stability term;quasistatic analysis;human assistive device;optimization","","","16","","","","","IEEE","IEEE Conferences"
"Real-Time Dance Generation to Music for a Legged Robot","T. Bi; P. Fankhauser; D. Bellicoso; M. Hutter","ETH Zurich, Robotics Systems Lab (RSL), Switzerland; ETH Zurich, Robotics Systems Lab (RSL), Switzerland; ETH Zurich, Robotics Systems Lab (RSL), Switzerland; ETH Zurich, Robotics Systems Lab (RSL), Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1038","1044","The development of robots that can dance has received considerable attention. However, they are often either limited to a pre-defined set of movements and music or demonstrate little variance when reacting to external stimuli, such as microphone or camera input. In this paper, we contribute with a novel approach allowing a legged robot to listen to live music while dancing in synchronization with the music in a diverse fashion. This is achieved by extracting the beat from an onboard microphone in real-time, and subsequently creating a dance choreography by picking from a user-generated dance motion library at every new beat. Dance motions include various stepping and base motions. The process of picking from the library is defined by a probabilistic model, namely a Markov chain, that depends on the previously picked dance motion and the current music tempo. Finally, delays are determined online by time-shifting a measured signal and a reference signal, and minimizing the least squares error with the time-shift as parameter. Delays are then compensated for by using a combined feedforward and feedback delay controller which shifts the robot whole-body controller reference input in time. Results from experiments on a quadrupedal robot demonstrate the fast convergence and synchrony to the perceived music.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593983","","Robot kinematics;Legged locomotion;Music;Delays;Trajectory;Real-time systems","feedback;feedforward;humanoid robots;image motion analysis;legged locomotion;Markov processes;motion control;music;robot vision;synchronisation","music tempo;dance generation;feedforward delay controller;Markov chain;quadrupedal robot;robot whole-body controller reference input;feedback delay controller;time-shifting;delays;picked dance motion;base motions;stepping motions;dance motions;user-generated dance motion library;dance choreography;onboard microphone;live music;external stimuli;legged robot","","","19","","","","","IEEE","IEEE Conferences"
"Robot Controllers Compatible with Human Beam Balancing Behavior","J. Lee; M. E. Huber; D. Stemad; N. Hogan","Department of Mechanical Engineering, Massachusetts Institute of Tech-nology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Tech-nology, Cambridge, MA, USA; Departments - of Biology, Electrical and Computer Engineering, and Physics, Northeastern University, Boston, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Tech-nology, Cambridge, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3335","3341","Standing on a beam is a challenging motor skill that requires the regulation of upright balance and stability. In this paper, we analyzed the behavior of humans balancing on a narrow beam without footwear. The results revealed high anti-correlation between lumped upper- and lower-body angular momentum. Despite differences in gross measures of balance, interlimb coordination was consistent between the novice and expert subjects, suggesting that both performances could be described with the same balance controller. By simulating a double inverted pendulum model utilizing different balancing controllers described in the robotics literature, we identified that the whole behavior observed from humans standing on a beam was best replicated with controllers that predominantly utilized hip actuation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593549","","Robot kinematics;Foot;Task analysis;Legged locomotion;Correlation;Exoskeletons","angular momentum;biocontrol;biomechanics;legged locomotion;mechanoception;motion control;pendulums;stability","human beam balancing behavior;challenging motor skill;upright balance;stability;humans;narrow beam;lower-body angular momentum;interlimb coordination;balance controller;robotics literature;robot controllers;balancing controllers","","","16","","","","","IEEE","IEEE Conferences"
"Accelerating Goal-Directed Reinforcement Learning by Model Characterization","S. Debnath; G. Sukhatme; L. Liu","NVIDIA Corporation, Santa Clara, CA, 95051, USA; Department of Computer Science at the University of Southern California, Los Angeles, CA, 90089, USA; Department at Indiana University - Bloomington, Intelligent Systems Engineering, Bloomington, IN, 47408, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We propose a hybrid approach aimed at improving the sample efficiency in goal-directed reinforcement learning. We do this via a two-step mechanism where firstly, we approximate a model from Model-Free reinforcement learning. Then, we leverage this approximate model along with a notion of reachability using Mean First Passage Times to perform Model-Based reinforcement learning. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Q-Learning (MFPT-Q)and Mean First Passage Time based DYNA (MFPT-DYNA), that have been fundamentally modified from the state-of-the-art reinforcement learning techniques. Preliminary results have shown that our hybrid approaches converge with much fewer iterations than their corresponding state-of-the-art counterparts and therefore requiring much fewer samples and much fewer training trials to converge.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593728","","Reinforcement learning;Computational modeling;Markov processes;Acceleration;Convergence;Learning systems","learning (artificial intelligence)","approximate model;hybrid approach;goal-directed reinforcement learning;model-based reinforcement learning;model characterization;model-free reinforcement learning;mean-first passage time","","","30","","","","","IEEE","IEEE Conferences"
"Analytical Model of Thermal Soaring: Towards Energy Efficient Path Planning for Flying Robots","J. Khaghani; M. Nekoui; R. Nasiri; M. N. Ahmadabadi","Control and Intelligent Processing Center of Excellence (CIPCE, School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran; Control and Intelligent Processing Center of Excellence (CIPCE, School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran; Control and Intelligent Processing Center of Excellence (CIPCE, School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran; Control and Intelligent Processing Center of Excellence (CIPCE, School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7589","7594","Developing analytical models of efficient locomotion in biology is one of the most interesting goals in bio- inspired robotics. This paper presents a mathematical framework in order to model one of the most energy efficient locomotion types in flying animals; i.e., thermal soaring. Unlike the legged locomotion, in flying, modeling the environmental effects on animals' behaviors is very important. In doing so, we develop our model by assuming thermals as bubbles of rising air. According to pieces of real evidence, this kind of modeling is more compatible with the nature of thermal soaring. Moreover, we present a simple hybrid control strategy for obtaining the optimal path in order to maximize benefit from the updraft of air-flow. By using this control strategy, the flying robot can plan a path for traveling between thermals without flapping; i.e., energy efficient flying. So as to investigate the compatibility of presented model and controller with reality, we set their parameters based on the biological evidences. As a result, in simulations, it is observed that the generated flying behavior is comparable with the thermal soaring behavior of real birds. This observation provides a confirmation for generality and applicability of the presented approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593907","Bio-inspired model;Thermal soaring;Path planning;Flying locomotion;Hybrid controller","Mathematical model;Birds;Thermal loading;Analytical models;Robots;Aerodynamics;Thermal variables control","aerospace robotics;biomimetics;continuous systems;discrete systems;mobile robots;path planning","simple hybrid control strategy;flying robot;energy efficient flying;thermal soaring behavior;energy efficient locomotion types;flying animals;energy efficient path planning","","","24","","","","","IEEE","IEEE Conferences"
"Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan","M. Prágr; P. Čížek; J. Faigl","Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1745","1750","The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593374","","Robots;Feature extraction;Image color analysis;Estimation;Unmanned aerial vehicles;Three-dimensional displays;Visualization","feature extraction;inference mechanisms;learning (artificial intelligence);legged locomotion;motion control;path planning;robot vision;terrain mapping","multilegged robot;crawled terrain;hexapod robot;legged robot;terrain features inference;aerial scan;robot locomotion;incremental learning;geometrical data;visual data;terrain learning;extraterrestrial missions;robot deployment;robot motion planning;cost of transport estimation;terrain descriptors;mechanical properties","","","32","","","","","IEEE","IEEE Conferences"
"Learning from Demonstration for Hydraulic Manipulators","M. Suomalainen; J. Koivumäki; S. Lampinen; V. Kyrki; J. Mattila","NA; NA; Tampere University of Technology, Finland; School of Electrical Engineering, Aalto University, Finland; Tampere University of Technology, Finland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3579","3586","This paper presents, for the first time, a method for learning in-contact tasks from a teleoperated demonstration with a hydraulic manipulator. Due to the use of extremely powerful hydraulic manipulator, a force-reflected bilateral teleoperation is the most reasonable method of giving a human demonstration. An advanced subsystem-dynamic-based control design framework, virtual decomposition control (VDC), is used to design a stability-guaranteed controller for the teleoperation system, while taking into account the full nonlinear dynamics of the master and slave manipulators. The use of fragile force/torque sensor at the tip of the hydraulic slave manipulator is avoided by estimating the contact forces from the manipulator actuators' chamber pressures. In the proposed learning method, it is observed that a surface-sliding tool has a friction-dependent range of directions (between the actual direction of motion and the contact force) from which the manipulator can apply force to produce the sliding motion. By this intuition, an intersection of these ranges can be taken over a motion to robustly find a desired direction for the motion from one or more demonstrations. The compliant axes required to reproduce the motion can be found by assuming that all motions outside the desired direction is caused by the environment, signalling the need for compliance. Finally, the learning method is incorporated to a novel VDC-based impedance control method to learn compliant behaviour from teleoperated human demonstrations. Experiments with 2-DOF hydraulic manipulator with a 475kg payload demonstrate the suitability and effectiveness of the proposed method to perform learning from demonstration (LfD) with heavy-duty hydraulic manipulators.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594285","","Hydraulic systems;Force;Task analysis;Manipulator dynamics;Impedance;Control design","control system synthesis;end effectors;force control;force sensors;friction;hydraulic systems;learning (artificial intelligence);manipulator dynamics;manipulators;motion control;position control;stability;telerobotics","fragile force-torque sensor;heavy-duty hydraulic manipulators;teleoperated human demonstrations;novel VDC-based impedance control method;sliding motion;learning method;manipulator actuators;contact force;hydraulic slave manipulator;slave manipulators;teleoperation system;stability-guaranteed controller;virtual decomposition control;advanced subsystem-dynamic-based control design framework;human demonstration;reasonable method;force-reflected bilateral teleoperation;extremely powerful hydraulic manipulator;teleoperated demonstration;in-contact tasks","","","34","","","","","IEEE","IEEE Conferences"
"Perception Based Locomotion System for a Humanoid Robot with Adaptive Footstep Compensation under Task Constraints","I. Kumagai; M. Morisawa; S. Nakaoka; T. Sakaguchi; H. Kaminaga; K. Kaneko; F. Kanehiro","National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan; National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan; National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan; National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan; National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan; National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan; National Institute of Advanced Industrial Science and Technology (AIST), 1-1-1 Umezono, Tsukuba, Ibaraki, 305-8560, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","713","719","In order to accurately reach a target position while executing a task which imposes occlusion or constraints of the posture, a humanoid robot requires an adaptive locomotion system, which can comprehensively integrate localization, environmental mapping, global locomotion planning and local error correction. In this paper, we propose a method of constructing a perception based locomotion system for a humanoid robot. The major contribution of this paper is solving a problem of the locomotion error caused by the task constraints, by locally compensating footsteps and assessing the need for global footstep re-planning online based on environmental measurements. The proposed system provides an accurate and dense ground point cloud, called HeightField, using plane estimation and space interpolation, and obstacle point cloud for frequent collision avoidance by accumulating laser scans. This environmental perception enables a humanoid robot to plan footsteps globally even in the situation where the sight of the robot is limited and compensate footsteps while estimating landing state during locomotion online with the localization result. We evaluated the practicality of the proposed system by applying it to our humanoid robot carrying a heavy object in a construction site and confirmed that the proposed system contributed to improved locomotion abilities of a humanoid robot engaging in heavy-duty or dangerous tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593553","","Humanoid robots;Task analysis;Planning;Foot;Three-dimensional displays;Estimation","adaptive control;collision avoidance;humanoid robots;interpolation;legged locomotion;path planning","task constraints;humanoid robot;adaptive footstep compensation;adaptive locomotion system;local error correction;perception based locomotion system;locomotion error;locomotion planning;point cloud;environmental measurements;plane estimation;space interpolation;collision avoidance;laser scans","","2","23","","","","","IEEE","IEEE Conferences"
"Learning-based Walking Assistance Control Strategy for a Lower Limb Exoskeleton with Hemiplegia Patients","R. Huang; Z. Pengl; H. Cheng; J. Hu; J. Qiu; C. Zou; Q. Chen","School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2280","2285","Lower exoskeleton has gained considerable interests in walking assistance applications for both paraplegia and hemiplegia patients. In walking assistance of hemiplegia patients, the exoskeleton should have the ability to control the affected leg to follow the unaffected leg's motion naturally. One critical issue of walking assistance for hemiplegia patients is how to adapt the controller of both lower limbs with different patients. This paper presents a novel learning-based walking assistance control strategy for lower exoskeleton with hemiplegia patients. In the proposed control strategy, we modeled the control system of lower exoskeleton with hemiplegia patient as a Leader-Follower Multi-Agent System (LF-MAS). In order to adapt different patients with different conditions, reinforcement learning framework is utilized to adapt controllers online. In reinforcement learning framework with LF-MAS, we employed a Policy Iteration Adaptive Dynamic Programming (PI-ADP) algorithm, which aims to achieve better tracking control performance for lower exoskeleton with hemiplegia patient. We demonstrate the efficiency of proposed learning-based walking assistance control strategy in an exoskeleton system with healthy subjects who simulate hemiplegia patients. Experimental results indicate that the proposed control strategy can adapt different pilots with good tracking performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594464","Walking Assistance Strategy;Leader-Follower Multi-Agent System;Reinforcement Learning;Lower Exoskeleton;Hemiplegia","Legged locomotion;Exoskeletons;Reinforcement learning;Control systems;Heuristic algorithms;Multi-agent systems;Cost function","adaptive control;dynamic programming;gait analysis;handicapped aids;iterative methods;learning (artificial intelligence);medical robotics;motion control;multi-agent systems;patient rehabilitation","hemiplegia patient;lower limb exoskeleton;learning-based walking assistance control strategy;paraplegia patients;leader-follower multi-agent system;LF-MAS;reinforcement learning framework;policy iteration adaptive dynamic programming algorithm;PI-ADP algorithm;tracking control","","","20","","","","","IEEE","IEEE Conferences"
"A Robust Control Method for the Elbow of the Humanoid Robot TEO Based on a Fractional Order Controller","J. Muñoz; C. A. Monje; F. Martín; C. Balaguer","Avda de la Universidad, Robotics Lab of the Carlos III University of Madrid, Madrid, 30, 28911, Spain; Avda de la Universidad, Robotics Lab of the Carlos III University of Madrid, Madrid, 30, 28911, Spain; Avda de la Universidad, Robotics Lab of the Carlos III University of Madrid, Madrid, 30, 28911, Spain; Avda de la Universidad, Robotics Lab of the Carlos III University of Madrid, Madrid, 30, 28911, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6378","6383","This paper presents a novel method for the control of the elbow joint of the humanoid robot TEO, based on a fractional order PD controller. Due to the graphical nature of the proposed method, a few basic operations are enough to tune the controller, offering very competitive results compared to classic methods. The experiments show a robust performance of the system to mass changes at the tip of the humanoid right arm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593732","","Gain;Humanoid robots;Tuning;Robustness;Elbow","humanoid robots;manipulators;PD control;robust control","robust control method;humanoid robot TEO;fractional order controller;elbow joint;fractional order PD controller;robust performance;humanoid right arm","","","24","","","","","IEEE","IEEE Conferences"
"A Soft-Exosuit Enables Multi-Scale Analysis of Wearable Robotics in a Bipedal Animal Model","S. M. Cox; J. Rubenson; G. S. Sawicki","Department of Kinesiology, Biomechanics Laboratory, Muscle Function and Locomotion Laboratory, Pennsylvania State University, University Park, PA, 16802, USA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4685","4691","Wearable robotics offers a unique opportunity to explore how biological systems interface with engineered parts. But, due to a gap in understanding of the underlying biological mechanisms at work, the state of the art in design and development is a sophisticated form of automated trial and error. Progress is hampered by the difficulty of assessing the direct impact of wearable robots on underlying muscles, tendons and bones during human experimentation. While animal models have provided an experimental platform to explore other biological mechanisms, as of yet, no animal model of a wearable robot during locomotion has been developed. To fill this gap, we have built the first ever wearable robotic device for a freely-Iocomoting, non-human, bipedal animal (Numida melaegris = Guinea fowl), a species whose gait closely mirrors human locomotion mechanics. We found that a spring-loaded soft-exosuit that passively augments the energy stored in distal tendons was both well tolerated and provided consistent torques. Preliminary data showed birds systematically change their kinematics in response to changes to exo-suit spring stiffness, adjusting the timing but not magnitude of the assistive torques. This animal model for wearable robotics allows experiments up and down the broader spatiotemporal scale that are not currently possible in humans. With it we can address questions from short-term adaptations in musculoskeletal dynamics within a single step to broader behavioral and physical changes that come with long term use.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593911","","Kinematics;Springs;Tendons;Robots;Birds;Fixtures","actuators;biocontrol;biomechanics;bone;gait analysis;legged locomotion;medical robotics;mobile robots;muscle;springs (mechanical)","underlying biological mechanisms;wearable robot;wearable robotic device;human locomotion mechanics;wearable robotics;soft-exosuit enables multiscale analysis;bipedal animal model;biological system interface","","","36","","","","","IEEE","IEEE Conferences"
"Perception-Driven Sparse Graphs for Optimal Motion Planning","T. Sayre-McCord; S. Karaman","Massachusetts Institute of Technology (MIT), Laboratory for Information and Decision Systems (LIDS), Cambridge, MA, 02139, USA; Massachusetts Institute of Technology (MIT), Laboratory for Information and Decision Systems (LIDS), Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8110","8117","Most existing motion planning algorithms assume that a map (of some quality) is fully determined prior to generating a motion plan. In many emerging applications of robotics, e.g., fast-moving agile aerial robots with constrained embedded computational platforms and visual sensors, dense maps of the world are not immediately available, and they are computationally expensive to construct. We propose a new algorithm for generating plan graphs which couples the perception and motion planning processes for computational efficiency. In a nutshell, the proposed algorithm iteratively switches between the planning sub-problem and the mapping sub-problem, each updating based on the other until a valid trajectory is found. The resulting trajectory retains a provable property of providing an optimal trajectory with respect to the full (unmapped) environment, while utilizing only a fraction of the sensing data in computational experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594209","","Planning;Trajectory;Robot sensing systems;Collision avoidance;Heuristic algorithms","collision avoidance;graph theory;mobile robots;optimal control;optimisation;robot vision;trajectory control","motion plan generation;planning subproblem;mapping subproblem;optimal motion planning;perception-driven sparse graphs;optimal trajectory;plan graphs;visual sensors","","","26","","","","","IEEE","IEEE Conferences"
"After You: Doorway Negotiation for Human-Robot and Robot-Robot Interaction","J. Thomas; R. Vaughan","School of Computing Science, Simon Fraser University; School of Computing Science, Simon Fraser University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3387","3394","We propose and test an autonomous robot behavior for socially-compliant navigation of doorways with both human and robot interlocutors. Building on previous work for “aggressive” interaction between robots to resolve navigation deadlocks in corridors, we demonstrate an “assertive” robot that negotiates right-of-way when faced with a human or other robot. The negotiation is implemented using only motion and common navigation sensors, without explicit message-passing. Our goal is for the correct agent to take priority, as decided both by time-efficiency and as judged subjectively by naive human participants. Our contribution is a practical method for doorway negotiation, and a study of human users' responses to a robot that appears to participate in existing social customs surrounding doors. Our method is evaluated with robot-robot experiments and a human-robot interaction study with nonexpert users.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594034","","Navigation;Collision avoidance;Robot sensing systems;System recovery;Autonomous robots;Safety","human-robot interaction;path planning","doorway negotiation;robot-robot interaction;autonomous robot behavior;aggressive interaction;navigation deadlocks;assertive robot;common navigation sensors;naive human participants;human users;robot-robot experiments;human-robot interaction study","","","14","","","","","IEEE","IEEE Conferences"
"Multimotion Visual Odometry (MVO): Simultaneous Estimation of Camera and Third-Party Motions","K. M. Judd; J. D. Gammell; P. Newman","Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3949","3956","Estimating motion from images is a well-studied problem in computer vision and robotics. Previous work has developed techniques to estimate the motion of a moving camera in a largely static environment (e.g., visual odometry) and to segment or track motions in a dynamic scene using known camera motions (e.g., multiple object tracking). It is more challenging to estimate the unknown motion of the camera and the dynamic scene simultaneously. Most previous work requires a priori object models (e.g., tracking-by-detection), motion constraints (e.g., planar motion), or fails to estimate the full SE (3) motions of the scene (e.g., scene flow). While these approaches work well in specific application domains, they are not generalizable to unconstrained motions. This paper extends the traditional visual odometry (VO) pipeline to estimate the full SE (3) motion of both a stereo/RGB-D camera and the dynamic scene. This multimotion visual odometry (MVO) pipeline requires no a priori knowledge of the environment or the dynamic objects. Its performance is evaluated on a real-world dynamic dataset with ground truth for all motions from a motion capture system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594213","","Cameras;Motion segmentation;Tracking;Dynamics;Trajectory;Estimation;Image segmentation","cameras;computer vision;image motion analysis;image segmentation;image sensors;image sequences;motion estimation;object detection;object tracking;stereo image processing","dynamic scene;multimotion visual odometry pipeline;MVO;dynamic objects;motion capture system;simultaneous estimation;third-party motions;computer vision;previous work;moving camera;largely static environment;segment;tracking-by-detection;motion constraints;planar motion;SE motion;scene flow;unconstrained motions;camera motions;object tracking;stereo/RGB-D camera;multimodal visual odometry pipeline","","1","38","","","","","IEEE","IEEE Conferences"
"Collision-Free Path Planning of Dual-Manipulator System Based on Energy Conversion","C. Su; R. Wei; M. Zhang; H. Rose; J. Xu","Huazhong University of Science & Technology, School of Mechanical Science & Engineering, Wuhan, China; Huazhong University of Science & Technology, School of Mechanical Science & Engineering, Wuhan, China; Bosch (China) Investment Ltd, Shanghai, China; Bosch (China) Investment Ltd, Shanghai, China; Huazhong University of Science & Technology, School of Mechanical Science & Engineering, Wuhan, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8360","8366","This paper is a preliminary exploration of how to solve the dual-manipulator path-planning problem from an energy perspective. A virtual spring is set up between the two manipulator bodies and becomes compressed as they move into the area of danger, thus producing elastic potential energy. The initial paths of the manipulators are modelled as two ends-fixed elastic ropes. The elastic potential energy stored in the virtual spring is distributed between the two elastic ropes in a certain proportion so as to deform them. In this way, the original paths of the two manipulators will deviate toward the direction of their respective bases thereby avoiding any collision crisis that may potentially occur. When the dual-manipulator moves away from the danger area, the elastic potential energy caused by the deviation of the elastic ropes will be converted back into energy stored by the virtual spring, such that the elastic ropes revert to their original state and drive the manipulators back to their initial paths. Simple but representative simulations are established and results of the simulations show the reliability of our proposed method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593696","","Manipulators;Path planning;Springs;Potential energy;Mobile robots","collision avoidance;elasticity;manipulators;mobile robots;path planning;springs (mechanical)","dual-manipulator moves;original paths;ends-fixed elastic ropes;manipulators;initial paths;elastic potential energy;manipulator bodies;virtual spring;energy perspective;dual-manipulator path-planning problem;energy conversion;dual-manipulator system;collision-free path planning","","","29","","","","","IEEE","IEEE Conferences"
"Towards a Passive Adaptive Planar Foot with Ground Orientation and Contact Force Sensing for Legged Robots","R. Käslin; H. Kolvenbach; L. Paez; K. Lika; M. Hutter","ETH Zurich, Robotic Systems Lab (RSL), Switzerland; ETH Zurich, Robotic Systems Lab (RSL), Switzerland; ETH Zurich, Robotic Systems Lab (RSL), Switzerland; ETH Zurich, Robotic Systems Lab (RSL), Switzerland; ETH Zurich, Robotic Systems Lab (RSL), Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2707","2714","Adapting to the ground enables stable footholds in legged locomotion by exploiting the structure of the terrain. On that account, we present a passive adaptive planar foot with three rotational degrees of freedom that is lightweight and thus suited for highly dynamic legged robots. Its low laying pivot joint provides high stability towards kinking. Information about the relative foot sole pose, and accordingly, the ground orientation is gathered by inertial measurement units (IMUs) placed on the foot sole and the shank. A complementary filter is presented that fuses these orientation estimates with an angular encoder to obtain a drift-free relative foot sole pose. The passive adaptive planar foot has been tested and compared to the classical point foot design on a variety of terrains and shows superior traction performance, especially on compressible soils. Being mounted on the quadrupedal robot ANYmal, the foot provides a reliable contact detection based on the fusion of the built-in 6-axis force/torque transducer and the IMUs. This allows to walk and trot on uneven terrain, loose soils, as well as climbing up a ramp and stairs while keeping the entire foot sole in ground contact all the time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593875","","Foot;Sensors;Legged locomotion;Force;Force measurement;Microcontrollers","force sensors;gait analysis;legged locomotion;robot dynamics;soil;stability","ground orientation;drift-free relative foot sole pose;passive adaptive planar foot;ground contact;highly dynamic legged robots;point foot design;legged locomotion;contact force sensor;stability;inertial measurement units;IMUs;quadrupedal robot ANYmal;compressible soils;built-in 6-axis force-torque transducer","","1","28","","","","","IEEE","IEEE Conferences"
"CultureNet: A Deep Learning Approach for Engagement Intensity Estimation from Face Images of Children with Autism","O. Rudovic; Y. Utsumi; J. Lee; J. Hernandez; E. C. Ferrer; B. Schuller; R. W. Picard","Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Chubu University, Japan; Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Imperial College London, UK; Massachusetts Institute of Technology, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","339","346","Many children on autism spectrum have atypical behavioral expressions of engagement compared to their neu-rotypical peers. In this paper, we investigate the performance of deep learning models in the task of automated engagement estimation from face images of children with autism. Specifically, we use the video data of 30 children with different cultural backgrounds (Asia vs. Europe) recorded during a single session of a robot-assisted autism therapy. We perform a thorough evaluation of the proposed deep architectures for the target task, including within- and across-culture evaluations, as well as when using the child-independent and child-dependent settings. We also introduce a novel deep learning model, named CultureNet, which efficiently leverages the multi-cultural data when performing the adaptation of the proposed deep architecture to the target culture and child. We show that due to the highly heterogeneous nature of the image data of children with autism, the child-independent models lead to overall poor estimation of target engagement levels. On the other hand, when a small amount of data of target children is used to enhance the model learning, the estimation performance on the held-out data from those children increases significantly. This is the first time that the effects of individual and cultural differences in children with autism have empirically been studied in the context of deep learning performed directly from face images.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594177","","Face;Autism;Deep learning;Estimation;Cultural differences;Task analysis;Robots","cultural aspects;face recognition;human-robot interaction;learning (artificial intelligence);medical disorders;medical robotics;paediatrics;patient treatment","deep learning model;cultural backgrounds;image data;target culture;multicultural data;child-dependent settings;across-culture evaluations;target task;deep architecture;robot-assisted autism therapy;video data;automated engagement estimation;deep learning models;neu-rotypical peers;autism spectrum;engagement intensity estimation;face images;cultural differences;individual differences;estimation performance;model learning;target children;target engagement levels;poor estimation;child-independent models","","","40","","","","","IEEE","IEEE Conferences"
"Extracting Phenotypic Characteristics of Corn Crops Through the Use of Reconstructed 3D Models","D. Zermas; V. Morellas; D. Mulla; N. Papanikolopoulos","University of Minnesota, Department of Computer Science and Engineering; University of Minnesota, Department of Computer Science and Engineering; Water and Climate, University of Minnesota, Department of Soil; University of Minnesota, Department of Computer Science and Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8247","8254","Financial and social elements of modern societies are closely connected to the cultivation of corn. Due to its massive production, deficiencies during the cultivation process directly translate to major financial losses. Since proper surveillance in a large scale is still very challenging, the companies that specialize in optimizing crop yield are trying to address the problem at its root by developing hybrid plants able to resist the harsh conditions of the field. The selection of the best hybrid is not easy and every year hundreds of test plants with different phenotypic characteristics are planted while their performance is quantified by inconsistent and rough measurements gathered by humans. We propose a pipeline that takes advantage of the structure from motion technology to create a detailed 3D point cloud of a few plants and segment it into the basic elements of the scene; the ground, the plants, the plant stems, and the plant leaves. The focus is on the segmentation process through which several phenotypic characteristics of individual plants can be extracted. As an example, we show the results for the plant counting and plant height estimation processes where we achieve an accuracy of 88.1% and 89.2%.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594356","","Three-dimensional displays;Agriculture;Solid modeling;Estimation;Computational modeling;Image segmentation;Vegetation","agriculture;crops;financial management;image reconstruction;image segmentation;solid modelling","social elements;cultivation process;financial losses;crop yield;hybrid plants;motion technology;segmentation process;corn crops;phenotypic characteristics;3D point cloud;reconstructed 3D models;financial elements","","","28","","","","","IEEE","IEEE Conferences"
"Learning Generalizable Robot Skills from Demonstrations in Cluttered Environments","M. Asif Rana; M. Mukadam; S. Reza Ahmadzadeh; S. Chernova; B. Boots","Georgia Institute of Technology, Institute for Robotics and Intelligent Machines (IRIM), Atlanta, GA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines (IRIM), Atlanta, GA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines (IRIM), Atlanta, GA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines (IRIM), Atlanta, GA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines (IRIM), Atlanta, GA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4655","4660","Learning from Demonstration (LfD) is a popular approach to endowing robots with skills without having to program them by hand. Typically, LfD relies on human demonstrations in clutter-free environments. This prevents the demonstrations from being affected by irrelevant objects, whose influence can obfuscate the true intention of the human or the constraints of the desired skill. However, it is unrealistic to assume that the robot's environment can always be restructured to remove clutter when capturing human demonstrations. To contend with this problem, we develop an importance weighted batch and incremental skill learning approach, building on a recent inference-based technique for skill representation and reproduction. Our approach reduces unwanted environmental influences on the learned skill, while still capturing the salient human behavior. We provide both batch and incremental versions of our approach and validate our algorithms on a 7-DOF JACO2 manipulator with reaching and placing skills.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593624","","Trajectory;Robots;Clamps;Covariance matrices;Collision avoidance;Stochastic processes;Clutter","collision avoidance;dexterous manipulators;intelligent robots;learning (artificial intelligence);trajectory control","learning from demonstration;LfD approach;reaching skills;placing skills;7-DOF JACO2 manipulator;clutter-free environments;human demonstrations;cluttered environments;generalizable robot skills;salient human behavior;recent inference-based technique;incremental skill learning approach;importance weighted batch","","","19","","","","","IEEE","IEEE Conferences"
"Navigation without localisation: reliable teach and repeat based on the convergence theorem","T. Krajník; F. Majer; L. Halodová; T. Vintr","Faculty of Electrical Engineering, Czech Technical University, Artificial Intelligence Center; Faculty of Electrical Engineering, Czech Technical University, Artificial Intelligence Center; Faculty of Electrical Engineering, Czech Technical University, Artificial Intelligence Center; Faculty of Electrical Engineering, Czech Technical University, Artificial Intelligence Center","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1657","1664","We present a novel concept for teach-and-repeat visual navigation. The proposed concept is based on a mathematical model, which indicates that in teach-and-repeat navigation scenarios, mobile robots do not need to perform explicit localisation. Rather than that, a mobile robot which repeats a previously taught path can simply “replay” the learned velocities, while using its camera information only to correct its heading relative to the intended path. To support our claim, we establish a position error model of a robot, which traverses a taught path by only correcting its heading. Then, we outline a mathematical proof which shows that this position error does not diverge over time. Based on the insights from the model, we present a simple monocular teach-and-repeat navigation method. The method is computationally efficient, it does not require camera calibration, and it can learn and autonomously traverse arbitrarily-shaped paths. In a series of experiments, we demonstrate that the method can reliably guide mobile robots in realistic indoor and outdoor conditions, and can cope with imperfect odometry, landmark deficiency, illumination variations and naturally-occurring environment changes. Furthermore, we provide the navigation system and the datasets gathered at www.github.com/gestom/stroll_bearnav.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593803","","Robot kinematics;Navigation;Cameras;Robot vision systems;Simultaneous localization and mapping;Feature extraction","calibration;cameras;mobile robots;navigation;path planning;robot vision;velocity control","mobile robot;taught path;learned velocities;camera information;position error model;mathematical proof;camera calibration;navigation system;mathematical model;explicit localisation;teach-and-repeat navigation scenarios;teach-and-repeat visual navigation","","","43","","","","","IEEE","IEEE Conferences"
"π-SoC: Heterogeneous SoC Architecture for Visual Inertial SLAM Applications","J. Tang; B. Yu; S. Liu; Z. Zhang; W. Fang; Y. Zhang","South China University of Technology, China; PerceptIn Inc, USA; PerceptIn Inc, USA; PerceptIn Inc, USA; Beijing Institute of Technology, China; Beijing Institute of Technology, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8302","8307","In recent years, we have observed a clear trend in the rapid rise of autonomous vehicles and robotics. One of the core technologies enabling these applications, Simultaneous Localization And Mapping (SLAM), imposes two main challenges: first, these workloads are computationally intensive and they often have real-time requirements; second, these workloads run on battery-powered mobile devices with limited energy budget. Hence, performance should be improved while simultaneously reducing energy consumption, two rather contradicting goals by conventional wisdom. Previous attempts to optimize SLAM performance and energy efficiency usually involve optimizing one function and fail to approach the problem systematically. In this paper, we first study the characteristics of visual inertial SLAM workloads on existing heterogeneous SoCs. Then based on the initial findings, we propose π-SoC, a heterogeneous SoC design that systematically optimize the IO interface, the memory hierarchy, as well as the the hardware accelerator. We implemented this system on a Xilinx Zynq UltraScale MPSoC and was able to deliver over 60 FPS performance with average power less than 5 W.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594181","","Simultaneous localization and mapping;Feature extraction;Three-dimensional displays;Instruction sets;Power demand;Graphics processing units;Computer architecture","energy consumption;mobile computing;mobile robots;optimisation;SLAM (robots);system-on-chip","visual inertial SLAM applications;autonomous vehicles;robotics;core technologies;battery-powered mobile devices;energy budget;energy consumption;energy efficiency;visual inertial SLAM workloads;60 FPS performance;heterogeneous SoC architecture;simultaneous localization and mapping;hardware accelerator;IO interface;memory hierarchy","","","15","","","","","IEEE","IEEE Conferences"
"User-Adaptive Human-Robot Formation Control for an Intelligent Robotic Walker Using Augmented Human State Estimation and Pathological Gait Characterization","G. Chalvatzaki; X. S. Papageorgiou; P. Maragos; C. S. Tzafestas","National Technical University of Athens, School of Electrical and Computer Engineering, Greece; National Technical University of Athens, School of Electrical and Computer Engineering, Greece; National Technical University of Athens, School of Electrical and Computer Engineering, Greece; National Technical University of Athens, School of Electrical and Computer Engineering, Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6016","6022","In this paper we describe a control strategy for a user-adaptive human-robot system for an intelligent robotic Mobility Assistive Device (MAD)using raw data from a single laser-range-finder (LRF)mounted on the MAD and scanning the walking area. The proposed control architecture consists of three modules. In the first module, a previously proposed methodology (termed IMM-PDA-PF)delivers the augmented human state estimation of the user by providing robust leg tracking and on-line estimation of the human gait phases. This information is processed at the next module for providing the pathological gait parametrization and characterization, by computing specific gait parameters for each gait cycle. These gait parameters form the feature vector that classifies the user in a certain class related to risk of fall. Those are of particular significance to the system, since the gait parameters and the respective class are used in the third module, i.e. the human-robot formation controller, in order to adapt the desired formation of the human-robot system, by selecting the appropriate control variables. The experimental evaluation comprises gait data from real patients, and demonstrates the stability of the human-robot formation control, indicating the importance of incorporating an on-line gait characterization of the user, using non-wearable and non-invasive methods, in the context of a robotic MAD.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594360","","Legged locomotion;Pathology;State estimation;Robot sensing systems;Robot kinematics;Real-time systems","assisted living;gait analysis;geriatrics;human-robot interaction;intelligent robots;laser ranging;medical robotics;multi-robot systems;stability;state estimation","on-line gait characterization;robotic MAD;IMM-PDA-PF;intelligent robotic mobility assistive device;human-robot formation controller;gait cycle;pathological gait parametrization;human gait phases;on-line estimation;single laser-range-finder;user-adaptive human-robot system;pathological gait characterization;augmented human state estimation;intelligent robotic walker;user-adaptive human-robot formation control","","","23","","","","","IEEE","IEEE Conferences"
"Adaptive Autonomous Grasp Selection via Pairwise Ranking","D. Kent; R. Toris","Georgia Institute of Technology; Petch Robotics, Inc","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2971","2976","Autonomous grasp selection for robot pick-and-place applications makes use of either empirical methods leveraging object databases, which generate grasps for specific objects at the initial cost of modeling effort, or analytical methods, which generalize to novel objects but fail on object subsets that require specific grasping strategies not captured by the algorithm. We introduce a grasp selection algorithm that ranks grasp candidates with a set of grasp metrics augmented with object features, creating an approach that adapts its strategies based on user-specified grasp preferences. We formulate grasp selection as a pairwise ranking problem, which significantly reduces data collection compared to traditional grasp ranking methods and generalizes to novel objects. Our approach outperforms a state-of-the-art grasp calculation baseline and a pointwise ranking formulation of the same problem.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594105","","Measurement;Solid modeling;Training data;Three-dimensional displays;Databases;Training;Data models","feature selection;manipulators;mobile robots;robot vision","object subsets;grasp selection algorithm;grasp metrics;object features;user-specified grasp preferences;pairwise ranking problem;pointwise ranking formulation;adaptive autonomous grasp selection;object databases;grasping strategies;robot pick-and-place applications","","","32","","","","","IEEE","IEEE Conferences"
"Model-Based Action Exploration for Learning Dynamic Motion Skills","G. Berseth; A. Kyriazis; I. Zinin; W. Choi; M. van de Panne","Faculty of Computer Science, University of British Columbia; NA; NA; NA; Faculty of Computer Science, University of British Columbia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1540","1546","Deep reinforcement learning has achieved great strides in solving challenging motion control tasks. Recently, there has been significant work on methods for exploiting the data gathered during training, but there has been less work on how to best generate the data to learn from. For continuous action domains, the most common method for generating exploratory actions involves sampling from a Gaussian distribution centred around the mean action output by a policy. Although these methods can be quite capable, they do not scale well with the dimensionality of the action space, and can be dangerous to apply on hardware. We consider learning a forward dynamics model to predict the result, (x<sub>t+1</sub>), of taking a particular action, (u), given a specific observation of the state, (x<sub>t</sub>). With this model we perform internal lookahead predictions of outcomes and seek actions we believe have a reasonable chance of success. This method alters the exploratory action space, thereby increasing learning speed and enables higher quality solutions to difficult problems, such as robotic locomotion and juggling.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593588","","Computational modeling;Stochastic processes;Robots;Predictive models;Task analysis;Training;Generative adversarial networks","Gaussian distribution;learning (artificial intelligence);mobile robots;motion control","model-based action exploration;dynamic motion skills;deep reinforcement learning;Gaussian distribution;forward dynamics model;motion control tasks;internal lookahead prediction;robotic locomotion;juggling","","","36","","","","","IEEE","IEEE Conferences"
"A Robust and Efficient Dynamic Network Protocol for a large-scale artificial robotic skin","C. Bader; F. Bergner; G. Cheng","Institute for Cognitive Systems (ICS), Technische Universitt Mnchen, Munich, Germany; Institute for Cognitive Systems (ICS), Technische Universitt Mnchen, Munich, Germany; Institute for Cognitive Systems (ICS), Technische Universitt Mnchen, Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1600","1605","Artificial robotic skins are continuously in contact with their environment, and therefore highly rely on proper connections in their skin cells' network. With a static network protocol approach, the affected skin area is unusable after a connection failure. Therefore, we developed a dynamic network protocol for large-scale artificial robotic skins, which re-routes the network upon connection failures to keep the whole skin in operation. Furthermore, the protocol balances the load for driving larger skins without packet loss. For verification, we validated the protocol on a large artificial robot skin we have developed and analyzed its performance with a skin network consisting of up to 204 cells. The failure recovery of the protocol converges in at most 50ms. We showed that the balancing method achieves a packet loss reduction of over 30% compared to the previously used protocol.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594499","","Skin;Routing protocols;Robot sensing systems;Routing;Heuristic algorithms","protocols;robots;skin;telecommunication network reliability","protocol converges;skin network;artificial robot skin;dynamic network protocol;static network protocol approach;skin cells;artificial robotic skins;large-scale artificial robotic skin","","","14","","","","","IEEE","IEEE Conferences"
"Computationally-Robust and Efficient Prioritized Whole-Body Controller with Contact Constraints","D. Kim; J. Lee; J. Ahn; O. Campbell; H. Hwang; L. Sentis","University of Texas at Austin, Luis Sentis is a Faculty of Aerospace Engineering, TX, USA; University of Texas at Austin, Luis Sentis is a Faculty of Aerospace Engineering, TX, USA; University of Texas at Austin, Luis Sentis is a Faculty of Aerospace Engineering, TX, USA; University of Texas at Austin, Luis Sentis is a Faculty of Aerospace Engineering, TX, USA; University of Texas at Austin, Luis Sentis is a Faculty of Aerospace Engineering, TX, USA; University of Texas at Austin, Luis Sentis is a Faculty of Aerospace Engineering, TX, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","In this paper, we devise methods for the multiobjective control of humanoid robots, a.k.a. prioritized whole-body controllers, that achieve efficiency and robustness in the algorithmic computations. We use a form of whole-body controllers that is very general via incorporating centroidal momentum dynamics, operational task priorities, contact reaction forces, and internal force constraints. First, we achieve efficiency by solving a quadratic program that only involves the floating base dynamics and the reaction forces. Second, we achieve computational robustness by relaxing task accelerations such that they comply with friction cone constraints. Finally, we incorporate methods for smooth contact transitions to enhance the control of dynamic locomotion behaviors. The proposed methods are demonstrated both in simulation and in real experiments using a passive-ankle bipedal robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593767","","Task analysis;Null space;Dynamics;Acceleration;Robots;Force;Torque","force control;friction;humanoid robots;legged locomotion;mechanical contact;quadratic programming;robot dynamics;robust control","centroidal momentum dynamics;computationally-robust whole-body controller;quadratic program;passive-ankle bipedal robot;dynamic locomotion behaviors;smooth contact transitions;friction cone constraints;task accelerations;computational robustness;floating base dynamics;internal force constraints;contact reaction forces;operational task priorities;algorithmic computations;prioritized whole-body controllers;humanoid robots;multiobjective control;contact constraints","","4","28","","","","","IEEE","IEEE Conferences"
"Real-Time Shape Estimation of an Elastic Rod Using a Robot Manipulator Equipped with a Sense of Force","N. Nakagawa; H. Mochiyama","University of Tsukuba, Tsukuba, Ibaraki, 305-8573, Japan; University of Tsukuba, Department of In-telligent Interaction Technologies","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8067","8073","This paper proposes a real-time method for estimating the shape of an elastic rod using a robot manipulator equipped with a sense of force. The proposed method does not use optical sensing devices, such as cameras or lasers, but relies only upon the sense of force in the manipulator. In the proposed method, the deformation of an elastic rod is calculated from the obtained force/torque information using the discretized Kirchhoff elastic rod model, and the three-dimensional shape of the rod is then estimated. Furthermore, by integrating the force information with the orientation of the manipulator end-effector, the proposed method can evaluate the effect of gravity on the shape estimation accurately. Experiments were carried out to verify the proposed method, where a thin elastic strip was employed as a typical elastic rod, attached to the end-effector of the robot manipulator, bent and twisted into various shapes. The results show that the proposed method that compensates for gravity is better than a method without gravity compensation, and it estimated the 142 mm length strip shape with a position error no greater than 7.76 mm and an average calculation time of 4.24 ms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593946","","Shape;Manipulators;Gravity;Torque;Estimation;Sensors","elasticity;end effectors;force control;manipulators;position control;rods (structures)","time shape estimation;robot manipulator equipped;real-time method;optical sensing devices;force/torque information;discretized Kirchhoff elastic rod model;three-dimensional shape;force information;manipulator end-effector;elastic strip;typical elastic rod;average calculation time;strip shape;size 142.0 mm","","","22","","","","","IEEE","IEEE Conferences"
"Magnetic-Field-Inspired Navigation for Soft Continuum Manipulator*This work was supported in part by King's College London, the EPSRC in the framework of the NCNR (National Centre for Nuclear Robotics) project (EP/R02572X/1), the STIFF-FLOP project grant from the European Communities Seventh Framework Programme under grant agreement 287728, and the Indonesia Endowment Fund for Education, Ministry of Finance Republic of Indonesia.","A. Ataka; A. Shiva; H. K. Lam; K. Althoefer","Department of Informatics, Kings College London, The Centre for Robotics Research(CoRe), London, WC2R 2LS, United Kingdom; Department of Informatics, Kings College London, The Centre for Robotics Research(CoRe), London, WC2R 2LS, United Kingdom; Department of Informatics, Kings College London, The Centre for Robotics Research(CoRe), London, WC2R 2LS, United Kingdom; Faculty of Science and Engineering, Queen Mary University of London, Centre for Advanced Robotics @ Queen Mary (ARQ), London, E1 4NS, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","168","173","Taking inspiration from the properties of magnetic fields, we propose a reactive navigation method for soft continuum manipulators operating in unknown environments. The proposed navigation method outperforms previous works since it is able to successfully achieve collision-free movements towards the goal in environments with convex obstacles without relying on a priori information of the obstacles' shapes and locations. Simulations for the kinematic model of a soft continuum manipulator and preliminary experiments with a 2-segments soft continuum arm are performed, showing promising results and the potential for our approach to be applied widely.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593592","","Manipulators;Navigation;Force;Wires;Collision avoidance;Service robots","collision avoidance;manipulators;mobile robots;navigation;path planning","2-segment soft continuum arm;unknown environments;reactive navigation method;magnetic fields;soft continuum manipulator;magnetic-field-inspired navigation","","","20","","","","","IEEE","IEEE Conferences"
"Probabilistic Kinematic State Estimation for Motion Planning of Planetary Rovers","S. Ghosh; K. Otsu; M. Ono","Sourish Ghosh is with the Department of Mathematics, Indian Institute of Technology, Kharagpur, West Bengal, 721302, India; Kyohei Otsu and Masahiro Ono are with the Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, 91109, USA; Kyohei Otsu and Masahiro Ono are with the Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, 91109, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5148","5154","Kinematics-based collision detection is important for robot motion planning in unstructured terrain. Especially, planetary rovers require such capability as a single collision may lead to the termination of a mission. For onboard computation, typical numeric approaches are unsuitable as they are computationally expensive and unstable on rocky terrain; instead, a light-weight analytic solution (ACE: Approximate Clearance Evaluation) is planning to be used for the Mars 2020 rover mission. ACE computes the state bounds of articulated suspension systems from terrain height bounds, and assess the safety by checking the constraint violation of states with the worst-case values. ACE's conservative safety check approach can sometimes lead to over-pessimism: feasible states are often reported as infeasible, thus resulting in frequent false positive detection. In this paper, we introduce a computationally efficient probabilistic variant of ACE (called p-ACE) which estimates the probability distributions of states in real time. The advantage of having probability distributions over states, instead of deterministic bounds, is to provide more flexible and less pessimistic worst-case evaluation with probabilistic safety guarantees. Empirically derived distribution models are used to compute the total probability of constraint satisfaction, which is then used for path assessment. Through experiments with a high-fidelity simulator, we empirically show that p-ACE relaxes the deterministic state bounds without losing safety guarantees.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593771","","Wheels;Kinematics;Planning;Space vehicles;Uncertainty;Numerical models;Probabilistic logic","aerospace robotics;Mars;mobile robots;path planning;planetary rovers;robot kinematics;state estimation;statistical distributions","light-weight analytic solution;rocky terrain;typical numeric approaches;onboard computation;single collision;unstructured terrain;robot motion planning;kinematics-based collision detection;planetary rovers;probabilistic kinematic state estimation;deterministic state bounds;distribution models;probabilistic safety guarantees;worst-case evaluation;deterministic bounds;probability distributions;frequent false positive detection;conservative safety check approach;worst-case values;constraint violation;terrain height;articulated suspension systems;Mars 2020 rover mission;Approximate Clearance Evaluation","","","11","","","","","IEEE","IEEE Conferences"
"Trigonometric Ratio-Based Remote Center of Motion Mechanism for Bone Drilling","S. Shim; S. Lee; D. Ji; H. Choi; J. Hong","Robotics Engineering Department, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, South Korea; Robotics Engineering Department, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, South Korea; Robotics Engineering Department, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, South Korea; Robotics Engineering Department, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, South Korea; Robotics Engineering Department, DGIST (Daegu Gyeongbuk Institute of Science and Technology), Daegu, 42988, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4958","4963","The remote center of motion (RCM) mechanism is a prominent candidate to aid bone drilling. The surgeon can simply place a drill with the RCM mechanism near the entry point to provide drill alignment with the target. Using this assistive mechanism for bone drilling improves drilling accuracy and reduces the complexity of bone drilling robotic systems. However, because most RCM mechanisms have been developed for laparoscopic surgery or needle insertion into soft tissue, they lack rigidity and are unsuitable for bone drilling. One of the most difficult and important surgical procedures in bone drilling is maintaining as well as guiding the orientation of the drill with respect to the target. This paper proposes an improved RCM mechanism in which a pair of linear actuators and a gearless arc-guide are employed to achieve high rigidity and resolution, which enable bone drilling. A vision-guided navigation system is also integrated into the proposed system to automatically guide the orientation. To verify that the proposed RCM mechanism has sufficient rigidity and targeting accuracy, a series of experiments was performed. The results obtained confirm that the proposed mechanism can maintain its tilting angle under up to 50 N, with a targeting error of approximately 0.28mm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594069","Remote center of motion mechanism;surgical robotics;vision-guided navigation;bone drilling","Bones;Robots;Surgery;Actuators;Force;Computed tomography;Task analysis","actuators;bone;medical robotics;motion control;orthopaedics;robot vision;surgery","bone drilling robotic systems;drill alignment;RCM mechanism;remote center of motion mechanism;surgical procedures;linear actuators;gearless arc-guide;vision-guided navigation system;orientation guidance;trigonometric ratio","","","24","","","","","IEEE","IEEE Conferences"
"Jacquard: A Large Scale Dataset for Robotic Grasp Detection","A. Depierre; E. Dellandréa; L. Chen","Siléane, Saint-Etienne, France; LIRIS, University of Lyon, Ecole Centrale de Lyon, CNRS UMR 5205, France; LIRIS, University of Lyon, Ecole Centrale de Lyon, CNRS UMR 5205, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3511","3516","Grasping skill is a major ability that a wide number of real-life applications require for robotisation. State-of-the-art robotic grasping methods perform prediction of object grasp locations based on deep neural networks. However, such networks require huge amount of labeled data for training making this approach often impracticable in robotics. In this paper, we propose a method to generate a large scale synthetic dataset with ground truth, which we refer to as the Jacquard grasping dataset. Jacquard is built on a subset of ShapeNet, a large CAD models dataset, and contains both RGB-D images and annotations of successful grasping positions based on grasp attempts performed in a simulated environment. We carried out experiments using an off-the-shelf CNN, with three different evaluation metrics, including real grasping robot trials. The results show that Jacquard enables much better generalization skills than a human labeled dataset thanks to its diversity of objects and grasping positions. For the purpose of reproducible research in robotics, we are releasing along with the Jacquard dataset a web interface for researchers to evaluate the successfulness of their grasping position detections using our dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593950","","Solid modeling;Grippers;Robot kinematics;Grasping;Data models;Neural networks","belief networks;CAD;computer vision;grippers;image classification;image representation;learning (artificial intelligence);object recognition;robot vision;solid modelling","robotic grasp detection;grasping skill;real-life applications;state-of-the-art robotic;deep neural networks;robotics;scale synthetic dataset;ground truth;Jacquard grasping dataset;CAD models dataset;successful grasping positions;grasp attempts;grasping robot trials;generalization skills;Jacquard dataset;grasping position detections;human labeled dataset;CNN;RGB-D images;ShapeNet","","1","23","","","","","IEEE","IEEE Conferences"
"Predicting Objective Function Change in Pose-Graph Optimization","F. Bai; T. Vidal-Calleja; S. Huang; R. Xiong","Centre for Autonomous Systems (CAS), University of Technology Sydney, Australia; Centre for Autonomous Systems (CAS), University of Technology Sydney, Australia; Centre for Autonomous Systems (CAS), University of Technology Sydney, Australia; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","145","152","Robust online incremental SLAM applications require metrics to evaluate the impact of current measurements. Despite its prevalence in graph pruning, information-theoretic metrics solely are insufficient to detect outliers. The optimal value of the objective function is a better choice to detect outliers but cannot be computed unless the problem is solved. In this paper, we show how the objective function change can be predicted in an incremental pose-graph optimization scheme, without actually solving the problem. The predicted objective function change can be used to guide online decisions or detect outliers. Experiments validate the accuracy of the predicted objective function, and an application to outlier detection is also provided, showing its advantages over M-estimators.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594248","","Linear programming;Optimization;Simultaneous localization and mapping;Measurement errors;Noise measurement;Reliability","graph theory;optimisation;SLAM (robots)","outlier detection;robust online incremental SLAM applications;graph pruning;information-theoretic metrics;pose-graph optimization scheme","","","32","","","","","IEEE","IEEE Conferences"
"Fast Cylinder and Plane Extraction from Depth Cameras for Visual Odometry","P. F. Proença; Y. Gao","Faculty of Engineering and Physical Sciences, University of Surrey, Surrey Space Centre, Guildford, GU2 7XH, U.K.; Faculty of Engineering and Physical Sciences, University of Surrey, Surrey Space Centre, Guildford, GU2 7XH, U.K.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6813","6820","This paper presents CAPE, a method to extract planes and cylinder segments from organized point clouds, which processes 640 × 480 depth images on a single CPU core at an average of 300 Hz, by operating on a grid of planar cells. While, compared to state-of-the-art plane extraction, the latency of CAPE is more consistent and 4-10 times faster, depending on the scene, we also demonstrate empirically that applying CAPE to visual odometry can improve trajectory estimation on scenes made of cylindrical surfaces (e.g. tunnels), whereas using a plane extraction approach that is not curve-aware deteriorates performance on these scenes. To use these geometric primitives in visual odometry, we propose extending a probabilistic RGB-D odometry framework based on points, lines and planes to cylinder primitives. Following this framework, CAPE runs on fused depth maps and the parameters of cylinders are modelled probabilistically to account for uncertainty and weight accordingly the pose optimization residuals.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593516","","Histograms;Eigenvalues and eigenfunctions;Cameras;Image segmentation;Three-dimensional displays;Probabilistic logic;Principal component analysis","cameras;distance measurement;feature extraction;image colour analysis;image segmentation;pose estimation","cylinder and plane extraction;pose optimization residuals;probabilistic RGB-D odometry framework;curve-aware deteriorates performance;plane extraction approach;single CPU core;organized point clouds;cylinder segments;CAPE;visual odometry","","","23","","","","","IEEE","IEEE Conferences"
"Generating Adaptive Attending Behaviors using User State Classification and Deep Reinforcement Learning","Y. Kohari; J. Miura; S. Oishi","Department of Computer Science and Engineering, Toyohashi University of Technology; Department of Computer Science and Engineering, Toyohashi University of Technology; Department of Computer Science and Engineering, Toyohashi University of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","548","555","This paper describes a method of generating attending behaviors adaptively to the user state. The method classifies the user state based on user information such as the relative position and the orientation. For each classified state, the method executes the corresponding policy for behavior generation, which has been trained using a deep reinforcement learning, namely DDPG (deep deterministic policy gradient). We use as a state space of DDPG a distance-transformed local map with person information, and define reward functions suitable for respective user states. We conducted attending experiments both in a simulated and a real environment to show the effectiveness of the proposed method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594427","","Legged locomotion;Reinforcement learning;Two dimensional displays;Cameras;Acceleration;Robot sensing systems","behavioural sciences computing;gradient methods;learning (artificial intelligence);mobile robots;pattern classification","deep deterministic policy gradient;user state classification;deep reinforcement learning;user information;adaptive attending behavior generation;DDPG;mobile robots","","","37","","","","","IEEE","IEEE Conferences"
"SCALAR - Simultaneous Calibration of 2D Laser and Robot's Kinematic Parameters Using Three Planar Constraints","T. S. Lembono; F. Suárez-Ruiz; Q. Pham","Idiap Research Institute, Martigny, Switzerland; Nanyang Technological University, School of Mechanical and Aerospace Engineering, Singapore; Nanyang Technological University, School of Mechanical and Aerospace Engineering, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5570","5575","Industrial robots are increasingly used in various applications where the robot accuracy becomes very important, hence calibrations of the robot's kinematic parameters and the measurement system's extrinsic parameters are required. However, the existing calibration approaches are either too cumbersome or require another expensive external measurement system such as laser tracker or measurement spinarm. In this paper, we propose SCALAR, a calibration method to simultaneously improve the kinematic parameters of a 6-DoF robot and the extrinsic parameters of a 2D Laser Range Finder (LRF) that is attached to the robot. Three flat planes are placed around the robot, and for each plane the robot moves to several poses such that the LRF's ray intersect the respective plane. Geometric planar constraints are then used to optimize the calibration parameters using Levenberg-Marquardt nonlinear optimization algorithm. We demonstrate through simulations that SCALAR can reduce the average position and orientation errors of the robot system from 14.6 mm and 4.05° to 0.09 mm and 0.02°.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594073","","Robot kinematics;Calibration;Cameras;Measurement by laser beam;Kinematics;Robot vision systems","calibration;industrial robots;laser ranging;position control;robot kinematics","calibration approaches;calibration parameters;geometric planar constraints;2D Laser Range Finder;6-DoF robot;calibration method;laser tracker;expensive external measurement system;calibrations;robot accuracy;industrial robots;kinematic parameters;simultaneous calibration;SCALAR;robot system","","","16","","","","","IEEE","IEEE Conferences"
"A Robot System for Automated Wound Filling with Jetted Materials","B. H. Jafari; L. Namhyung; R. Thompson; J. Schellhorn; B. Antohe; N. Gans","Department of Electrical and Computer Engineering; Department of Electrical and Computer Engineering; Plano West High School, Plano, TX; Department of Mechanical Engineering, The University of Texas at Dallas, Richardson, TX, 75080, USA; Microfab Technologies Inc., Plano, TX; Department of Electrical and Computer Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1789","1794","Skin surface wounds due to burns, surgeries and chronic illness affect millions of people worldwide. Tissue engineering has become an increasingly popular treatment, but it is a highly manual process. Increasing the automation in tissue engineering could increase the rate of treatment for patients and improve outcomes. We present an initial investigation into an automated in-situ treatment. In our proposed method, a 3D machine vision system detects a skin wound to be treated and then determines the 3D point set corresponding to the wound. The 3D point set is then passed to path planning algorithm for a robot manipulator to move an ink-jet nozzle over the wound and fill the cavity with quick-curing/gelling fluids such collagen and other biomaterials and cell growth promoters. This paper details initial results and experimental validation of each of the proposed steps.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594252","","Wounds;Three-dimensional displays;Robot kinematics;Cameras;Machine vision;Manuals","computer vision;control engineering computing;diseases;medical robotics;nozzles;path planning;patient treatment;proteins;skin;surgery;tissue engineering;wounds","robot system;automated wound filling;jetted materials;skin surface wounds;chronic illness;tissue engineering;3D machine vision system;skin wound;3D point set;path planning algorithm;robot manipulator;ink-jet nozzle;biomaterials;cell growth promoters","","","18","","","","","IEEE","IEEE Conferences"
"Sensor Selection and Stage & Result Classifications for Automated Miniature Screwdriving","X. Cheng; Z. Jia; A. Bhatia; R. M. Aronson; M. T. Mason","Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6078","6085","Hundreds of billions of small screws are assembled in consumer electronics industry every year, yet reliably automating the screwdriving process remains one of the most challenging tasks. Two barriers to further adoption of robotic threaded fastening systems are system cost and technical challenges, especially for small screws. An affordable intelligent screwdriving system that can support online stage and result classification is the first step to bridge the gap. To this end, starting from a state transition graph of screwdriving processes and a labeled screwdriving dataset (1862 runs of M1.4 screws) on multiple sensor signals, we develop classification algorithms and perform sensor reduction. Fast and accurate result classifiers are developed using linear discriminant analysis, while a wrapper method for feature subset selection is used to identify the optimal feature subset and corresponding sensor signals to reduce cost. A stage classifier based on decision tree is developed using the optimal sensor subset. The stage classifier achieves high accuracy in realtime prediction of various stages when augmented with the state transition graph.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593520","","Robot sensing systems;Fasteners;Joining processes;Fault detection;Torque;Reliability","control engineering computing;decision trees;fasteners;industrial robots;pattern classification;production engineering computing;robotic assembly;sensors;support vector machines","technical challenges;affordable intelligent screwdriving system;online stage;result classification;state transition graph;labeled screwdriving dataset;multiple sensor signals;classification algorithms;sensor reduction;accurate result classifiers;linear discriminant analysis;feature subset selection;optimal feature subset;corresponding sensor signals;stage classifier;optimal sensor subset;sensor selection;stage & result classifications;automated miniature screwdriving;consumer electronics industry every year;screwdriving process;challenging tasks;robotic threaded fastening systems;system cost","","","23","","","","","IEEE","IEEE Conferences"
"Adaptive step rotation in biped walking","N. Bohórquez; P. Wieber","Inria, CNRS, Grenoble INP*, LJK, Univ. Grenoble Alpes, Grenoble, 38000, France; Inria, CNRS, Grenoble INP*, LJK, Univ. Grenoble Alpes, Grenoble, 38000, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","720","725","We want to enable the robot to reorient its feet in order to face its direction of motion. Model Predictive Control schemes for biped walking usually assume fixed feet rotation since adapting them online leads to a nonlinear problem. Nonlinear solvers do not guarantee the satisfaction of nonlinear constraints at every iterate and this can be problematic for the real-time operation of robots. We propose to define safe linear constraints that are always inside the intersection of the nonlinear constraints. We make simulations of the robot walking on a crowd and compare the performance of the proposed method with respect to the original nonlinear problem solved as a Sequential Quadratic Program.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594431","","Legged locomotion;Foot;Collision avoidance;Robot kinematics;Dynamics;Predictive control","legged locomotion;predictive control;quadratic programming","adaptive step rotation;biped walking;fixed feet rotation;nonlinear solvers;safe linear constraints;model predictive control schemes;robot walking;sequential quadratic program","","","25","","","","","IEEE","IEEE Conferences"
"Variations on a Theme: “It's a Poor Sort of Memory that Only Works Backwards”","F. Bálint-Benczédi; M. Beetz","University of Bremen, Artificial Intelligence; University of Bremen, Artificial Intelligence","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8390","8396","Adapting the perceptual capabilities of mobile robots to new objects or new environments can be a time consuming task. In this paper we focus on specializing perceptual capabilities of mobile robots to new objects through a knowledge based, virtual scene rendering approach. Episodic memories of a robotic agent, gathered during the execution of a task are considered to be the main ""theme"". Variations of this theme are then generated based on background knowledge about the objects and data gathered with the purpose of learning new models for detection and recognition. We demonstrate the applicability of our approach by adapting the perceptual capabilities of a mobile robot performing pick and place tasks, to recognize new sets of objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594001","","Task analysis;Games;Engines;Rendering (computer graphics);Mobile robots;Solid modeling","learning (artificial intelligence);mobile robots;rendering (computer graphics)","mobile robots;virtual scene rendering approach;episodic memories;robotic agent;knowledge based approach;model learning","","","22","","","","","IEEE","IEEE Conferences"
"Localization of an Acoustic Fish-Tag using the Time-of-Arrival Measurements: Preliminary results using eXogenous Kalman Filter","R. P. Jain; A. P. Aguiar; J. B. de Sousa; A. Zolich; T. A. Johansen; J. A. Alfredsen; E. Erstorp; J. Kuttenkeuler","Faculty of Electrical and Computer Engineering, University of Porto, Porto, 4200-465, Portugal; Faculty of Electrical and Computer Engineering, University of Porto, Porto, 4200-465, Portugal; Faculty of Electrical and Computer Engineering, University of Porto, Porto, 4200-465, Portugal; Department of Engineering Cybernetics, Norwegian University of Science and Technology, Center for Autonomous Marine Operations and Systems, Trondheim, 7491, Norway; Department of Engineering Cybernetics, Norwegian University of Science and Technology, Center for Autonomous Marine Operations and Systems, Trondheim, 7491, Norway; Department of Engineering Cybernetics, Norwegian University of Science and Technology, Center for Autonomous Marine Operations and Systems, Trondheim, 7491, Norway; Aeronautical and Vehicle Engineering, KTH Royal Institute of Technology, School of Engineering Sciences, Stockholm, Sweden; Aeronautical and Vehicle Engineering, KTH Royal Institute of Technology, School of Engineering Sciences, Stockholm, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1695","1702","This paper addresses the source localization problem of an acoustic fish-tag using the Time-of-Arrival measurement of an acoustic signal, transmitted by the fish-tag. The Time-of-Arrival measurements denote the pseudo-range information between the acoustic receiver and the fish-tag, except that the Time-of-Transmission of the acoustic signal is unknown. Starting with the pseudo-range measurement equation, a globally valid quasi-linear time-varying measurement model is presented that is independent of the Time-of-Transmission of the acoustic signal. Using this measurement model, an Uniformly Globally Asymptotically Stable (UGAS), three stage estimation strategy (eXogenous Kalman Filter) is designed to estimate the position of an acoustic fish-tag and evaluated against a benchmark Extended Kalman Filter based estimator. The efficacy of the developed estimation method is demonstrated experimentally, in presence of intermittent observations using an array of receivers mounted on three Unmanned Surface Vessels (USVs).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593659","","Acoustics;Mathematical model;Receivers;Acoustic measurements;Kalman filters;Estimation;Measurement uncertainty","Kalman filters;remotely operated vehicles;time-varying systems","time-of-arrival measurement;eXogenous Kalman filter;three stage estimation strategy;time-of-transmission;acoustic fish-tag localization;uniformly globally asymptotically stable;UGAS;unmanned surface vessels;Kalman Filter based estimator;quasilinear time-varying measurement model;pseudorange measurement equation;acoustic receiver;acoustic signal;source localization problem","","","21","","","","","IEEE","IEEE Conferences"
"Deep Neural Object Analysis by Interactive Auditory Exploration with a Humanoid Robot","M. Eppe; M. Kerzel; E. Strahl; S. Wermter","Knowledge Technology, Department of Informatics, University of Hamburg, Germany; Knowledge Technology, Department of Informatics, University of Hamburg, Germany; Knowledge Technology, Department of Informatics, University of Hamburg, Germany; Knowledge Technology, Department of Informatics, University of Hamburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","284","289","We present a novel approach for interactive auditory object analysis with a humanoid robot. The robot elicits sensory information by physically shaking visually indistinguishable plastic capsules. It gathers the resulting audio signals from microphones that are embedded into the robotic ears. A neural network architecture learns from these signals to analyze properties of the contents of the containers. Specifically, we evaluate the material classification and weight prediction accuracy and demonstrate that the framework is fairly robust to acoustic real-world noise.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593838","","Robot sensing systems;Humanoid robots;Robot kinematics;Mel frequency cepstral coefficient;Microsoft Windows;Plastics","audio signal processing;humanoid robots;neural net architecture;signal classification;signal denoising","deep neural object analysis;interactive auditory exploration;humanoid robot;interactive auditory object analysis;robot elicits sensory information;robotic ears;neural network architecture;audio signals;microphone;material classification;weight prediction","","","24","","","","","IEEE","IEEE Conferences"
"Gaussian Process Dynamic Programming for Optimizing Ungrounded Haptic Guidance","J. M. Walker; A. M. Okamura; M. J. Kochenderfer","Department of Mechanical Engineering, Stanford University, Stanford, CA, 94305, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, 94305, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, 94305, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8758","8764","Adapting robot actions to human motions can make human-robot interactions (HRI) more effective. Here, we aim to optimize guidance from haptic devices based on a user's response to produce better task performance. We used Gaussian processes to model the motions a human user made in response to applied torques from an ungrounded control moment gyroscope haptic device. We then used Gaussian process dynamic programming to generate optimized haptic cues to guide the user to rotate the device toward 3D targets. We compared the performance of naive and optimized policies in simulations and with a human user, and found that dynamic programming can significantly improve haptic guidance in cases where human responses are highly variable or inconsistent with the cued haptic direction.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594395","","Haptic interfaces;Torque;Brushless motors;Quaternions;Task analysis;Gaussian processes;Robots","dynamic programming;Gaussian processes;gyroscopes;haptic interfaces;human-robot interaction","Gaussian process dynamic programming;ungrounded haptic guidance;human-robot interactions;haptic devices;ungrounded control moment gyroscope haptic device;cued haptic direction","","","33","","","","","IEEE","IEEE Conferences"
"Decentralised Mission Monitoring with Spatiotemporal Optimal Stopping","G. Best; S. Huang; R. Fitch","Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Centre for Autonomous Systems (CAS), University of Technology Sydney, Sydney, Australia; Centre for Autonomous Systems (CAS), University of Technology Sydney, Sydney, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4810","4817","We consider a multi-robot variant of the mission monitoring problem. This problem arises in tasks where a robot observes the progress of another robot that is stochastically following a known trajectory, among other applications. We formulate and solve a variant where multiple tracker robots must monitor a single target robot, which is important because it enables the use of multi-robot systems to improve task performance in practice, such as in marine robotics missions. Our algorithm coordinates the behaviour of the trackers by computing optimal single-robot paths given a probabilistic representation of the other robots' paths. We employ a decentralised scheme that optimises over probability distributions of plans and has useful analytical properties. The planned trajectories collectively maximise the probability of observing the target throughout the mission with respect to probabilistic motion and observation models. We report simulation results for up to 8 robots that support our analysis and indicate that our algorithm is a feasible solution for improving the performance of mission monitoring systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593663","","Monitoring;Trajectory;Target tracking;Robot kinematics;Probabilistic logic;Predictive models","mobile robots;multi-robot systems;optimisation;path planning;probability","decentralised mission monitoring;spatiotemporal optimal stopping;multirobot variant;mission monitoring problem;multiple tracker robots;single target robot;multirobot systems;task performance;marine robotics missions;single-robot paths;probabilistic representation;decentralised scheme;useful analytical properties;planned trajectories;probabilistic motion;observation models;mission monitoring systems","","","24","","","","","IEEE","IEEE Conferences"
"Towards a Context Enhanced Framework for Multi Object Tracking in Human Robot Collaboration","S. C. Akkaladevi; M. Plasch; C. Eitzinger; A. Pichler; B. Rinner","GmbH, Steyr–Gleink, Im Stadtgut A2, 4407, Austria; GmbH, Steyr–Gleink, Im Stadtgut A2, 4407, Austria; GmbH, Steyr–Gleink, Im Stadtgut A2, 4407, Austria; GmbH, Steyr–Gleink, Im Stadtgut A2, 4407, Austria; Alpen-Adria-Universität Klagenfurt, Institute of Networked and Embedded Systems, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","168","173","In a goal-oriented Human Robot Collaborative (HRC) scenario, where the goal is to complete an assembly process, a robust object tracker might not necessarily fulfill its functional role due to the dynamic nature of HRC. Moreover, for an efficient HRC, the functional role of the object tacker should not only be limited to localizing and tracking objects for robotic manipulation. It should also help to determine the current state of the assembly process and verify if the chosen action has been successfully performed and thus to enable an uninterrupted completion of an HRC assembly process. We present a Context Enhanced Framework for Multi Object Tracking, that i) allows uninterrupted completion of an assembly process, ii) improves the overall functional accuracy of the object tracker from 49 percent to 96 percent, and iii) enables the object tracker to handle multiple instance of multiple objects in a HRC setting.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593842","","Robot kinematics;Cognition;Task analysis;Object tracking;Three-dimensional displays","human-robot interaction;manipulators;object detection;object tracking;robot vision","uninterrupted completion;functional accuracy;multiple objects;HRC setting;robust object tracker;functional role;object tacker;robotic manipulation;HRC assembly process;multiobject tracking;goal-oriented human robot collaborative scenario;context enhanced framework","","","27","","","","","IEEE","IEEE Conferences"
"Motion Generators Combined with Behavior Trees: A Novel Approach to Skill Modelling","F. Rovida; D. Wuthier; B. Grossmann; M. Fumagalli; V. Krüger","The Robotics Vision, and Machine Intelligence (RVMI)Lab at Aalborg University Copenhagen, Copenhagen, 2450, Denmark; The Robotics Vision, and Machine Intelligence (RVMI)Lab at Aalborg University Copenhagen, Copenhagen, 2450, Denmark; The Robotics Vision, and Machine Intelligence (RVMI)Lab at Aalborg University Copenhagen, Copenhagen, 2450, Denmark; The Robotics Vision, and Machine Intelligence (RVMI)Lab at Aalborg University Copenhagen, Copenhagen, 2450, Denmark; The Robotics Vision, and Machine Intelligence (RVMI)Lab at Aalborg University Copenhagen, Copenhagen, 2450, Denmark","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5964","5971","Task level programming based on skills has often been proposed as a mean to decrease programming complexity of industrial robots. Several models are based on encapsulating complex motions into self-contained primitive blocks. A semantic skill is then defined as a deterministic sequence of these primitives. A major limitation is that existing frameworks do not support the coordination of concurrent motion primitives with possible interference. This decreases their reusability and scalability in unstructured environments where a dynamic and reactive adaptation of motions is often required. This paper presents a novel framework that generates adaptive behaviors by modeling skills as concurrent motion primitives activated dynamically when conditions trigger. The approach exploits the additive property of motion generators to superpose multiple contributions. We demonstrate the applicability on a real assembly use-case and discuss the gained benefits.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594319","industrial robots;skills;reactive system;behavior tress;motio generators;assembly","Task analysis;Generators;Robot kinematics;Force;Planning;Grippers","control engineering computing;industrial robots;motion control;robot programming;trees (mathematics)","programming complexity;industrial robots;complex motions;self-contained primitive blocks;semantic skill;concurrent motion primitives;modeling skills;motion generators;behavior trees;task level programming","","","23","","","","","IEEE","IEEE Conferences"
"Efficient Distributed Torque Computation for Large Scale Robot Skin","F. Bergner; E. Dean-Leon; G. Cheng","Institute for Cognitive Systems, Technische Universität München, Munich, Germany; Institute for Cognitive Systems, Technische Universität München, Munich, Germany; Institute for Cognitive Systems, Technische Universität München, Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1593","1599","The realization of a kinesthetic robot behavior using robot skin requires a reactive skin torque controller, which fuses skin information and robot information to an appropriate skin joint torque in real-time. This fusion of information in real-time is challenging when deploying large scale skin. In this paper, we present a system which efficiently computes the torque of distributed skin cells locally at the point of contacts, completely removing this complex computations from the real-time loop. We demonstrate the feasibility of realizing the skin joint torque computations on the local micro-controllers of the skin cells. Conducting experiments with a real robot, we compare the accuracy of the distributed skin joint torque computation with the computation on the control PC. We also show that the novel distributed approach completely eliminates the computational delay of computing skin joint torques in the robot's real-time control loop. As a result, this approach removes any limits for the maximum number of skin cells in control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594144","","Skin;Torque;Robot sensing systems;Real-time systems;Robot kinematics","computational complexity;control engineering computing;mobile robots;real-time systems;sensor fusion;skin;tactile sensors;torque control","skin information;reactive skin torque controller;kinesthetic robot behavior;scale robot skin;efficient distributed torque computation;real-time control loop;skin joint torques;computational delay;control PC;distributed skin joint torque computation;local microcontrollers;skin joint torque computations;real-time loop;complex computations;distributed skin cells;scale skin;appropriate skin joint torque","","","24","","","","","IEEE","IEEE Conferences"
"History-Aware Autonomous Exploration in Confined Environments Using MAVs","C. Witting; M. Fehr; R. Bähnemann; H. Oleynikova; R. Siegwart","Technical University of Denmark, Master student at the Faculty of Electrical Engineering, Lyngby, Denmark; ETH Zürich, Autonomous Systems Lab (ASL), Zürich, Switzerland; ETH Zürich, Autonomous Systems Lab (ASL), Zürich, Switzerland; ETH Zürich, Autonomous Systems Lab (ASL), Zürich, Switzerland; ETH Zürich, Autonomous Systems Lab (ASL), Zürich, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 × faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 × faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594502","","Planning;Robot sensing systems;Three-dimensional displays;Trajectory;History;Optimization","attitude control;autonomous aerial vehicles;mobile robots;path planning","sampling-based exploration algorithms;3D exploration planner;field-of-view depth sensor;configuration space;high sampling efficiency;computational constrained real world MAV;history-aware autonomous exploration;confined environments;inspection tasks;high-dimensional path planning problem;microaerial vehicle;search and rescue missions;next-best views;robot orientation","","1","33","","","","","IEEE","IEEE Conferences"
"3D Deep Object Recognition and Semantic Understanding for Visually-Guided Robotic Service","S. Lee; A. M. Naguib; N. U. Islam","Intelligent Systems Research Institute, School of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea; Intelligent Systems Research Institute, School of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea; Intelligent Systems Research Institute, School of Information and Communication Engineering, Sungkyunkwan University, Suwon, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","903","910","For the success of visually-guided robotic errand service, it is critical to ensure dependability under various ill-conditioned visual environments. To this end, we have developed Adaptive Bayesian Recognition Framework in which in-situ selection of multiple sets of optimal features or evidences as well as proactive collection of sufficient evidences are proposed to implement the principle of dependability. The framework has shown excellent performance with a limited number of objects in a scene. However, there arises a need to extend the framework for handling a larger number of objects without performance degradation, while avoiding difficulty in feature engineering. To this end, a novel deep learning architecture, referred to here as FER-CNN, is introduced and integrated into the Adaptive Bayesian Recognition Framework. FER-CNN has capability of not only extracting but also reconstructing a hierarchy of features with the layer-wise independent feedback connections that can be trained. Reconstructed features representing parts of 3D objects then allow them to be semantically linked to ontology for exploring object categories and properties. Experiments are conducted in a home environment with real 3D daily-life objects as well as with the standard ModelNet dataset. In particular, it is shown that FER-CNN allows the number of objects and their categories to be extended by 10 and 5 times, respectively, while registering the recognition rate for ModelNet10 and ModelNet40 by 97% and 89.5%, respectively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593985","","Three-dimensional displays;Bayes methods;Robots;Object recognition;Deep learning;Feature extraction;Two dimensional displays","Bayes methods;convolutional neural nets;feature extraction;image reconstruction;learning (artificial intelligence);neurocontrollers;object recognition;ontologies (artificial intelligence);robot vision;service robots","semantic understanding;visually-guided robotic service;visually-guided robotic errand service;visual environments;deep learning architecture;FER-CNN;layer-wise independent feedback connections;reconstructed features;object categories;3D daily-life objects;recognition rate;ontology;feature extraction;3D deep object recognition;adaptive Bayesian recognition framework","","1","33","","","","","IEEE","IEEE Conferences"
"A Framework for Modeling Closed Kinematic Chains with a Focus on Legged Robots","V. R. Kamidi; A. Williams; P. Ben–Tzvi","Robotics and Mechatronics Lab at Virginia Tech, Blacksburg, VA, USA; Robotics and Mechatronics Lab at Virginia Tech, Blacksburg, VA, USA; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2733","2738","This paper presents the foundations of a MATLAB framework for dynamic modeling and simulation of closed kinematic chain (CKC) mechanisms, with a particular focus on implementation with legged locomotive mechanisms. As such, the framework supports both floating-base and fixed-base systems. Through the use of singular perturbation theory, various CKC mechanisms can be modeled so that constraint errors asymptotically converge to zero, thus avoiding the numerical drift that plagues commonly used methods. A functional API and the relevant core commands necessary to construct a model are presented. Two robotic legs incorporating CKC mechanisms are utilized as case studies, and simulations of each leg performing a dynamic monopedal gait are illustrated.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593909","","Mathematical model;Legged locomotion;Kinematics;Software;Computational modeling;Couplings","legged locomotion;robot kinematics;singularly perturbed systems","legged robots;MATLAB framework;dynamic modeling simulation;legged locomotive mechanisms;fixed-base systems;singular perturbation theory;CKC mechanisms;dynamic monopedal gait;closed kinematic chains;floating-base systems;functional API","","","19","","","","","IEEE","IEEE Conferences"
"LDSO: Direct Sparse Odometry with Loop Closure","X. Gao; R. Wang; N. Demmel; D. Cremers","Department of Informatics, Technical University of Munich, Computer Vision Group, Germany; Department of Informatics, Technical University of Munich, Computer Vision Group, Germany; Department of Informatics, Technical University of Munich, Computer Vision Group, Germany; Department of Informatics, Technical University of Munich, Computer Vision Group, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2198","2204","In this paper we present an extension of Direct Sparse Odometry (DSO) [1] to a monocular visual SLAM system with loop closure detection and pose-graph optimization (LDSO). As a direct technique, DSO can utilize any image pixel with sufficient intensity gradient, which makes it robust even in featureless areas. LDSO retains this robustness, while at the same time ensuring repeatability of some of these points by favoring corner features in the tracking frontend. This repeatability allows to reliably detect loop closure candidates with a conventional feature-based bag-of-words (BoW) approach. Loop closure candidates are verified geometrically and Sim(3) relative pose constraints are estimated by jointly minimizing 2D and 3D geometric error terms. These constraints are fused with a co-visibility graph of relative poses extracted from DSO's sliding window optimization. Our evaluation on publicly available datasets demonstrates that the modified point selection strategy retains the tracking accuracy and robustness, and the integrated pose-graph optimization significantly reduces the accumulated rotation-, translation- and scale-drift, resulting in an overall performance comparable to state-of-the-art feature-based systems, even without global bundle adjustment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593376","","Optimization;Feature extraction;Microsoft Windows;Simultaneous localization and mapping;Cameras;Bundle adjustment;Robustness","feature extraction;graph theory;mobile robots;optimisation;pose estimation;robot vision;SLAM (robots)","intensity gradient;DSO sliding window optimization;Sim(3) relative pose constraints;image pixel;loop closure detection;monocular visual SLAM system;Direct Sparse Odometry;state-of-the-art feature-based systems;pose-graph optimization;modified point selection strategy;relative poses;co-visibility graph;3D geometric error terms;conventional feature-based bag-of-words approach;loop closure candidates;tracking frontend;corner features;LDSO;featureless areas","","","27","","","","","IEEE","IEEE Conferences"
"Plugo: A Scalable Visible Light Communication System Towards Low-Cost Indoor Localization","Q. Liang; L. Wang; Y. Li; M. Liu","Department of ECE, Hong Kong University of Science and Technology; Chinese Academy of Sciences, Center for Cloud Computing, Shenzhen Institutes of Advanced Technology; Department of MBE, City University of Hong Kong; Department of ECE, Hong Kong University of Science and Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3709","3714","Indoor localization is critical to many location-aware applications, however, a low-cost solution with guaranteed accuracies has not yet come. Visible Light Communication (VLC-) based localization techniques are very promising to fill this gap. In this paper, we propose Plugo, a novel VLC system with random multiple access towards low-cost indoor localization. Compared to conventional RF-based approaches that rely on dedicated wireless access points as location beacons, the proposed system has the potential to deliver better accuracies with reduced cost. Specifically, we build a handful of compact VLC-compatible LED bulbs out of low-cost offthe-shelf components (around $10 total cost for each assembly) and recover VLC signals using a cheap photodiode receiver. The basic framed slotted Additive Links On-line Hawaii Area (ALOHA) is exploited to achieve random multiple access over the shared optical medium. We show its effectiveness in beacon broadcasting by experiments, and further, demonstrate a preliminary localization result with sound accuracy by using fingerprinting-based methods in a customized testbed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594287","","Light emitting diodes;Receivers;Wireless communication;Optical transmitters;Encoding;Frequency modulation","free-space optical communication;indoor communication;photodiodes","Plugo;novel VLC system;cheap photodiode receiver;VLC-based localization techniques;location-aware applications;scalable visible light communication system;preliminary localization result;VLC signals;low-cost offthe-shelf components;compact VLC-compatible;dedicated wireless access points;conventional RF-based approaches;low-cost indoor localization;random multiple access","","","20","","","","","IEEE","IEEE Conferences"
"Manipulation Planning Under Changing External Forces","L. Chen; L. F. C. Figueredo; M. Dogar","University of Leeds, School of Computing, Leeds, UK; University of Leeds, School of Computing, Leeds, UK; University of Leeds, School of Computing, Leeds, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3503","3510","We present a manipulation planning algorithm for a robot to keep an object stable under changing external forces. We particularly focus on the case where a human may be applying forceful operations, e.g. cutting or drilling, on an object that the robot is holding. The planner produces an efficient plan by intelligently deciding when the robot should change its grasp on the object as the human applies the forces. The planner also tries to choose subsequent grasps such that they will minimize the number of regrasps that will be required in the long-term. Furthermore, as it switches from one grasp to the other, the planner solves the problem of bimanual regrasp planning, where the object is not placed on a support surface, but instead it is held by a single gripper until the second gripper moves to a new position on the object. This requires the planner to also reason about the stability of the object under gravity. We provide an implementation on a bimanual robot and present experiments to show the performance of our planner.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593555","","Planning;Grippers;Manifolds;Manipulators;Task analysis;Robot kinematics","grippers;path planning;position control;stability","bimanual regrasp planning;bimanual robot;external forces;manipulation planning algorithm;forceful operations;subsequent grasps;single gripper;stability","","1","26","","","","","IEEE","IEEE Conferences"
"Adaptive Path Following of Snake Robot on Ground with Unknown and Varied Friction Coefficients","G. Wang; W. Yang; Y. Shen; H. Shao","Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, 89557, USA; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, 89557, USA; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, 89557, USA; University of Jinan, School of Mechanical Engineering, Jinan, 250022, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7583","7588","This paper investigates the straight path following problem for a class of underactuated bio-inspired snake robots on ground with unknown and varied friction coefficients. Existing works usually design control input requiring the exact values of these friction coefficients, which however rely on the specific operating terrain and may not always be known a priori. By virtue of backstepping technique, we present a novel adaptive controller that can compensate for unknown and varied friction coefficients in real-time. Moreover, it is proved via LaSalle-Yoshizawa theorem that the path following errors converge to zero asymptotically and all the parameter estimates are bounded. Simulations and experiments on an 8-link snake robot are carried out to illustrate the effectiveness of the proposed controller.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594466","","Snake robots;Friction;Tuning;Backstepping;Adaptation models;Stability analysis","adaptive control;control nonlinearities;control system synthesis;friction;mobile robots;motion control;parameter estimation","varied friction coefficients;underactuated bio-inspired snake robots;adaptive controller;8-link snake robot;adaptive path following;backstepping technique;parameter estimation;control design input;LaSalle-Yoshizawa theorem","","","15","","","","","IEEE","IEEE Conferences"
"Multi-Limbed Robot Vertical Two Wall Climbing Based on Static Indeterminacy Modeling and Feasibility Region Analysis","X. Lin; H. Krishnan; Y. Su; D. W. Hong","Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA, 90024; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA, 90024; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA, 90024; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA, 90024","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4355","4362","This paper presents a technique to model statically indeterminate forces based on stiffness matrices for multi-limbed climbing robots. Current wall climbing robots in literature overlook statically indeterminate forces, causing an incapability to estimate climbing failure under certain circumstances. Accounting for these forces, robot deformation can be approximated, paving the way for the proposed two-wall climbing approach. During a wall climb, two failure modes, slide and over-torque, are identified to compute feasible climbing region. A hexapod robot is used to verify the proposed technique by climbing between walls with pure friction end effectors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593734","","Strain;Mathematical model;Friction;Force;Robot kinematics;Manipulators","end effectors;friction;legged locomotion","climbing region;feasibility region analysis;multilimbed climbing robots;slide failure mode;over-torque failure mode;pure friction end effectors;walls;hexapod robot;robot deformation;climbing failure;robots;stiffness matrices;statically indeterminate forces;static indeterminacy modeling;multilimbed robot vertical two wall climbing","","","23","","","","","IEEE","IEEE Conferences"
"Fast Trajectory Planning for Automated Vehicles Using Gradient-Based Nonlinear Model Predictive Control","F. Gritschneder; K. Graichen; K. Dietmayer","Control and Microtechnology, Ulm University, Institute of Measurement, Ulm, 89081, Germany; Control and Microtechnology, Ulm University, Institute of Measurement, Ulm, 89081, Germany; Control and Microtechnology, Ulm University, Institute of Measurement, Ulm, 89081, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7369","7374","Motion trajectory planning is one crucial aspect for automated vehicles, as it governs the own future behavior in a dynamically changing environment. A good utilization of a vehicle's characteristics requires the consideration of the nonlinear system dynamics within the optimization problem to be solved. In particular, real-time feasibility is essential for automated driving, in order to account for the fast changing surrounding, e.g. for moving objects. The key contributions of this paper are the presentation of a fast optimization algorithm for trajectory planning including the nonlinear system model. Further, a new concurrent operation scheme for two optimization algorithms is derived and investigated. The proposed algorithm operates in the submillisecond range on a standard PC. As an exemplary scenario, the task of driving along a challenging reference course is demonstrated.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593913","","Mathematical model;Planning;Vehicle dynamics;Trajectory;Optimization;Task analysis;Heuristic algorithms","gradient methods;mobile robots;nonlinear control systems;optimisation;path planning;predictive control;road vehicles","automated vehicles;motion trajectory planning;dynamically changing environment;nonlinear system dynamics;automated driving;nonlinear system model;optimization algorithms;gradient-based nonlinear model predictive control;standard PC","","","14","","","","","IEEE","IEEE Conferences"
"Real-Time Clustering and Multi-Target Tracking Using Event-Based Sensors","F. Barranco; C. Fermuller; E. Ros","Univ. of Granada, Dept. of Comp. Arch. and Tech., Spain; UMIACS, University of Maryland, Dept. of Computer Science, College Park, MD, USA; Univ. of Granada, Dept. of Comp. Arch. and Tech., Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5764","5769","Clustering is crucial for many computer vision applications such as robust tracking, object detection and segmentation. This work presents a real-time clustering technique that takes advantage of the unique properties of event-based vision sensors. Since event-based sensors trigger events only when the intensity changes, the data is sparse, with low redundancy. Thus, our approach redefines the well-known mean-shift clustering method using asynchronous events instead of conventional frames. The potential of our approach is demonstrated in a multi-target tracking application using Kalman filters to smooth the trajectories. We evaluated our method on an existing dataset with patterns of different shapes and speeds, and a new dataset that we collected. The sensor was attached to the Baxter robot in an eye-in-hand setup monitoring real-world objects in an action manipulation task. Clustering accuracy achieved an F-measure of 0.95, reducing the computational cost by 88% compared to the frame-based method. The average error for tracking was 2.5 pixels and the clustering achieved a consistent number of clusters along time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593380","","Sensors;Shape;Real-time systems;Kalman filters;Target tracking;Robots","computer vision;image segmentation;image sensors;Kalman filters;object detection;pattern clustering;target tracking","event-based sensors;computer vision applications;robust tracking;object detection;segmentation;real-time clustering technique;event-based vision sensors;mean-shift clustering method;asynchronous events;multitarget tracking application;clustering accuracy;frame-based method","","","21","","","","","IEEE","IEEE Conferences"
"Interactive Robotic Manipulation of Elastic Objects","S. Duenser; J. M. Bern; R. Poranne; S. Coros","Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3476","3481","In this paper, we address the challenge of robotic manipulation of elastically deforming objects. To this end, we model elastic objects using the Finite Element Method. Through a quasi-static assumption, we leverage sensitivity analysis to mathematically model how changes in the robot's configuration affect the deformed shape of the object being manipulated. This enables an interactive, simulation-based control methodology, wherein user-specified deformations for the elastic objects are automatically mapped to joint angle commands. The optimization formulation we introduce is general, operates directly within a robot's workspace and can readily incorporate joint limits as well as collision avoidance between the links. We validate our control methodology on a YuMi® IRB 14000, which we use to manipulate a variety of elastic objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594291","","Robots;Computational modeling;Shape;Collision avoidance;Mathematical model;Strain;Finite element analysis","collision avoidance;elastic deformation;finite element analysis;force control;manipulators;robot kinematics;sensitivity analysis;simulation","interactive simulation-based control methodology;interactive robotic manipulation;finite element method;sensitivity analysis;mathematical model;robots configuration;collision avoidance;elastic deformation objects;quasistatic assumption","","","15","","","","","IEEE","IEEE Conferences"
"Active Disturbance Rejection Control of a Flying-Wing Tailsitter in Hover Flight","Y. Yang; J. Zhu; X. Zhang; X. Wang","Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, 100084, China; Department of Automation, Tsinghua University, Beijing, 100084, China; Department of Automation, Tsinghua University, Beijing, 100084, China; Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, 100084, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6390","6396","This paper presents the development and hovering control of a tailsitter unmanned aerial vehicle (UAV) that merges long endurance and vertical takeoff and landing (VTOL) abilities. The designed tailsitter contains one flying-wing with two motors and two elevons. Vehicle aerodynamics and a six-degrees-of-freedom (6-DOF) model are especially developed for the tailsitter. To achieve a good performance in outdoor stationary hovering and accurate vertical flying, the active disturbance rejection control (ADRC) for attitude controller is proposed. With signals from extended state observer (ESO) and tracking differentiator (TD), ADRC decouples the system model into a controllable chain of integrators. Based on the decoupled system dynamics, the motion of tailsitter can be easily handled by developed position controller. Experimental results are presented to corroborate the effectiveness of the controller in disturbance rejection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594470","","Propellers;Aerodynamics;Attitude control;Aircraft;Earth;Unmanned aerial vehicles;Gravity","active disturbance rejection control;aerodynamics;aerospace components;aircraft control;attitude control;autonomous aerial vehicles;control system synthesis;helicopters;motion control;observers;position control","active disturbance rejection control;flying-wing tailsitter;hover flight;tailsitter unmanned aerial vehicle;vehicle aerodynamics;accurate vertical flying;attitude controller;tracking differentiator;vertical takeoff and landing;tailsitter design;position controller;VTOL;six-degrees-of-freedom model;6-DOF model;outdoor stationary hovering;ADRC;extended state observer;ESO;TD","","","18","","","","","IEEE","IEEE Conferences"
"A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *","G. I. Parisi; P. Barros; D. Fu; S. Magg; H. Wu; X. Liu; S. Wermter","Knowledge Technology, Department of Informatics, Universität Hamburg, Germany; Knowledge Technology, Department of Informatics, Universität Hamburg, Germany; Knowledge Technology, Department of Informatics, Universität Hamburg, Germany; Knowledge Technology, Department of Informatics, Universität Hamburg, Germany; CAS Key Laboratory of Behavioral Science, Chinese Academy of Sciences (CAS), Beijing, China; CAS Key Laboratory of Behavioral Science, Chinese Academy of Sciences (CAS), Beijing, China; Knowledge Technology, Department of Informatics, Universität Hamburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2330","2335","Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594036","","Avatars;Visualization;Robot sensing systems;Lips;Task analysis;Spatial resolution","audio signal processing;audio-visual systems;avatars;humanoid robots;learning (artificial intelligence);motion control","crossmodal conflict resolution;robot sensorimotor coupling;swift behaviour;robust behaviour;neurorobotic experiment;iCub robot exhibits;complex crossmodal environment;multisensory conflicts;behavioural study;audio-visual cues;visual bias;discrete behavioural response;complex environments;incongruent dynamic audio-visual cues;human-like responses;environmental statistics;stereophonic sound processing;facial features;body motion;deep learning model;animated avatars","","","20","","","","","IEEE","IEEE Conferences"
"MMAC Height Control System of a Quadrotor for Constant Unknown Load Transportation","P. Outeiro; C. Cardeira; P. Oliveira","IDMEC Universidade de Lisboa, Instituto Superior Tesbco, Portugal; IDMEC Universidade de Lisboa, Instituto Superior Tesbco, Portugal; IDMEC Universidade de Lisboa, Instituto Superior Tesbco, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4192","4197","This paper presents a methodology for height control of a quadrotor that transports a constant unknown load, given the estimates on both weight and state variables, based on measurements from motion sensors installed on-board. The proposed control and estimation framework is a Multi-Model Adaptive Controller using LQR with integrative action and Kalman filter with integrative component. The control system obtained is validated both in simulation and experimentally, resorting to an off-the-shelf commercially available quadrotor equipped with an IMU, an ultrasound height sensor, and a barometer, among other sensors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594215","","Gravity;Estimation;Sensors;Kalman filters;Computational modeling;Control systems;Transportation","adaptive control;control system synthesis;helicopters;Kalman filters;linear quadratic control;motion sensors","quadrotor;multimodel adaptive controller;LQR;IMU;motion sensors;state variables;constant unknown load transportation;MMAC height control system;ultrasound height sensor;Kalman filter","","","8","","","","","IEEE","IEEE Conferences"
"Adaptive Task Planner for Performing Home Service Tasks in Cooperation with a Human","S. Lee; J. Park; D. Kim; J. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, 34141, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, 34141, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, 34141, Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, 34141, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2857","2864","To perform a home service task through cooperation with a human in a real environment, a robot needs to deal with the environmental changes and accordingly plan appropriate behavior sequence. For this purpose, in this paper, we propose an adaptive task planner which is based on memory and reasoning. A robot perceives user behaviors and objects using an RGB-depth and thermal sensor. The robot stores a temporal sequence of behaviors for performing a task in its episodic memory that is realized by a sequence to sequence network. When the user command is given, the episodic memory is used to retrieve the behavior sequence to carry out the command. On the other hand, when the robot perceives user behaviors, the robot postpones its behavior till his/her behavior is stopped. Once stopped, the episodic memory retrieves the behavior sequence to conduct a task that the user has intended. A task scheduler schedules the behavior sequence from the memory and sends it to an internal simulator. The internal simulator confirms the behavior sequence to be executable and then if executable, it sends the next executable behavior to the execution module. If a behavior fails in the internal simulation test, fast forward planner generates an alternative behavior sequence to resolve the failed behavior problem. The effectiveness and applicability of the proposed planner is demonstrated by a wheel-based humanoid robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594040","","Task analysis;Robot sensing systems;Robot kinematics;Planning;Generators;Thermal sensors","humanoid robots;human-robot interaction;image colour analysis;image sensors;path planning;robot vision","sequence network;episodic memory;user behaviors;task scheduler schedules;executable behavior;alternative behavior sequence;failed behavior problem;wheel-based humanoid robot;adaptive task planner;home service task;temporal sequence;fast forward planner;sequence to sequence network","","","28","","","","","IEEE","IEEE Conferences"
"The Earth Ain't Flat: Monocular Reconstruction of Vehicles on Steep and Graded Roads from a Moving Camera","J. A. Ansari; S. Sharma; A. Majumdar; J. K. Murthy; K. M. Krishna","KCIS, IIIT, Robotics Research Center, Hyderabad, India; Universite de Montreal, Ontreal Institute of Learning Algorithms (MILA), Canada; KCIS, IIIT, Robotics Research Center, Hyderabad, India; Universite de Montreal, Ontreal Institute of Learning Algorithms (MILA), Canada; KCIS, IIIT, Robotics Research Center, Hyderabad, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8404","8410","Accurate localization of other traffic participants is a vital task in autonomous driving systems. State-of-the-art systems employ a combination of sensing modalities such as RGB cameras and LiDARs for localizing traffic participants, but monocular localization demonstrations have been confined to plain roads. We demonstrate - to the best of our knowledge - the first results for monocular object localization and shape estimation on surfaces that are non-coplanar with the moving ego vehicle mounted with a monocular camera. We approximate road surfaces by local planar patches and use semantic cues from vehicles in the scene to initialize a local bundle-adjustment like procedure that simultaneously estimates the 3D pose and shape of the vehicles, and the orientation of the local ground plane on which the vehicle stands. We also demonstrate that our approach transfers from synthetic to real data, without any hyperparameter-/fine-tuning. We evaluate the proposed approach on the KITTI and SYNTHIA-SF benchmarks, for a variety of road plane configurations. The proposed approach significantly improves the state-of-the-art for monocular object localization on arbitrarily-shaped roads.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593698","","Shape;Roads;Three-dimensional displays;Cameras;Image reconstruction;Automobiles;Surface reconstruction","cameras;image reconstruction;pose estimation;road vehicles;SLAM (robots);stereo image processing;traffic engineering computing","local bundle-adjustment like procedure;3D pose;semantic cues;moving ego vehicle;shape estimation;plain roads;monocular localization demonstrations;autonomous driving systems;traffic participants;moving camera;monocular reconstruction;arbitrarily-shaped roads;monocular object localization;road plane configurations;local ground plane;local planar patches;monocular camera","","","25","","","","","IEEE","IEEE Conferences"
"The Co-Gripper: A Wireless Cooperative Gripper for Safe Human Robot Interaction","G. Salvietti; Z. Iqbal; I. Hussain; D. Prattichizzo; M. Malvezzi","Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Siena, Via Roma 56, Siena, 53100, Italy; Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Siena, Via Roma 56, Siena, 53100, Italy; Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Siena, Via Roma 56, Siena, 53100, Italy; Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Siena, Via Roma 56, Siena, 53100, Italy; Dipartimento di Ingegneria dell'Informazione, Università degli Studi di Siena, Via Roma 56, Siena, 53100, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4576","4581","In this paper, we introduce a set of guidelines for the design of grippers suitable for a safe human robot/interaction in cooperative tasks. Modularity, adaptability, robustness, intuitive control, limited weight are some of the key elements that could allow to effectively spread these devices in industrial and service applications. Following such guidelines, we present the prototype of the Co-Gripper: a robotic device for cooperative manipulation tasks with humans. The gripper is composed of two pairs of fingers, actuated with two motors, that can be controlled in a coordinated way or independently. Each finger has a modular underactuated structure, composed of three phalanges connected by passive joints. The gripper is wireless, so it can be easily connected both to the robotic arms and on passive structures. We designed a wearable wireless control interface composed of a ring and a bracelet allowing a simple and intuitive activation of the gripper without limiting human operator's manipulation capabilities. We performed a set of tests to quantify gripper performance and to exploit its potentialities in human-robot cooperation tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593877","","Grippers;Collaboration;Robot kinematics;Manipulators;Service robots;Wireless communication","grippers;human-robot interaction;robust control","safe human robot interaction;intuitive control;industrial service applications;robotic device;manipulation tasks;modular underactuated structure;robotic arms;wearable wireless control interface;human operator;gripper performance;human-robot cooperation tasks;co-gripper","","1","24","","","","","IEEE","IEEE Conferences"
"Reinforcement Learning with Symbolic Input-Output Models","E. Derner; J. Kubalík; R. Babuška","Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague, Czech Republic","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3004","3009","It is well known that reinforcement learning (RL) can benefit from the use of a dynamic prediction model which is learned on data samples collected online from the process to be controlled. Most RL algorithms are formulated in the state-space domain and use state-space models. However, learning state-space models is difficult, mainly because in the vast majority of problems the full state cannot be measured on the system or reconstructed from the measurements. To circumvent this limitation, we propose to use input-output models of the NARX (nonlinear autoregressive with exogenous input) type. Symbolic regression is employed to construct parsimonious models and the corresponding value functions. Thanks to this approach, we can learn accurate models and compute optimal policies even from small amounts of training data. We demonstrate the approach on two simulated examples, a hopping robot and a 1-DOF robot arm, and on a real inverted pendulum system. Results show that our proposed method can reliably determine a good control policy based on a symbolic input-output process model and value function.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593881","Model learning;symbolic regression;reinforcement learning;optimal control","Robots;Springs;Data models;Computational modeling;Optimal control;Reinforcement learning;Process control","autoregressive processes;learning systems;optimal control;regression analysis;state-space methods","reinforcement learning;symbolic input-output models;dynamic prediction model;RL algorithms;nonlinear autoregressive with exogenous input;symbolic regression;parsimonious models;symbolic input-output process model;state-space models","","","17","","","","","IEEE","IEEE Conferences"
"Fast Convergence for Object Detection by Learning how to Combine Error Functions","B. Schnieders; K. Tuvls","Department of Computer Science, University of Liverpool, Liverpool, L69 3BX, United Kingdom; Department of Computer Science, University of Liverpool, Liverpool, L69 3BX, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7329","7335","In this paper, we introduce an innovative method to improve the convergence speed and accuracy of object detection neural networks. Our approach, Converge-fast-auxnet, is based on employing multiple, dependent loss metrics and weighting them optimally using an on-line trained auxiliary network. Experiments are performed in the well-known RoboCup@Work challenge environment. A fully convolutional segmentation network is trained on detecting objects' pickup points. We empirically obtain an approximate measure for the rate of success of a robotic pickup operation based on the accuracy of the object detection network. Our experiments show that adding an optimally weighted Euclidean distance loss to a network trained on the commonly used Intersection over Union (IoU) metric reduces the convergence time by 42.48%. The estimated pickup rate is improved by 39.90%. Compared to state-of-the-art task weighting methods, the improvement is 24.5% in convergence, and 15.8% on the estimated pickup rate.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594179","","Object detection;Training;Convergence;Task analysis;Mathematical model;Euclidean distance","image segmentation;learning (artificial intelligence);mobile robots;multi-robot systems;neural nets;object detection","union metric;estimated pickup rate;convergence time;optimally weighted Euclidean distance loss;object detection network;robotic pickup operation;approximate measure;detecting objects;fully convolutional segmentation network;RoboCup@Work challenge environment;on-line trained auxiliary network;dependent loss metrics;Converge-fast-auxnet;object detection neural networks;convergence speed;error functions;fast convergence","","","20","","","","","IEEE","IEEE Conferences"
"VLASE: Vehicle Localization by Aggregating Semantic Edges","X. Yu; S. Chaturvedi; C. Feng; Y. Taguchi; T. Lee; C. Fernandes; S. Ramalingam","University of Utah, Salt Lake City, UT, 84112, USA; University of Utah, Salt Lake City, UT, 84112, USA; New York University, Brooklyn, NY, 11201, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, 02139, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, 02139, USA; University of Utah, Salt Lake City, UT, 84112, USA; University of Utah, Salt Lake City, UT, 84112, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3196","3203","We propose VLASE, a framework to use semantic edge features from images to achieve on-road localization. Semantic edge features denote edge contours that separate pairs of distinct objects such as building-sky, road-sidewalk, and building-ground. While prior work has shown promising results by utilizing the boundary between prominent classes such as sky and building using skylines, we generalize this to consider 19 semantic classes. We extract semantic edge features using CASENet architecture and utilize VLAD framework to perform image retrieval. We achieve improvement over state-of-the-art localization algorithms such as SIFT-VLAD and its deep variant NetVLAD. Ablation study shows the importance of different semantic classes, and our unified approach achieves better performance compared to individual prominent features such as skylines. We also introduce SLC Marathon dataset, a challenging dataset covering most of Salt Lake City with sufficient lighting variations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594358","","Semantics;Image edge detection;Feature extraction;Buildings;Databases;Visualization;Urban areas","feature extraction;geographic information systems;image retrieval;image segmentation;road vehicles;traffic information systems","semantic edge features;edge contours;building-sky;state-of-the-art localization algorithms;individual prominent features;VLASE;vehicle localization;on-road localization;semantic classes;VLAD framework;image retrieval;SIFT-VLAD;NetVLAD;SLC Marathon dataset;Salt Lake city;lighting variations","","","57","","","","","IEEE","IEEE Conferences"
"Closed-Loop Single-Beacon Passive Acoustic Navigation for Low-Cost Autonomous Underwater Vehicles","N. R. Rypkema; E. M. Fischel; H. Schmidt","Electrical Engineering and Computer Science Department, Cambridge, MA, 02139, USA; Applied Ocean Physics and Engineering Department, Woods Hole Oceanographic Institution, Woods Hole, MA, 02543, USA; Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","641","648","Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593626","","Acoustics;Navigation;Array signal processing;Receivers;Acoustic measurements;Transponders;Time-frequency analysis","autonomous underwater vehicles;closed loop systems;computational complexity;hydrophones;inertial navigation;marine navigation;mobile robots;particle filtering (numerical methods);position control","localization;autonomous underwater vehicles;Doppler velocity log;positional error;acoustic beacon;DVL-aided INS;LBL system;SandShark AUV;underwater navigation;computational complexity;phased-array beamforming;closed-loop operation;particle filter;vehicle-mounted passive hydrophone receiver-array;multiAUV operations;power requirements;inertial navigation system;robotic vehicle","","1","21","","","","","IEEE","IEEE Conferences"
"Event-Based Moving Object Detection and Tracking","A. Mitrokhin; C. Fermüller; C. Parameshwara; Y. Aloimonos","The Department of Computer Science; Neuroscience and Cognitive Science Program, Institute for Advanced Computer Studies; University of Maryland, College Park, MD 20740, USA; The Department of Computer Science","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Event-based vision sensors, such as the Dynamic Vision Sensor (DVS), are ideally suited for real-time motion analysis. The unique properties encompassed in the readings of such sensors provide high temporal resolution, superior sensitivity to light and low latency. These properties provide the grounds to estimate motion efficiently and reliably in the most sophisticated scenarios, but these advantages come at a price - modern event-based vision sensors have extremely low resolution, produce a lot of noise and require the development of novel algorithms to handle the asynchronous event stream. This paper presents a new, efficient approach to object tracking with asynchronous cameras. We present a novel event stream representation which enables us to utilize information about the dynamic (temporal)component of the event stream. The 3D geometry of the event stream is approximated with a parametric model to motion-compensate for the camera (without feature tracking or explicit optical flow computation), and then moving objects that don't conform to the model are detected in an iterative process. We demonstrate our framework on the task of independent motion detection and tracking, where we use the temporal model inconsistencies to locate differently moving objects in challenging situations of very fast motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593805","","Tracking;Three-dimensional displays;Cameras;Optical imaging;Motion compensation;Voltage control;Sensors","cameras;computer vision;feature extraction;image sensors;image sequences;motion compensation;motion estimation;object detection;object tracking","dynamic component;temporal model inconsistencies;independent motion detection;feature tracking;motion-compensate;event stream representation;asynchronous cameras;asynchronous event stream;extremely low resolution;modern event-based vision sensors;high temporal resolution;real-time motion analysis;Dynamic Vision Sensor;object detection","","1","26","","","","","IEEE","IEEE Conferences"
"Automatic Parameter Tuning of Motion Planning Algorithms","J. Cano; Y. Yang; B. Bodin; V. Nagarajan; M. O'Boyle","University of Edinburgh, School of Informatics, UK; University of Edinburgh, School of Informatics, UK; University of Edinburgh, School of Informatics, UK; University of Edinburgh, School of Informatics, UK; University of Edinburgh, School of Informatics, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8103","8109","Motion planning algorithms attempt to find a good compromise between planning time and quality of solution. Due to their heuristic nature, they are typically configured with several parameters. In this paper we demonstrate that, in many scenarios, the widely used default parameter values are not ideal. However, finding the best parameters to optimise some metric(s) is not trivial because the size of the parameter space can be large. We evaluate and compare the efficiency of four different methods (i.e. random sampling, AUC-Bandit, random forest, and bayesian optimisation) to tune the parameters of two motion planning algorithms, BKPIECE and RRT-connect. We present a table-top-reaching scenario where the seven degrees-of-freedom KUKA LWR robotic arm has to move from an initial to a goal pose in the presence of several objects in the environment. We show that the best methods for BKPIECE (AUC-Bandit) and RRT-Connect (random forest) improve the performance by 4.5x and 1.26x on average respectively. Then, we generate a set of random scenarios of increasing complexity, and we observe that optimal parameters found in simple environments perform well in more complex scenarios. Finally, we find that the time required to evaluate parameter configurations can be reduced by more than 2/3 with low error. Overall, our results demonstrate that for a variety of motion planning problems it is possible to find solutions that significantly improve the performance over default configurations while requiring very reasonable computation times.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594183","","Planning;Tuning;Optimization;Bayes methods;Manipulators;Mathematical model","Bayes methods;manipulators;mobile robots;motion control;optimisation;path planning;sampling methods","random sampling;AUC-Bandit;random forest;motion planning algorithms;RRT-connect;table-top-reaching scenario;BKPIECE;random scenarios;parameter configurations;automatic parameter tuning;motion planning;default parameter values;Bayesian optimisation;KUKA LWR robotic arm","","","20","","","","","IEEE","IEEE Conferences"
"Stereo Camera Localization in 3D LiDAR Maps","Y. Kim; J. Jeong; A. Kim","Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","As simultaneous localization and mapping (SLAM) techniques have flourished with the advent of 3D Light Detection and Ranging (LiDAR) sensors, accurate 3D maps are readily available. Many researchers turn their attention to localization in a previously acquired 3D map. In this paper, we propose a novel and lightweight camera-only visual positioning algorithm that involves localization within prior 3D LiDAR maps. We aim to achieve the consumer level global positioning system (GPS) accuracy using vision within the urban environment, where GPS signal is unreliable. Via exploiting a stereo camera, depth from the stereo disparity map is matched with 3D LiDAR maps. A full six degree of freedom (DOF) camera pose is estimated via minimizing depth residual. Powered by visual tracking that provides a good initial guess for the localization, the proposed depth residual is successfully applied for camera pose estimation. Our method runs online, as the average localization error is comparable to ones resulting from state-of-the-art approaches. We validate the proposed method as a stand-alone localizer using KITTI dataset and as a module in the SLAM framework using our own dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594362","","Cameras;Three-dimensional displays;Laser radar;Simultaneous localization and mapping;Visualization;Global Positioning System","cameras;Global Positioning System;image matching;image reconstruction;mobile robots;optical radar;pose estimation;robot vision;SLAM (robots);stereo image processing","stereo disparity map;average localization error;stereo camera localization;Global Positioning System;3D LiDAR maps;simultaneous localization and mapping techniques;SLAM techniques;3D light detection and ranging sensors;visual positioning algorithm;GPS signal;visual tracking;six degree of freedom;DOF;camera pose estimation;KITTI dataset","","","28","","","","","IEEE","IEEE Conferences"
"Resilient Active Information Gathering with Mobile Robots","B. Schlotfeldt; V. Tzoumas; D. Thakur; G. J. Pappas","Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104-6228, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4309","4316","Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593630","","Robot sensing systems;Target tracking;Mobile robots;Robot kinematics;Task analysis","mobile robots;multi-robot systems","information acquisition tasks;failure-prone;resilient design problems;submodular approximation algorithms;active robots;mobile robots;resilient active information gathering;multirobot target tracking;active information gathering scenario;denial-of-service attacks;system-wide resiliency;minimal communication","","","29","","","","","IEEE","IEEE Conferences"
"Building Dense Reflectance Maps of Indoor Environments Using an RGB-D Camera","M. Krawez; T. Caselitz; D. Büscher; M. Van Loock; W. Burgard","Autonomous Intelligent Systems, University of Freiburg, Germany; Autonomous Intelligent Systems, University of Freiburg, Germany; Autonomous Intelligent Systems, University of Freiburg, Germany; R&D - Advanced Technology, Toyota Motor Europe, Brussels, Belgium; Autonomous Intelligent Systems, University of Freiburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3210","3217","The ability to build models of the environment is an essential prerequisite for many robotic applications. In recent years, mapping of dense surface geometry using RGB-D cameras has seen extensive progress. Many approaches build colored models, typically directly using the intensity values provided by the camera. Unfortunately, these intensities are inherently affected by illumination. Therefore, the resulting maps only represent the environment for one specific lighting condition. To overcome this limitation, we propose to build reflectance maps that are invariant against changes in lighting. Our approach estimates the diffuse reflectance of a surface by recovering its radiosity and the corresponding irradiance. As imperfections in this process can significantly degrade the reflectance estimate, we remove outliers in the high dynamic range radiosity estimation and propose a method to refine the reflectance estimate. Our system implements the whole pipeline for offline reconstruction of dense reflectance maps including the segmentation of light emitters in the scene. We demonstrate the applicability of our approach in real-world experiments under varying lighting conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594107","","Cameras;Lighting;Image reconstruction;Robots;Geometry;Indoor environments;Surface treatment","brightness;cameras;image colour analysis;image reconstruction","lighting conditions;light emitters;high dynamic range radiosity estimation;reflectance estimate;diffuse reflectance;specific lighting condition;colored models;extensive progress;RGB-D cameras;dense surface geometry;robotic applications;indoor environments;building dense reflectance maps","","","22","","","","","IEEE","IEEE Conferences"
"Long-Duration Autonomy for Small Rotorcraft UAS Including Recharging","C. Brommer; D. Malyuta; D. Hentzen; R. Brockers","Alpen-Adria-Universität, Control of Networked Systems Group, Klagenfurt; University of Washington., Autonomous Controls Laboratory; California Institute of Technology, Jet Propulsion Laboratory; California Institute of Technology, Jet Propulsion Laboratory","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7252","7258","Many unmanned aerial vehicle surveillance and monitoring applications require observations at precise locations over long periods of time, ideally days or weeks at a time (e.g. ecosystem monitoring), which has been impractical due to limited endurance and the requirement of humans in the loop for operation. To overcome these limitations, we propose a fully autonomous small rotorcraft UAS that is capable of performing repeated sorties for long-term observation missions without any human intervention. We address two key technologies that are critical for such a system: full platform autonomy including emergency response to enable mission execution independently from human operators, and the ability of vision-based precision landing on a recharging station for automated energy replenishment. Experimental results of up to 11 hours of fully autonomous operation in indoor and outdoor environments illustrate the capability of our system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594111","","Global Positioning System;Batteries;Magnetometers;Sensors;Monitoring;Three-dimensional displays;State estimation","autonomous aerial vehicles;helicopters;mobile robots;surveillance","autonomous small rotorcraft;autonomous operation;UAS;recharging station;vision-based precision landing;human operators;mission execution;emergency response;unmanned aerial vehicle surveillance","","","32","","","","","IEEE","IEEE Conferences"
"Robot-Supported Multiplayer Rehabilitation: Feasibility Study of Haptically Linked Patient-Spouse Training","K. Baur; P. Wolf; V. Klamroth-Marganska; W. Bierbauer; U. Scholz; R. Riener; J. E. Duarte","Institute of Robotics and Intelligent Systems (IRIS), Sensory-Motor Systems (SMS) Lab, ETH Zurich, Switzerland; Institute of Robotics and Intelligent Systems (IRIS), Sensory-Motor Systems (SMS) Lab, ETH Zurich, Switzerland; Institute of Robotics and Intelligent Systems (IRIS), Sensory-Motor Systems (SMS) Lab, ETH Zurich, Switzerland; Institute of Robotics and Intelligent Systems (IRIS), Sensory-Motor Systems (SMS) Lab, ETH Zurich, Switzerland; Applied Social and Health Psychology Department of Psychology & University Research Priority Program (URPP) Dynamics of Healthy Aging, University of Zurich, Switzerland; Institute of Robotics and Intelligent Systems (IRIS), Sensory-Motor Systems (SMS) Lab, ETH Zurich, Switzerland; Institute of Robotics and Intelligent Systems (IRIS), Sensory-Motor Systems (SMS) Lab, ETH Zurich, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4679","4684","Multiplayer environments are thought to increase and prolongate active participation in robot-aided rehabilitation. We expect that environments linking patients with their spouses will particularly foster active participation. Thus, we developed two multiplayer games to link the game experience of two players: an Air Hockey game and a Haptic Kitchen game. In the competitive Air Hockey game, differences in skill levels between players were balanced by individualizing haptic guidance or damping forces. In the Haptic Kitchen game, a healthy player could support the patient's movements using a virtual force field. The two players could control the haptic interaction since both the force field and the point of application were visualized. We tested the haptic performance balancing algorithm of the Air Hockey game and the spouse-controlled haptic support of the Kitchen game with patients post-stroke who trained both single- (i.e., alone) and multiplayer training (i.e., with spouse) in eight therapy sessions lasting 45 min each. Mean total rating in Intrinsic Motivation Inventory was 46.9 points (out of 63 points) for multiplayer modes, and 42.7 points for single player modes, respectively. The spouses applied the haptic support in the Haptic Kitchen game during 42 % of the total game duration. We are currently testing more patient-spouse couples to better understand the effects of using these haptic approaches on the behavior and recovery of patients. We foresee this approach can improve the motivation during training and positively influence the at-home behavior of patients, an important goal of rehabilitation training efforts.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593769","","Games;Haptic interfaces;Training;Robots;Damping;Trajectory;Sports","computer games;control engineering computing;haptic interfaces;medical computing;medical robotics;patient rehabilitation;user experience;virtual reality","game experience;Haptic Kitchen game;haptic guidance;haptic interaction;haptic performance balancing algorithm;spouse-controlled haptic support;patients post-stroke;robot-supported multiplayer rehabilitation;haptically linked patient-spouse training;robot-aided rehabilitation;multiplayer games;Air Hockey game","","","18","","","","","IEEE","IEEE Conferences"
"Decentralized Localization Framework using Heterogeneous Map-matchings","S. Lee; J. Kim; J. Kim; G. Oh; S. W. Seo","Department of Electrical Engineering and Computer Science, Seoul National University; Department of Electrical Engineering and Computer Science, Seoul National University; Department of Electrical Engineering and Computer Science, Seoul National University; Department of Electrical Engineering and Computer Science, Seoul National University; Department of Electrical Engineering and Computer Science, Seoul National University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2183","2189","Highly accurate and robust real-time localization is an essential technique for various autonomous driving applications. Numerous localization methods have been proposed that combine various types of sensors, including an environmental sensor, IMU and GPS. However, the usage of a single environmental sensor is rather fragile. Although the use of multi-environment sensors is a better alternative, fusion methods from previous studies have not adequately compensated for shortcomings in dissimilar sensors or have not considered errors in the pre-built map. In this paper, we propose a decentralized localization framework using heterogeneous map-matching sources. Decentralized localization performs two independent map-matchings and integrates them with a stochastic situational analysis model. By applying a stochastic model, the reliability of the two map matchings is collected and system stability is verified. A number of experiments with autonomous vehicles within the actual driving environment have shown that combining multiple map-matching sources ensures more robust results than the use of a single environmental sensor.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593948","","Roads;Laser radar;Three-dimensional displays;Cameras;Feature extraction;Sensor fusion","decentralised control;mobile robots;road vehicles;sensor fusion;stability;stochastic processes","decentralized localization framework;heterogeneous map-matchings;system stability;localization methods;map matchings;stochastic situational analysis model;heterogeneous map-matching sources;dissimilar sensors;fusion methods;multienvironment sensors;single environmental sensor;autonomous driving applications;robust real-time localization","","","22","","","","","IEEE","IEEE Conferences"
"Edge-Based Robust RGB-D Visual Odometry Using 2-D Edge Divergence Minimization","C. Kim; P. Kim; S. Lee; H. Jin Kim","Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper proposes an edge-based robust RGB-D visual odometry (VO) using 2-D edge divergence minimization. Our approach focuses on enabling the VO to operate in more general environments subject to low texture and changing brightness, by employing image edge regions and their image gradient vectors within the iterative closest points (ICP) framework. For more robust and stable ICP-based optimization, we propose a robust edge matching criterion with image gradient vectors. In addition, to reduce a bad effect of outlier residuals, we propose an improved edge registration problem of 2-D edge divergence minimization in the manner of an iterative re-weight least squares (IRLS) motion estimation. To accelerate the proposed approach, a pixel sub-sampling method is employed. We evaluate estimation performance of our method in changing brightness conditions and low-textured scenes. Our approach shows more robust motion estimation than state-of-the-art methods while maintaining comparable accuracy in challenging image sequences at real-time (25 Hz) operation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593594","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593594","","Image edge detection;Cameras;Brightness;Motion estimation;Minimization;Visual odometry;Lighting","edge detection;gradient methods;image colour analysis;image matching;image registration;image sequences;image texture;least squares approximations;minimisation;motion estimation","motion estimation;ICP-based optimization;edge matching criterion;edge registration problem;iterative re-weight least squares;IRLS;sub-sampling method;image sequences;VO algorithm;iterative closest points framework;image gradient vectors;image edge regions;edge-based robust RGB-D visual odometry;2-D edge divergence minimization","","","26","","","","","IEEE","IEEE Conferences"
"ίVAMOS! Underwater Mining Machine Navigation System","J. Almeida; A. Ferreira; B. Matias; C. Lomba; A. Martins; E. Silva","INESC TEC-INESC Technology and Science, Porto, Portugal; INESC TEC-INESC Technology and Science, Porto, Portugal; INESC TEC-INESC Technology and Science, Porto, Portugal; INESC TEC-INESC Technology and Science, Porto, Portugal; INESC TEC-INESC Technology and Science, Porto, Portugal; INESC TEC-INESC Technology and Science, Porto, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1520","1526","Limited perception capabilities underwater shrink the envelope of effective localization techniques that can be applied in this environment. Long-term localization in six degrees of freedom can only be achieved by combining different sources of information. A multiple vehicle underwater localization solution, for localizing an underwater mining vehicle and its support vessel, is presented in this paper. The surface vessel carries a short baseline network, that interact with the inverted ultra-short baseline, carried by the underwater mining vehicle. A multiple antenna GNSS system provides data for localizing the surface vessel and to georeference the short baseline array. Localization of the mining vehicle results from a data fusion approach, that combines multiple sources of sensor information using the Extended Kalman Filter (EKF) framework. The developed solutions were applied in the context of the ¡VAMOS! European project. Long-term real time position errors below 0.2 meters, for the underwater machine, and 0.02 meters, for the surface vessel, were accomplished in the field. All presented results are based on data acquired in a real scenario.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593773","","Position measurement;Global navigation satellite system;Receivers;Transponders;Accelerometers;Data mining;Gravity","autonomous underwater vehicles;Kalman filters;mining;mining equipment;mobile robots;nonlinear filters;satellite navigation;sensor fusion;underwater acoustic communication","underwater mining machine navigation system;data fusion approach;sensor information;extended kalman filter;EKF;¡VAMOS;multiple antenna GNSS system;inverted ultra-short baseline;surface vessel;underwater mining vehicle;multiple vehicle underwater localization solution","","","14","","","","","IEEE","IEEE Conferences"
"Decentralized Motion Control in a Cabled-based Multi-drone Load Transport System","K. Mohammadi; M. Jafarinasab; S. Sirouspour; E. Dyer","Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, L8S 4L8, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, L8S 4L8, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, L8S 4L8, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, L8S 4L8, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4198","4203","A provably stable decentralized control scheme is proposed to allow multiple conventional quadcopters carry a cable-suspended payload. The method exploits a fundamental energetic passivity property of the combined drones, cables, and payload system to stably move the payload from its origin to destination. This is achieved without making any assumption about the status of the cables tension during the flight, and any measurement from the payload. The controller is decentralized in the sense that inter-drone communication of feedback measurements is not required. Motion stability is demonstrated via a Lyapunov analysis. The proposed controller is successfully implemented on a three-drone payload transport system in an indoor environment, using measurement from an optical tracking systems and the drones on-board IMUs.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593952","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593952","","Payloads;Drones;Force;Stability analysis;Trajectory","aerospace robotics;decentralised control;helicopters;Lyapunov methods;materials handling;mobile robots;motion control;multi-robot systems;optical tracking;stability","energetic passivity property;drone on-board IMUs;Lyapunov analysis;optical tracking systems;three-drone payload transport system;motion stability;cable-suspended payload;multiple conventional quadcopters;cabled-based multidrone load transport system;decentralized motion control","","","24","","","","","IEEE","IEEE Conferences"
"Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization","Y. S. Liang; D. Pellier; H. Fiorino; S. Pesty; M. Cakmak","LIG, University Grenoble Alpes, Grenoble, F-38000, France; LIG, University Grenoble Alpes, Grenoble, F-38000, France; LIG, University Grenoble Alpes, Grenoble, F-38000, France; LIG, University Grenoble Alpes, Grenoble, F-38000, France; University of Washington, Paul G. Allen School of Computer Science & Engineering, Seattle, Washington, 98195, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6566","6573","Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593518","","Task analysis;Programming;Manipulators;Shape;Packaging;Education","human-robot interaction;inference mechanisms;learning (artificial intelligence);mobile robots;teaching;user interfaces","teaching strategies;end-user programming;learning task;human teachers;fetch mobile manipulator;warehouses;robotic shelf organization;online user study;goal inference approach;system implementation;grocery store shelf images","","","31","","","","","IEEE","IEEE Conferences"
"Structured Skip List: A Compact Data Structure for 3D Reconstruction","S. Li; M. Cheng; Y. Liu; S. Lu; Y. Wang; V. Adrian Prisacariu","College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; Department of Engineering, Oxford University, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","The model produced by 3D reconstruction algorithm is usually represented by voxels. The management of these voxels is usually divided into two categories: ordered and unordered methods. The ordered method holds too many empty voxels to maintain data order which leads to a low storage efficiency. On the contrary, the unordered method keeps massive index data to only store nonempty voxels. In this paper, we design a new data management method for real-time indoor 3D reconstruction, called Structured Skip List (SSL). The SSL can be treated as a semi-ordered method, because the advantages of both the ordered and unordered methods are taken into account: 1) it only holds nonempty voxels similar to the unordered method; 2) the structured information is introduced to reduce the storage space of index data. By these designs, the SSL has a better performance on storage efficiency. To handle the data collision in voxel allocation, a hash allocation list (HAL) is proposed. The length of each Skip List is kept balanced by fusing the IMU (Inertial Measurement Unit) information for a high operation efficiency. The storage efficiency analysis of different data management methods is shown in this paper. What's more, exhaustive investigation is carried out on several datasets with these methods. The experimental result demonstrates that our design can achieve a high storage efficiency with little time loss compared to the state-of-the-art methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594075","","Three-dimensional displays;Indexes;Data structures;Image reconstruction;Resource management;Solid modeling;Pipelines","data reduction;data structures;image reconstruction","data management methods;Structured Skip List;Structured Skip List;high storage efficiency;storage efficiency analysis;hash allocation list;voxel allocation;data collision;storage space;structured information;semiordered method;SSL;real-time indoor 3D reconstruction;data management method;store nonempty voxels;massive index data;low storage efficiency;data order;unordered methods;ordered methods;3D reconstruction algorithm;compact data structure","","","27","","","","","IEEE","IEEE Conferences"
"Indoor Mapping and Localization for Pedestrians using Opportunistic Sensing with Smartphones","Q. Liang; L. Wang; Y. Li; M. Liu","Department of ECE, Hong Kong University of Science and Technology; Center for Cloud Computing, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Department of MBE, City University of Hong Kong; Department of ECE, Hong Kong University of Science and Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1649","1656","Indoor localization for pedestrians has gained increasing popularity among the rich body of literature for the last decade. In this paper, a low-cost indoor mapping and localization solution is proposed using the opportunistic signals from ambient indoor environments with a smartphone. It is composed of GraphSLAM-based offline mapping and Bayesian filtering-based online localization using generated signal maps. The GraphSLAM front-end is constructed by motion constraints from pedestrian dead-reckoning (PDR), loop-closure constraints identified by magnetic sequence matching with WiFi signal similarity validation, and observation constraints from opportunistic magnetic headings after error rejection. Globally consistent trajectories are created by graph optimization, after which signal maps (e.g., WiFi, magnetic fields, lights) are generated by Gaussian Processes Regression (GPR) for later localization. We propose to use the pseudo-wall constraints from the GPR variance map of magnetic fields and the lights measurements as observations for particle filtering. The proposed method is evaluated on several datasets collected from both the in-compass office buildings and outside public areas. Real-time localization is demonstrated on a smartphone in an office building covering 2000 square meters with the 50- and 90-percentile accuracies being 2.30 m and 3.41 m, respectively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594254","","Wireless fidelity;Trajectory;Smart phones;Simultaneous localization and mapping;Ground penetrating radar;Legged locomotion","Bayes methods;Gaussian processes;indoor radio;mobile computing;mobile robots;optimisation;particle filtering (numerical methods);path planning;radionavigation;regression analysis;SLAM (robots);smart phones;wireless LAN","Gaussian Processes Regression;real-time localization;GPR variance map;pseudowall constraints;magnetic fields;globally consistent trajectories;opportunistic magnetic headings;WiFi signal similarity validation;magnetic sequence matching;loop-closure constraints;pedestrian dead-reckoning;motion constraints;GraphSLAM front-end;signal maps;Bayesian filtering-based online localization;GraphSLAM-based offline mapping;ambient indoor environments;low-cost indoor mapping;indoor localization;smartphone;size 2.3 m;size 3.41 m","","","20","","","","","IEEE","IEEE Conferences"
"HERO: Accelerating Autonomous Robotic Tasks with FPGA","X. Shi; L. Cao; D. Wang; L. Liu; G. You; S. Liu; C. Wang","Intel Labs China, Beijing, 100190, China; Intel Labs China, Beijing, 100190, China; Intel Labs China, Beijing, 100190, China; Intel Labs China, Beijing, 100190, China; Intel Labs China, Beijing, 100190, China; Intel Labs China, Beijing, 100190, China; Intel Labs China, Beijing, 100190, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7766","7772","The Heterogeneous Extensible Robot Open (HERO) platform is designed for autonomous robotic research. While bringing in the flexible computational capacities by CPU and FPGA, it addresses the challenges of heterogeneous computing by embracing OpenCL programming. We propose heterogeneous computing approaches for three fundamental robotic tasks: simultaneous localization and mapping (SLAM), motion planning and convolutional neural network (CNN) inference. With FPGA acceleration, the SLAM and motion planning tasks are performed 2-4 times faster on the HERO platform against fine-tuned software implementation. For CNN inference, it can process 20-30 images per second with the network of VGG-16 or ResNet-50. We expect the open platform and the developing experiences shared in this paper can facilitate future robotic research, especially for those compute intensive tasks of perception, movement and manipulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593522","","Field programmable gate arrays;Kernel;Acceleration;Simultaneous localization and mapping;Task analysis;Planning","convolutional neural nets;field programmable gate arrays;mobile robots;path planning;SLAM (robots)","motion planning tasks;HERO platform;CNN inference;autonomous robotic tasks;Heterogeneous Extensible Robot Open platform;OpenCL programming;SLAM;convolutional neural network inference;FPGA acceleration;heterogeneous computing;simultaneous localization and mapping;VGG-16;ResNet-50","","","20","","","","","IEEE","IEEE Conferences"
"Cost Functions for Robot Motion Style","A. Zhou; A. D. Dragan","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, U.S.A; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, U.S.A","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3632","3639","We focus on autonomously generating robot motion for day to day physical tasks that is expressive of a certain style or emotion. Because we seek generalization across task instances and task types, we propose to capture style via cost functions that the robot can use to augment its nominal task cost and task constraints in a trajectory optimization process. We compare two approaches to representing such cost functions: a weighted linear combination of hand-designed features, and a neural network parameterization operating on raw trajectory input. For each cost type, we learn weights for each style from user feedback. We contrast these approaches to a nominal motion across different tasks and for different styles in a user study, and find that they both perform on par with each other, and significantly outperform the baseline. Each approach has its advantages: featurized costs require learning fewer parameters and can perform better on some styles, but neural network representations do not require expert knowledge to design features and could even learn more complex, nuanced costs than an expert can easily design.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594433","","Task analysis;Robots;Cost function;Neural networks;Trajectory optimization","control engineering computing;learning (artificial intelligence);mobile robots;neurocontrollers","task constraints;nominal task cost;task types;task instances;robot motion style;nuanced costs;featurized costs;nominal motion;cost type;raw trajectory input;neural network parameterization operating;hand-designed features;weighted linear combination;cost functions;trajectory optimization process","","","22","","","","","IEEE","IEEE Conferences"
"Estimation of Interaction Forces in Robotic Surgery using a Semi-Supervised Deep Neural Network Model","A. Marban; V. Srinivasan; W. Samek; J. Fernández; A. Casals","Research Centre for Biomedical Engineering (CREB), Universitat Politècnica de Catalunya, Barcelona, 08034, Spain; Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Research Centre for Biomedical Engineering (CREB), Universitat Politècnica de Catalunya, Barcelona, 08034, Spain; Research Centre for Biomedical Engineering (CREB), Universitat Politècnica de Catalunya, Barcelona, 08034, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","761","768","Providing force feedback as a feature in current Robot-Assisted Minimally Invasive Surgery systems still remains a challenge. In recent years, Vision-Based Force Sensing (VBFS) has emerged as a promising approach to address this problem. Existing methods have been developed in a Supervised Learning (SL) setting. Nonetheless, most of the video sequences related to robotic surgery are not provided with ground-truth force data, which can be easily acquired in a controlled environment. A powerful approach to process unlabeled video sequences and find a compact representation for each video frame relies on using an Unsupervised Learning (UL) method. Afterward, a model trained in an SL setting can take advantage of the available ground-truth force data. In the present work, UL and SL techniques are used to investigate a model in a Semi-Supervised Learning (SSL) framework, consisting of an encoder network and a Long-Short Term Memory (LSTM) network. First, a Convolutional Auto-Encoder (CAE) is trained to learn a compact representation for each RGB frame in a video sequence. To facilitate the reconstruction of high and low frequencies found in images, this CAE is optimized using an adversarial framework and a L1-loss, respectively. Thereafter, the encoder network of the CAE is serially connected with an LSTM network and trained jointly to minimize the difference between ground-truth and estimated force data. Datasets addressing the force estimation task are scarce. Therefore, the experiments have been validated in a custom dataset. The results suggest that the proposed approach is promising.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593701","Vision Based Force Sensing;Robotic Surgery;Deep Neural Networks;Semi-Supervised Learning","Video sequences;Force;Tools;Robot sensing systems;Surgery;Estimation","force feedback;image reconstruction;image representation;learning (artificial intelligence);medical robotics;neural nets;surgery;unsupervised learning;video signal processing","interaction forces;force estimation task;LSTM network;RGB frame;CAE;Convolutional Auto-Encoder;Long-Short Term Memory network;encoder network;SemiSupervised Learning framework;SL techniques;UL;Unsupervised Learning method;video frame;compact representation;unlabeled video sequences;video sequence;Supervised Learning setting;Vision-Based Force Sensing;current Robot-Assisted Minimally Invasive Surgery systems;force feedback;semisupervised deep neural network model;robotic surgery","","","29","","","","","IEEE","IEEE Conferences"
"A modular framework for model-based visual tracking using edge, texture and depth features","S. Trinh; F. Spindler; E. Marchand; F. Chaumette","Inria, Univ Rennes, CNRS, IRISA, France; Inria, Univ Rennes, CNRS, IRISA, France; Inria, Univ Rennes, CNRS, IRISA, France; Inria, Univ Rennes, CNRS, IRISA, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","89","96","We present in this paper a modular real-time model-based visual tracker. It is able to fuse different types of measurement, that is, edge points, textured points, and depth map, provided by one or multiple vision sensors. A confidence index is also proposed for determining if the outputs of the tracker are reliable or not. As expected, experimental results show that the more various measurements are combined, the more accurate and robust is the tracker. The corresponding C++ source code is available for the community in the ViSP library.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594003","","Cameras;Visualization;Solid modeling;Image edge detection;Three-dimensional displays;Sensors;Robustness","feature extraction;image colour analysis;image sensors;object tracking","modular framework;confidence index;multiple vision sensors;depth map;textured points;edge points;real-time model-based visual tracker;depth features;model-based visual tracking using edge","","","30","","","","","IEEE","IEEE Conferences"
"Fast Walking with Rhythmic Sway of Torso in a 2D Passive Ankle Walker","R. Bao; T. Geng","Brunel University, London, UK; Middlesex University, London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4363","4368","There is a category of biped robots that are equipped with passive or un-actuated ankles, which we call Passive-Ankle Walkers (PAWs). Lack of actuation at ankles is a disadvantage in the fast walking of PAWs. We started this study with an intuitive hypothesis that rhythmic sway of torso may enable faster walking in PAWs. To test this hypothesis, firstly, we optimized the rhythmic sway of torso of a simulated PAW model for fast walking speed, and analyzed the robustness of the optimal trajectories. Then we implemented the optimal trajectories on a real robot. Both the simulation analysis and the experimental results indicated that optimized torso-swaying can greatly increase the walking speed by 40%. By analyzing the walking patterns of the simulated model and the real robot, we identified the reason for the faster walking with swaying-torso: The rhythmic sway of torso enables the robot to walk with a relatively large step-length while still keeninu a hizh sten-frenuencv.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593665","Biped robots;legged locomotion","Legged locomotion;Torso;Trajectory;Optimization;Mathematical model;Foot","gait analysis;legged locomotion","2D passive ankle walker;biped robots;rhythmic sway;torso-swaying optimization;optimal trajectories;fast walking speed;un-actuated ankles","","","33","","","","","IEEE","IEEE Conferences"
"A Maximum Likelihood Approach to Extract Polylines from 2-D Laser Range Scans","A. Schaefer; D. Büscher; L. Luft; W. Burgard","Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4766","4773","Man-made environments such as households, offices, or factory floors are typically composed of linear structures. Accordingly, polylines are a natural way to accurately represent their geometry. In this paper, we propose a novel probabilistic method to extract polylines from raw 2-D laser range scans. The key idea of our approach is to determine a set of polylines that maximizes the likelihood of a given scan. In extensive experiments carried out on publicly available real-world datasets and on simulated laser scans, we demonstrate that our method substantially outperforms existing state-of-the-art approaches in terms of accuracy, while showing comparable computational requirements. Our implementation is available under https://github.com/acschaefer/ple.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593844","","Feature extraction;Sensors;Lasers;Probabilistic logic;Optimization;Measurement by laser beam;Laser radar","image reconstruction;image registration;laser ranging;maximum likelihood estimation;probability","simulated laser scans;maximum likelihood approach;2-D laser range scans;man-made environments;factory floors;linear structures;probabilistic method;polylines extraction","","","26","","","","","IEEE","IEEE Conferences"
"Mobile Robot Localization Considering Class of Sensor Observations","N. Akai; L. Y. Morales; H. Murase","Institute of Innovation for Future Society (MIRAI), Nagoya University, Nagoya, 464-8601, Japan; Institute of Innovation for Future Society (MIRAI), Nagoya University, Nagoya, 464-8601, Japan; Graduate School of Information Science, Nagoya University, Nagoya, 464-8603, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3159","3166","Localization robustness against environment dynamics is significant for robots to achieve autonomous navigation in unmodified environments. A basic method of improving the robustness of a robot is considering the sensor observations obtained from mapped obstacles and using them for localizing the robot's pose. This study proposes an observation model that considers the class of sensor observations, where “class” categorizes the sensor observations as those obtained from mapped and unmapped obstacles. In the proposed approach, the robot's pose and the class are estimated simultaneously. As a result, the robot's pose can be localized using the sensor observations obtained only from mapped obstacles. First, we evaluated the performance of the proposed approach using simulations. Further, we tested the proposed approach in a real-world mobile robot navigation competition, called “Tsukuba Challenge,” held in Japan. The robustness and effectiveness of the proposed approach against environment dynamics were verified from the experimental results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594146","","Robot sensing systems;Mathematical model;Robustness;Hidden Markov models;Mobile robots;Collision avoidance","collision avoidance;mobile robots","localization robustness;environment dynamics;robots;sensor observations;mapped obstacles;observation model;unmapped obstacles;real-world mobile robot navigation competition;mobile robot localization","","1","32","","","","","IEEE","IEEE Conferences"
"Designing for Robust Movement in a Child-Friendly Robot","J. Taufatofua; S. Heath; C. A. Ramirez-Brinez; K. Sommer; G. Durantin; W. Kong; J. Wiles; P. Pounds","Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia; Authors are with the University of Queensland, Brisbane, 4072, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7667","7674","Motion is a critical aspect of communication, required to create natural interactions between humans and robots. Robots for the classroom pose several constraints on motion, which make them challenging to design, including maintaining the safety of the child and the robot, responding in a timely fashion, and creating motions that are expressive and not scary. In this paper we present the mechanical design of a social robot and demonstrate that it is capable of safe motion within the proximity of children through analysis and empirical testing of the arms. The robot has a novel mechanical design for its two arms, which include torso-mounted, back-drivable, torque-limited stepper motors. The results suggest that our design succeeds at increasing safety levels while enabling the use of socially acceptable speeds of motion during the interaction. This study implies that the design of robotic agents for social interaction with children should consider the design of mechanical features that enable safe contact between the human and the robot while not limiting the robot to slow motions that would impair the timing of the interaction.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593414","","Safety;Manipulators;Actuators;Prototypes;Torque;Three-dimensional displays","design;humanoid robots;human-robot interaction;manipulator dynamics;mobile robots;motion control;safety","torque-limited stepper motors;robotic agents;social interaction;mechanical features;child-friendly robot;social robot;mechanical design;torso-mounted;back-drivable","","","27","","","","","IEEE","IEEE Conferences"
"A Topology-Based Path Similarity Metric and its Application to Sampling-Based Motion Planning","J. Denny; K. Chen; H. Zhou","Department of Mathematics and Computer Science, University of Richmond, Spider Robotics Lab (SpiRoL), VA, USA; Department of Mathematics and Computer Science, University of Richmond, Spider Robotics Lab (SpiRoL), VA, USA; Department of Mathematics and Computer Science, University of Richmond, Spider Robotics Lab (SpiRoL), VA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6498","6505","Many applications of robotic motion planning benefit from considering multiple homotopically distinct paths rather than a single path from start to goal. However, determining whether paths represent different homotopy classes can be difficult to compute. We propose metrics for efficiently approximating the homotopic similarity of two paths are, instead of verifying homotopy equivalence directly. We propose two metrics: (1) a naive application of local planning, a common subroutine of sampling-based motion planning, and (2) a novel approach that reasons about the topologically distinct portions of the workspace that a path visits. We present three applications of our metric to demonstrate its use and effectiveness: extracting topologically distinct paths from an existing roadmap, comparing paths for robot manipulators, and improving the computational efficiency of an existing sampling-based method, Path Deformation Roadmaps (PDRs), by over two orders of magnitude. We explore the trade-off between quality and computational efficiency in the proposed metrics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594325","","Measurement;Planning;Strain;Algorithms;Merging;Manipulators","mobile robots;path planning;sampling methods;topology","homotopic similarity;homotopy equivalence;naive application;local planning;sampling-based motion planning;topologically distinct portions;topologically distinct paths;robotic motion planning;homotopy classes;topology-based path similarity metric;path deformation roadmaps;multiple homotopically distinct paths","","","30","","","","","IEEE","IEEE Conferences"
"Skating with a Force Controlled Quadrupedal Robot","M. Bjelonic; C. Dario Bellicoso; M. Efe Tiryaki; M. Hutter","ETH Zurich, All authors are with the Robotic Systems Lab, Zürich, 8092, Switzerland; ETH Zurich, All authors are with the Robotic Systems Lab, Zürich, 8092, Switzerland; ETH Zurich, All authors are with the Robotic Systems Lab, Zürich, 8092, Switzerland; ETH Zurich, All authors are with the Robotic Systems Lab, Zürich, 8092, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7555","7561","Traditional legged robots are capable of traversing challenging terrain, but lack of energy efficiency when compared to wheeled systems operating on flat environments. The combination of both locomotion domains overcomes the trade-off between mobility and efficiency. Therefore, this paper presents a novel motion planner and controller which together enable a legged robot equipped with skates to perform skating maneuvers. These are achieved by an appropriate combination of planned reaction forces and gliding motions. Our novel motion controller formulates a Virtual Model Controller and an optimal contact force distribution which takes into account the nonholonomic constraints introduced by the skates. This approach has been tested on the torque-controllable robot ANY mal equipped with passive wheels and ice skates as end-effectors. We conducted experiments on flat and inclined terrain, whereby we show that skating motions reduces the cost of transport by up to 80 % with respect to traditional walking gaits.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594504","","Legged locomotion;Force;Torso;Wheels;Robot kinematics","end effectors;force control;legged locomotion;locomotives;motion control;robot dynamics;torque control;wheels","motion planner;legged robot;gliding motions;Virtual Model Controller;optimal contact force distribution;torque-controllable robot ANY mal;passive wheels;ice skates;flat terrain;inclined terrain;skating motions;force controlled quadrupedal robot;wheeled systems;flat environments;locomotion domains;end-effectors;motion controller","","1","26","","","","","IEEE","IEEE Conferences"
"On Designing 2D Discrete Workspaces to Sort or Classify Polynminoes","P. Keldenich; S. Manzoor; L. Huang; D. Krupke; A. Schmidt; S. P. Fekete; A. T. Becker","Department of Computer Science, TU Braunschweig, Germany; Department of Electrical and Computer Engineering, University of Houston, USA; Department of Electrical and Computer Engineering, University of Houston, USA; Department of Computer Science, TU Braunschweig, Germany; Department of Computer Science, TU Braunschweig, Germany; Department of Computer Science, TU Braunschweig, Germany; Department of Electrical and Computer Engineering, University of Houston, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper studies the general problem of physically sorting polyominoes according to shape using a 2D, rigid, grid-based workspace. The workspace is designed for sensorless operation, using a fixed set of open-loop force-field inputs that move a polyomino from an inlet port to an outlet port that corresponds to the polyomino's shape, and reset the workspace to classify the next polyomino. This paper proves that static workspaces can classify all orthoconvex polyominoes of width w and height h, and provides a motion sequence and required size of workspace as a function of wand h. By allowing moving polyomino cams that assist in the sorting, we can design dynamic works paces that can sort all polyomi-noes that are “completely filled” using a constant number of force-field inputs. Hardware experiments using magnetic and gravity-based actuation demonstrate these static and dynamic sensorless classifiers at the millimeter scale.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594150","","Sorting;Shape;Robot sensing systems;Two dimensional displays;Machine vision;Cams;Dynamics","materials handling;robotic assembly","polyominoes sorting;2D discrete workspace design;dynamic sensorless classifiers;orthoconvex polyominoes;grid-based workspace","","","12","","","","","IEEE","IEEE Conferences"
"SMA based wrist exoskeleton for rehabilitation therapy*","D. Serrano; D. Copaci; L. Moreno; D. Blanco","Systems Engineering and Automation, Carlos III University of Madrid, Spain; Systems Engineering and Automation, Carlos III University of Madrid, Spain; Systems Engineering and Automation, Carlos III University of Madrid, Spain; Systems Engineering and Automation, Carlos III University of Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2318","2323","This paper presents a rehabilitation wearable exoskeleton for wrist joint with two degrees of freedom (DOF), flexion-extension and adduction-abduction (radial and ulnar deviation), actuated with Shape Memory Alloy (SMA) based actuators. Thanks to this type of actuators, the proposed device presents a very light weight and noiseless operation, in comparison with similar devices. The preliminary results obtained over real tests with the wrist exoskeleton are presented. This prototype demonstrates that SMA actuator technology is a viable alternative when investigating possible improvement of rehabilitation robotic devices in terms of weight, size and cost.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593987","","Wrist;Actuators;Exoskeletons;Wires;Medical treatment;Robots;Biological system modeling","biomechanics;electroactive polymer actuators;medical robotics;patient rehabilitation;pneumatic actuators;shape memory effects;wearable robots","SMA based wrist exoskeleton;rehabilitation therapy;rehabilitation wearable exoskeleton;wrist joint;flexion-extension;adduction-abduction;Shape Memory Alloy based actuators;SMA actuator technology;rehabilitation robotic devices","","","21","","","","","IEEE","IEEE Conferences"
"Interacting with a “Transparent” Upper-Limb Exoskeleton: A Human Motor Control Approach","S. Bastide; N. Vignais; F. Geffard; B. Berret","ClAMS, Univ. Paris-Sud Université Paris-Saclay, Orsay, 91405, France; ClAMS, Univ. Paris-Sud Université Paris-Saclay, Orsay, 91405, France; CEA, List, Interactive Robotics Laboratory, Gif sur Yvette, 91191, France; ClAMS, Univ. Paris-Sud Université Paris-Saclay, Orsay, 91405, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4661","4666","Establishing a symbiotic relationship between a human and a exoskeleton is the end goal in many applications in order to provide benefits to the user. However, the literature focusing on the human side of human-exoskeleton interaction has remained less exhaustive than the literature focusing on the design (hardware/software) of the exoskeleton device itself. It is, though, essential to understand how a human adapts his motor control when interacting with an exoskeleton. Motor adaptation is an implicit process carried out by the central nervous system when the body encounters a perturbation, a paradigm that has been extensively studied in the field of human motor control research. When wearing an exoskeleton, even “as-transparent-as-possible”, contact/interaction forces may impact well-known motor control laws in a way that may be detrimental to the user, and even compromise usability in real applications. The present paper investigates how interaction with a backdrivable upper-limb exoskeleton (ABLE) set in “transparent” mode of control affects the kinematics/dynamics of human movement in a simple task. We find that important motor control features are preserved when moving with ABLE but an overall movement slowness occurs, likely as a response to increased inertia according to optimal control simulations. Such a human motor control approach illustrates one possible way to assess the degree of symbiosis between human and exoskeleton, i.e. by grounding on well-known findings in motor control research.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593991","","Exoskeletons;Motor drives;Robots;Torque;Task analysis;Perturbation methods;Kinematics","biomechanics;human-robot interaction;medical robotics;motion control;neurophysiology;optimal control;patient rehabilitation;robot dynamics;robot kinematics","transparent upper-limb exoskeleton;human motor control approach;human-exoskeleton interaction;exoskeleton device;motor adaptation;human motor control research;as-transparent-as-possible contact/interaction forces;motor control laws;human movement;optimal control simulations;motor control features","","","28","","","","","IEEE","IEEE Conferences"
"Visual Vehicle Tracking Through Noise and Occlusions Using Crowd-Sourced Maps","S. M. S; H. Grimmett; L. Platinský; P. Onduska","Blue Vision Labs, London, UK; Blue Vision Labs, London, UK; Blue Vision Labs, London, UK; Blue Vision Labs, London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4531","4538","We present a location-specific method to visually track the positions of observed vehicles based on large-scale crowd-sourced maps. We equipped a large fleet of cars that drive around cities with camera phones mounted on the dashboard, and performed city-scale structure-from-motion to accurately reconstruct the trajectories taken by the vehicles. We show that these data can be used to first create a system enabling high-accuracy localisation, and then to accurately predict the future motion of newly observed cars in the camera view. As a basis for the method we use a recently proposed system [1] for unsupervised motion prediction and extend it to a real-time visual tracking pipeline which can track vehicles through noise and extended occlusions using only a monocular camera. The system is tested using two large-scale datasets of San Francisco and New York City containing millions of frames. We demonstrate the performance of the system in a variety of traffic, time, and weather conditions. The presented system requires no manual annotation or knowledge of road infrastructure. To our knowledge, this is the first time a perception system based on a large-scale crowd-sourced maps has been evaluated at this scale.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593378","","Automobiles;Trajectory;Tracking;Three-dimensional displays;Cameras;Pipelines;Hidden Markov models","image motion analysis;image reconstruction;image segmentation;object detection;object tracking;traffic engineering computing;video signal processing;video surveillance","camera phones;performed city-scale structure-from-motion;high-accuracy localisation;unsupervised motion prediction;real-time visual tracking pipeline;monocular camera;large-scale datasets;New York City;perception system;large-scale crowd-sourced maps;visual vehicle tracking;location-specific method","","","19","","","","","IEEE","IEEE Conferences"
"Autonomous Navigation Using Multimodal Potential Field to Initiate Interaction with Multiple People","Y. Kawasaki; A. Yorozu; M. Takahashi","Department of System Design Engineering, Keio University, Yokohama, 223-8522, Japan; Keio University, Graduate School of Science and Technology, Yokohama, 223-8522, Japan; Department of System Design Engineering, Keio University, Yokohama, 223-8522, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7654","7659","In a human-robot interaction, a robot needs to move to a position where the robot can obtain high reliability data of people, such as positions, postures, and voice. This is because the human recognition reliability depends on the positional relation between the people and the robot. In addition, the robot should choose the sensor data which is necessary to perform the interaction task. Therefore, it is necessary to navigate the robot to the position to obtain the data for initiation of the interaction task. Accordingly, we need to design a path-planning method considering sensor characteristics, human recognition reliability, and task contents. Although previous studies proposed path-planning methods using an interaction potential considering sensor characteristics, they did not consider the task contents and the human recognition reliability, which are important for practical application and did not applied to interaction with multiple people. Consequently, we present a path-planning method considering the task contents and the human recognition reliability using multimodal potential field integrating these information. We verified effectiveness of the path-planning method for interaction with multiple people.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594289","","Robot sensing systems;Reliability;Task analysis;Character recognition;Robot kinematics;Cameras","human-robot interaction;image recognition;mobile robots;navigation;path planning;robot vision;sensors","path-planning;sensor characteristics;autonomous navigation;sensor data;human recognition reliability;human-robot interaction;multiple people;initiate interaction;multimodal potential field","","","10","","","","","IEEE","IEEE Conferences"
"Combining Method of Alternating Projections and Augmented Lagrangian for Task Constrained Trajectory Optimization","A. Kumar Singh; R. Ghabcheloo; A. Muller; H. Pandya","Department of Hydraulics and Automation Tampere, University of Technology, Finland; Department of Hydraulics and Automation Tampere, University of Technology, Finland; Johannes Kepler University, Austria; Robotics Research Center, IIIT-Hyderabad, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7568","7575","Motion planning for manipulators under task space constraints is difficult as it constrains the joint configurations to always lie on an implicitly defined manifold. It is possible to view task constrained motion planning as an optimization problem with non-linear equality constraints, which can be solved by general non-linear optimization techniques. In this paper, we present a novel custom optimizer which exploits the underlying structure present in many task constraints. At the core of our approach are some simple reformulations, which when coupled with the method of alternating projection, leads to an efficient convex optimization based routine for computing a feasible solution to the task constraints. We subsequently build on this result and use the concept of Augmented Lagrangian to guide the feasible solutions towards those that also minimize the user defined cost function. We show that the proposed optimizer is fully distributive and thus, can be easily parallelized. We validate our formulation on some common robotic benchmark problems. In particular, we show that the proposed optimizer achieves cyclic motion in the joint space corresponding to a similar nature trajectory in the task space. Furthermore, as a baseline, we compare the proposed optimizer with an off-the-shelf non-linear solver provide in open source package SciPy. We show that for similar task constraint residuals and smoothness cost, it can be upto more than three times faster than the SciPy alternative.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593557","","Task analysis;Planning;Trajectory optimization;Cost function;Kinematics","collision avoidance;convex programming;optimisation;path planning;robot dynamics","similar nature trajectory;off-the-shelf nonlinear solver;similar task constraint residuals;SciPy alternative;alternating projections;Augmented Lagrangian;task constrained trajectory optimization;task space constraints;joint configurations;implicitly defined manifold;task constrained motion planning;optimization problem;nonlinear equality constraints;nonlinear optimization techniques;custom optimizer;task constraints;efficient convex optimization;feasible solution;common robotic benchmark problems;cyclic motion;joint space","","","22","","","","","IEEE","IEEE Conferences"
"In pixels we trust: From Pixel Labeling to Object Localization and Scene Categorization","C. Herranz-Perdiguero; C. Redondo-Cabrera; R. J. López-Sastre","Department of Signal Theory and Communications, University of Alcalá, GRAM research group, Alcalá de Henares, 28805, Spain; Department of Signal Theory and Communications, University of Alcalá, GRAM research group, Alcalá de Henares, 28805, Spain; Department of Signal Theory and Communications, University of Alcalá, GRAM research group, Alcalá de Henares, 28805, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","355","361","While there has been significant progress in solving the problems of image pixel labeling, object detection and scene classification, existing approaches normally address them separately. In this paper, we propose to tackle these problems from a bottom-up perspective, where we simply need a semantic segmentation of the scene as input. We employ the DeepLab architecture, based on the ResNet deep network, which leverages multi-scale inputs to later fuse their responses to perform a precise pixel labeling of the scene. This semantic segmentation mask is used to localize the objects and to recognize the scene, following two simple yet effective strategies. We evaluate the benefits of our solutions, performing a thorough experimental evaluation on the NYU Depth V2 dataset. Our approach achieves a performance that beats the leading results by a significant margin, defining the new state of the art in this benchmark for the three tasks comprising the scene understanding: semantic segmentation, object detection and scene categorization.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593736","","Semantics;Labeling;Image segmentation;Task analysis;Object detection;Histograms;Kernel","image classification;image segmentation;object detection","pixels;image pixel labeling;object detection;pixel labeling;scene understanding;semantic segmentation mask","","","29","","","","","IEEE","IEEE Conferences"
"The Future of Legal and Ethical Regulations for Autonomous Robotics","H. Xu; J. E. Borson","Faculty of Aerospace Engineering, University of Maryland, College Park, MD, 20742, USA; Harvard Law School, Washington, DC, 20009, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2362","2366","“Autonomous robotics” promise significant improvements across a host of different complex systems, which will need to be managed within regulatory frameworks to promote, at a minimum, device safety. Contrary to how they are often portrayed, however, these systems do not necessarily require fundamentally new approaches to engineering or regulatory challenges, i.e., the development of a novel “autonomy framework” applicable to different types of devices. Rather, because autonomous systems generally represent a progressive improvement of existing complex systems, preexisting regulatory scheme offer the best guidance for considering future regulation of autonomous elements. Moreover, the regulatory landscape differs considerably based on the type of device at issue (e.g., consumer electronics vis-á-vis medical devices). This paper argues that users and regulators must consider future autonomy regulations within the specific framework those devices currently inhabit, rather than focusing on a novel set of rules divorced from the preexisting context.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593915","","Autonomous systems;Robots;Law;Standards;Ethics;Complex systems","consumer electronics;mobile robots","autonomous robotics;autonomous systems;novel autonomy framework;device safety;regulatory frameworks;specific framework those devices;future autonomy regulations;consumer electronics vis-á-vis medical devices;regulatory landscape;autonomous elements;future regulation","","","26","","","","","IEEE","IEEE Conferences"
"Design for Control of a Soft Bidirectional Bending Actuator","R. A. Bilodeau; M. C. Yuen; J. C. Case; T. L. Buckner; R. Kramer-Bottiglio","Yale University, School of Engineering and Applied Science, New Haven CT, USA; Yale University, School of Engineering and Applied Science, New Haven CT, USA; Yale University, School of Engineering and Applied Science, New Haven CT, USA; Yale University, School of Engineering and Applied Science, New Haven CT, USA; Yale University, School of Engineering and Applied Science, New Haven CT, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","In this paper, we present sensor-controlled antagonistic pneumatic actuators (SCAPAs) that integrate proven soft robotic actuators and sensors into a simplified, controllable design. The antagonistic actuators together compose a bidirectional bending actuator with embedded capacitive strain sensors. By designing the SCAPAs from the ground-up for closed-loop control, we are able to minimize both the number of constituent components and the types of materials used, and further streamline the manufacturing processes. These improvements are embodied in the multipurpose use of a single conductive fabric sheet for both actuation and sensing, integrated into an otherwise all-silicone device. Such reduced material complexity allows us to use simple finite element analysis (FEA) models to predict the performance of a given design. We compare various designs to maximize sensor effectiveness using FEA and experimentally verify the suitability of select designs for state reconstruction. After converging on our final design, we demonstrate that this design evaluation process enables the use of simple control strategies to achieve closed-loop control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594293","soft material robotics;hydraulic/pneumatic actuators;sensor-based control","Actuators;Capacitive sensors;Fabrics;Strain;Robot sensing systems;Sensor systems","bending;capacitive sensors;closed loop systems;finite element analysis;pneumatic actuators;strain sensors","sensor effectiveness;design evaluation process;simple control strategies;closed-loop control;soft bidirectional bending actuator;SCAPAs;controllable design;antagonistic actuators;embedded capacitive strain sensors;sensor-controlled antagonistic pneumatic actuators;soft robotic actuators;manufacturing processes;finite element analysis;state reconstruction;single conductive fabric sheet","","","41","","","","","IEEE","IEEE Conferences"
"Towards Robust Visual Odometry with a Multi-Camera System","P. Liu; M. Geppert; L. Heng; T. Sattler; A. Geiger; M. Pollefeys","Department of Computer Science, ETH Zürich, Computer Vision and Geometry Group, Switzerland; Department of Computer Science, ETH Zürich, Computer Vision and Geometry Group, Switzerland; Manned - Unmanned Programme, Information Division, DSO National Laboratories, Robotics Autonomy Lab, Singapore; Department of Computer Science, ETH Zürich, Computer Vision and Geometry Group, Switzerland; Department of Computer Science, ETH Zürich, Computer Vision and Geometry Group, Switzerland; Department of Computer Science, ETH Zürich, Computer Vision and Geometry Group, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1154","1161","We present a visual odometry (VO) algorithm for a multi-camera system and robust operation in challenging environments. Our algorithm consists of a pose tracker and a local mapper. The tracker estimates the current pose by minimizing photometric errors between the most recent keyframe and the current frame. The mapper initializes the depths of all sampled feature points using plane-sweeping stereo. To reduce pose drift, a sliding window optimizer is used to refine poses and structure jointly. Our formulation is flexible enough to support an arbitrary number of stereo cameras. We evaluate our algorithm thoroughly on five datasets. The datasets were captured in different conditions: daytime, night-time with near-infrared (NIR) illumination and nighttime without NIR illumination. Experimental results show that a multi-camera setup makes the VO more robust to challenging environments, especially night-time conditions, in which a single stereo configuration fails easily due to the lack of features.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593561","","Cameras;Tracking;Lighting;Visual odometry;Robot vision systems;Robustness;Simultaneous localization and mapping","cameras;distance measurement;image sampling;minimisation;photometry;pose estimation;position measurement;stereo image processing","robust visual odometry algorithm;robust VO algorithm;current pose tracker estimation;photometric error minimisation;plane-sweeping stereo cameras;near-infrared illumination;NIR illumination;single stereo configuration;multicamera setup;sliding window optimizer;sampled feature points;local mapper;multicamera system","","","26","","","","","IEEE","IEEE Conferences"
"A Deep Reinforcement Learning Technique for Vision-Based Autonomous Multirotor Landing on a Moving Platform","A. Rodriguez-Ramos; C. Sampedro; H. Bavle; I. G. Moreno; P. Campoy","Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1010","1017","Deep learning techniques for motion control have recently been qualitatively improved, since the successful application of Deep Q- Learning to the continuous action domain in Atari-like games. Based on these ideas, Deep Deterministic Policy Gradients (DDPG) algorithm was able to provide impressive results in continuous state and action domains, which are closely linked to most of the robotics-related tasks. In this paper, a vision-based autonomous multirotor landing maneuver on top of a moving platform is presented. The behaviour has been completely learned in simulation without prior human knowledge and by means of deep reinforcement learning techniques. Since the multirotor is controlled in attitude, no high level state estimation is required. The complete behaviour has been trained with continuous action and state spaces, and has provided proper results (landing at a maximum velocity of 2 m/s), Furthermore, it has been validated in a wide variety of conditions, for both simulated and real-flight scenarios, using a low-cost, lightweight and out-of-the-box consumer multirotor.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594472","","Reinforcement learning;Unmanned aerial vehicles;Robots;Cameras;Aerospace electronics;Neural networks;Task analysis","attitude control;autonomous aerial vehicles;continuous systems;helicopters;learning (artificial intelligence);learning systems;mobile robots;motion control;neurocontrollers;robot vision;state-space methods","deep learning techniques;deep deterministic policy gradients algorithm;motion control;deep Q- learning;active domain;robotics-related tasks;multirotor control;attitude control;state space;continuous action space;deep reinforcement learning technique;vision-based autonomous multirotor landing maneuver;continuous state;continuous action domain;moving platform","","","29","","","","","IEEE","IEEE Conferences"
"Interaction System Based on an Avatar Projected on a Pyramidal Display","D. Loza Matovelle; S. Marcos; E. Zalama; J. Gómez García Bermejo","DISA, University of Valladolid, Valladolid, España; CARTIF Foundation, Valladolid, España; University of Valladolid, ITAP-DISA, Valladolid, España; University of Valladolid, ITAP-DISA, Valladolid, España","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3943","3948","In this paper an interaction system based on a three dimensional virtual head projected onto a pyramidal display is proposed. The proposed system makes use of a social robot behavioral architecture already developed in our lab, which allows us to interchange developments between our robotic realizations and the 3D avatar. The overall system is divided into two parts: back projection subsystem and expression generator subsystem. The back projection subsystem projects a three-dimensional avatar onto a pyramidal structure in order to achieve a sensation of depth and realism. The expression generator subsystem carries out the avatar animations using shape keys and bones, following the Facial Action Coding System (FACS). The system consists in several nodes that are integrated in ROS middleware (Robotic Operating System), and includes a user interface that makes the avatar teleoperation easier (the package is avaible in github public respository). In order to evaluate the expressiveness of the system, two sets of experiments have been performed: one to analyze the avatar's gestural ability, that is, its capability to perform expressions that can be identified by an observer, and a second experiment to measure the emotion displaying ability in terms of valence and arousal.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593740","","Avatars;Animation;Robots;Solid modeling;Face;Shape;Bones","avatars;computer animation;control engineering computing;emotion recognition;face recognition;human computer interaction;human-robot interaction;middleware;mobile robots;operating systems (computers);telerobotics","pyramidal structure;expression generator subsystem;avatar animations;avatar teleoperation;emotion displaying ability;interaction system;pyramidal display;social robot behavioral architecture;back projection subsystem;three-dimensional avatar;robotic operating system;three dimensional virtual head;3D avatar;facial action coding system;ROS middleware;user interface;avatars gestural ability","","","12","","","","","IEEE","IEEE Conferences"
"Planning Topological Navigation for Complex Indoor Environments","F. Martín; J. Ginés; D. Vargas; F. J. Rodríguez-Lera; V. Matellán","Intelligent Robotics Labs, University Rey Juan Carlos, Fuenlabrada, Spain; Intelligent Robotics Labs, University Rey Juan Carlos, Fuenlabrada, Spain; Intelligent Robotics Labs, University Rey Juan Carlos, Fuenlabrada, Spain; The CSC Research Unit, University of Luxembourg Esch-sur-Alzette, Luxembourg; The Mech., Computer and Aerospace Eng. Dept. University of León, León, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","The ability to move around the environment is one of the most important capabilities of a mobile robot. Although navigation is considered an already achieved capacity, there is still much work to be done to integrate navigation with high level reasoning and acting. Navigate in indoor environments also involve complex actions, such as opening doors, use elevators, and many others. We propose a topological navigation system based on Artificial Intelligence (AI) Planning. Starting from a symbolic representation of the environment, navigation tasks are divided into phases, in which different actions are required. This approach has demonstrated to be very effective to plan the operations of a robot at indoor environments. The final result is method compact, efficient and scalable. Our system has been successfully tested at European Robotics League in the humanoid robot Pepper.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594038","","Navigation;Planning;Task analysis;Measurement;Robot kinematics;Indoor environments","humanoid robots;mobile robots;multi-robot systems;planning (artificial intelligence)","artificial intelligence planning;topological navigation planning;symbolic representation;European Robotics League;humanoid robot Pepper;high level acting;high level reasoning;mobile robot;complex indoor environments","","","26","","","","","IEEE","IEEE Conferences"
"Computation of Safe Path Velocity for Collaborative Robots","C. Sloth; H. G. Petersen","University of Southern Denmark, SDU Robotics, Denmark; University of Southern Denmark, SDU Robotics, Denmark","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6142","6148","This paper presents a method for numerically computing the highest path velocity that a collaborative robot can attain, while complying with safety requirements. The safety requirements are obtained from ISO/TS 15066 that describes a collaborative method called power and force limiting, which specifies safe collisions between humans and robots. In particular, we assume that a path is given and compute the point-wise maximal path velocity that ensures a safe impact, i.e., the paper provides no considerations on the post impact safety.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594217","","Robots;Collision avoidance;Force;Safety;Collaboration;Effective mass;Limiting","collision avoidance;human-robot interaction;industrial robots;ISO standards;manufacturing systems;motion control;occupational safety;velocity control","safe path velocity;collaborative robot;safety requirements;collaborative method;safe collisions;point-wise maximal path velocity;post impact safety;ISO/TS 15066;power and force limiting;industrial manufacturing","","","16","","","","","IEEE","IEEE Conferences"
"Seeing the Wood for the Trees: Reliable Localization in Urban and Natural Environments","G. Tinchev; S. Nobili; M. Fallon","Oxford Robotics Institute at the University of Oxford, United Kingdom; Oxford Robotics Institute at the University of Oxford, United Kingdom; Oxford Robotics Institute at the University of Oxford, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8239","8246","In this work we introduce Natural Segmentation and Matching (NSM), an algorithm for reliable localization, using laser, in both urban and natural environments. Current state-of-the-art global approaches do not generalize well to structure-poor vegetated areas such as forests or orchards. In these environments clutter and perceptual aliasing prevents repeatable extraction of distinctive landmarks between different test runs. In natural forests, tree trunks are not distinctive, foliage intertwines and there is a complete lack of planar structure. In this paper we propose a method for place recognition which uses a more involved feature extraction process which is better suited to this type of environment. First, a feature extraction module segments stable and reliable object-sized segments from a point cloud despite the presence of heavy clutter or tree foliage. Second, repeatable oriented key poses are extracted and matched with a reliable shape descriptor using a Random Forest to estimate the current sensor's position within the target map. We present qualitative and quantitative evaluation on three datasets from different environments - the KITTI benchmark, a parkland scene and a foliage-heavy forest. The experiments show how our approach can achieve place recognition in woodlands while also outperforming current state-of-the-art approaches in urban scenarios without specific tuning.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594042","","Feature extraction;Vegetation;Three-dimensional displays;Forestry;Reliability;Clutter;Hidden Markov models","feature extraction;geophysical image processing;image matching;image segmentation;robot vision;vegetation mapping","reliable localization;urban environments;natural environments;current state-of-the-art global approaches;structure-poor vegetated areas;orchards;environments clutter;repeatable extraction;distinctive landmarks;natural forests;tree trunks;foliage intertwines;planar structure;place recognition;feature extraction module segments;reliable object-sized segments;heavy clutter;foliage-heavy forest;urban scenarios;random forest;shape descriptor","","1","18","","","","","IEEE","IEEE Conferences"
"Design, Modeling and Control of a Soft Robotic Arm","M. Hofer; R. D'Andrea","ETH Zürich, Institute for Dynamic Systems and Control, Switzerland; ETH Zürich, Institute for Dynamic Systems and Control, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1456","1463","In this paper we present the design of a hybrid robotic arm using soft, inflatable bladders for actuation. Low cost switching valves are used for pressure control, where the valve model is identified experimentally. A model of the robotic arm is derived based on system identification and used to derive a linear quadratic Gaussian controller. A method to solve limitations of the employed switching valves is proposed and experimentally proven to improve tracking performance. The closed loop control performance of the robotic arm is demonstrated by stabilizing a rotational inverted pendulum known as the Furuta pendulum.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594221","","Actuators;Valves;Manipulators;Fabrics;Welding;Switches","closed loop systems;design engineering;linear quadratic Gaussian control;manipulators;nonlinear control systems;pendulums;pressure control;stability;valves","soft robotic arm;hybrid robotic arm;soft bladders;inflatable bladders;low cost switching valves;pressure control;valve model;system identification;linear quadratic Gaussian controller;closed loop control performance;stabilization;rotational inverted pendulum;Furuta pendulum","","","29","","","","","IEEE","IEEE Conferences"
"Controller Synthesis for Discrete-Time Polynomial Systems via Occupation Measures","W. Han; R. Tedrake","Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, 77 Massachusetts Avenue, MA, 02139, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, 77 Massachusetts Avenue, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6911","6918","In this paper, we design nonlinear state feedback controllers for discrete-time polynomial dynamical systems via the occupation measure approach. We propose the discrete-time controlled Liouville equation, and use it to formulate the controller synthesis problem as an infinite-dimensional linear programming problem on measures, which is then relaxed as finite-dimensional semidefinite programming problems on moments of measures and their duals on sums-of-squares polynomials. Nonlinear controllers can be extracted from the solutions to the relaxed problems. The advantage of the occupation measure approach is that we solve convex problems instead of generally non-convex problems, and the computational complexity is polynomial in the state and input dimensions, and hence the approach is more scalable. In addition, we show that the approach can be applied to over-approximating the backward reachable set of discrete-time autonomous polynomial systems and the controllable set of discrete-time polynomial systems under known state feedback control laws. We illustrate our approach on several dynamical systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594400","","Volume measurement;Trajectory;State feedback;Mathematical model;Topology;Aerospace electronics","computational complexity;control system synthesis;convex programming;discrete time systems;linear programming;Liouville equation;multidimensional systems;nonlinear control systems;reachability analysis;set theory;stability;state feedback","discrete-time polynomial systems;occupation measures;discrete-time polynomial dynamical systems;occupation measure approach;discrete-time controlled Liouville equation;controller synthesis problem;infinite-dimensional linear programming problem;finite-dimensional semidefinite programming problems;sums-of-squares polynomials;nonlinear controllers;relaxed problems;convex problems;discrete-time autonomous polynomial systems;controllable set;nonlinear state feedback controllers;state feedback control laws;controller design;computational complexity;backward reachable set","","","25","","","","","IEEE","IEEE Conferences"
"Real-Time Motion Planning in Changing Environments Using Topology-Based Encoding of Past Knowledge","R. Fisher; B. Rosman; V. Ivan","University of the Witwatersrand, School of Computer Science and Applied Mathematics', Johannesburg, SA; University of the Witwatersrand, School of Computer Science and Applied Mathematics', Johannesburg, SA; University of Edinburgh, School of Informatics, Edinburgh, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6512","6517","Trajectory planning and replanning in complex environments often reuses very little information from the previous solutions. This is particularly evident when the motion is repeated multiple times with only a limited amount of variation between each run. To address this issue, we propose the DRM-connect algorithm, a combination of dynamic reachability maps (DRM) with lazy collision checking and a fallback strategy based on the RRT-connect algorithm which is used to repair the roadmap through further exploration. This fallback allows us to use much sparser roadmaps. Furthermore, we investigate using an approximate Reeb graph to capture the topology-persistent features of the past solutions of the problem utilising this sparsity. We evaluate DRM-connect with a Reeb graph on reaching tasks, and we compare it to state-of-the-art methods. We show that the proposed method outperforms both RRT-connect and BKPIECE algorithms in the number of collision checks required and we show that our method has the potential to scale to systems with higher number degrees of freedom.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593879","","Task analysis;Trajectory;Planning;Heuristic algorithms;Robots;Topology;Maintenance engineering","collision avoidance;encoding;graph theory;mobile robots;reachability analysis;topology","approximate Reeb graph;BKPIECE algorithms;topology-based encoding;trajectory planning;complex environments;DRM-connect algorithm;dynamic reachability maps;lazy collision checking;fallback strategy;RRT-connect algorithm;sparser roadmaps;motion planning;changing environments","","","21","","","","","IEEE","IEEE Conferences"
"Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails","M. L. Iuzzolino; M. E. Walker; D. Szafir","Department of Computer Science, University of Colorado, Boulder; Department of Computer Science, University of Colorado, Boulder; Department of Computer Science, ATLAS Institute, University of Colorado, Boulder","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","576","582","Robots hold promise in many scenarios involving outdoor use, such as search-and-rescue, wildlife management, and collecting data to improve environment, climate, and weather forecasting. However, autonomous navigation of outdoor trails remains a challenging problem. Recent work has sought to address this issue using deep learning. Although this approach has achieved state-of-the-art results, the deep learning paradigm may be limited due to a reliance on large amounts of annotated training data. Collecting and curating training datasets may not be feasible or practical in many situations, especially as trail conditions may change due to seasonal weather variations, storms, and natural erosion. In this paper, we explore an approach to address this issue through virtual-to-real-world transfer learning using a variety of deep learning models trained to classify the direction of a trail in an image. Our approach utilizes synthetic data gathered from virtual environments for model training, bypassing the need to collect a large amount of real images of the outdoors. We validate our approach in three main ways. First, we demonstrate that our models achieve classification accuracies upwards of 95% on our synthetic data set. Next, we utilize our classification models in the control system of a simulated robot to demonstrate feasibility. Finally, we evaluate our models on real-world trail data and demonstrate the potential of virtual-to-real-world transfer learning.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593883","","Cameras;Robot vision systems;Deep learning;Training;Navigation;Data collection","control engineering computing;learning (artificial intelligence);mobile robots;pattern classification","virtual-to-real-world transfer learning;deep learning models;virtual environments;model training;real-world trail data;robots;wilderness trails;outdoor trails;classification models","","","13","","","","","IEEE","IEEE Conferences"
"Haptic Feedback and Dynamic Active Constraints for Robot-Assisted Endovascular Catheterization","G. Dagnino; J. Liu; M. E. M. K. Abdelaziz; W. Chi; C. Riga; G. -. Yang","The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Faculty of Medicine, Department of Surgery & Cancer, Imperial College London, UK; The Hamlyn Centre for Robotic Surgery, Imperial College London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1770","1775","Robotic and computer assistance can bring significant benefits to endovascular procedures in terms of precision and stability, reduced radiation doses, improved comfort and access to difficult and tortuous anatomy. However, the design of current commercially available platforms tends to alter the natural bedside manipulation skills of the operator, so that the manually acquired experience and dexterity are not well utilized. Furthermore, most of these systems lack of haptic feedback, preventing their acceptance and limiting the clinical usability. In this paper a new robotic platform for endovascular catheterization, the CathBot, is presented. It is an ergonomic master-slave system with navigation system and integrated vision-based haptic feedback, designed to maintain the natural bedside skills of the vascular surgeon. Unlike previous work reported in literature, dynamic motion tracking of both the vessel walls the catheter tip is incorporated to create dynamic active constraints. The system was evaluated through a combined quantitative and qualitative user study simulating catheterization tasks on a phantom. Forces exerted on the phantom were measured. The results showed a 70% decrease in mean force and 61% decrease in maximum force when force feedback is provided. This research provides the first integration of vision-based dynamic active constraints within an ergonomic robotic catheter manipulator. The technological advances presented here, demonstrates that vision-based haptic feedback can improve the effectiveness, precision, and safety of robot-assisted endovascular procedures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593628","","Catheters;Surgery;Navigation;Force feedback;Robot sensing systems","blood vessels;catheters;ergonomics;force feedback;haptic interfaces;manipulators;medical robotics;phantoms;surgery","robot-assisted endovascular catheterization;computer assistance;reduced radiation doses;tortuous anatomy;natural bedside manipulation skills;dexterity;clinical usability;robotic platform;ergonomic master-slave system;navigation system;integrated vision-based haptic feedback;natural bedside skills;dynamic motion tracking;catheterization tasks;phantom;mean force;maximum force;force feedback;vision-based dynamic active constraints;ergonomic robotic catheter manipulator;robot-assisted endovascular procedures;CathBot;vessel walls;vascular surgeon;catheter tip","","","18","","","","","IEEE","IEEE Conferences"
"Body-Mounted Robot for Image-Guided Percutaneous Interventions: Mechanical Design and Preliminary Accuracy Evaluation","N. A. Patel; J. Yan; D. Levi; R. Monfaredi; K. Cleary; I. Iordachita","Laboratory for Computational Sensing and Robotics, Johns Hopkins University, 3400 N. Charles Street, Baltimore, MD, 21218; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, 3400 N. Charles Street, Baltimore, MD, 21218; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, 3400 N. Charles Street, Baltimore, MD, 21218; Children/s National Health System, 111 Michigan Avenue, NW Washington, DC, 20010; Children/s National Health System, 111 Michigan Avenue, NW Washington, DC, 20010; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, 3400 N. Charles Street, Baltimore, MD, 21218","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1443","1448","This paper presents a body-mounted, four degree-of-freedom (4-DOF) parallel mechanism robot for image-guided percutaneous interventions. The design of the robot is optimized to be light weight and compact such that it could be mounted to the patient body. It has a modular design that can be adopted for assisting various image-guided, needle-based percutaneous interventions such as arthrography, biopsy and brachytherapy seed placement. The robot mechanism and the control system are designed and manufactured with components compatible with imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT). The current version of the robot presented in this paper is optimized for shoulder arthrography under MRI guidance; a Z-shaped fiducial frame is attached to the robot, providing accurate and repeatable robot registration with the MR scanner coordinate system. Here we present the mechanical design of the manipulator, robot kinematics, robot calibration procedure, and preliminary bench-top accuracy assessment. The bench-top accuracy evaluation of the robotic manipulator shows average translational error of 1.01 mm and 0.96 mm in X and Z axes, respectively, and average rotational error of 3.06 degrees and 2.07 degrees about the X and Z axes, respectively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593807","","Robot kinematics;Magnetic resonance imaging;Needles;Manipulators;Computed tomography;Calibration","biomedical MRI;computerised tomography;diagnostic radiography;image registration;manipulators;medical image processing;medical robotics;needles;robot kinematics;surgery","needle-based percutaneous interventions;biopsy seed placement;brachytherapy seed placement;robot mechanism;Magnetic Resonance Imaging;repeatable robot registration;robot kinematics;robot calibration procedure;robotic manipulator;body-mounted robot;image-guided percutaneous interventions;MRI guidance;Computed Tomography;shoulder arthrography","","","17","","","","","IEEE","IEEE Conferences"
"Semantic Segmentation from Sparse Labeling Using Multi-Level Superpixels","I. Alonso; A. C. Murillo","DIIS, I3A, Universidad de Zaragoza, RoPeRt group, Spain; DIIS, I3A, Universidad de Zaragoza, RoPeRt group, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5785","5792","Semantic segmentation is a challenging problem that can benefit numerous robotics applications, since it provides information about the content at every image pixel. Solutions to this problem have recently witnessed a boost on performance and results thanks to deep learning approaches. Unfortunately, common deep learning models for semantic segmentation present several challenges which hinder real life applicability in many domains. A significant challenge is the need of pixel level labeling on large amounts of training images to be able to train those models, which implies a very high cost. This work proposes and validates a simple but effective approach to train dense semantic segmentation models from sparsely labeled data. Labeling only a few pixels per image reduces the human interaction required. We find many available datasets, e.g., environment monitoring data, that provide this kind of sparse labeling. Our approach is based on augmenting the sparse annotation to a dense one with the proposed adaptive superpixel segmentation propagation. We show that this label augmentation enables effective learning of state-of-the-art segmentation models, getting similar results to those models trained with dense ground-truth. We demonstrate the applicability of the presented approach to different image modalities in real domains (underwater, aerial and urban scenarios) with publicly available datasets.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594185","","Image segmentation;Semantics;Labeling;Training;Biological system modeling;Monitoring;Deep learning","image annotation;image segmentation;learning (artificial intelligence)","image modalities;sparse labeling data;human interaction reduction;environment monitoring data;sparse annotation augmentation;dense ground-truth;label augmentation;adaptive superpixel segmentation propagation;dense semantic segmentation models;pixel level labeling;life applicability;common deep learning models;deep learning approaches;image pixel;multilevel superpixels;effective learning","","","37","","","","","IEEE","IEEE Conferences"
"SLIP-Model-Based Dynamic Motion Transition Between Different Fixed Points in One Stride in a Leg-Wheel Transformable Robot","H. Lin; Y. Lin; P. Lin","Department of Mechanical Engineering, National Taiwan University (NTU), No.1 Roosevelt Rd. Sec.4, Taipei 106, Taiwan; Department of Mechanical Engineering, National Taiwan University (NTU), No.1 Roosevelt Rd. Sec.4, Taipei 106, Taiwan; Department of Mechanical Engineering, National Taiwan University (NTU), No.1 Roosevelt Rd. Sec.4, Taipei 106, Taiwan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2715","2720","We report on the development of a motion generation strategy that allows the robot to transit from one stable running motion to another in one stride by actively changing leg stiffness in real time. Stable motion of the robot is generated based on the stable fixed-point trajectories of the spring-loaded inverted pendulum (SLIP) model. While the transition of the ordinary SLIP model with fixed parameters gradually converges if stable, a robot that uses force control to simulate the passive spring of the SLIP can actively modulate leg-spring stiffness. This enables the robot to switch instantly to another fixed-point trajectory of the SLIP model without going through multi-stride transition. The proposed method is implemented on a leg-wheel transformable robot, TurboQuad, and is evaluated experimentally. The results confirm that the robot can successfully transit between different fixed-point trajectories.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594364","","Legged locomotion;Springs;Robot kinematics;Mathematical model;Dynamics;DC motors","force control;legged locomotion;motion control;nonlinear control systems;pendulums","stable running motion;stable fixed-point trajectories;ordinary SLIP model;passive spring;leg-spring stiffness;fixed-point trajectory;multistride transition;leg-wheel transformable robot;SLIP-model-based dynamic motion transition;motion generation strategy;force control;TurboQuad","","","23","","","","","IEEE","IEEE Conferences"
"Real-time Control of Whole-body Robot Motion and Trajectory Generation for Physiotherapeutic Juggling in VR","P. Mohammadi; M. Malekzadeh; J. Kodl; A. Mukovskiy; D. L. Wigand; M. Giese; J. J. Steil","TU Braunschweig, Institute for Robotics and Process Control (IRP), Muehlenpfordtstr. 23, Braunschweig, 38106, Germany; TU Braunschweig, Institute for Robotics and Process Control (IRP), Muehlenpfordtstr. 23, Braunschweig, 38106, Germany; Section for Computational Sensomotorics, Department of Cognitive Neurology, HIH, CIN, University Clinic Tübingen, Tübingen, Germany; Section for Computational Sensomotorics, Department of Cognitive Neurology, HIH, CIN, University Clinic Tübingen, Tübingen, Germany; Technical Faculty, Bielefeld University, Germany; Section for Computational Sensomotorics, Department of Cognitive Neurology, HIH, CIN, University Clinic Tübingen, Tübingen, Germany; TU Braunschweig, Institute for Robotics and Process Control (IRP), Muehlenpfordtstr. 23, Braunschweig, 38106, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","270","277","Motor rehabilitation is in increasingly high demand to deal with minor functional motor impairments resulting from stroke, cerebellar ataxia, or Parkinson's disease. Juggling physiotherapy has shown to induce brain plasticity and to improve coordination and balance in this context. The physiotherapy, however, relies on large number of repetitions to be effective which prompts to deploy robots to release the burden on therapists both in terms of time as well as physical strain. This paper provides a framework to enable juggling games for patients in interacting with robots through Virtual Reality (VR). A set of throwing motions is recorded from the therapist and is retargeted to the humanoid robot COMAN's wrist. The respective whole-body motion is then solved in a stack of Quadratic Programs (QP) in a real-time architecture that integrates OROCOS and Gazebo. The resulting motion is finally streamed to VR for animation of the robot and the thrown ball, which the user can catch in VR using a controller device. We regard the VR setting as an essential step towards physiotherapeutic robotic juggling, because it ensures safety of the patients and effective testing of the methods and already has potential for actual therapeutic intervention. The control framework, however, is already validated in this paper for switching to full real-time operation on the physical robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593632","","Trajectory;Real-time systems;Robot kinematics;Task analysis;Medical treatment;Switches","brain;control engineering computing;diseases;humanoid robots;medical computing;medical robotics;motion control;neurophysiology;patient rehabilitation;patient treatment;quadratic programming;trajectory control;virtual reality","whole-body robot motion;trajectory generation;physiotherapeutic juggling;motor rehabilitation;functional motor impairments;cerebellar ataxia;Parkinson's disease;juggling physiotherapy;brain plasticity;physical strain;juggling games;throwing motions;whole-body motion;real-time architecture;controller device;VR setting;physiotherapeutic robotic juggling;real-time operation;physical robot;virtual reality;humanoid robot COMAN wrist;quadratic program;real-time control","","","33","","","","","IEEE","IEEE Conferences"
"Delineating boundaries of feasibility between robot designs","S. Ghasemlou; J. M. OKane; D. A. Shell","Department of Computer Science & Engineering, University of South Carolina, Columbia, South Carolina, United States; Department of Computer Science & Engineering, University of South Carolina, Columbia, South Carolina, United States; Department of Computer Science & Engineering, Texas A&M University, College Station, Texas, United States","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","422","429","Motivated by the need for tools to aid in the design of effective robots, we examine how to determine the role that particular sensing and actuator resources play in enabling a robot to achieve useful ends. Rather than merely asking “will this sensor suffice?” we classify general modifications to the set of sensors and actuators based on the feasibility of accomplishing given tasks using these sets. The goal is to probe the boundary between modifications that are destructive on a given planning problem, and modifications that are not. Since this boundary itself can be impractically large, classic search methods are of no avail to summarize discriminatory features on this boundary. Instead, we propose a decision tree learning method to efficiently construct a compact implicit representation of the boundary. The idea is to allow the designer to use prior knowledge to constrain the search, then use the tool to probe the boundary subject to those constraints, gaining insight into the information necessary for a robot to ensure task achievement. Ultimately we envision a interactive process where additional constraints are repeatedly included as new light is shed. We aim to pave the way for interactive tools that help the roboticist navigate the complexities of the design space. We describe an implementation of this approach along with experimental results that show that the method can construct decision trees with explanatory value. Our experiments suggest that some domain knowledge (specifically picking features that emphasize monotonicity) substantially improves running-time with only negligible reduction in accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593811","","Robot sensing systems;Planning;Actuators;Task analysis;Tools;Decision trees","decision trees;learning (artificial intelligence);mobile robots;pattern classification;planning (artificial intelligence)","sensors;actuators;classic search methods;planning problem;actuator resources;effective robots;robot designs;delineating boundaries;domain knowledge;design space;interactive tools;interactive process;boundary subject;compact implicit representation;decision tree learning method;discriminatory features","","","24","","","","","IEEE","IEEE Conferences"
"Improved Quadcopter Disturbance Rejection Using Added Angular Momentum","N. Bucki; M. W. Mueller","University of California, High Performance Robotics Lab, Berkeley, CA, 94703, USA; University of California, High Performance Robotics Lab, Berkeley, CA, 94703, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4164","4170","This paper presents a novel quadcopter design with an added momentum wheel for enhanced stability. The novel vehicle has improved torque disturbance rejection capabilities compared to a standard quadcopter. An analysis of the vehicle dynamics shows that the effect of torque disturbances decreases monotonically with increasing angular momentum of the momentum wheel. A framework for choosing the mass moment of inertia and speed of the momentum wheel is given based on an upper bound on the allowable energy stored in the wheel. Theoretical results are experimentally validated by comparing responses to torque impulses applied to the vehicle with and without the momentum wheel spinning.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594109","","Wheels;Vehicle dynamics;Propellers;Torque;Attitude control;Angular velocity;State feedback","attitude control;control system synthesis;helicopters;position control;stability;torque control;vehicle dynamics;wheels","quadcopter disturbance rejection;added angular momentum;novel quadcopter design;added momentum wheel;enhanced stability;torque disturbance rejection capabilities;standard quadcopter;vehicle dynamics;torque disturbances;torque impulses","","","17","","","","","IEEE","IEEE Conferences"
"HMAPs - Hybrid Height- Voxel Maps for Environment Representation","L. Garrote; C. Premebida; D. Silva; U. J. Nunes","Department of Electrical and Computer Engineering, University of Coimbra, Institute of Systems and Robotics, Portugal; Department of Electrical and Computer Engineering, University of Coimbra, Institute of Systems and Robotics, Portugal; Department of Electrical and Computer Engineering, University of Coimbra, Institute of Systems and Robotics, Portugal; Department of Electrical and Computer Engineering, University of Coimbra, Institute of Systems and Robotics, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1197","1203","This paper presents a hybrid 3D-like grid-based mapping approach, that we called HMAP, used as a reliable and efficient 3D representation of the environment surrounding a mobile robot. Considering 3D point-clouds as input data, the proposed mapping approach addresses the representation of height-voxel (HVoxel) elements inside the HMAP, where free and occupied space is modeled through HVoxels, resulting in a reliable method for 3D representation. The proposed method corrects some of the problems inherent to the representation of complex environments based on 2D and 2.5D representations, while keeping an updated grid representation. Additionally, we also propose a complete pipeline for SLAM based on HMAPs. Indoor and outdoor experiments were carried out to validate the proposed representation using data from a Microsoft Kinect One (indoor) and a Velodyne VLP-16 LiDAR (outdoor). The obtained results show that HMAPs can provide a more detailed view of complex elements in a scene when compared to a classic 2.5D representation. Moreover, validation of the proposed SLAM approach was carried out in an outdoor dataset with promising results, which lay a foundation for further research in the topic.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594113","","Two dimensional displays;Three-dimensional displays;Simultaneous localization and mapping;Pipelines;Ray tracing;Planning;Indexing","mobile robots;optical radar;path planning;robot vision;SLAM (robots)","2.5D representation;Microsoft Kinect One;SLAM approach;complex elements;Velodyne VLP-16 LiDAR;updated grid representation;complex environments;reliable method;occupied space;free space;HVoxel;height-voxel elements;3D point-clouds;mobile robot;grid-based mapping approach;environment representation;hybrid height- voxel maps;HMAP","","","13","","","","","IEEE","IEEE Conferences"
"Structure preserving Multi-Contact Balance Control for Series-Elastic and Visco-Elastic Humanoid Robots","A. Werner; B. Henze; M. Keppler; F. Loeffl; S. Leyendecker; C. Ott","Institute for Robotics and Mechatronics, German Aerospace Center (DLR); Institute for Robotics and Mechatronics, German Aerospace Center (DLR); Institute for Robotics and Mechatronics, German Aerospace Center (DLR); Institute for Robotics and Mechatronics, German Aerospace Center (DLR); Department of Mechanical Engineering, University of Erlangen-Nuremberg; Institute for Robotics and Mechatronics, German Aerospace Center (DLR)","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1233","1240","This paper proposes an integration of multi-body and actuator control for multi-contact balancing for robots with highly elastic joints. Inspired by the structure preserving control concept for series-elastic fixed-base robots, the presented approach aims to minimize the control effort by keeping the system structure intact. Balancing on multiple contacts requires to solve the force distribution problem. In locomotion, contacts change quickly, requiring a swift redistribution of contact forces. This is a challenge for elastic robots as the actuator dynamics and limits prevent instantaneous changes of contact forces. The proposed dynamically consistent force distribution is implemented as a model predictive controller which resolves redundancy while complying with contact force and actuator constraints.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593596","","Force;Actuators;Robot kinematics;Dynamics;Task analysis;Humanoid robots","actuators;elasticity;humanoid robots;legged locomotion;predictive control;robot dynamics","visco-elastic humanoid robots;actuator control;multicontact balancing;force distribution problem;actuator dynamics;dynamically consistent force distribution;model predictive controller;contact force;actuator constraints;multicontact balance control;series-elastic humanoid robos;structure preservation control concept;locomotion","","","18","","","","","IEEE","IEEE Conferences"
"Reducing the Computational Complexity of Mass-Matrix Calculation for High DOF Robots","M. Safeea; R. Bearee; P. Neto","University of Coimbra, Department of Mechanical Engineering, Portugal; Arts et Métiers, LISPEN, Lille, France; University of Coimbra, Department of Mechanical Engineering, Coimbra, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5614","5619","Increasingly, robots have more degrees of freedom (DOF), imposing a need for calculating more complex dynamics. As a result, better efficiency in carrying out dynamics computations is becoming more important. In this study, an efficient method for computing the joint space inertia matrix (JSIM) for high DOF serially linked robots is addressed. We call this method the Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ). GDAHJ is non-symbolic, preserve simple formulation, and it is convenient for numerical implementation. This is achieved by simplifying the way to recursively derive the mass-matrix exploiting the unique property of each column of the JSIM and minimizing the number of operations with O(n2) complexity. Results compare favorably with existing methods, achieving better performance over state-of-the-art by Featherstone when applied for robots with more than 13 DOF.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593775","mass-matrix;dynamics;Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ);high DOF robots","Acceleration;Mathematical model;Heuristic algorithms;Robot kinematics;Dynamics;Computational complexity","computational complexity;manipulator dynamics;matrix algebra;position control","high DOF robots;geometric dynamics algorithm for high number of robot joints;GDAHJ;JSIM;joint space inertia matrix;dynamics computations;degrees of freedom;mass-matrix calculation;computational complexity","","","21","","","","","IEEE","IEEE Conferences"
"Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality","J. S. Dyrstad; E. Ruud Øye; A. Stahl; J. Reidar Mathiassen","SINTEF Ocean AS, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway; Department of Engineering Cybernetics, NTNU, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7185","7192","We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593954","","Robots;Task analysis;Three-dimensional displays;Grippers;Grasping;Cameras;Virtual reality","convolutional neural nets;grippers;learning (artificial intelligence);mobile robots;pose estimation;virtual reality","teaching;gripper;domain randomization approach;depth imaging;3D occupancy grid;robot imitation learning;deep 3D convolutional neural network;virtual robot;grasp real fish;virtual reality;human supervisor","","","19","","","","","IEEE","IEEE Conferences"
"Realtime State Estimation with Tactile and Visual Sensing for Inserting a Suction-held Object","K. Yu; A. Rodriguez","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Mechanical Engineering Department, Massachusetts Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1628","1635","We develop a real-time state estimation system to recover the pose and contact formation of an object relative to its environment. In this paper, we focus on the application of inserting an object picked by a suction cup into a tight space, a key technology for robotic packaging. We propose a framework that fuses tactile and visual sensing. Visual sensing is versatile and non-intrusive, but suffers from occlusions and limited accuracy, especially for tasks involving contact. Tactile sensing is local, but provides accuracy and robustness to occlusions. The proposed algorithm to fuse them is based on iSAM, an on-line estimation technique, which we use to incorporate kinematic measurements from the robot, contact geometry of the object and the container, and visual tracking. In this paper, we generalize previous results in planar settings [1] to a 3D task with more complex contact interactions. A key challenge is that we do not observe contact locations between the suction-held object and the container directly. We propose a data-driven method to infer the contact formation, which is then used in real-time by the state estimator. We demonstrate and evaluate the algorithm in a setup instrumented to provide groundtruth.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594077","","Robot sensing systems;Visualization;State estimation;Task analysis;Containers","mobile robots;robot kinematics;robot vision;state estimation;tactile sensors","visual sensing;suction-held object;real-time state estimation system;robotic packaging;tactile sensing;on-line estimation technique;contact geometry;complex contact interactions;iSAM;robot kinematic measurement;planar settings;data-driven method","","","22","","","","","IEEE","IEEE Conferences"
"Approaches for Action Sequence Representation in Robotics: A Review","H. Nakawala; P. J. S. Goncalves; P. Fiorini; G. Ferringo; E. D. Momi","University of Verona, Department of Computer Science, Verona, Via S. Francesco, 22, 37129; Castelo Branco, Portugal and IDMEC, Instituto Superior Técnico, Universidade de Lisboa, Instituto Politcnico de Castelo Branco, Lisboa, Portugal; University of Verona, Department of Computer Science, Verona, Via S. Francesco, 22, 37129; Information and Bioengineering (DEIB), Politecnico di Milano, Department of Electronics, Milan, Piazza Leonardo da Vinci, 32, 20133, Italy; Information and Bioengineering (DEIB), Politecnico di Milano, Department of Electronics, Milan, Piazza Leonardo da Vinci, 32, 20133, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5666","5671","Robust representation of actions and its sequences for complex robotic tasks would transform robot's understanding to execute robotic tasks efficiently. The challenge is to understand action sequences for highly unstructured environments and to represent and construct action and action sequences. In this manuscript, we present a review of literature dealing with representation of action and action sequences for robot task planning and execution. The methodological review was conducted using Google Scholar and IEEE Xplore, searching the specific keywords. This manuscript gives an overview of current approaches for representing action sequences in robotics. We propose a classification of different methodologies used for action sequences representation and describe the most important aspects of the reviewed publications. This review allows the reader to understand several options that do exist in the research community, to represent and deploy such action representations in real robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594256","","Task analysis;Planning;Calculus;Strips;Service robots;Proposals","reviews;robots","robotics;action sequences representation;robots;action sequence representation;complex robotic tasks;robot task","","","53","","","","","IEEE","IEEE Conferences"
"Semantically Meaningful View Selection","J. Guérin; O. Gibaru; E. Nyiri; S. Thieryl; B. Boots","Arts et Metiers ParisTech, Laboratoire d'Ingénierie des Systèmes Physiques Et Numériques, Lille, France; Arts et Metiers ParisTech, Laboratoire d'Ingénierie des Systèmes Physiques Et Numériques, Lille, France; Arts et Metiers ParisTech, Laboratoire d'Ingénierie des Systèmes Physiques Et Numériques, Lille, France; Arts et Metiers ParisTech, Laboratoire d'Ingénierie des Systèmes Physiques Et Numériques, Lille, France; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, 30332","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1061","1066","An understanding of the nature of objects could help robots to solve both high-level abstract tasks and improve performance at lower-level concrete tasks. Although deep learning has facilitated progress in image understanding, a robot's performance in problems like object recognition often depends on the angle from which the object is observed. Traditionally, robot sorting tasks rely on a fixed top-down view of an object. By changing its viewing angle, a robot can select a more semantically informative view leading to better performance for object recognition. In this paper, we introduce the problem of semantic view selection, which seeks to find good camera poses to gain semantic knowledge about an observed object. We propose a conceptual formulation of the problem, together with a solvable relaxation based on clustering. We then present a new image dataset consisting of around 10k images representing various views of 144 objects under different poses. Finally we use this dataset to propose a first solution to the problem by training a neural network to predict a “semantic score” from a top view image and camera pose. The views predicted to have higher scores are then shown to provide better clustering results than fixed top-down views.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593524","","Cameras;Semantics;Robot vision systems;Task analysis;Feature extraction;Measurement","feature extraction;image classification;learning (artificial intelligence);manipulators;neural nets;object recognition;pattern clustering;pose estimation;robot vision","meaningful view selection;high-level abstract tasks;lower-level concrete tasks;deep learning;image understanding;object recognition;robot sorting tasks;fixed top-down view;viewing angle;semantically informative view;semantic view selection;semantic knowledge;observed object;image dataset;semantic score;view image;camera","","","16","","","","","IEEE","IEEE Conferences"
"Weighted Hybrid Admittance-Impedance Control with Human Intention Based Stiffness Estimation for Human-Robot Interaction","H. Kim; J. Kwon; Y. Oh; B. J. You; W. Yang","Kwangwoon University, Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea; Korea Institute of Science and Technology (KIST), Seoul, Republic of Korea; Korea Institute of Science and Technology (KIST), Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","In a human-robot interaction (HRI) device that performs physical collaboration operations in constant contact with the user, admittance control and impedance control are generally used. Since the two controllers exhibit opposite performances depending on the stiffness condition, controllers capable of dealing with various magnitudes of stiffness are required. As such, this study proposes hybrid control that adjusts the control distribution ratios of admittance control and impedance control based on the operating frequency analysis to react to the user intention and various stiffness conditions in real time. The proposed controller algorithm exhibited lower overshoot than impedance control in the step input response simulation, faster response speed compared to admittance control in the response simulation for 0-5 Hz input frequencies, and the smallest vibration magnitude and number of vibrations in the case of a virtual wall collision, resulting in improved performance compared to existing control methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594435","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594435","","Impedance;Admittance;Force;Manipulators;Stability analysis;Mathematical model","biomechanics;control engineering computing;elastic constants;haptic interfaces;human-robot interaction;manipulator dynamics;vibrations","human intention based stiffness estimation;HRI device;frequency analysis;input response simulation;vibration magnitude;virtual wall collision;control distribution ratios;physical collaboration operations;human-robot interaction device;weighted hybrid admittance-impedance control","","","16","","","","","IEEE","IEEE Conferences"
"Robust LIDAR Localization for Autonomous Driving in Rain","C. Zhang; M. H. Ang; D. Rus","Singapore-MIT Alliance for Research and Technology Centre, Singapore; National University of Singapore, Singapore; Massachusetts Institute of Technology, Cambridge, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3409","3415","This paper introduces a map-based localization method aiming to increase robustness in rainy conditions. This method utilizes two types of features: ground reflectivity features and vertical features extracted from 3D LIDAR scans and builds vehicle pose belief with two filters: a histogram filter and a particle filter. The posterior distributions from the two filters are integrated to estimate vehicle poses. This method exploits advantages of both features and filters, compensating respective weakness to deal with complex urban environments. Testing was performed in the fair and rainy weather. Road test results prove robustness and reliability of the proposed method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593703","","Feature extraction;Three-dimensional displays;Laser radar;Histograms;Rain;Measurement by laser beam;Two dimensional displays","feature extraction;mobile robots;optical radar;particle filtering (numerical methods);stereo image processing;traffic engineering computing","3D LIDAR scans;histogram filter;particle filter;posterior distributions;vehicle poses;complex urban environments;fair weather;rainy weather;robust LIDAR localization;autonomous driving;map-based localization method;rainy conditions;ground reflectivity features;vertical features extraction","","","23","","","","","IEEE","IEEE Conferences"
"Development of a Pneumatically Driven Flexible Finger with Feedback Control of a Polyurethane Bend Sensor","Y. Mori; M. Zhu; H. Kim; A. Wada; M. Mitsuzuka; Y. Tajitsu; S. Kawamura","Ritsumeikan University, Engineering and Robotics, Shiga, 1-1-1 Noji-Higashi, Kusatsu, 525-8577, Japan; Ritsumeikan University, Ritsumeikan Global Innovation Research Organization, Shiga, 1-1-1 Noji-Higashi, Kusatsu, 525-8577, Japan; Ritsumeikan University, Engineering and Robotics, Shiga, 1-1-1 Noji-Higashi, Kusatsu, 525-8577, Japan; Ritsumeikan University, Engineering and Robotics, Shiga, 1-1-1 Noji-Higashi, Kusatsu, 525-8577, Japan; MITUSI CHEMICALS, INC., Chiba, 580–32 Nagaura, Sodegaura-City, 299-0265, Japan; Kansai University, Vice-Dean of Faculty of Engineering Science, Osaka, 3-3-35 Yamate-cho, Suita-shi, 564-8680, Japan; Ritsumeikan University, Engineering and Robotics, Shiga, 1-1-1 Noji-Higashi, Kusatsu, 525-8577, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5952","5957","A pneumatically-driven flexible finger equipped with a flexible sensor is realized for improving the performance of the soft robotic hand. First, we propose a flexible angle estimation sensor. This sensor measures the change in the amount of light passing through polyurethane material and estimates the angle with high repeatability. Next, we design a flexible finger that makes this sensor easy to incorporate. The flexible fingers are produced with a multi-material 3D printer that can use flexible material. The flexible finger can accommodate the proposed flexible sensor within it. It is possible to place the sensor's signal line in the air pressure pipeline. Because the flexible finger is produced with a 3D printer, variations in each model's characteristics are small as compared with manufacturing through molding. In this paper, we show an improvement of positional accuracy in the proposed flexible finger using angle feedback control from the proposed sensor. The effectiveness of this sensor is also shown to solve the problem of vibration problems for the flexible finger during high speed motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594081","","Robot sensing systems;Optical sensors;Cameras;Optical fiber amplifiers;Voltage measurement;Three-dimensional displays;Printers","bending;dexterous manipulators;feedback;medical robotics;pipelines;pneumatic control equipment;pneumatic systems;position control;sensors;tactile sensors;vibrations","flexible material;flexible angle estimation sensor;flexible sensor;pneumatically driven flexible finger","","","14","","","","","IEEE","IEEE Conferences"
"Master-Slave Coordination Using Virtual Constraints for a Redundant Dual-Arm Haptic Interface","M. M. Ghazaei Ardakani; M. Karlsson; K. Nilsson; A. Robertsson; R. Johansson","Istituto Italiano di Tecnologia (IIT), Department of Advanced Robotics (ADVR), Genoa, Via Morego 30, 16163, Italy; LTH, Lund University, Members of the LCCC Linnaeus Center, The ELLIIT Excellence Center at Lund University, Department of Automatic Control, Lund, SE-221 00, Sweden; LTH, Lund University, Department of Computer Science, Lund, SE-221 00; LTH, Lund University, Members of the LCCC Linnaeus Center, The ELLIIT Excellence Center at Lund University, Department of Automatic Control, Lund, SE-221 00, Sweden; LTH, Lund University, Department of Computer Science, Lund, SE-221 00","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8751","8757","Programming robots for tasks involving force interaction is difficult, since both the knowledge of the task and the dynamics of the robots are necessary. An immersive haptic interface for task demonstration is proposed, where the operator can sense and act through the robot. This is achieved by coupling two robotic systems with virtual constraints such that they have the same coordinates in the operational space disregarding a fixed offset. Limitations caused by the singular configurations or the reach of the robots are naturally reflected to either side as haptic feedback.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594260","","Robot kinematics;Task analysis;Haptic interfaces;Manipulators;Kinematics;Tools","force feedback;redundant manipulators","master-slave coordination;virtual constraints;redundant dual-arm haptic interface;force interaction;immersive haptic interface;task demonstration;robotic systems;haptic feedback","","","36","","","","","IEEE","IEEE Conferences"
"Development of Low-Inertia High-Stiffness Manipulator LIMS2 for High-Speed Manipulation of Foldable Objects","H. Song; Y. Kim; J. Yoon; S. Yun; J. Seo; Y. Kim","Cheonan-City, Rep. of Korea, Korea University of Technology and Education (Koreatech); Cheonan-City, Rep. of Korea, Korea University of Technology and Education (Koreatech); Cheonan-City, Rep. of Korea, Korea University of Technology and Education (Koreatech); Cheonan-City, Rep. of Korea, Korea University of Technology and Education (Koreatech); Cheonan-City, Rep. of Korea, Korea University of Technology and Education (Koreatech); Cheonan-City, Rep. of Korea, Korea University of Technology and Education (Koreatech)","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4145","4151","In this paper, a dual-arm robot system for high-speed manipulations, which is named LIMS2-AMBIDEX and is developed to compete in the IROS2018 Robotic Challenge, is presented. It has two seven-degrees-of-freedom (DO F) lightweight arms, a three-DOF head, and a one-DOF gripper to manipulate foldable objects. Because all the heavy actuators are placed at the shoulder, it has remarkably low mass beyond the shoulder (2.63 kg), which guarantees an inherent safety at high speeds. Utilizing tension-amplification mechanisms, the high stiffness and strength are achieved, and thus it has the control performance comparable to conventional industrial manipulators. A unique three-DOF wrist mechanism, whose motions directly represent the quaternion values of the joint orientation, can manipulate objects without singular points in the entire range of motion. In order to utilize the object's inertia during rapid manipulation, the gripper was specially designed: it has a one-DOF finger to grasp the upper rib of the foldable fan and two supporting forks to grasp the bottom rib stably. For real-time performance and increased scalability, a software framework was developed based on Robot Operating System (ROS). The real-time capability is achieved by using the real-time development framework Xenomai and the high-speed communication protocol EtherCAT. As most of the algorithms are implemented in the distributed nodes using ROS, it is convenient to expand, improve, and replace the algorithms. Consequentially, the entire motion of the Fan Robotic Challenge Phase I Modality B required 1.05 s, which is substantially faster than a similar manipulation by most humans.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594005","","Wrist;Fans;Robots;Elbow;Shoulder;Grippers;Actuators","actuators;control engineering computing;dexterous manipulators;elastic constants;fans;grippers;manipulator dynamics;manipulator kinematics;motion control;operating systems (computers);protocols","low-inertia high-stiffness manipulator;high-speed manipulation;foldable objects;dual-arm robot system;LIMS2-AMBIDEX;IROS2018 Robotic Challenge;seven-degrees-of-freedom;foldable fan;Fan Robotic Challenge Phase;high-speed communication protocol;tension-amplification mechanisms;gripper;robot operating system;Xenomai;real-time development framework;EtherCAT;software framework;mass 2.63 kg","","","8","","","","","IEEE","IEEE Conferences"
"Hallucinating Robots: Inferring Obstacle Distances from Partial Laser Measurements","J. Lundell; F. Verdoja; V. Kyrki","Aalto University, School of Electrical Engineering, Finland; Aalto University, School of Electrical Engineering, Finland; Aalto University, School of Electrical Engineering, Finland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4781","4787","Many mobile robots rely on 2D laser scanners for localization, mapping, and navigation. However, those sensors are unable to correctly provide distance to obstacles such as glass panels and tables whose actual occupancy is invisible at the height the sensor is measuring. In this work, instead of estimating the distance to obstacles from richer sensor readings such as 3D lasers or RGBD sensors, we present a method to estimate the distance directly from raw 2D laser data. To learn a mapping from raw 2D laser distances to obstacle distances we frame the problem as a learning task and train a neural network formed as an autoencoder. A novel configuration of network hyperparameters is proposed for the task at hand and is quantitatively validated on a test set. Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the trained network can successfully infer obstacle distances from partial 2D laser readings.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594399","","Lasers;Two dimensional displays;Measurement by laser beam;Robot sensing systems;Neural networks","collision avoidance;distance measurement;learning (artificial intelligence);mobile robots;neural nets;optical scanners","hallucinating robots;obstacle distances;partial laser measurements;mobile robots;2D laser scanners;glass panels;richer sensor readings;RGBD sensors;raw 2D laser data;raw 2D laser distances;partial 2D laser readings","","","20","","","","","IEEE","IEEE Conferences"
"Improving indoor robots localisation by fusing different sensors","B. P. Alvarado; F. Matía; R. Galán","Centre for Automation and Robotics (CAR) at the UPM-CSIC, Madrid, Spain; Full Professor at Universidad Politécnica de Madrid, Madrid, Spain; Full Professor at Universidad Politécnica de Madrid, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2616","2623","Indoor mobile robots navigation must use external sensors to complement odometry. This paper analyses two different external sensors such as a laser LMS-200 and an omnidirectional camera Mobotix C2S. Experiments with only one of these sensors and with both integrated are carried out on a tour guide robot in order to obtain conclusions about their contribution to robot pose estimation, and how to locate external landmarks in the environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593667","","Cameras;Measurement by laser beam;Lasers;Robot vision systems","cameras;mobile robots;navigation;path planning;pose estimation","laser LMS-200;omnidirectional camera Mobotix C2S;tour guide robot;external landmarks;indoor mobile robots navigation;odometry;external sensors;indoor robots localisation","","","13","","","","","IEEE","IEEE Conferences"
"Laser Map Aided Visual Inertial Localization in Changing Environment","X. Ding; Y. Wang; D. Li; L. Tang; H. Yin; R. Xiong","State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4794","4801","Long-term visual localization in outdoor environment is a challenging problem, especially faced with the cross-seasonal, bi-directional tasks and changing environment. In this paper we propose a novel visual inertial localization framework that localizes against the LiDAR-built map. Based on the geometry information of the laser map, a hybrid bundle adjustment framework is proposed, which estimates the poses of the cameras with respect to the prior laser map as well as optimizes the state variables of the online visual inertial odometry system simultaneously. For more accurate crossmodal data association, the laser map is optimized using multisession laser and visual data to extract the salient and stable subset for visual localization. To validate the efficiency of the proposed method, we collect data in south part of our campus in different seasons, along the same and opposite-direction route. In all sessions of localization data, our proposed method gives satisfactory results, and shows the superiority of the hybrid bundle adjustment and map optimization<sup>1</sup>.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593846","","Visualization;Lasers;Bundle adjustment;Laser radar;Robots;Cameras","cameras;geometry;optical radar;optimisation;robot vision;SLAM (robots)","map optimization;changing environment;bi-directional tasks;LiDAR-built map;online visual inertial odometry system;laser map aided visual inertial localization;geometry information;crossmodal data association;multisession laser","","","31","","","","","IEEE","IEEE Conferences"
"Evolving a Sensory-Motor Interconnection for Dynamic Quadruped Robot Locomotion Behavior","A. Aulia Saputra; W. Hong Chin; J. Botzheim; N. Kubota","Tokyo Metropolitan University, Hino, Tokyo, 191-0065, Japan; Tokyo Metropolitan University, Hino, Tokyo, 191-0065, Japan; János Botzheim is with Budapest University of Technology and Economics, Budapest, 111, Hungary; Tokyo Metropolitan University, Hino, Tokyo, 191-0065, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7089","7095","In this paper, we present a novel biologically inspired evolving neural oscillator for quadruped robot locomotion to minimize constraints during the locomotion process. The proposed sensory-motor coordination model is formed by the interconnection between motor and sensory neurons. The model utilizes Bacterial Programming to reconstruct the number of joints and neurons in each joint based on environmental conditions. Bacterial Programming is inspired by the evolutionary process of bacteria that includes bacterial mutation and gene transfer process. In this system, either the number of joints, the number of neurons, or the interconnection structure are changing dynamically depending on the sensory information from sensors equipped on the robot. The proposed model is simulated in computer for realizing the optimization process and the optimized structure is then applied to a real quadruped robot for locomotion process. The optimizing process is based on tree structure optimization to simplify the sensory-motor interconnection structure. The proposed model was validated by series of real robot experiments in different environmental conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593671","","Neurons;Legged locomotion;Robot sensing systems;Microorganisms;Robot kinematics;Optimization","legged locomotion;optimisation;robot dynamics;trees (mathematics)","dynamic quadruped robot locomotion;sensory-motor coordination model;sensory neurons;neural oscillator;bacterial programming;sensory-motor interconnection structure;tree structure optimization;gene transfer process;bacterial mutation","","","16","","","","","IEEE","IEEE Conferences"
"Continuous State-Action-Observation POMDPs for Trajectory Planning with Bayesian Optimisation","P. Morere; R. Marchant; F. Ramos","The University of Sydney; The University of Sydney; The University of Sydney","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8779","8786","Decision making under uncertainty is a challenging task, especially when dealing with complex robotics scenarios. The Partially Observable Markov Decision Process (POMDP) framework, designed to solve this problem, was subject to much work lately. Most POMDP solvers, however, focus on planning in discrete state, action and/or observations spaces, which does not truly reflect the complexity of most real world problems. This paper addresses the issue by devising a method for solving POMDPs with continuous state, action and observations spaces. The proposed planner, Continuous Belief Tree Search (CBTS), uses Bayesian Optimisation (BO) to dynamically sample promising actions while constructing a belief tree. This dynamic sampling allows for richer action selection than offline action discretisation. CBTS is complemented by a novel trajectory generation technique, relying on the theory of Reproducing Kernel Hilbert Spaces (RKHS), yielding trajectories amenable for robotics applications. The resulting trajectory planner kCBTS outperforms other continuous planners on space modelling and robot parking problems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593850","","Trajectory;Planning;Robots;Optimization;Kernel;Bayes methods;Mathematical model","belief networks;decision making;decision theory;Hilbert spaces;Markov processes;mobile robots;optimisation;path planning;trees (mathematics)","trajectory planning;POMDP solvers;CBTS;dynamic sampling;robot parking problems;bayesian optimisation;partially observable Markov decision process;reproducing kernel Hilbert spaces;kCBTS;continuous belief tree search;RKHS","","","25","","","","","IEEE","IEEE Conferences"
"An Active Stabilizer for Cable-Driven Parallel Robot Vibration Damping","M. Lesellier; L. Cuvillon; J. Gangloff; M. Gouttefarde","CNRS, LIRMM University of Montpellier, Montpellier, France; Icube Laboratory, University of Strasbourg, France; Icube Laboratory, University of Strasbourg, France; CNRS, LIRMM University of Montpellier, Montpellier, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5063","5070","Cable-Driven Parallel Robots (CDPRs) can execute fast motions across a large workspace. However, these performances are reached at the cost of a relatively low stiffness which often yields parasitic vibrations at the CDPR mobile platform. In this paper, vibration damping of CDPRs is addressed by means of an original active stabilizer consisting of actuated rotating arms installed on-board the CDPR mobile platform. A control strategy for the whole system, which consists of the CDPR and the stabilizer, and with one purpose for each-position control for the platform and vibration damping for the stabilizer-is designed. The system being controlled at two different time scales, the singular perturbation theory can be used to prove the stability of the corresponding closed-loop system. The efficiency of the proposed device and control strategy is tested in simulations in the case of a planar 3-DOF CDPR equipped with a three-arm stabilizer.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594148","","Vibrations;Damping;Actuators;Stability analysis;Symmetric matrices;Torque;Jacobian matrices","actuators;cables (mechanical);closed loop systems;damping;manipulator kinematics;position control;vibration control;vibrations","parasitic vibrations;CDPR mobile platform;vibration damping;actuated rotating arms;control strategy;planar 3-DOF CDPR;three-arm stabilizer;cable-driven parallel robots;active stabilizer;position control;cable-driven parallel robot vibration;closed-loop system","","","32","","","","","IEEE","IEEE Conferences"
"Deep Reinforcement Learning for Audio-Visual Gaze Control","S. Lathuilière; B. Massé; P. Mesejo; R. Horaud","INRIA Grenoble Rhône-Alpes, Univ. Grenoble Alpes; INRIA Grenoble Rhône-Alpes, Univ. Grenoble Alpes; INRIA Grenoble Rhône-Alpes, Univ. Grenoble Alpes; INRIA Grenoble Rhône-Alpes, Univ. Grenoble Alpes","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1555","1562","We address the problem of audio-visual gaze control in the specific context of human-robot interaction, namely how controlled robot motions are combined with visual and acoustic observations in order to direct the robot head towards targets of interest. The paper has the following contributions: (i) a novel audio-visual fusion framework that is well suited for controlling the gaze of a robotic head; (ii) a reinforcement learning (RL) formulation for the gaze control problem, using a reward function based on the available temporal sequence of camera and microphone observations; and (iii) several deep architectures that allow to experiment with early and late fusion of audio and visual data. We introduce a simulated environment that enables us to learn the proposed deep RL model without the need of spending hours of tedious interaction. By thoroughly experimenting on a publicly available dataset and on a real robot, we provide empirical evidence that our method achieves state-of-the-art performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594327","","Visualization;Cameras;Robot vision systems;Robot kinematics;Reinforcement learning","gaze tracking;human-robot interaction;learning (artificial intelligence)","deep reinforcement;audio-visual gaze control;human-robot interaction;controlled robot motions;visual observations;acoustic observations;robot head;robotic head;reinforcement learning formulation;gaze control problem;audio data;visual data;audio-visual fusion framework;RL;microphone observations;deep architectures","","","27","","","","","IEEE","IEEE Conferences"
"Bayesian Information Recovery from CNN for Probabilistic Inference","D. Kopitkov; V. Indelman","Technion - Israel Institute of Technology, Technion Autonomous Systems Program (TASP), Haifa, 32000, Israel; Technion - Israel Institute of Technology, Department of Aerospace Engineering, Haifa, 32000, Israel","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7795","7802","Typical inference approaches that work with high-dimensional visual measurements use hand-engineered image features (e.g, SIFT) that require combinatorial data association, or predict only hidden state mean without considering its uncertainty and multi-modality aspects. We develop a novel approach to infer system hidden state from visual observations via CNN features which are outputs of a CNN classifier. To that end, at pre-deployment stage we use neural networks to learn a generative viewpoint-dependent model of CNN features given the robot pose and approximate this model by a spatially-varying Gaussian distribution. Further, at deployment this model is utilized within a Bayesian framework for probabilistic inference, considering a robot localization problem. Our method does not involve data association and provides uncertainty covariance of the final estimation. Moreover, we show empirically that the CNN feature likelihood is unimodal which simplifies the inference task. We test our method in a simulated Unreal Engine environment, where we succeed to retrieve high-level state information from CNN features and produce trajectory estimation with high accuracy. Additionally, we analyze robustness of our approach to different light conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594506","","Robots;Trajectory;Cameras;Bayes methods;Estimation;Uncertainty;Neural networks","Bayes methods;Gaussian distribution;image classification;image fusion;learning (artificial intelligence);mobile robots;navigation;neural nets;pose estimation;probability;robot vision;target tracking","probabilistic inference approach;light conditions;trajectory estimation;simulated unreal engine environment;uncertainty covariance;robot localization problem;robot pose;hidden state mean prediction;high-level state information;inference task;CNN feature likelihood;Bayesian framework;spatially-varying Gaussian distribution;generative viewpoint-dependent model;CNN classifier;visual observations;system hidden state;combinatorial data association;hand-engineered image features;high-dimensional visual measurements;Bayesian information recovery","","","20","","","","","IEEE","IEEE Conferences"
"Sparse 3D Topological Graphs for Micro-Aerial Vehicle Planning","H. Oleynikova; Z. Taylor; R. Siegwart; J. Nieto","ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab; ETH Zürich, Autonomous Systems Lab","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Micro-Aerial Vehicles (MAVs) have the advantage of moving freely in 3D space. However, creating compact and sparse map representations that can be efficiently used for planning for such robots is still an open problem. In this paper, we take maps built from noisy sensor data and construct a sparse graph containing topological information that can be used for 3D planning. We use a Euclidean Signed Distance Field, extract a 3D Generalized Voronoi Diagram (GVD), and obtain a thin skeleton diagram representing the topological structure of the environment. We then convert this skeleton diagram into a sparse graph, which we show is resistant to noise and changes in resolution. We demonstrate global planning over this graph, and the orders of magnitude speed-up it offers over other common planning methods. We validate our planning algorithm in real maps built onboard an MAV, using RGB-D sensing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594152","","Planning;Three-dimensional displays;Two dimensional displays;Skeleton;Robot sensing systems;Topology","autonomous aerial vehicles;computational geometry;graph theory;image colour analysis;mobile robots;path planning;topology","Euclidean signed distance field;3D generalized Voronoi diagram;RGB-D sensing;global planning;skeleton diagram;topological information;noisy sensor data;sparse map representations;compact map representations;MAV;microaerial vehicle planning;sparse 3D topological graphs","","","24","","","","","IEEE","IEEE Conferences"
"Safe Reinforcement Learning on Autonomous Vehicles","D. Isele; A. Nakhaei; K. Fujimura","Honda Research Institute, USA; Honda Research Institute, USA; Honda Research Institute, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","There have been numerous advances in reinforcement learning, but the typically unconstrained exploration of the learning process prevents the adoption of these methods in many safety critical applications. Recent work in safe reinforcement learning uses idealized models to achieve their guarantees, but these models do not easily accommodate the stochasticity or high-dimensionality of real world systems. We investigate how prediction provides a general and intuitive framework to constraint exploration, and show how it can be used to safely learn intersection handling behaviors on an autonomous vehicle.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593420","","Safety;Autonomous vehicles;Trajectory;Games;Pipelines;Noise measurement;Standards","learning (artificial intelligence);remotely operated vehicles;road traffic control;road vehicles","intersection handling behaviors;autonomous vehicle;safety critical applications;learning process;safe reinforcement learning","","","33","","","","","IEEE","IEEE Conferences"
"Towards an Autonomous Robotic Dragonfly: At-Scale Lift Experiments Modeling Dragonfly Forewings","P. A. K. Szabo; G. M. T. D'Eleuterio","University of Toronto Institute for Aerospace Studies (UTIAS), 4925 Dufferin Street Toronto ON M3H 5T6, Canada; University of Toronto Institute for Aerospace Studies (UTIAS), 4925 Dufferin Street Toronto ON M3H 5T6, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We report on lift experiments conducted at scale for an artificial platform mimicking the dragonfly species: Sympetrum sanguineum. The platform, as well as the lift sensor, was custom designed and built. The flapping mechanism consisted of a piezoelectric bending-beam actuator, transmission using carbon-fiber elements and polymide-film joints, and wings constructed of polyester film with carbon-fiber support structure. The flapping kinematics of the Sympetrum san-guineum was replicated as closely as possible although only a pair of forewings were used in these experiments. The lift generated, when accounting for the addition of a pair of hindwings, is sufficient to allow for the hovering of a real-life dragonfly. The results, the first at-scale fully transient measurements of artificial dragonfly forewings, show that the lift curves quantitatively as well as qualitatively validate existing 2D and 3D computer simulations of dragonfly forewings.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594331","","Insects;Aerodynamics;Actuators;Resonant frequency;Frequency measurement;Carbon;Power supplies","aerodynamics;aerospace components;aerospace robotics;bending;carbon fibres;design engineering;mobile robots;piezoelectric actuators;polymer films;robot kinematics;sensors","hindwing pair;Sympetrum san-guineum;flapping kinematics;carbon-fiber support structure;polyester film;polymide-film joints;piezoelectric bending-beam actuator;lift sensor;Sympetrum sanguineum;autonomous robotic dragonfly;artificial dragonfly forewings","","","20","","","","","IEEE","IEEE Conferences"
"Conductive Knit-covered Pneumatic Artificial Muscle (k-PAM) Actuator","B. Jamil; S. Lee; Y. Choi","Department of Electrical and Electronic Engineering, Hanyang University, Ansan, 15588, South Korea; Department of Electrical and Electronic Engineering, Hanyang University, Ansan, 15588, South Korea; Department of Electrical and Electronic Engineering, Hanyang University, Ansan, 15588, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1476","1481","The paper presents design, fabrication and characteristics of two kinds of conductive Knit-covered Pneumatic Artificial Muscle (it is called as k-PAM in the paper) actuators, in which two different knits are made by braiding silver-coated (conductive) yarn and spandex (non-conductive) yarn with different stitch methods. The k-PAM is able to measure the change in length of the actuator body according to the applied air pressures as well as the strain due to external force. A complete fabrication method is presented to make the actuator work for higher pressure (≥ 300[kPa]). Since the force generated by the actuator is decoupled from the external force, ultimately, it can be directly used to measure not only the length but also the force. Experimental validations are performed describing the characteristics of two different types of k-PAMs. It is expected that the k-PAM can be used directly for robotic applications in higher pressure condition, while the semi-permanent conductive knit provides the actuator with durability in high repetitive operation environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594510","","Actuators;Yarn;Bladder;Fabrication;Force;Sensors;Resistance","durability;fabrics;pneumatic actuators;silver;yarn","stitch methods;semipermanent conductive knit;high repetitive operation environment;nonconductive yarn;external force;actuator body;k-PAM;conductive knit-covered pneumatic artificial muscle","","","18","","","","","IEEE","IEEE Conferences"
"Dynamic Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM)Robot","R. S. Novin; A. Yazdani; T. Hermans; A. Merryweather","Department of Mechanical Engineering, University of Utah, Utah, US; Department of Mechanical Engineering, University of Utah, Utah, US; University of Utah, School of Computing and Robotics Center, Utah, USA; Department of Mechanical Engineering, University of Utah, Utah, US","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","One of the most concerning and costly problems in hospitals is patients falls. We address this problem by introducing PAM, a patient assistant mobile robot, that maneuvers mobility aids to assist with fall prevention. Common objects found inside hospitals include objects with legs (i.e. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. We describe a probabilistic method to do this by fitting pre-categorized object models learned from minimal force and motion interactions with an object. In addition, we account for multiple manipulation strategies, which requires a hybrid control system comprised of discrete grasps on legs and continuous applied forces. To do this, we use a simple one-wheel point-mass model. A hybrid MPC-based manipulation planning algorithm was developed to compensate for modeling errors. While the proposed algorithm applies to a broad range of legged objects, we only show results for the case of a 2-wheel, 4-legged walker in this paper. Simulation and experimental tests show that the obtained dynamic model is sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot can successfully move the object to a desired position without collision.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593989","","Legged locomotion;Dynamics;Planning;Manipulator dynamics;Grippers","collision avoidance;hospitals;manipulator dynamics;medical robotics;mobile robots;predictive control;probability","PAM robot;probabilistic method;2-wheel walker;autonomous learning;fall prevention;maneuvers mobility aids;patient assistant mobile robot;dynamic model learning;collision-free manipulation;4-legged walker;hybrid MPC-based manipulation planning algorithm;one-wheel point-mass model;hybrid control system;motion interactions;minimal force;approximate dynamic model","","","36","","","","","IEEE","IEEE Conferences"
"Fast and Accurate Semantic Mapping through Geometric-based Incremental Segmentation","Y. Nakajima; K. Tateno; F. Tombari; H. Saito","Department of Science and Technology, Keio University, Kanagawa, Japan; Chair for Computer Aided Medical Procedures (CAMP), TU Munich, Boltzmannstr 3, Munich, 85748, Germany; Chair for Computer Aided Medical Procedures (CAMP), TU Munich, Boltzmannstr 3, Munich, 85748, Germany; Department of Science and Technology, Keio University, Kanagawa, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","385","392","We propose an efficient and scalable method for incrementally building a dense, semantically annotated 3D map in real-time. The proposed method assigns class probabilities to each region, not each element (e.g., surfel and voxel), of the 3D map which is built up through a robust SLAM framework and incrementally segmented with a geometric-based segmentation method. Differently from all other approaches, our method has a capability of running at over 30Hz while performing all processing components, including SLAM, segmentation, 2D recognition, and updating class probabilities of each segmentation label at every incoming frame, thanks to the high efficiency that characterizes the computationally intensive stages of our framework. By utilizing a specifically designed CNN to improve the frame-wise segmentation result, we can also achieve high accuracy. We validate our method on the NYUv2 dataset by comparing with the state of the art in terms of accuracy and computational efficiency, and by means of an analysis in terms of time and space complexity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593993","","Semantics;Three-dimensional displays;Image segmentation;Simultaneous localization and mapping;Cameras;Real-time systems;Two dimensional displays","image segmentation;probability;SLAM (robots);stereo image processing","SLAM framework;NYUv2 dataset;computational efficiency;frame-wise segmentation result;computationally intensive stages;segmentation label;updating class probabilities;processing components;geometric-based segmentation method;geometric-based incremental segmentation","","","31","","","","","IEEE","IEEE Conferences"
"vTSL - A Formally Verifiable DSL for Specifying Robot Tasks","C. Heinzemann; R. Lange","Corporate Sector Research and Advance Engineering, Robert Bosch GmbH, Renningen, 71272, Germany; Corporate Sector Research and Advance Engineering, Robert Bosch GmbH, Renningen, 71272, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8308","8314","Preprogramming of tasks still plays an important role in complex robotic systems despite the advances in automated planning and symbolic learning. Often, it is desired that end-users implement further tasks to adapt the robotic application to their needs. These user-defined tasks have to meet safety and integrity constraints for protecting the robotic platform and its users. We introduce a verifiable task specification language (vTSL) that enables to automatically prove that a task specification satisfies a set of predefined or task-specific constraints. We illustrate our approach using an example of a self-driving vehicle for intra-logistics and report experiences with two commercial applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593559","","Task analysis;DSL;Semantics;Planning;Loading;Robot sensing systems","constraint handling;control engineering computing;formal specification;formal verification;learning (artificial intelligence);mobile robots;robot programming;specification languages","vTSL;formally verifiable DSL;robot tasks;preprogramming;automated planning;symbolic learning;robotic application;user-defined tasks;integrity constraints;robotic platform;verifiable task specification language;task-specific constraints;robotic systems","","","19","","","","","IEEE","IEEE Conferences"
"A Mobility Model Based on Improved Artificial Potential Fields for Swarms of UAVs","E. Falomir; S. Chaumette; G. Guerrini","LaBRI, UMR5800, Univ. Bordeaux, Talence, F-33400, France; LaBRI, UMR5800, Univ. Bordeaux, Talence, F-33400, France; Thales DMS France, Mérignac, F-33700, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8499","8504","A combination of several autonomous UAVs can be used to perform collaborative tasks. Such a combination is referred to as a swarm of drones. The use of multiple platforms can extend the system global capacities thanks to the resulting variety of embedded sensors and to information sharing. In this case, path planning and thus obstacles avoidance is still a major task. To deal with this issue, mobility models have to be implemented. Our contribution presented in this paper is a mobility model for swarms of UAVs based on the Artificial Potential Fields (APF) principle. In our model, the involved UAVs collaborate by sharing data about the obstacles that they detected. By doing so, a UAV which is not close enough to an obstacle to detect it thanks to its own sensors will still have the proper data to take this obstacle into account in its path planning. To validate our mobility strategies with realistic constraints we simulate the performances of existing sensors and transmitters, and consider real-world environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593738","","Path planning;Sensors;Adaptation models;Collaboration;Task analysis;Laser radar;Collision avoidance","autonomous aerial vehicles;collision avoidance;mobile robots;path planning;remotely operated vehicles","information sharing;path planning;obstacles avoidance;mobility model;swarms;UAV;involved UAVs collaborate;mobility strategies;autonomous UAVs;collaborative tasks;multiple platforms;artificial potential fields principle;APF principle","","","26","","","","","IEEE","IEEE Conferences"
"Embedding Temporally Consistent Depth Recovery for Real-time Dense Mapping in Visual-inertial Odometry","H. Cheng; Z. Zheng; J. He; C. Chen; K. Wang; L. Lin","School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","693","698","Dense mapping is always the desire of simultaneous localization and mapping (SLAM), especially for the applications that require fast and dense scene information. Visual-inertial odometry (VIO) is a light-weight and effective solution to fast self-localization. However, VIO-based SLAM systems have difficulty in providing dense mapping results due to the spatial sparsity and temporal instability of the VIO depth estimations. Although there have been great efforts on real-time mapping and depth recovery from sparse measurements, the existing solutions for VIO-based SLAM still fail to preserve sufficient geometry details in their results. In this paper, we propose to embed depth recovery into VIO-based SLAM for real-time dense mapping. In the proposed method, we present a subspace-based stabilization scheme to maintain the temporal consistency and design a hierarchical pipeline for edge-preserving depth interpolation to reduce the computational burden. Numerous experiments demonstrate that our method can achieve an accuracy improvement of up to 49.1 cm compared to state-of-the-art learning-based methods for depth recovery and reconstruct sufficient geometric details in dense mapping when only 0.07% depth samples are available. Since a simple CPU implementation of our method already runs at 10-20 fps, we believe our method is very favorable for practical SLAM systems with critical computational requirements.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593917","","Simultaneous localization and mapping;Real-time systems;Feature extraction;Pipelines;Interpolation;Three-dimensional displays","distance measurement;image reconstruction;interpolation;learning (artificial intelligence);mobile robots;robot vision;SLAM (robots)","real-time dense mapping;visual-inertial odometry;dense scene information;fast self-localization;VIO-based SLAM systems;VIO depth estimations;subspace-based stabilization scheme;temporal consistency;edge-preserving depth interpolation;simultaneous localization and mapping;learning-based methods;embedding temporally consistent depth recovery","","","25","","","","","IEEE","IEEE Conferences"
"Fused Angles and the Deficiencies of Euler Angles","P. Allgeuer; S. Behnke","Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5109","5116","Just like the well-established Euler angles representation, fused angles are a convenient parameterisation for rotations in three-dimensional Euclidean space. They were developed in the context of balancing bodies, most specifically walking bipedal robots, but have since found wider application due to their useful properties. A comparative analysis between fused angles and Euler angles is presented in this paper, delineating the specific differences between the two representations that make fused angles more suitable for representing orientations in balance-related scenarios. Aspects of comparison include the locations of the singularities, the associated parameter sensitivities, the level of mutual independence of the parameters, and the axisymmetry of the parameters.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593384","","Quaternions;Task analysis;Legged locomotion;Rotation measurement;Intelligent robots;Sensitivity","gait analysis;legged locomotion;robot dynamics","fused angles;Euler angles representation;balance-related scenarios;parameter sensitivities;walking bipedal robots;three-dimensional Euclidean space","","1","12","","","","","IEEE","IEEE Conferences"
"Estimating an Articulated Tool's Kinematics via Visuo-Tactile Based Robotic Interactive Manipulation","Q. Li; A. Ückermann; R. Haschke; H. Ritter","Bielefeld University, Neuroinformatics Group / CITEC, Germany; Bielefeld University, Neuroinformatics Group / CITEC, Germany; Bielefeld University, Neuroinformatics Group / CITEC, Germany; Bielefeld University, Neuroinformatics Group / CITEC, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6938","6944","The usage of articulated tools for autonomous robots is still a challenging task. One of the difficulties is to automatically estimate the tool's kinematics model. This model cannot be obtained from a single passive observation, because some information, such as a rotation axis (hinge), can only be detected when the tool is being used. Inspired by a baby using its hands while playing with an articulated toy, we employ a dual arm robotic setup and propose an interactive manipulation strategy based on visual-tactile servoing to estimate the tool's kinematics model. In our proposed method, one hand is holding the tool's handle stably, and the other arm equipped with tactile finger flips the movable part of the articulated tool. An innovative visuo-tactile servoing controller is introduced to implement the flipping task by integrating the vision and tactile feedback in a compact control loop. In order to deal with the temporary invisibility of the movable part in camera, a data fusion method which integrates the visual measurement of the movable part and the fingertip's motion trajectory is used to optimally estimate the orientation of the tool's movable part. The important tool's kinematic parameters are estimated by geometric calculations while the movable part is flipped by the finger. We evaluate our method by flipping a pivoting cleaning head (flap) of a wiper and estimating the wiper's kinematic parameters. We demonstrate that the flap of the wiper is flipped robustly, even the flap is shortly invisible. The orientation of the flap is tracked well compared to the ground truth data. The kinematic parameters of the wiper are estimated correctly.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594295","","Tools;Robot kinematics;Kinematics;Task analysis;End effectors;Robot sensing systems","dexterous manipulators;feedback;haptic interfaces;manipulator kinematics;mobile robots;motion control;robot vision;sensor fusion;tactile sensors","visuo-tactile based robotic interactive manipulation;autonomous robots;single passive observation;articulated toy;dual arm robotic setup;tactile finger;visuo-tactile servoing controller;flipping task;tactile feedback;compact control loop;kinematic parameters;vision feedback;articulated tools kinematics;data fusion method;fingertips motion trajectory","","","30","","","","","IEEE","IEEE Conferences"
"A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal","M. Hassan; D. Liu","Centre for Autonomous Systems (CAS), University of Technology Sydney, 15 Broadway, Ultimo, NSW, 2007, Australia; Centre for Autonomous Systems (CAS), University of Technology Sydney, 15 Broadway, Ultimo, NSW, 2007, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1913","1918","Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593563","","Spirals;Cleaning;Path planning;Fatigue;Underwater structures;Manipulators;Poles and towers","autonomous underwater vehicles;bridges (structures);inspection;multi-robot systems;path planning","underwater structures;DSCPP;smooth paths;spiral path;popular boustrophedon-based coverage approach;intervention autonomous underwater vehicle;deformable spiral coverage path planning algorithm;smooth coverage path planning;deformable spiral-based algorithm","","","16","","","","","IEEE","IEEE Conferences"
"Incremental Skill Learning of Stable Dynamical Systems","M. Saveriano; D. Lee","German Aerospace Center (DLR), Institute of Robotics and Mechatronics, WeBling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, WeBling, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6574","6581","Efficient skill acquisition, representation, and online adaptation to different scenarios has become of fundamental importance for assistive robotic applications. In the past decade, dynamical systems (DS) have arisen as a flexible and robust tool to represent learned skills and to generate motion trajectories. This work presents a novel approach to incrementally modify the dynamics of a generic autonomous DS when new demonstrations of a task are provided. A control input is learned from demonstrations to modify the trajectory of the system while preserving the stability properties of the reshaped DS. Learning is performed incrementally through Gaussian process regression, increasing the robot's knowledge of the skill every time a new demonstration is provided. The effectiveness of the proposed approach is demonstrated with experiments on a publicly available dataset of complex motions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594474","","Robots;Trajectory;Task analysis;Training;Training data;Gaussian processes;Dynamics","control engineering computing;Gaussian processes;learning (artificial intelligence);mobile robots;motion control;regression analysis;robot programming;stability;trajectory control","control input;Gaussian process regression;incremental skill learning;online adaptation;assistive robotic applications;motion trajectories;dynamical systems;skill acquisition;autonomous DS;stability properties","","","37","","","","","IEEE","IEEE Conferences"
"Interval-Based Cooperative Uavs Pose Domain Characterization from Images and Ranges","I. Kenmogne; V. Drevelle; E. Marchand","Inria, CNRS, IRISA, Univ Rennes; Inria, CNRS, IRISA, Univ Rennes; Inria, CNRS, IRISA, Univ Rennes","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6349","6356","An interval-based approach to cooperative localization for a group of unmanned aerial vehicles (UAVs) is proposed. It computes a pose uncertainty domain for each robot, i.e., a set that contains the true robot pose, assuming bounded error measurements. The algorithm combines distances measurements to the ground station and between UAVs, with the tracking of known landmarks in camera images, and provides a guaranteed enclosure of the robots pose domains. Pose uncertainty domains are computed using interval constraint propagation techniques, thanks to a branch and bound algorithm. We show that the proposed method also provides a good point estimate, that can be further refined using nonlinear iterative weighted least squares. Results are presented for simulated two-robots configurations, for experimental data, and compared with a classical Extended Kalman Filter.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593742","","Cameras;Robot kinematics;Robot vision systems;Position measurement;Base stations","autonomous aerial vehicles;constraint handling;control engineering computing;distance measurement;iterative methods;least squares approximations;mobile robots;pose estimation;robot vision;tree searching","pose uncertainty domains;interval constraint propagation techniques;simulated two-robots configurations;unmanned aerial vehicles;bounded error measurements;distances measurements;ground station;camera images;UAV;cooperative localization;branch and bound algorithm;nonlinear iterative weighted least squares","","","26","","","","","IEEE","IEEE Conferences"
"A Novel Shared Position Control Method for Robot Navigation Via Low Throughput Human-Machine Interfaces","D. A. Sinyukov; T. Padır","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, 02115; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, 02115","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3913","3920","In this paper, we analyze systems with low throughput human-machine interfaces (such as a brain-computer interface, single switch interface) from the controls perspective. We develop some principles for performance improvement in such systems based on the parallelization of inference and robot motion. The proposed principles are used to design a novel shared position control to navigate a circular massless holonomic robot in a known environment. The system is implemented in simulation and integrated with a real robotic wheelchair. Robot experiments demonstrated the viability of the proposed navigation method in various modes of operation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593921","","Navigation;Wheelchairs;Mobile robots;Position control;Linear systems;Throughput","mobile robots;motion control;path planning;position control;user interfaces;wheelchairs","shared position control method;inference parallelization;low throughput human-machine interfaces;robot navigation;robotic wheelchair;circular massless holonomic robot;robot motion;single switch interface;brain-computer interface","","","31","","","","","IEEE","IEEE Conferences"
"Design and Implementation of a Novel Semi-Active Hybrid Unilateral Stance Control Knee Ankle Foot Orthosis","J. Gil; M. C. Sánchez-Villamañán; J. Gòmez; A. Ortiz; J. L. Pons; J. C. Moreno; A. J. Del-Ama","Neural Rehabilitation Group, Spanish National Research Council (CSIC), Cajal Institute, Avda Doctor Arce, 37, Madrid, 28002, Spain; Neural Rehabilitation Group, Spanish National Research Council (CSIC), Cajal Institute, Avda Doctor Arce, 37, Madrid, 28002, Spain; Neural Rehabilitation Group, Spanish National Research Council (CSIC), Cajal Institute, Avda Doctor Arce, 37, Madrid, 28002, Spain; Neural Rehabilitation Group, Spanish National Research Council (CSIC), Cajal Institute, Avda Doctor Arce, 37, Madrid, 28002, Spain; Neural Rehabilitation Group, Spanish National Research Council (CSIC), Cajal Institute, Avda Doctor Arce, 37, Madrid, 28002, Spain; Neural Rehabilitation Group, Spanish National Research Council (CSIC), Cajal Institute, Avda Doctor Arce, 37, Madrid, 28002, Spain; Unidad de Neurorrehabilitación, Biomecánica y Función sensitivo-motora (HNP-SESCAM), Unidad asociada al CSIC, Unidad de Biomecánica del Hospital Nacional de Parapléjicos, Finca La Peraleda S/N, Toledo, 45071, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5163","5168","This work presents the design and development of a semi-active hybrid orthotic system for support and facilitation of unilateral pathological human walking. The system is based on a novel lower limb orthosis with mechanical control and its combination with non-invasive muscle electrostimulation. The paper presents the concept design and realization of a novel Stance Control Knee Ankle Foot Orthoses (SCKAFO) and the design of Functional Electrical Stimulation (FES) strategies for artificial activation of ankle joint muscles in this hybrid scheme for gait support. In particular, we present the investigation of the effects of electrical stimulation patterns of ankle muscles synchronized in real-time with gait events., on the possible biomechanical alterations to gait in able-bodied individuals (n=8). Bilateral 3D ground reaction forces (GRF) were analyzed between barefoot overground walking with and without FES of ankle muscles. The observed effects of the tested FES strategy are coherent with a physiological gait strategy and compatible with the proposed SCKAFO.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594219","","Iron;Muscles;Knee;Legged locomotion;Foot;Exoskeletons;Fatigue","bioelectric phenomena;gait analysis;medical control systems;muscle;neuromuscular stimulation;orthotics;patient rehabilitation","semiactive hybrid orthotic system;unilateral pathological human walking;mechanical control;noninvasive muscle electrostimulation;artificial activation;ankle joint muscles;hybrid scheme;electrical stimulation patterns;ankle muscles;stance control knee ankle foot orthoses","","","21","","","","","IEEE","IEEE Conferences"
"Leveraging Convolutional Pose Machines for Fast and Accurate Head Pose Estimation","Y. Cao; O. Canévet; J. Odobez","Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1089","1094","We propose a head pose estimation framework that leverages on a recent keypoint detection model. More specifically, we apply the convolutional pose machines (CPMs) to input images, extract different types of facial keypoint features capturing appearance information and keypoint relationships, and train multilayer perceptrons (MLPs) and convolutional neural networks (CNNs) for head pose estimation. The benefit of leveraging on the CPMs (which we apply anyway for other purposes like tracking) is that we can design highly efficient models for practical usage. We evaluate our approach on the Annotated Facial Landmarks in the Wild (AFLW) dataset and achieve competitive results with the state-of-the-art.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594223","","Magnetic heads;Pose estimation;Face;Feature extraction;Nose;Ear","face recognition;feature extraction;feedforward neural nets;learning (artificial intelligence);multilayer perceptrons;object detection;pose estimation","appearance information;keypoint relationships;convolutional neural networks;multilayer perceptrons;keypoint detection model;CPM;head pose estimation;facial keypoint features;estimation framework;convolutional pose machines","","","21","","","","","IEEE","IEEE Conferences"
"Algorithmization of Constrained Motion for Car-Like Robots Using the VFO Control Strategy with Parallelized Planning of Admissible Funnels","T. Gawron; M. M. Michalek","Poznan University of Technology (PUT), Institute of Automation and Robotics, Poznan, Piotrowo 3A, 60-965, Poland; Poznan University of Technology (PUT), Institute of Automation and Robotics, Poznan, Piotrowo 3A, 60-965, Poland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6945","6951","Vehicles with car-like kinematics are ubiquitous, therefore an ability to algorithmize (i.e., how to plan and effectively execute) complex maneuvers in the presence of obstacles is vital to mobile robotics and intelligent vehicles. Traditionally, this problem is solved using the well known motion planning algorithms, which generate the open-loop control signals neglecting the effects of measurement noises, modeling uncertainties and imperfect robot actuation. While such effects can be compensated to some extent by online replanning, the application of feedback control algorithms to motion execution is unavoidable if robustness of the system is desired. Consequently, the recent works focus on integration of both motion planning and control algorithms to obtain motion plans robust to uncertainty of the initial conditions. In accordance with this trend, we propose a modified VFO (Vector Field Orientation) control law, which is designed to satisfy the state and input constraints resulting from the presence of obstacles in the environment, respect the steering angle limits in conjunction with steering dynamics of the car-like robot, and preserve continuity of the control input signals. Thanks to analytic characterization of admissible funnels (i.e. positively invariant subsets of the configuration space) developed from an analysis of the VFO control law, we guarantee satisfaction of all the mentioned constraints in the continuous domains of time and configuration space of the robot without sacrificing computational efficiency of the planning process. A specific funnel is planned with a highly parallelized deterministic sampling-based algorithm achieving quasi-real-time performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594402","","Robots;Planning;Kinematics;Electron tubes;Vehicle dynamics;Uncertainty;Feedback control","automobiles;collision avoidance;control system synthesis;feedback;mobile robots;motion control;robust control","input constraints;control input signals;admissible funnels;planning process;constrained motion;car-like robots;VFO control strategy;parallelized planning;car-like kinematics;mobile robotics;intelligent vehicles;feedback control algorithms;motion execution;VFO control law;state constraints;motion planning algorithms;robot actuation;open loop control signals;parallelized deterministic sampling-based algorithm;vector field orientation;steering dynamics;modeling uncertainties","","","15","","","","","IEEE","IEEE Conferences"
"MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot","G. Bledt; M. J. Powell; B. Katz; J. Di Carlo; P. M. Wensing; S. Kim","Department of Mechanical Engineering, MIT, Cambridge, MA, 02139, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, 02139, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, 02139, USA; Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA, 02139, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, 46556, USA; Department of Mechanical Engineering, MIT, Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2245","2252","This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593885","","Legged locomotion;Actuators;Torque;Force;Knee;Robot sensing systems","actuators;gait analysis;legged locomotion;motion control;robot dynamics;robust control","control architecture;legged locomotion;abduction-adduction degrees;gait modification;cost of transport;CoT;proprioceptive actuation;leg design;mechanical design;dynamic quadruped robot;robust robot;MIT cheetah 3","","1","25","","","","","IEEE","IEEE Conferences"
"A Novel Input Device for Robotic Prosthetic Hand: Design and Preliminary Results","Y. Kim; D. Lee; H. Parkl; J. Park; J. Bae","Robot R&D Group, Research Institute of Industrial Technology ConvergenceKorea Institute of Industrial Technology (KITECH), Ansan, Korea; Robot R&D Group, Research Institute of Industrial Technology ConvergenceKorea Institute of Industrial Technology (KITECH), Ansan, Korea; Robot R&D Group, Research Institute of Industrial Technology ConvergenceKorea Institute of Industrial Technology (KITECH), Ansan, Korea; Robot R&D Group, Research Institute of Industrial Technology ConvergenceKorea Institute of Industrial Technology (KITECH), Ansan, Korea; Robot R&D Group, Research Institute of Industrial Technology ConvergenceKorea Institute of Industrial Technology (KITECH), Ansan, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, we propose a novel input device for a robotic prosthetic hand based on capacitance change. The proposed device can sense the deformation of the skin due to the activity of the muscle by measuring the capacitance change between the skin and the electrode. Therefore, it can be used as a sensor for estimating a user's intention through medical electrodiagnostic techniques such as electromyogram (EMG)and force myography (FMG). The proposed device can acquire data in a non-invasive way and is advantageous with easier data processing than that for an EMG signal. Moreover, it is resistant to the impedance change of skin because the capacitance is measured in a non-contact manner, unlike the existing methods which work with direct contact with the skin such as EMG. Additionally, unlike FMG, the device is lightly attached to the skin without being strongly fixed with velcro, which offsets problems that occur while re-wearing the device. To demonstrate the feasibility of the proposed idea, three of the newly developed input devices were used to classify four hand movements (fist, scissors, paper, and rest)using a multilayer perceptron (MLP). As a result, the classification success rates for the fist, paper, scissor, and rest motions were obtained as 99.3%, 98.3%, 98.4%, and 99.1%, respectively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593809","","Skin;Electrodes;Capacitance;Muscles;Robot sensing systems;Electromyography;Input devices","biomechanics;biomedical electrodes;electromyography;medical robotics;medical signal processing;multilayer perceptrons;prosthetics;signal classification","medical electrodiagnostic techniques;EMG signal;impedance change;skin;noncontact manner;hand movements;novel input device;robotic prosthetic hand;capacitance change;data processing;deformation;electrode;sensor;multilayer perceptron;classification success rates","","","20","","","","","IEEE","IEEE Conferences"
"Object Assembly Guidance in Child-Robot Interaction using RGB-D based 3D Tracking","J. Hadfield; P. Koutras; N. Efthymiou; G. Potamianos; C. S. Tzafestas; P. Maragos","Athena Research and Innovation Center, Maroussi, 15125, Greece; Athena Research and Innovation Center, Maroussi, 15125, Greece; Athena Research and Innovation Center, Maroussi, 15125, Greece; Athena Research and Innovation Center, Maroussi, 15125, Greece; School of ECE, National Technical Univ. of Athens, Athens, 15773, Greece; Athena Research and Innovation Center, Maroussi, 15125, Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","347","354","This work examines how and to what benefit an autonomous humanoid robot can supervise a child in an object assembly task. In order to understand the child's actions, a novel 3D object tracking algorithm for RGB-D data is employed. The tracker consists of two stages: the first performs a tracking-by-detection scheme on the color stream, to locate the objects on the image plane, while the second uses a particle filter that operates on the depth data stream to refine the first stage output and infer the objects' rotations. Given the six degrees-of-freedom of the assembly part poses, the system is able to recognize which connections have been completed at any given time. This information is then used to select an appropriate verbal or gestural response for the robot. Experimental results show that (a) the tracking algorithm is accurate, fast and robust to severe occlusions and fast movements, (b) the proposed method of assembly state estimation is indeed effective, and (c) the resulting Child-Robot Interaction scenario is educational and enjoyable for the children involved.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594187","","Three-dimensional displays;Task analysis;Robotic assembly;Robot kinematics;Tracking;Streaming media","gesture recognition;human computer interaction;humanoid robots;human-robot interaction;image colour analysis;mobile robots;object detection;object recognition;object tracking;particle filtering (numerical methods)","verbal response;3D object tracking algorithm;RGB-D data;object assembly task;autonomous humanoid robot;RGB-D based 3D;object assembly guidance;resulting Child-Robot Interaction scenario;assembly state estimation;gestural response;assembly part;degrees-of-freedom;depth data stream;particle filter;image plane;color stream;tracking-by-detection scheme","","","27","","","","","IEEE","IEEE Conferences"
"From Human Physical Interaction To Online Motion Adaptation Using Parameterized Dynamical Systems","M. Khoramshahi; A. Laurens; T. Triquet; A. Billard","EPFL, Learning Algorithm and Systems Laboratory; EPFL, Learning Algorithm and Systems Laboratory; EPFL, Learning Algorithm and Systems Laboratory; EPFL, Learning Algorithm and Systems Laboratory","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1361","1366","In this work, we present an adaptive motion planning approach for impedance-controlled robots to modify their tasks based on human physical interactions. We use a class of parameterized time-independent dynamical systems for motion generation where the modulation of such parameters allows for motion flexibility. To adapt to human interactions, we update the parameters of our dynamical system in order to reduce the tracking error (i.e., between the desired trajectory generated by the dynamical system and the real trajectory influenced by the human interaction). We provide analytical analysis and several simulations of our method. Finally, we investigate our approach through real world experiments with a 7-DOF KUKA LWR 4+ robot performing tasks such as polishing and pick-and-place.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594366","","Task analysis;Trajectory;Impedance;Service robots;Convergence;Planning","adaptive control;control engineering computing;human-robot interaction;manipulator dynamics;motion control;path planning;trajectory control","parameterized time-independent dynamical systems;motion flexibility;motion generation;impedance-controlled robots;adaptive motion planning approach;parameterized dynamical systems;online motion adaptation;human physical interaction","","","30","","","","","IEEE","IEEE Conferences"
"Multi-Modal Robot Apprenticeship: Imitation Learning Using Linearly Decayed DMP+ in a Human-Robot Dialogue System","Y. Wu; R. Wang; L. F. D'Haro; R. E. Banchs; K. P. Tee","Yan Wu and Keng Peng Tee are with the A*STAR Institute for• Infocomm Research, Singapore; Ruohan Wang is with Imperial College London, United Kingdom; Luis F. D'Haro is with Universidad Politécnica de Madrid, Spain; Rafael E. Banchs is with Nanyang Technological University, Singapore; Yan Wu and Keng Peng Tee are with the A*STAR Institute for• Infocomm Research, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","Robot learning by demonstration gives robots the ability to learn tasks which they have not been programmed to do before. The paradigm allows robots to work in a greater range of real-world applications in our daily life. However, this paradigm has traditionally been applied to learn tasks from a single demonstration modality. This restricts the approach to be scaled to learn and execute a series of tasks in a real-life environment. In this paper, we propose a multi-modal learning approach using DMP+ with linear decay integrated in a dialogue system with speech and ontology for the robot to learn seamlessly through natural interaction modalities (like an apprentice) while learning or re-learning is done on the fly to allow partial updates to a learned task to reduce potential user fatigue and operational downtime in teaching. The performance of new DMP+ with linear decay system is statistically benchmarked against state-of-the-art DMP implementations. A gluing demonstration is also conducted to show how the system provides seamless learning of multiple tasks in a flexible manufacturing set-up.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593634","","Task analysis;Trajectory;Ontologies;Convergence;Robot learning;Kernel","human computer interaction;human-robot interaction;interactive systems;learning (artificial intelligence);robot programming","linear decay system;seamless learning;multimodal robot apprenticeship;imitation learning;linearly decayed DMP;human-robot dialogue system;robot learning;robots;single demonstration modality;multimodal learning approach;natural interaction modalities","","","35","","","","","IEEE","IEEE Conferences"
"Search-Based Optimal Motion Planning for Automated Driving","Z. Ajanovic; B. Lacevic; B. Shyrokau; M. Stolz; M. Horn","Virtual Vehicle Research Center, Inffeldgasse 21a, Graz, 8010, Austria; Faculty of Electrical Engineering, University of Sarajevo, Sarajevo, 7100, Bosnia and Herzegovina; Department of Cognitive Robotics, Delft University of Technology, The Netherlands, Mekelweg 2, Delft, 2628 CD, The Netherlands; Virtual Vehicle Research Center, Inffeldgasse 21a, Graz, 8010, Austria; Graz University of Technology, Institute of Automation and Control, Inffeldgasse 21b, Graz, 8010, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4523","4530","This paper presents a framework for fast and robust motion planning designed to facilitate automated driving. The framework allows for real-time computation even for horizons of several hundred meters and thus enabling automated driving in urban conditions. This is achieved through several features. Firstly, a convenient geometrical representation of both the search space and driving constraints enables the use of classical path planning approach. Thus, a wide variety of constraints can be tackled simultaneously (other vehicles, traffic lights, etc.). Secondly, an exact cost-to-go map, obtained by solving a relaxed problem, is then used by A*-based algorithm with model predictive flavour in order to compute the optimal motion trajectory. The algorithm takes into account both distance and time horizons. The approach is validated within a simulation study with realistic traffic scenarios. We demonstrate the capability of the algorithm to devise plans both in fast and slow driving conditions, even when full stop is required.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593813","motion planning;automated driving;lane change;multi-lane driving;traffic lights;A* search;MPC","Planning;Vehicle dynamics;Trajectory;Dynamics;Roads;Search problems;Automation","mobile robots;optimisation;path planning;road vehicles;search problems;trajectory control","automated driving;fast motion planning;robust motion planning;real-time computation;urban conditions;convenient geometrical representation;search space;driving constraints;classical path planning approach;exact cost-to-go map;optimal motion trajectory;time horizons;fast driving conditions;slow driving conditions;search-based optimal motion planning","","","32","","","","","IEEE","IEEE Conferences"
"An Adaptive Robotic Gripper with L-Shape Fingers for Peg-in-Hole Tasks","K. Nie; W. Wan; K. Harada","Osaka University, Graduate School of Engineering Science, Japan; Osaka University, Graduate School of Engineering Science, Japan; Osaka University, Graduate School of Engineering Science, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4022","4028","This paper develops an adaptive gripper for peg-in-hole tasks. Conventional grippers require complicated compliant mechanisms or complicated control strategy and force sensing to successfully insert pegs into holes. Different from them, this paper proposes a simple gripper with an L-shape finger as a low-cost peg-in-hole solution. The basic idea is to divide a peg-in-hole process into a preparation phase and an execution phase, and eliminate uncertainty step-by-step by pushing using the L-shape finger in the preparation phase. The robustness of the gripper for peg-in-hole tasks is examined by repeated executions for different pegs in the International Robotic Exhibition 2017 (IREX) in Tokyo. The experimental section presents details of the executions, and qualitatively shows the high performance of the proposed gripper.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594370","","Grippers;Task analysis;Uncertainty;Manufacturing processes;Robot sensing systems;Planning","force sensors;grippers;mobile robots","adaptive robotic gripper;L-shape finger;peg-in-hole process;force sensor;IREX;international robotic exhibition 2017","","","36","","","","","IEEE","IEEE Conferences"
"Model-Based Engineering, Safety Analysis and Risk Assessment for Personal Care Robots","N. Yakymets; M. Sango; S. Dhouib; R. Gelin","LIST, DILS - Point Courrier 174, CEA, Gif-sur-Yvette, 91191, France; Model Based Solutions & Engineering Company, ALL4TEC, Massy, 5 Avenue Carnot, 91300, France; LIST, DILS - Point Courrier 174, CEA, Gif-sur-Yvette, 91191, France; SoftBank Robotics, Paris, 43 rue du Colonel Pierre Avia, 75015, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6136","6141","In this paper, we propose a method and associate platform to couple model-based system engineering and safety analysis at the early phases of robotic system (RS) life-cycle. The method is compatible with IEC12100 and ISO13482. The platform is based on Papyrus UML modeler and supports RobotML, a domain specific language for RSs, as well as tools for safety analysis and risk assessment, Sophia and Safety Architect. It includes an ability (a) to model architecture of RSs; (b) to automatically run safety analysis (e.g. failure mode and effects analysis, fault tree analysis, etc.); (c) to save and reuse safety artefacts; (d) to represent safety analysis results in the modeling environment. We illustrate the proposed method by considering a humanoid personal care robot from SoftBank Robotics developed in the scope of the ROMEO2 project.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594115","","Safety;Unified modeling language;Tools;Analytical models;Risk management;Humanoid robots","control engineering computing;fault trees;humanoid robots;risk management;safety;safety-critical software;service robots;specification languages;Unified Modeling Language","model-based engineering;risk assessment;personal care robots;couple model-based system engineering;robotic system life-cycle;Papyrus UML modeler;Safety Architect;failure mode;effects analysis;fault tree analysis;safety artefacts;modeling environment;humanoid personal care robot;safety analysis","","","16","","","","","IEEE","IEEE Conferences"
"Evolutionary Motion Control Optimization in Physical Human-Robot Interaction","N. A. Nadeau; I. A. Bonev","École de technologie supérieure, Montréal, Québec, Canada; École de technologie supérieure, Montréal, Québec, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1347","1353","Given that the success of an interaction task depends on the capability of the robot system to handle physical contact with its environment, pure motion control is often insufficient. This is especially true in the context of medical freehand ultrasound where the human body is a deformable surface and an unstructured environment, representing both a safety concern and a challenge for trajectory planning and control. The systematic tuning of practical high degree-of-freedom physical human-robot interaction (pHRI) tasks is not trivial and there are many parameters to be tuned. While traditional tuning is generally performed ad hoc and requires knowledge of the robot and environment dynamics, we propose a simple and effective online tuning framework using differential evolution (DE) to optimize the motion parameters for parallel force/impedance control in a pHRI and medical ultrasound motion application. Through real-world experiments with a KUKA LBR iiwa 7 R800 collaborative robot, the DE framework tuned motion control for optimal and safe trajectories along a human leg phantom. The optimization process was able to successfully reduce the mean absolute error of the motion contact force to 0.537 N through the evolution of eight motion control parameters.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593598","","Ultrasonic imaging;Task analysis;Tuning;Legged locomotion;Force;Robot kinematics","biomedical ultrasonics;evolutionary computation;force control;human-robot interaction;medical robotics;motion control;optimisation;phantoms;trajectory control","evolutionary motion control optimization;medical freehand ultrasound;trajectory planning;optimal trajectories;human leg phantom;physical human-robot interaction;online tuning;collaborative robot;medical ultrasound motion;parallel force-impedance control;differential evolution;pHRI;mean absolute error","","","29","","","","","IEEE","IEEE Conferences"
"Online Spatial Sound Perception Using Microphone Array on Mobile Robot*","Y. Sasaki; R. Tanabe; H. Takernura","National Institute of Advanced Industrial Science and Technology, Aomi 2-3-26, Koto-ku, Tokyo, Japan; Department of Mechanical Engineering, Tokyo University of Science, Yamazaki 2641, Noda-shi, Chiba, Japan; Department of Mechanical Engineering, Tokyo University of Science, Yamazaki 2641, Noda-shi, Chiba, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2478","2484","The paper proposes a spatial sound perception system for an autonomous mobile robot. The system performs three-dimensional position localization and recognition as online processing from a robot in motion. For online processing, the sound positions are estimated as probabilistic regions in three dimensional space, because the robot could observe only arrival direction of the sound at a moment. The detected sound signals are recognized using Convolutional Neural Network (CNN), for the adjustment to short input signals. The experimental results show our mobile robot could observe surrounding sound sources online and continuously update its position and sound label.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593777","","Mobile robots;Robot sensing systems;Microphone arrays;Estimation;Probabilistic logic","acoustic generators;acoustic signal detection;acoustic signal processing;convolutional neural nets;microphone arrays;mobile robots;probability","probabilistic regions;sound sources;microphone array;autonomous mobile robot;three-dimensional position localization;sound signals detection;online spatial sound perception system;convolutional neural network;CNN;three-dimensional position recognition;sound positions estimation","","","17","","","","","IEEE","IEEE Conferences"
"A Multi-Position Joint Particle Filtering Method for Vehicle Localization in Urban Area","S. Gu; Z. Xiang; Y. Zhang; Q. Qian","College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science & Electronic Engineering, Zhejiang University, Hangzhou, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","656","662","Robust localization is a prerequisite for autonomous vehicles. Traditional visual localization methods like visual odometry suffer error accumulation on long range navigation. In this paper, a flexible road map based probabilistic filtering method is proposed to tackle this problem. To effectively match the ego-trajectory to various curving roads in map, a new representation based on anchor point (AP) which captures the main curving points on the trajectory is presented. Based on APs of the map and trajectory, a flexible Multi-Position Joint Particle Filtering (MPJPF) framework is proposed to correct the position error. The method features the capability of adaptively estimating a series of APs jointly and only updates the estimation at situations with low uncertainty. It explicitly avoids the drawbacks of obliging to determine the current position at large uncertain situations such as dense parallel road branches. The experiments carried out on KITTI benchmark demonstrate our success.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593781","","Roads;Trajectory;Filtering;Urban areas;Wheels;Simultaneous localization and mapping;Navigation","distance measurement;image matching;mobile robots;particle filtering (numerical methods);path planning;probability;robot vision","flexible multiposition joint particle filtering;position error;anchor point;curving roads;ego-trajectory;probabilistic filtering method;flexible road map;long range navigation;error accumulation;visual odometry;traditional visual localization methods;autonomous vehicles;robust localization;urban area;vehicle localization;dense parallel road branches","","","19","","","","","IEEE","IEEE Conferences"
"Towards Norm Realization in Institutions Mediating Human-Robot Societies","A. Wasik; S. Tomic; A. Saffiotti; F. Pecora; A. Martinoli; P. U. Lima","École Polytechnique Fédérale de Lausanne, Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Switzerland; Federico Pecora are with Centre for Applied Autonomous Sensor Systems, Örebro University; Federico Pecora are with Centre for Applied Autonomous Sensor Systems, Örebro University; Federico Pecora are with Centre for Applied Autonomous Sensor Systems, Örebro University; École Polytechnique Fédérale de Lausanne, Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Switzerland; Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","297","304","Social norms are the understandings that govern the behavior of members of a society. As such, they regulate communication, cooperation and other social interactions. Robots capable of reasoning about social norms are more likely to be recognized as an extension of our human society. However, norms stated in a form of the human language are inherently vague and abstract. This allows for applying norms in a variety of situations, but if the robots are to adhere to social norms, they must be capable of translating abstract norms to the robotic language. In this paper we use a notion of institution to realize social norms in real robotic systems. We illustrate our approach in a case study, where we translate abstract norms into concrete constraints on cooperative behaviors of humans and robots. We investigate the feasibility of our approach and quantitatively evaluate the performance of our framework in 30 real experiments with user-based evaluation with 40 participants.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594079","","Robot kinematics;Grounding;Art;Cognition;Decision making;Semantics","human-robot interaction;social sciences computing","human-robot societies;norm realization;social interactions;robotic systems;robotic language;human language;human society;social norms","","","28","","","","","IEEE","IEEE Conferences"
"Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team","P. Maini; G. Gupta; P. Tokekar; P. Sujit","IIIT-Delhi, India; IIIT-Delhi, India; Virginia Tech., Dept. of ECE, US; IIIT-Delhi, Dept. of ECE, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3765","3770","We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593960","","Unmanned aerial vehicles;Robot sensing systems;Educational robots;Monitoring;Dynamic programming;Integrated circuits","aerospace robotics;dynamic programming;integer programming;linear programming;mobile robots;multi-robot systems;path planning","visibility-based monitoring;heterogeneous robot team;terrain path;aerial robots;route planning;dynamic programming approach;integer linear programming solution;ground robots","","","23","","","","","IEEE","IEEE Conferences"
"Human Motion Prediction Under Social Grouping Constraints","A. Rudenko; L. Palmieri; A. J. Lilienthal; K. O. Arras","Bosch Corporate Research, Stuttgart, Germany; Bosch Corporate Research, Stuttgart, Germany; Orebro University, Center of Applied Autonomous Sensor Systems (AASS), Sweden; Bosch Corporate Research, Stuttgart, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3358","3364","Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594258","","Force;Task analysis;Trajectory;Predictive models;Computational modeling;Tracking;Planning","Markov processes;mobile robots;motion control;multi-robot systems;planning (artificial intelligence);probability;random processes","human motion prediction;social grouping constraints;long-term prediction;social relations;social norms;surrounding agents;MDP planning problem;social forces;social grouping information;prediction process;soft formation constraints;mobile robots","","","26","","","","","IEEE","IEEE Conferences"
"Variable Admittance Control for Human-Robot Collaboration based on Online Neural Network Training","A. Sharkawy; P. N. Koustournpardis; N. Aspragathos","Mechanical Engineering Department, Faculty of Engineering, South Valley University, Qena, 83523, Egypt; Dept. of Mechanical Engineering & Aeronautics, University of Patras, Robotics Group, Rio, 26504, Greece; Dept. of Mechanical Engineering & Aeronautics, University of Patras, Robotics Group, Rio, 26504, Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1334","1339","In this paper, a method for variable admittance control in human-robot cooperation is proposed. A multilayer feedforward neural network is designed using the Cartesian velocity of the robot and the applied force by the operator as its inputs to modify online the virtual damping of the admittance controller. The neural network is trained online using the error backpropagation algorithm based on the error between the velocity of the minimum jerk trajectory model and the measured velocity of the robot. The performance of the proposed controller and the NN generalization ability are evaluated by conducting a point-to-point cooperative motion with multiple subjects using the KUKA LWR robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593526","Variable Admittance Control;Neural Networks;Error Backpropagation;Minimum Jerk Trajectory","Admittance;Artificial neural networks;Damping;Trajectory;Robot kinematics;Training","backpropagation;feedforward neural nets;human-robot interaction;manipulators;motion control;neurocontrollers","variable admittance control;human-robot collaboration;online neural network training;human-robot cooperation;multilayer feedforward neural network;Cartesian velocity;admittance controller;error backpropagation algorithm;KUKA LWR robot;virtual damping;point-to-point cooperative motion","","1","15","","","","","IEEE","IEEE Conferences"
"Design and Development of Biaxial Active Nozzle with Flexible Flow Channel for Air Floating Active Scope Camera","A. Ishii; Y. Ambe; Y. Yamauchi; H. Ando; M. Konyo; K. Tadakuma; S. Tadokoro","Graduate School of Information Sciences, Tohoku University, Japan; Graduate School of Information Sciences, Tohoku University, Japan; Graduate School of Information Sciences, Tohoku University, Japan; Graduate School of Information Sciences, Tohoku University, Japan; Graduate School of Information Sciences, Tohoku University, Japan; Graduate School of Information Sciences, Tohoku University, Japan; Graduate School of Information Sciences, Tohoku University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","442","449","Long flexible continuum robots have a high potential for search and rescue operations that explore deep layered debris. A general problem of these robots is in the control of the head motion because their thin bodies limit the space available to mount multiple actuators. This paper develops a biaxial active nozzle which can rotate the air jet direction along a roll and pitch axis in order to control the direction of reaction force and the head motion of a long flexible robot. A major challenge is how to change the air jet direction without a large resistance to the flow, which reduces the reaction force induced by the air jet. We propose a nozzle whose outlet is connected with a flexible air tube. The direction of the air jet is controlled by the smooth shape deformation of the tube. The nozzle should be compact enough to be installed on a thin robot, although the shape deformation of the tube may cause buckling. The flexible tube is modeled and simulated by a multiple link model used to derive the geometric parameters of the nozzle so that the nozzle is compact and the tube does not buckle. Based on the derived parameters, the biaxial active nozzle was developed. A basic performance experiment shows that the nozzle can change the reaction force direction by deforming the tube shape, while the magnitude of the reaction force is almost constant. We integrated the proposed nozzle with a conventional Active Scope Camera (ASC). The range where the robot can look around in a vertical exploration was significantly improved, which was three times larger than the previous ASC whose head was controlled by pneumatic actuators. The rubble field test demonstrates that the integrated ASC could move over rubble (maximum height of 200 mm) and steer the course.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594437","","Electron tubes;Robots;Force;Shape;Cameras;Strain;Pneumatic systems","buckling;cameras;deformation;design engineering;jets;mobile robots;motion control;nozzles;pneumatic actuators;position control;service robots;shapes (structures)","flexible robot;shape deformation;air floating active scope camera;pneumatic actuators;geometric parameters;ASC;rescue operations;reaction force direction;flexible air tube;air jet direction;head motion;flexible flow channel;biaxial active nozzle","","","16","","","","","IEEE","IEEE Conferences"
"Online Human Muscle Force Estimation for Fatigue Management in Human-Robot Co-Manipulation","L. Peternel; C. Fang; N. Tsagarakis; A. Ajoudani","Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab and HCMM Lab, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab and HCMM Lab, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab and HCMM Lab, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab and HCMM Lab, Via Morego 30, Genoa, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1340","1346","In this paper, we propose a novel method for selective management of muscle fatigue in human-robot co-manipulation. The proposed framework enables the detection of excessive fatigue levels of an individual muscle group while executing a certain task, and provides anticipatory robotic responses to distribute the effort among less-fatigued muscles of human arm. Our approach uses a machine learning technique to enable online predictions of muscle forces in different arm configurations and endpoint interaction forces. The estimated muscle forces are then used for the model-based estimation of muscle fatigue levels. Through optimisation, the fatigue management system can alter the task execution in a way that specific fatigued muscles are offloaded, while at the same time enables the production of task force using muscles with lower levels of fatigue. The main advantage of the proposed method is that it can operate online, and that all the measurements are performed by the robot sensory system, which can significantly increase the applicability in real-world scenarios. To validate the proposed method, we performed proof-of-concept experiments where the task of the human operator was to use a tool to polish an object that was manipulated by the robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593705","","Muscles;Force;Fatigue;Task analysis;Robot sensing systems;Optimization","electromyography;human-robot interaction;learning (artificial intelligence);medical computing;medical robotics;muscle","arm configurations;human-robot comanipulation;optimisation;online human muscle force estimation;human operator;robot sensory system;task force;specific fatigued muscles;task execution;fatigue management system;muscle fatigue levels;model-based estimation;estimated muscle forces;endpoint interaction forces;online predictions;machine learning technique;human arm;less-fatigued muscles;anticipatory robotic responses;individual muscle group;excessive fatigue levels;selective management","","","34","","","","","IEEE","IEEE Conferences"
"Autonomous Acquisition of Behavior Trees for Robot Control","B. Banerjee","The University of Southern Mississippi, School of Computing, Hattiesburg, MS, 39406","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3460","3467","Behavior trees (BT) are a popular control architecture in the computer game industry, and have been more recently applied in robotics. One open question is how can intelligent agents/robots autonomously acquire their behavior trees for task level control? In contrast with existing approaches that either refine an initially given BT, or directly build the BT based on human feedback/demonstration, we leverage reinforcement learning (RL) that allows robots to autonomously learn control policies by repeated task interaction, but often expressed in a language more difficult to interpret than BTs. The learned control policy is then converted to a behavior tree via our proposed <i>decanonicalization</i> algorithm. The feasibility of this idea is based on a proposed notion of <i>canonical behavior</i> trees (CBT). In particular, we show (1) CBTs are sufficiently expressive to capture RL control policies, and (2) that RL can be independent of an optimal behavior permutation, despite the BT convention of left-to-right priority, thus obviating the need for a combinatorial search. Two evaluation domains help illustrate our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594083","","Task analysis;Computer architecture;Reinforcement learning;Robot control;Games;Industries","computer games;feedback;intelligent robots;learning (artificial intelligence);mobile robots;optimisation;trees (mathematics)","robot control;learned control policy;RL control policies;optimal behavior permutation;intelligent agents;autonomous acquisition;computer game industry;intelligent robots;reinforcement learning;decanonicalization algorithm;canonical behavior tree;combinatorial search","","","20","","","","","IEEE","IEEE Conferences"
"On the Use of Energy Tanks for Multi-Robot Interconnection","G. Riggio; C. Fantuzzi; C. Secchi","Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3738","3743","In multi-robot systems passive interconnections among agents are often exploited to achieve a desired and robustly stable cooperative behavior. Nevertheless, the passivity constraint limits the kinds of behaviors that can be achieved. In this paper, we exploit the concept of energy tank for building a novel generalized interconnection that allows to impose any kind of dynamic coupling between two passive systems in a flexible way while preserving the passivity of the overall coupled system. The proposed strategy is validated by simulations and experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594262","","Couplings;Damping;Robots;Multi-robot systems;Robust stability;Buildings;Nonlinear dynamical systems","mobile robots;multi-robot systems;robust control","energy tank;multirobot systems passive interconnections;robustly stable cooperative behavior;passivity constraint;novel generalized interconnection;passive systems;coupled system","","","23","","","","","IEEE","IEEE Conferences"
"Soft Robotic Burrowing Device with Tip-Extension and Granular Fluidization","N. D. Naclerio; C. M. Hubicki; Y. O. Aydin; D. I. Goldman; E. W. Hawkes","University of California, Department of Mechanical Engineering, Santa Barbara, CA, 93106, USA; Georgia Institute of Technology, School of Physics, Atlanta, GA, 30332; Georgia Institute of Technology, School of Physics, Atlanta, GA, 30332; Georgia Institute of Technology, School of Physics, Atlanta, GA, 30332; University of California, Department of Mechanical Engineering, Santa Barbara, CA, 93106, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5918","5923","Mobile robots of all shapes and sizes move through the air, water, and over ground. However, few robots can move through the ground. Not only are the forces resisting movement much greater than in air or water, but the interaction forces are more complicated. Here we propose a soft robotic device that burrows through dry sand while requiring an order of magnitude less force than a similarly sized intruding body. The device leverages the principles of both tip-extension and granular fluidization. Like roots, the device extends from its tip; the principle of tip-extension eliminates skin drag on the sides of the body, because the body is stationary with respect to the medium. We implement this with an everting, pressure-driven thin film body. The second principle, granular fluidization, enables a granular medium to adopt a dynamic fluid-like state when pressurized fluid is passed through it, reducing the forces acting on an object moving through it. We realize granular fluidization with a flow of air through the core of the body that mixes with the medium at the tip. The proposed device could lead to applications such as search and rescue in mudslides or shallow subterranean exploration. Further, because it creates a physical conduit with its body, electrical lines, fluids, or even tools could be passed through this channel.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593530","","Electron tubes;Force;Robots;Strips;Fluidization;Pneumatic systems;Fabrics","fluidisation;granular materials;mobile robots;sand;underground equipment","granular fluidization;soft robotic burrowing device;mobile robots;interaction forces;pressure-driven thin film body;tip-extension;pressurized fluid","","","22","","","","","IEEE","IEEE Conferences"
"Neuroscientifically-Grounded Research for Improved Human-Robot Interaction","K. Kompatsiari; J. Pérez-Osorio; D. De Tommaso; G. Metta; A. Wykowska","Istituto Italiano di Tecnologia, Genova, 16145; Istituto Italiano di Tecnologia, Genova, 16145; Istituto Italiano di Tecnologia, Genova, 16145; Istituto Italiano di Tecnologia, Genova, 16145; Istituto Italiano di Tecnologia, Genova, 16145","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3403","3408","The present study highlights the benefits of using well-controlled experimental designs, grounded in experimental psychology research and objective neuroscientific methods, for generating progress in human-robot interaction (HRI) research. More specifically, we aimed at implementing a well-studied paradigm of attentional cueing through gaze (the so-called “joint attention” or “gaze cueing”) in an HRI protocol involving the iCub robot. Similarly to documented results in gaze-cueing research, we found faster response times and enhanced event-related potentials of the EEG signal for discrimination of cued, relative to uncued, targets. These results are informative for the robotics community by showing that a humanoid robot with mechanistic eyes and human-like characteristics of the face is in fact capable of engaging a human in joint attention to a similar extent as another human would do. More generally, we propose that the methodology of combining neuroscience methods with an HRI protocol, contributes to understanding mechanisms of human social cognition in interactions with robots and to improving robot design, thanks to systematic and well-controlled experimentation tapping onto specific cognitive mechanisms of the human, such as joint attention.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594441","","Cognition;Psychology;Humanoid robots;Protocols;Electroencephalography;Robot sensing systems","cognition;electroencephalography;humanoid robots;human-robot interaction;man-machine systems;neurophysiology;psychology","objective neuroscientific methods;experimental psychology research;well-controlled experimental designs;improved human-robot interaction;experimentation tapping;robot design;human social cognition;humanoid robot;robotics community;enhanced event-related potentials;faster response times;gaze-cueing research;documented results;iCub robot;HRI protocol;gaze cueing;joint attention;attentional cueing;human-robot interaction research","","","35","","","","","IEEE","IEEE Conferences"
"Information Sparsification in Visual-Inertial Odometry","J. Hsiung; M. Hsiao; E. Westman; R. Valencia; M. Kaess","Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1146","1153","In this paper, we present a novel approach to tightly couple visual and inertial measurements in a fixed-lag visual-inertial odometry (VIO) framework using information sparsification. To bound computational complexity, fixed-lag smoothers typically marginalize out variables, but consequently introduce a densely connected linear prior which significantly deteriorates accuracy and efficiency. Current state-of-the-art approaches account for the issue by selectively discarding measurements and marginalizing additional variables. However, such strategies are sub-optimal from an information-theoretic perspective. Instead, our approach performs a dense marginalization step and preserves the information content of the dense prior. Our method sparsifies the dense prior with a nonlinear factor graph by minimizing the information loss. The resulting factor graph maintains information sparsity, structural similarity, and nonlinearity. To validate our approach, we conduct real-time drone tests and perform comparisons to current state-of-the-art fixed-lag VIO methods in the EuRoC visual-inertial dataset. The experimental results show that the proposed method achieves competitive and superior accuracy in almost all trials. We include a detailed run-time analysis to demonstrate that the proposed algorithm is suitable for real-time applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594007","","Optimization;Markov processes;Microsoft Windows;Computational complexity;Cameras;Simultaneous localization and mapping;Visualization","computational complexity;distance measurement;graph theory;mobile robots;SLAM (robots)","information sparsification;tightly couple visual measurements;inertial measurements;fixed-lag visual-inertial odometry framework;bound computational complexity;fixed-lag smoothers;densely connected linear;information-theoretic perspective;dense marginalization step;information content;nonlinear factor graph;information loss;information sparsity;VIO methods;EuRoC visual-inertial dataset;structural similarity;nonlinearity;computational complexity","","","45","","","","","IEEE","IEEE Conferences"
"Scale-Robust Localization Using General Object Landmarks","A. Holliday; G. Dudek","Center for Intelligent Machines, McGill University, Sherbrooke St, Montreal, 845, Canada; Center for Intelligent Machines, McGill University, Sherbrooke St, Montreal, 845, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1688","1694","Visual localization under large changes in scale is an important capability in many robotic mapping applications, such as localizing at low altitudes in maps built at high altitudes, or performing loop closure over long distances. Existing approaches, however, are robust only up to about a 3× difference in scale between map and query images. We propose a novel combination of deep-learning-based object features and state-of-the-art SIFT point-features that yields improved robustness to scale change. This technique is training-free and class-agnostic, and in principle can be deployed in any environment out-of-the-box. We evaluate the proposed technique on the KITTI Odometry benchmark and on a novel dataset of outdoor images exhibiting changes in visual scale of 7× and greater, which we have released to the public. Our technique consistently outperforms localization using either SIFT features or the proposed object features alone, achieving both greater accuracy and much lower failure rates under large changes in scale.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594011","","Visualization;Measurement;Simultaneous localization and mapping;Robustness;Databases;Search problems","distance measurement;feature extraction;learning (artificial intelligence);mobile robots;object detection;robot vision;SLAM (robots)","deep-learning-based object features;KITTI Odometry benchmark;outdoor images;scale-robust localization;visual localization;robotic mapping applications;object landmarks;SIFT point-features","","","38","","","","","IEEE","IEEE Conferences"
"Autonomous Grasping Robotic Aerial System for Perching (AGRASP)","K. M. Popek; M. S. Johannes; K. C. Wolfe; R. A. Hegeman; J. M. Hatch; J. L. Moore; K. D. Katyal; B. Y. Yeh; R. J. Bamberger","The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA; The Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593669","","Manipulators;Tendons;Robot sensing systems;Bars;Grasping;Three-dimensional displays","autonomous aerial vehicles;biomimetics;control system synthesis;helicopters;manipulators;mobile robots;path planning;robot vision;sensors","AGRASP;multirotor aerial vehicles;robotics perception;vision-based path planning;highly-constrained sensor;autonomous grasping robotic aerial system for perching;biomimetically-inspired manipulation;perch structures;innovative manipulator design;active grasp;passive grip;quadrotor autonomously detection;onboard sensing;onboard processing","","","18","","","","","IEEE","IEEE Conferences"
"3D Underground Mapping with a Mobile Robot and a GPR Antenna","G. Kouros; I. Kotavelis; E. Skartados; D. Giakoumis; D. Tzovaras; A. Simi; G. Manacorda","Information Technologies Institute, Centre for Research and Technology Hellas, 6th Km Charilaou Thermi Road, Thessaloniki, 57100, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, 6th Km Charilaou Thermi Road, Thessaloniki, 57100, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, 6th Km Charilaou Thermi Road, Thessaloniki, 57100, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, 6th Km Charilaou Thermi Road, Thessaloniki, 57100, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, 6th Km Charilaou Thermi Road, Thessaloniki, 57100, Greece; IDS GeoRadar- part of Hexagon, Via A. Righi, 1–2 - Ospedaletto, PISA, 56121, Italy; IDS GeoRadar- part of Hexagon, Via A. Righi, 1–2 - Ospedaletto, PISA, 56121, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3218","3224","Automatic subsurface mapping is essential in the construction services, as it is anticipated to become the main operational environment of the future robots to be realized in the respective domain. Towards this direction, the paper at hand, introduces for the first time herein, an integrated framework for subsurface mapping by exploiting a surface operating mobile robot with a Ground Penetrating Radar (GPR). The mobile robot tows the GPR antenna, which is mounted on a specifically designed trailer, and is utilized as the mean to cover the surface area, while at the same time the antenna scans the subsurface by emitting electromagnetic pulses. The gathered data are processed for the construction of a subsurface 3D map. Specifically, image processing techniques, that involve background segmentation, HOG [1] feature extraction, hypothesis verification and matching are applied on the 2D radargram (B-Scan) for the detection of the salient points that correspond to buried utilities. By employing the pulse propagation velocity into the subsurface and the soil utilities, the salient points are expressed in world coordinates and used for the composition of the 3D subsurface map. Our method has been evaluated on a real test site, accompanied by ground-truth annotation data of experts and revealed remarkable performance, exhibiting not only the feasibility of underground mapping but also the capacity to obtain exploitable results for underground robotic applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593848","","Ground penetrating radar;Three-dimensional displays;Feature extraction;Mobile antennas;Mobile robots;Antenna measurements","feature extraction;ground penetrating radar;image matching;image segmentation;mobile robots;radar imaging","underground robotic applications;image processing techniques;subsurface 3D map;Ground Penetrating Radar;construction services;automatic subsurface mapping;GPR antenna;mobile robot;underground mapping","","","24","","","","","IEEE","IEEE Conferences"
"Achieving Flexible Assembly Using Autonomous Robotic Systems","K. Gilday; J. Hughes; F. Iida","Department of Engineering, Bio-Inspired Robotics Lab University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Lab University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Lab University of Cambridge, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Prefabrication of structures is currently used in a limited capacity, due to the lack of flexibility, despite the potential cost and speed advantages. Autonomous flexible reassembly enables structures to be developed which can be continuously and iteratively dis-assembled and re-assembled providing far more flexibility in comparison to single shot pre-fabrication methods. Dis-assembly of structures should be considered when assembling, due to the asymmetry of assembly and dis-assembly processes, to ensure structures can be recycled and re-assembled. This allows for agile development, significantly reducing the time and resource usage during the build process. In this work, a framework for flexible re-assembly is developed and a robotic platform is developed to implement and test this framework with simple Lego bricks. The tradeoffs in terms of time, resource use and probability of success of this new assembly method can be understood by using a cost function to compare to alternative fabrication methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593852","","Robots;Grippers;Fabrication;Morphology;Robotic assembly;Optimization;Force","mobile robots;recycling;robotic assembly","single shot pre-fabrication methods;assembling;dis-assembly processes;agile development;resource usage;build process;robotic platform;assembly method;cost function;alternative fabrication methods;flexible assembly;autonomous robotic systems;prefabrication;speed advantages;autonomous flexible reassembly;simple Lego bricks","","","18","","","","","IEEE","IEEE Conferences"
"Actuator and Friction Dynamics Formulation in Control of PKMs: From Design to Real-Time Experiments","H. Saied; A. Chemori; M. E. Rafei; C. Francis; F. Pierret","de Robotique, et de Microlectronique de Montpellier (LIRMM), Univ. Montpellier - CNRS, Laboratoire d'Informatique, Montpellier, 161rue Ada, 34095, France; de Robotique, et de Microlectronique de Montpellier (LIRMM), Univ. Montpellier - CNRS, Laboratoire d'Informatique, Montpellier, 161rue Ada, 34095, France; Lebanese Univ., Faculty of Engineering, Scientific Research Center in Engineering (CRSI), Hadath, Beirut, Lebanon; Lebanese Univ., Faculty of Engineering, Scientific Research Center in Engineering (CRSI), Hadath, Beirut, Lebanon; de Robotique, et de Microlectronique de Montpellier (LIRMM), Univ. Montpellier - CNRS, Laboratoire d'Informatique, Montpellier, 161rue Ada, 34095, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5634","5639","This paper deals with a new dynamic formulation of parallel manipulators incorporating the actuator and friction dynamics to be utilized in control. A model-based controller, PD with computed feedforward, is implemented for a parallel robot taking into consideration the formulated dynamics. The motivation behind this contribution is to enhance the control performance by compensating the unfavourable nonlinearities abundant extensively in PKMs. Those nonlinearities may increase considerably when operating at high-speed motions. The proposed feedforward part relies on the reference trajectories instead of the measured ones improving the control performance and the computational efforts. To validate our contribution, real-time experiments are conducted on a four degree-of-freedom parallel robot named VELOCE in different operating conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594329","","Friction;Actuators;Dynamics;Manipulator dynamics;Computational modeling;Torque","actuators;control system synthesis;feedforward;friction;manipulator dynamics;motion control;position control","real-time experiments;dynamic formulation;parallel manipulators;actuator;friction dynamics;model-based controller;computed feedforward;formulated dynamics;control performance;high-speed motions;feedforward part;computational efforts;PKM;four-degree-of-freedom parallel robot;unfavourable nonlinearity abundant extensively","","","22","","","","","IEEE","IEEE Conferences"
"Hands-Free Assistive Manipulator Using Augmented Reality and Tongue Drive System","F. Chu; R. Xu; Z. Zhang; P. A. Vela; M. Ghovanloo","Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, GA, USA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, GA, USA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, GA, USA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, GA, USA; Georgia Institute of Technology, Institute for Robotics and Intelligent Machines, GA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5463","5468","A human-in-the-loop system is proposed to enable hands-free collaborative manipulation for people with physical disabilities. Studies show that the cognitive burden of interfacing with a robotic assistant decreases with increased robot autonomy. Incorporating modern advances in perception with augmented reality, this paper describes a framework for obtaining high-level intents from the user to specify manipulation tasks for execution. Augmented reality glasses provide an egocentric perspective to the robot. The glasses also provide visual feedback to users on a virtual menu showing a summary of robot affordances. The system processes the vision input to interpret the users environment. A Tongue Drive System serves as the input modality for triggering task execution by the robotic arm. Several manipulation experiments are performed with comparison to Cartesian control. The outcomes are also compared to reported state-of-the-art approaches. The results demonstrate competitive performance with minimal user input requirements.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594508","","Manipulators;Task analysis;Visualization;Tongue;Three-dimensional displays;Machine vision","assisted living;augmented reality;handicapped aids;human-robot interaction;manipulators;mobile robots;robot vision;user interfaces","augmented reality glasses;robot autonomy;tongue drive system;egocentric perspective;visual feedback;Cartesian control;robotic assistant;cognitive burden;physical disabilities;hands-free collaborative manipulation;human-in-the-loop system;hands-free assistive manipulator;robotic arm","","","30","","","","","IEEE","IEEE Conferences"
"Precision Jumping Limits from Flight-phase Control in Salto-1P","J. K. Yim; R. S. Fearing","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, 94720, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2229","2236","We developed a deadbeat foot placement hopping controller for an untethered monopedal robot, Salto-1P. The controller uses a third order Taylor series approximation to an offline dynamic model and performs well on the physical platform. The robot demonstrated precise foot placement even on trajectories with aggressive changes in speed, direction, and height: in a random walk, its error standard deviation was 0.10 m. We establish how foot placement precision is tightly limited by attitude control accuracy, requiring attitude error less than 0.7 degrees for some tasks. We also show how foot placement precision degrades linearly as hopping height increases. These precision results apply to the large class of controllers that prescribe touchdown angle to control running velocity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594154","","Foot;Legged locomotion;Trajectory;Attitude control;Mathematical model;Robot kinematics","approximation theory;attitude control;control system synthesis;gait analysis;legged locomotion;motion control;position control;robot dynamics;velocity control","running velocity;precision results;height increases;foot placement precision degrades;attitude error;attitude control accuracy;error standard deviation;random walk;aggressive changes;precise foot placement;physical platform;offline dynamic model;order Taylor series approximation;untethered monopedal robot;deadbeat foot placement;Salto-1P;flight-phase control;precision jumping limits","","","22","","","","","IEEE","IEEE Conferences"
"End-effector with a Hook and Two Fingers for the Locomotion and Simple Work of a Four-limbed Robot","T. Matsuzawa; A. Imai; K. Hashimoto; T. Teramachi; X. Sun; S. Kimura; N. Sakai; Y. Yoshida; K. Kumaaai; T. Matsubara; K. Yamaguchi; A. Takanishi","Graduate School of Advanced Science and Engineering, Waseda University, #41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, JAPAN; Graduate School of Creative Science and Engineering, Waseda University; School of Science and Technology, Meiji University, Humanoid Robotics Institute (HRI), Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Graduate School of Creative Science and Engineering, Waseda University; Department of Modern Mechanical Engineering, Waseda University, Humanoid Robotics Institute (HRI), Waseda University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2727","2732","In this paper, we propose an end-effector for realizing various locomotion modes and simple work of a legged robot. The locomotion modes include climbing a vertical ladder, crawling, and walking. The simple work includes grasping and switching motions required at a disaster site. The developed end-effector has a two-pronged hook shape and two fingers for grasping and working and can be used to perform the locomotion and manipulation tasks described above. The experimental results confirmed that the four-limb robot WAREC-1 (WAseda REsCuer-No. 1) equipped with our proposed end-effector was able to climb a vertical ladder and perform the crawling motion. We also confirmed that the end-effector could grasp and switch five types of objects: a cylinder, cylinder with trigger, T-shaped, disk, and thin plate.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593422","","End effectors;Thumb;Grasping;Force;Shape","end effectors;legged locomotion;motion control","manipulation tasks;four-limb robot WAREC-1;vertical ladder;fingers;locomotion modes;legged robot;hook shape;grasping working;end-effector","","","15","","","","","IEEE","IEEE Conferences"
"Through-the-Lens Drone Filming","C. Huang; Z. Yang; Y. Kong; P. Chen; X. Yang; K. T. Cheng","Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA, 93106, USA; Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA, 93106, USA; Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA, 93106, USA; Zhejiang University of Technology, College of Information and Engineering, Hangzhou, 310023, China; Huazhong University of Science and Technology, School of Electronics Information and Communications, Wuhan, Hubei, 430074, China; Hong Kong University of Science and Technology, School of Engineering, Clear Water Bay, Kowloon, Hong Kong","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4692","4699","Aerial filming in action scenes using a drone is difficult for inexperienced flyers because manipulating a remote controller and meeting the desired image composition are two independent, while concurrent, tasks. Existing systems attempt to utilize wearable GPS-based or infrared-based sensors to track the human movement and to assist in capturing footage. However, these sensors work only in either indoor (infrared-based) or outdoor environments (GPS-based), but not both. In this paper, we introduce a novel drone filming system which integrates monocular 3D human pose estimation and localization into a drone platform to remove the constraints imposed by wearable-sensor-based solutions. Meanwhile, given the estimated position, we propose a novel drone control system, called “through-the-lens drone filming”, to allow a cameraman to conveniently control the drone by manipulating a 3D model in the preview, which closes the gap between the flight control and the viewpoint design. Our system includes two key enabling techniques: 1) subject localization based on visual-inertial fusion, and 2) through-the-lens camera planning. This is the first drone camera system which allows users to capture human actions by manipulating the camera in a virtual environment. From the drone hardware, we integrate a gimbal camera and two GPUs into the limited space of a drone and demonstrate the feasibility of running the entire system onboard with insignificant delays, which are sufficient for filming in our real-time application. Experimental results, in both simulation and real-world scenarios, demonstrate that our techniques can greatly ease camera control and capture better videos.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594333","","Cameras;Drones;Three-dimensional displays;Sensors;Pose estimation;Solid modeling;Two dimensional displays","autonomous aerial vehicles;cameras;feature extraction;Global Positioning System;image motion analysis;image sensors;mobile robots;pose estimation;robot vision;video signal processing","image composition;monocular 3D human pose estimation;drone control system;drone filming system;wearable GPS-based sensors;wearable infrared-based sensors;through-the-lens drone filming;aerial filming;camera control;drone hardware;human actions;drone camera system;through-the-lens camera planning;flight control;through-the-lens drone;wearable-sensor-based solutions;drone platform;outdoor environments;human movement;remote controller;action scenes","","","20","","","","","IEEE","IEEE Conferences"
"Design and Implementation of Cloud-Like Soft Drone S-Cloud","S. Hwan Song; H. Wook Shon; G. Yang Yeon; H. Ryeol Choi","Sungkyunkwan University, The School of Mechanical Engineering, Suwon, Korea; Sungkyunkwan University, The School of Mechanical Engineering, Suwon, Korea; Sungkyunkwan University, The School of Mechanical Engineering, Suwon, Korea; Sungkyunkwan University, The School of Mechanical Engineering, Suwon, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This study presents a new drone, called S-CLOUD, developed for safe and long flight time. It provides 3-axial (x, y, and z)translational motion and stable hovering for more than an hour after takeoff. S-CLOUD consists of two parts; soft blimp part and driving one. The soft blimp is a center-pierced torus-shaped part filled with Helium gas. Thus, it is safe to fly near people because it is light and soft, and all its rotating parts are at the center of the vehicle, which does not get damaged on collision. The driving part is plugged into the center of the soft blimp and includes the flow control mechanism, which consists of co-axial rotors and 2-axis crossed flaps. It controls the altitude, attitude, and translational movements of the vehicle. Its dynamic and reaction features against disturbances are derived using Newton-Euler formulation, and the simulation results are discussed. Finally, a prototype of S-CLOUD is fabricated and its feasibility is experimentally validated with practical applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593601","","Rotors;Force;Drones;Helium;Vehicle dynamics;Buoyancy","aerodynamics;airships;attitude control;autonomous aerial vehicles;flow control;helium;prototypes;rotors (mechanical)","soft blimp part;center-pierced torus-shaped part;flow control mechanism;co-axial rotors;2-axis crossed flaps;cloud-like soft drone S-cloud;translational motion;helium gas;collision damage;altitude control;attitude control;vehicle translational movements;Newton-Euler formulation;prototypes;He","","","17","","","","","IEEE","IEEE Conferences"
"Recovery Control for Quadrotor UAV Colliding with a Pole","G. Dicker; I. Sharf; P. Rustagi","NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6247","6254","Small quadrotor UAVs are projected to fly increasingly in urban environments for a wide variety of applications such as disaster response, police surveillance, civil infrastructure inspection, and air quality measurement. Micro UAVs can detect and avoid obstacles using onboard cameras; nevertheless, disturbances such as wind gusts, operator error, or failure of onboard vision can still result in dangerous collisions with objects. In the urban setting, the most predominant obstacles are walls and poles. With the aim of developing collision recovery control solutions for quadrotor UAVs, this paper investigates the collision dynamics between a propeller-protected quadrotor UAV and a vertical pole. Simulations provide insight into a quadrotor's post-collision dynamics and experimental trials demonstrate the feasibility of autonomously recovering to stable flight using only inertial onboard sensing in real-time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594512","","Force;Collision avoidance;Mathematical model;Geometry;Drones;Aerodynamics;Propellers","autonomous aerial vehicles;cameras;collision avoidance;helicopters;mobile robots;robot dynamics;robot vision;telerobotics","inertial onboard sensing;propeller-protected quadrotor UAV;collision recovery control solutions;poles;operator error;wind gusts;onboard cameras;microUAVs;air quality measurement;civil infrastructure inspection;police surveillance;disaster response;postcollision dynamics;onboard vision failure","","","18","","","","","IEEE","IEEE Conferences"
"Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing","A. Ajay; J. Wu; N. Fazeli; M. Bauza; L. P. Kaelbling; J. B. Tenenbaum; A. Rodriguez","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3066","3073","An efficient, generalizable physical simulator with universal uncertainty estimates has wide applications in robot state estimation, planning, and control. In this paper, we build such a simulator for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals. Combining symbolic, deterministic simulators with learnable, stochastic neural nets provides us with expressiveness, efficiency, and generalizability simultaneously. Our model outperforms both purely analytical and purely learned simulators consistently on real, standard benchmarks. Compared with methods that model uncertainty using Gaussian processes, our model runs much faster, generalizes better to new object shapes, and is able to characterize the complex distribution of object trajectories.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593995","","Analytical models;Predictive models;Physics;Data models;Uncertainty;Engines;Neural networks","Gaussian processes;learning (artificial intelligence);neural nets;state estimation","robot state estimation;planar pushing;ball bouncing;analytical rigid-body simulator;model uncertainty;symbolic simulators;stochastic neural networks;generalizable physical simulator;universal uncertainty estimates;analytical learned simulators;Gaussian processes;object trajectories","","","26","","","","","IEEE","IEEE Conferences"
"Determining Effective Swarm Sizes for Multi-Job Type Missions","M. Chandarana; M. Lewis; K. Sycara; S. Scherer","Mechanical Engineering at Carnegie Mellon University, Pittsburgh, PA, USA; Information Sciences and Intelligent Systems at the University of Pittsburgh, Pittsburgh, PA, USA; The authors are with the Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; The authors are with the Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4848","4853","Swarm search and service (SSS) missions require large swarms to simultaneously search an area while servicing jobs as they are encountered. Jobs must be immediately serviced and can be one of several different job types - each requiring a different service time and number of vehicles to complete its service successfully. After jobs are serviced, vehicles are returned to the swarm and become available for reallocation. As part of SSS mission planning, human operators must determine the number of vehicles needed to achieve this balance. The complexities associated with balancing vehicle allocation to multiple as yet unknown tasks with returning vehicles makes this extremely difficult for humans. Previous work assumes that all system jobs are known ahead of time or that vehicles move independently of each other in a multi-agent framework. We present a dynamic vehicle routing (DVR) framework whose policies optimally allocate vehicles as jobs arrive. By incorporating time constraints into the DVR framework, an M/M/k/k queuing model can be used to evaluate overall steady state system performance for a given swarm size. Using these estimates, operators can rapidly compare system performance across different configurations, leading to more effective choices for swarm size. A sensitivity analysis is performed and its results are compared with the model, illustrating the appropriateness of our method to problems of plausible scale and complexity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593919","","Robot sensing systems;Routing;Time factors;Planning;Task analysis","multi-agent systems;multi-robot systems;optimisation;particle swarm optimisation;queueing theory;sensitivity analysis;vehicle routing","sensitivity analysis;M/M/k/k queuing model;swarm search and service mission;SSS mission;swarm sizes;DVR;dynamic vehicle routing;multijob type missions;multiagent framework;balancing vehicle allocation;human operators","","","18","","","","","IEEE","IEEE Conferences"
"Predicting Out-of-View Feature Points for Model-Based Camera Pose Estimation","O. Moolan-Feroze; A. Calway","Department of Computer Science, University of Bristol, Merchant Venturers Building, Bristol, BS8 1UB, United Kingdom; Department of Computer Science, University of Bristol, Merchant Venturers Building, Bristol, BS8 1UB, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","82","88","In this work we present a novel framework that uses deep learning to predict object feature points that are out-of-view in the input image. This system was developed with the application of model-based tracking in mind, particularly in the case of autonomous inspection robots, where only partial views of the object are available. Out-of-view prediction is enabled by applying scaling to the feature point labels during network training. This is combined with a recurrent neural network architecture designed to provide the final prediction layers with rich feature information from across the spatial extent of the input image. To show the versatility of these out-of-view predictions, we describe how to integrate them in both a particle filter tracker and an optimisation based tracker. To evaluate our work we compared our framework with one that predicts only points inside the image. We show that as the amount of the object in view decreases, being able to predict outside the image bounds adds robustness to the final pose estimation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594297","","Cameras;Heating systems;Feature extraction;Pose estimation;Computational modeling;Two dimensional displays;Predictive models","cameras;feature extraction;inspection;learning (artificial intelligence);mobile robots;object tracking;particle filtering (numerical methods);pose estimation;recurrent neural nets","rich feature information;recurrent neural network architecture;network training;autonomous inspection robots;model-based tracking;input image;object feature points;deep learning;model-based camera pose estimation;out-of-view feature points;optimisation based tracker","","","17","","","","","IEEE","IEEE Conferences"
"Multi-Level Bayesian Decision-Making for Safe and Flexible Autonomous Navigation in Highway Environment","D. Iberraken; L. Adouane; D. Denis","CNRS, SIGMA Clermont, Université Clermont Auvergne, Institut Pascal, Clermont-Ferrand, F-63000, France; CNRS, SIGMA Clermont, Université Clermont Auvergne, Institut Pascal, Clermont-Ferrand, F-63000, France; R&D Department La Garenne Colombe, Sherpa Engineering Company, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3984","3990","This paper proposes an overall Multi-Controller Architecture (MCA) for safe and flexible navigation of autonomous navigation, under uncertainties in highway use-cases. In addition to the details given about the main modules (and their interactions) composing the proposed MCA, an important focus of the paper is made on the definition of a robust Two-Sequential Level Decision Network (TSLDN), which uses both: Extended Time-To-Collision (ETTC) metric and a new definition of a specific Predicted Inter-Distance Profile (PIDP, between vehicles during lane changes maneuvers) in order to estimate the maneuvers risks. The TSLDN is utilized for: the driving situation assessment, decision-making and for safety retrospection over the current maneuver risk. It allows us to have the best decision to achieve the vehicle navigation task while maximizing its safety. Several simulation results show the good performance of the overall proposed control architecture, mainly in terms of efficiency to handle probabilistic decision-making even for very risky scenarios.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593565","","Safety;Decision making;Navigation;Trajectory;Road transportation;Uncertainty;Probabilistic logic","Bayes methods;control engineering computing;decision making;navigation;probability;road safety;road traffic control;road vehicles;traffic engineering computing","TSLDN;driving situation assessment;vehicle navigation task;control architecture;probabilistic decision-making;safe navigation;flexible autonomous navigation;highway environment;MCA;multi-level Bayesian decision-making;multi-controller architecture;two-sequential level decision network;Extended Time-To-Collision metric;ETTC metric;Predicted Inter-Distance Profile","","","15","","","","","IEEE","IEEE Conferences"
"Learning and Generalization of Dynamic Movement Primitives by Hierarchical Deep Reinforcement Learning from Demonstration","W. Kim; C. Lee; H. J. Kim","Faculty of Aerospace and Mechanical Engineering, Seoul National University, 08826, South Korea; Faculty of Aerospace and Mechanical Engineering, Seoul National University, 08826, South Korea; Faculty of Aerospace and Mechanical Engineering, Seoul National University, 08826, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3117","3123","This paper presents an approach to learn and generalize robotic skills from a demonstration using deep reinforcement learning (deep RL). Dynamic Movement Primitives (DMPs) formulate a nonlinear differential equation and produce the observed movement from a demonstration. However, it is hard to generate new behaviors from using DMPs. Thus, we apply DMPs framework into deep RL as an initial setting for learning the robotic skills. First, we build a network to represent this differential equation, and learn and generalize the movements by optimizing the shape of DMPs with respect to the rewards up to the end of each sequence of movement primitives. In order to do this, we consider a deterministic actor-critic algorithm for deep RL and we also apply a hierarchical strategy. This drastically reduces the search space for a robot by decomposing the task, which allows to solve the sparse reward problem from a complex task. In order to integrate DMPs with hierarchical deep RL, the differential equation is considered as temporal abstraction of option. The overall structure is mainly composed of two controllers: meta-controller and sub-controller. The meta-controller learns a policy over intrinsic goals and a sub-controller learns a policy over actions to accomplish the given goals. We demonstrate our approach on a 6 degree-of-freedom (DOF) arm with a I-DOF gripper and evaluate our approach through a pick-and-place task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594476","","Task analysis;Robots;Reinforcement learning;Mathematical model;Differential equations;Dynamics;Deep learning","grippers;learning (artificial intelligence);nonlinear differential equations","meta-controller;learning generalization;dynamic movement primitives;hierarchical deep reinforcement learning;nonlinear differential equation;observed movement;hierarchical strategy;hierarchical deep RL;DMP framework;6-degree-of-freedom arm;deterministic actor-critic algorithm;robotic skill learning","","","20","","","","","IEEE","IEEE Conferences"
"Child-Sized Passive Exoskeleton for Supporting Voluntary Sitting and Standing Motions","K. Sasaki; M. Sugimoto; T. Sugiyama; D. F. Paez Granados; K. Suzuki","Ph.D. Program in Empowerment Informatics, University of Tsukuba, Japan; Ph.D. Program in Empowerment Informatics, University of Tsukuba, Japan; Ph.D. Program in Empowerment Informatics, University of Tsukuba, Japan; University of Tsukuba, Center of Cybernics Research, Japan; University of Tsukuba, Center of Cybernics Research, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5457","5462","This paper describes a novel passive exoskeleton for voluntary sitting-standing posture transition for children with lower limb impairment. The design of the exoskeleton is based on the utilization of the center of gravity transition through the user's upper body motion. The passive exoskeleton powered by gas springs allows the user to realize a natural-like posture transition by the user's voluntary upper body motion. We designed the posture transition model such that the user can realize the posture transition in a natural manner based on a minimum jerk criterion. The proposed design aims to permit toilet usage without transferring seating positions between the exoskeleton and toilet seat. Furthermore, the developed mechanism can be integrated with a regular wheelchair, which would allow users to have locomotion capability. We believe that the design can improve children's self-reliant social activities by supporting their voluntary posture transition and toilet use. In this paper, we describe the detailed design process of the exoskeleton and preliminary experiments to investigate its effectiveness through evaluation with a healthy participant.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593744","","Exoskeletons;Knee;Wheelchairs;Pediatrics;Mathematical model;Trajectory;Springs","biomechanics;handicapped aids;medical robotics;motion control;patient rehabilitation;position control;springs (mechanical);wearable robots","child-sized passive exoskeleton;voluntary sitting-standing posture transition;lower limb impairment;gas springs;voluntary upper body motion;posture transition model;minimum jerk criterion;toilet usage;toilet seat;voluntary posture transition;voluntary sitting motion;voluntary standing motion;exoskeleton design;center of gravity transition;seating position;locomotion capability;children self-reliant social activities","","","13","","","","","IEEE","IEEE Conferences"
"Disparity Sliding Window: Object Proposals from Disparity Images","J. Müller; A. Fregin; K. Dietmayer","Control and Microtechnology, University of Ulm, Dietmayer are with the Department of Measurement, Ulm, 89081, Germany; Research and Development, Daimler AG, Ulm, 89081, Germany; Control and Microtechnology, University of Ulm, Dietmayer are with the Department of Measurement, Ulm, 89081, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5777","5784","Sliding window approaches have been widely used for object recognition tasks in recent years [19], [4], [5], [18]. They guarantee an investigation of the entire input image for the object to be detected and allow a localization of that object. Despite the current trend towards deep neural networks, sliding window methods are still used in combination with convolutional neural networks [22]. The risk of overlooking an object is clearly reduced compared to alternative detection approaches which detect objects based on shape, edges or color. Nevertheless, the sliding window technique strongly increases the computational effort as the classifier has to verify a large number of object candidates. This paper proposes a sliding window approach which also uses depth information from a stereo camera. This leads to a greatly decreased number of object candidates without significantly reducing the detection accuracy. A theoretical investigation of the conventional sliding window approach is presented first. Other publications to date only mentioned rough estimations of the computational cost. A mathematical derivation clarifies the number of object candidates with respect to parameters such as image and object size. Subsequently, the proposed disparity sliding window approach is presented in detail. The approach is evaluated on pedestrian detection with annotations and images from the KITTI [10] object detection benchmark. Furthermore, a comparison with two state-of-the-art methods is made. Code is available in C++ and Python https://github.com/julimueller/disparity-sliding-window.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593390","","Microsoft Windows;Proposals;Computational efficiency;Task analysis;Cameras;Real-time systems;Image edge detection","convolutional neural nets;image classification;object detection;object recognition;stereo image processing","object proposals;disparity images;object recognition tasks;deep neural networks;convolutional neural networks;sliding window technique;object candidates;object size;disparity sliding window approach;pedestrian detection;KITTI object detection benchmark;object detection;classifier;depth information;stereo camera","","","30","","","","","IEEE","IEEE Conferences"
"Self-Supervised Learning of the Drivable Area for Autonomous Vehicles","J. Mayr; C. Unger; F. Tombari","BMW Group, Munich, 80788, Germany; BMW Group, Munich, 80788, Germany; Chair for Computer Aided Medical Procedures, Technical University Munich, Boltzmannstr.3, Garching, 85748, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","362","369","We propose a new approach for generating training data for the task of drivable area segmentation with deep neural networks (DNN). The impressive progress of deep learning in recent years demonstrated a superior performance of DNNs over traditional machine learning and deterministic algorithms for various tasks. Nevertheless, the acquisition of large-scale datasets with associated ground truth labels still poses an expensive and labor-intensive problem. We contribute to the solution of this problem for the task of road segmentation by proposing an automatic labeling pipeline which leverages a deterministic stereo-based approach for ground plane detection to create large datasets suitable for training neural networks. Based on the popular Cityscapes [1] and KITTI dataset [2] and two off-the-shelf DNNs for semantic segmentation, we show that we can achieve good segmentation results on monocular images, which substantially exceed the performance of the algorithm employed for automatic labeling without the need of any manual annotation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594480","","Image segmentation;Training data;Labeling;Generators;Histograms;Training;Cameras","image segmentation;learning (artificial intelligence);neural nets;object detection;stereo image processing","road segmentation;automatic labeling pipeline;deterministic stereo-based approach;ground plane detection;KITTI dataset;semantic segmentation;good segmentation results;self-supervised learning;autonomous vehicles;training data;drivable area segmentation;deep neural networks;impressive progress;deep learning;traditional machine learning;deterministic algorithms;large-scale datasets;associated ground truth labels;expensive labor-intensive problem;off-the-shelf DNN","","","23","","","","","IEEE","IEEE Conferences"
"Modified Adaptive Control of an Actuated Ankle Foot Orthosis to assist Paretic Patients","V. Arnez-Paniagua; H. Rifaï; Y. Amirat; S. Mohammed; M. Ghedira; J. M. Gracies","Signaux et Systémes Intelligents (LISSI), Université Paris-Est Créteil (UPEC), Laboratoire Images, Vitry-sur-Seine, 94400, France; Signaux et Systémes Intelligents (LISSI), Université Paris-Est Créteil (UPEC), Laboratoire Images, Vitry-sur-Seine, 94400, France; Signaux et Systémes Intelligents (LISSI), Université Paris-Est Créteil (UPEC), Laboratoire Images, Vitry-sur-Seine, 94400, France; Signaux et Systémes Intelligents (LISSI), Université Paris-Est Créteil (UPEC), Laboratoire Images, Vitry-sur-Seine, 94400, France; EA BIOTN, UPEC, Service de Rééducation, Neu-rolocomotrice, CHU Henri Mondor, Laboratoire ARM, Creteil, 94010, France; EA BIOTN, UPEC, Service de Rééducation, Neu-rolocomotrice, CHU Henri Mondor, Laboratoire ARM, Creteil, 94010, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2311","2317","In this paper, a model reference adaptive control with saturated proportional derivative (PD) action for an active ankle foot orthosis (AAFO) to assist the gait of paretic patients, is studied. Unlike most classical model-based controllers, the proposed controller does not require any prior estimation of the system's model parameters. The AAFO system is actively driven by the residual human torque delivered by muscles spanning the ankle joint and the AAFO's actuator's torque. The ankle reference trajectory is updated online based on the self-selected walking speed of the wearer. The input-to-state stability of the AAFO-wearer system with respect to a bounded human muscular torque is proved in closed-loop based on a Lyapunov analysis. Experimental results, obtained from one healthy subject and one paretic patient, show satisfactory results in terms of tracking performance and ankle joint assistance throughout the full gait cycle.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594046","","Torque;Foot;Legged locomotion;Lyapunov methods;Adaptation models;Trajectory;Muscles","actuators;closed loop systems;gait analysis;Lyapunov methods;medical control systems;model reference adaptive control systems;muscle;orthotics;stability","modified adaptive control;actuated ankle foot orthosis;saturated proportional derivative action;active ankle foot orthosis;classical model-based controllers;prior estimation;AAFO system;residual human torque;ankle joint;ankle reference trajectory;AAFO-wearer system;bounded human muscular torque;model reference adaptive control;AAFO actuator;paretic patient gait;self-selected walking speed;Lyapunov analysis;closed-loop;gait cycle;input-to-state stability","","","16","","","","","IEEE","IEEE Conferences"
"Any-Time Trajectory Planning for Safe Emergency Landing","P. Váňa; J. Sláma; J. Faigl; P. Pačes","Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, 166 27, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, 166 27, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, 166 27, Czech Republic; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, 166 27, Czech Republic","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5691","5696","Loss of thrust is a critical situation for human pilots of fixed-wing aircraft which force them to select a landing site in the nearby range and perform an emergency landing. The time for the landing site selection is limited by the actual altitude of the aircraft, and it may be fatal if the correct decision is not chosen fast enough. Therefore, we propose a novel RRT* -based planning algorithm for finding the safest emergency landing trajectory towards a given set of possible landing sites. Multiple landing sites are evaluated simultaneously during the flight even before any mechanical issue occurs, and the roadmap of possible landing trajectories is updated permanently. Thus, the proposed algorithm has the any-time property and provides the best emergency landing trajectory almost instantly.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594225","","Trajectory;Aircraft;Planning;Turning;Drag;Atmospheric modeling;Force","aerospace components;aerospace engineering;aircraft control;aircraft landing guidance;path planning;trajectory control","landing site selection;safest emergency landing trajectory;multiple landing sites;any-time property;time trajectory planning;safe emergency landing;critical situation;human pilots;landing trajectories;aircraft","","","15","","","","","IEEE","IEEE Conferences"
"Simultaneous Task Allocation and Planning Under Uncertainty","F. Faruq; D. Parker; B. Laccrda; N. Hawes","University of Birmingham, School of Computer Science; University of Birmingham, School of Computer Science; University of Oxford, Oxford Robotics Institute; University of Oxford, Oxford Robotics Institute","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3559","3564","We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594404","","Task analysis;Planning;Robot kinematics;Resource management;Uncertainty;Probabilistic logic","control engineering computing;formal verification;iterative methods;Markov processes;mobile robots;multi-robot systems;operating systems (computers);path planning;resource allocation;robot programming;temporal logic","simultaneous task allocation;uncertain environments;individual robot behaviour;linear temporal logic;multirobot policies;simultaneous task planning;Markov decision processes;formal verification;multirobot operating systems","","","28","","","","","IEEE","IEEE Conferences"
"Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network","S. Hosseinzadeh; M. Shakeri; H. Zhang","Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3124","3129","In recent years, various shadow detection methods from a single image have been proposed and used in vision systems; however, most of them are not appropriate for the robotic applications due to the expensive time complexity. This paper introduces a fast shadow detection method using a deep learning framework, with a time cost that is appropriate for robotic applications. In our solution, we first obtain a shadow prior map with the help of multi-class support vector machine using statistical features. Then, we use a semantic-aware patch-level Convolutional Neural Network that efficiently trains on shadow examples by combining the original image and the shadow prior map. Experiments on benchmark datasets demonstrate the proposed method significantly decreases the time complexity of shadow detection, by one or two orders of magnitude compared with state-of-the-art methods, without losing accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594050","","Image color analysis;Image edge detection;Support vector machines;Robots;Image segmentation;Training;Time complexity","convolutional neural nets;learning (artificial intelligence);object detection;robot vision;statistical analysis;support vector machines","patched convolutional neural network;semantic-aware patch-level convolutional neural network;statistical features;multiclass support vector machine;deep learning framework;robotic applications;vision systems;shadow detection methods","","","29","","","","","IEEE","IEEE Conferences"
"A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching","H. Nakamoto; M. Ohtake; K. Komoda; A. Sugahara; A. Ogawa","Corporate R&D Center Toshiba Corporation, Kawasaki, Komukai-Toshiba-cho 1, Saiwai-ku, 212-8582, Japan; Corporate R&D Center Toshiba Corporation, Kawasaki, Komukai-Toshiba-cho 1, Saiwai-ku, 212-8582, Japan; Corporate R&D Center Toshiba Corporation, Kawasaki, Komukai-Toshiba-cho 1, Saiwai-ku, 212-8582, Japan; Corporate R&D Center Toshiba Corporation, Kawasaki, Komukai-Toshiba-cho 1, Saiwai-ku, 212-8582, Japan; Corporate R&D Center Toshiba Corporation, Kawasaki, Komukai-Toshiba-cho 1, Saiwai-ku, 212-8582, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6093","6098","Suction is an effective method for picking various objects because it makes trajectory planning and control easy. However, suction has not been used due to misalignment and leakage of suction air when handling a variety of shapes. We therefore develop a hand to handle these characteristics. First, we model the vacuum pump and pad characteristics to allow evaluation of momentum and suction force in the case of leakage. Utilizing this, we select a configuration suitable for the items in the Amazon Robotics Challenge 2017. In addition, we design a mechanism for switching from suction to pinching for grasping items that cannot be sucked. Moreover, robust pinching is made possible by equipping the fingertips with a passive linear motion mechanism. In the Amazon Robotics Challenge 2017, it was shown possible to stably grasp items with irregularities and items with large moments. Furthermore, items that cannot be grasped by suction can also be grasped robustly by switching to the pinching mechanism.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593887","","Conferences;Intelligent robots","force control;grippers;motion control;robust control;trajectory control;vacuum pumps","robust pinching;Amazon Robotics Challenge 2017;suction air;vacuum pump;pad characteristics;gripper system;trajectory planning;trajectory control;suction force;passive linear motion mechanism","","","14","","","","","IEEE","IEEE Conferences"
"Magneto: A Versatile Multi-Limbed Inspection Robot","T. Bandyopadhyay; R. Steindl; F. Talbot; N. Kottege; R. Dungavell; B. Wood; J. Barker; K. Hoehn; A. Elfes","CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia; CSIRO, Robotics and Autonomous Systems Research Group, Brisbane, QLD, 4069, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2253","2260","In this paper we present the design and control strategies of a novel quadruped climbing robot (named Magneto) with three degrees of freedom (3-DOF) actuated limbs and a 3-DOF compliant magnetic foot. By exploiting its high degrees of freedom, Magneto is able to deform its body shape to squeeze through gaps of 23cm, which is smaller than standard human entry portholes of industrial confined spaces. Its compact foot design of footprint 4cm allows Magneto to walk on narrow beams of thickness less than 5cm, even at varying separation. The inherent high dimensional system design enables the body to be positioned in a wide range of orientations and seamlessly switch a limb function from locomotion to manipulation mode mid-climb. This capability enables access to confined space openings and occluded pockets and navigation through complex 3-D structures previously not demonstrated on legged climbing robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593891","","Adhesives;Legged locomotion;Magnetic separation;Foot;Inspection;Soft magnetic materials","actuators;design engineering;inspection;legged locomotion;manipulator kinematics","quadruped climbing robot;high dimensional system design;human entry portholes;three degrees of freedom actuated limbs;3-DOF compliant magnetic foot;locomotion;complex 3-D structures;industrial confined spaces;body shape;multilimbed inspection robot;legged climbing robots;confined space openings;manipulation mode mid-climb;limb function;Magneto;compact foot design","","1","20","","","","","IEEE","IEEE Conferences"
"Improving Repeatability of Experiments by Automatic Evaluation of SLAM Algorithms","F. Amigoni; V. Castelli; M. Luperto","Politecnico di Milano, Artificial Intelligence and Robotics Laboratory, Milano, Piazza Leonardo da Vinci 32, 20133, Italy; Politecnico di Milano, Artificial Intelligence and Robotics Laboratory, Milano, Piazza Leonardo da Vinci 32, 20133, Italy; Universita degli Studi di Milano, Applied Intelligent Systems Laboratory, Milano, Via Festa del Perdono 7, 20122, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7237","7243","The development of good experimental methodologies for robotics takes often inspiration from general principles of experimental practice. Repeatability prescribes that experiments should involve several trials in order to guarantee that results are not achieved by chance, but are systematic, and statistically significant trends can be identified. In this paper, we propose an approach to improve the repeatability of experiments performed in robotics. In particular, we focus on the domain of SLAM (Simultaneous Localization And Mapping) and we introduce a system that exploits simulations to generate a large number of test data on which SLAM algorithms are automatically evaluated in order to obtain consistent results, according to the principle of repeatability.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594189","","Simultaneous localization and mapping;Buildings;Measurement;Data models;Lasers","robot vision;SLAM (robots)","SLAM algorithms;robotics;repeatability;Simultaneous Localization And Mapping","","","26","","","","","IEEE","IEEE Conferences"
"Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration","E. Misimi; A. Olofsson; A. Eilertsen; E. R. Øye; J. R. Mathiassen","SINTEF Ocean, Trondheim, NO, 7465, Norway; SINTEF Ocean, Trondheim, NO, 7465, Norway; SINTEF Ocean, Trondheim, NO, 7465, Norway; SINTEF Ocean, Trondheim, NO, 7465, Norway; SINTEF Ocean, Trondheim, NO, 7465, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6972","6979","The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594368","Compliant food objects;Learning from Demonstration;Robotic handling;Multifingered gripper","Grasping;Visualization;Service robots;Task analysis;Robot sensing systems;Three-dimensional displays","grippers;intelligent robots;learning (artificial intelligence);mobile robots;pose estimation;robot vision;solid modelling","complex processing tasks;current robot learning policies;consistent learning policy;skilled operators;robotic automation;variable outcomes;tedious nature;laborious nature;human operators;food industries;ocean space;huge demand;mechanical structures;complex geometrical 3D shapes;high biological variation;deformable food raw materials;compliant food raw materials;robotic handling;complex 3D shapes;compliant food objects;inconsistent demonstrations;LfD learning policy;effective robot handling;gripper finger configuration;RGB-D images;food compliant objects;robotic grasping;robust learning policy","","","32","","","","","IEEE","IEEE Conferences"
"Intelligent Robotic IoT System (IRIS)Testbed","J. A. Tran; P. Ghosh; Y. Gu; R. Kim; D. D'Souza; N. Ayanian; B. Krishnamachari","Ming Hsieh Department of Electrical Engineering; Ming Hsieh Department of Electrical Engineering; Ming Hsieh Department of Electrical Engineering; Ming Hsieh Department of Electrical Engineering; Ming Hsieh Department of Electrical Engineering; Department of Computer Science; Ming Hsieh Department of Electrical Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We present the Intelligent Robotic IoT System (IRIS), a modular, portable, scalable, and open-source testbed for robotic wireless network research. There are two key features that separate IRIS from most of the state-of-the-art multi-robot testbeds. (1)Portability: IRIS does not require a costly static global positioning system such as a VICON system nor time-intensive vision-based SLAM for its operation. Designed with an inexpensive Time Difference of Arrival (TDoA)localization system with centimeter level accuracy, the IRIS testbed can be deployed in an arbitrary uncontrolled environment in a matter of minutes. (2)Programmable Wireless Communication Stack: IRIS comes with a modular programmable low-power IEEE 802.15.4 radio and IPv6 network stack on each node. For the ease of administrative control and communication, we also developed a lightweight publish-subscribe overlay protocol called ROMANO that is used for bootstrapping the robots (also referred to as the IRISbots), collecting statistics, and direct control of individual robots, if needed. We detail the modular architecture of the IRIS testbed design along with the system implementation details and localization performance statistics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593636","","Iris recognition;Iris;Robot kinematics;Protocols;Transceivers;Ultrasonic imaging","Global Positioning System;intelligent robots;IP networks;middleware;mobile radio;mobile robots;multi-robot systems;personal area networks;protocols;robot vision;SLAM (robots);wireless LAN","IPv6 network stack;individual robots;system implementation details;Intelligent robotic IoT system;modular source testbed;portable source testbed;open-source testbed;robotic wireless network research;IRIS;Time Difference of Arrival localization system;Time Difference of Arrival localization system;static global positioning system;multirobot testbeds;multirobot testbeds;Programmable Wireless Communication Stack;scalable source testbed;lightweight publish-subscribe overlay protocol;ROMANO;modular architecture","","","22","","","","","IEEE","IEEE Conferences"
"MAP - A Mobile Agile Printer Robot for on-site Construction","J. Sustarevas; D. Butters; M. Hammid; G. Dwyer; R. Stuart-Smith; V. M. Pawar","Department of Computer Science, University College London, Autonomous Manufacturing Laboratory, Gower Street, WC1E 6BT, UK; Department of Computer Science, University College London, Autonomous Manufacturing Laboratory, Gower Street, WC1E 6BT, UK; Department of Computer Science, University College London, Autonomous Manufacturing Laboratory, Gower Street, WC1E 6BT, UK; Department of Computer Science, University College London, Autonomous Manufacturing Laboratory, Gower Street, WC1E 6BT, UK; Department of Computer Science, University College London, Autonomous Manufacturing Laboratory, Gower Street, WC1E 6BT, UK; Department of Computer Science, University College London, Autonomous Manufacturing Laboratory, Gower Street, WC1E 6BT, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2441","2448","In this paper, we present a Mobile Agile Printer (MAP) construction robot; a highly agile, 4-legged, omnidirectional robot capable of 3D printing large structures. To overcome dynamic challenges when operating within an outdoors construction site, MAP incorporates a high-DoF 3D printing system connected to a mobile platform with novel features designed to enable disturbance rejection and live adaption to the robot's pose. In doing so, we demonstrate the benefits of designing construction robots with a focus on agility, a compact working volume and ability to operate within a potentially unlimited workspace. Performance tests were conducted showing smooth omni-directional motion as a key requirement for maintaining low 3D printing trajectory deviations over a large volume. In doing so, we show that MAP has the ability to construct in new ways more sensitive to its environment, context and concurrent on-site operations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593815","","Three-dimensional printing;Wheels;Legged locomotion;Printers","construction;legged locomotion;mobile robots;robot kinematics;service robots;three-dimensional printing;wheels","outdoors construction site;3D printing large structures;omnidirectional robot capable;Mobile Agile Printer construction robot;on-site construction;concurrent on-site operations;low 3D printing trajectory deviations;construction robots;mobile platform;high-DoF 3D printing system;MAP","","","31","","","","","IEEE","IEEE Conferences"
"Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots","A. Nagabandi; G. Yang; T. Asmar; R. Pandya; G. Kahn; S. Levine; R. S. Fearing","University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4606","4613","Millirobots are a promising robotic platform for many applications due to their small size and low manufacturing costs. Legged millirobots, in particular, can provide increased mobility in complex environments and improved scaling of obstacles. However, controlling these small, highly dynamic, and underactuated legged systems is difficult. Hand-engineered controllers can sometimes control these legged millirobots, but they have difficulties with dynamic maneuvers and complex terrains. We present an approach for controlling a real-world legged millirobot that is based on learned neural network models. Using less than 17 minutes of data, our method can learn a predictive model of the robot's dynamics that can enable effective gaits to be synthesized on the fly for following user-specified waypoints on a given terrain. Furthermore, by leveraging expressive, high-capacity neural network models, our approach allows for these predictions to be directly conditioned on camera images, endowing the robot with the ability to predict how different terrains might affect its dynamics. This enables sample-efficient and effective learning for locomotion of a dynamic legged millirobot on various terrains, including gravel, turf, carpet, and styrofoam. Videos and further details can be found at https://sites.google.com/view/imageconddyn.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594193","","Vehicle dynamics;Legged locomotion;Neural networks;Adaptation models;Predictive models;Robot sensing systems","collision avoidance;learning (artificial intelligence);legged locomotion;microrobots;mobile robots;neural nets;robot dynamics","underactuated legged systems;hand-engineered controllers;dynamic maneuvers;complex terrains;real-world legged millirobot;learned neural network models;predictive model;expressive capacity neural network models;high-capacity neural network models;effective learning;dynamic legged millirobot;image-conditioned dynamics models;underactuated legged millirobots;low manufacturing costs;complex environments;highly dynamic systems","","","52","","","","","IEEE","IEEE Conferences"
"An Omnidirectional Jumper with Expanded Movability via Steering, Self-Righting and Take-off Angle Adjustment","S. Yim; S. Baek; G. Jung; K. Cho","Biorobotics Laboratory, School of Mechanical Engineering, Seoul National University, Seoul, Republic of Korea; Biorobotics Laboratory, School of Mechanical Engineering, Seoul National University, Seoul, Republic of Korea; Bio-inspired Design Laboratory, School of Mechanical & Automotive Engineering, Seoul National University of Science & Technology, Seoul, Republic of Korea; Biorobotics Laboratory, School of Mechanical Engineering, Seoul National University, Seoul, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","416","421","In this paper, we propose an omnidirectional jumper with expanded locomotion capabilities. The mechanisms for four functions-jumping, steering, self-righting and take-off angle adjustment-are designed using only two motors to maximize the jumping performance. Jumping uses the modified active triggering mechanism with one motor. Steering shares this motor and uses the wheel touching the ground. The take-off angle is adjusted by changing the angle between the body and the foot using another motor. Self-righting is possible by utilizing combinations of the movements that occur in the energy storing and angle adjustment processes. With these four functions, the robot is capable of jumping in all directions and can jump anywhere in between the maximum height and maximum distance. It can also jump multiple times by self-righting. The robot, with a mass of 64.4 g, jumps up to 113 cm in vertical height, and 170 cm in horizontal distance. This robot can be deployed to explore various environments. Moreover, the design method to implement more functions than the number of motors can be applied to design other small-scale robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594372","","Robots;Couplings;Gears;Windings;Pulleys;Wheels;Energy storage","biomechanics;mobile robots","steering shares;modified active triggering mechanism;jumping performance;expanded locomotion capabilities;angle adjustment;self-righting;expanded movability;omnidirectional jumper","","","21","","","","","IEEE","IEEE Conferences"
"Modeling of Robotic Fish Propelled by a Servo/IPMC Hybrid Tail","Z. Chen; P. Hou; Z. Ye","Department of Mechanical Engineering at the University of Houston, Houston, TX, 77204-4006; Wichita State University, Department of Electrical Engineering and Computer Science; Wichita State University, Department of Electrical Engineering and Computer Science","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8146","8151","This paper presents modeling of robotic fish propelled by a hybrid tail with Servo and IPMC actuated two joints. The first joint is driven by a servo motor, which generates flapping motion for main propulsion. The second joint is actuated by a soft actuator, or ionic polymer-metal composite (IPMC) artificial muscle, which directs the propelled fluid for steering. A dynamic model is developed to capture the 2D motion dynamics of the robotic fish. The model fully captures the actuation dynamics of the IPMC soft actuator, two-link tail motion dynamics, and body motion dynamics. Experimental results have shown that the robotic fish is capable of swimming forward (up to 0.45 body length/second) and turning left and right (up to 40 degree/sec) with a small turning radius (less than half a body length). Finally, the dynamic model has been validated with experimental data, in terms of steady-state forward speed and turning speed versus the flapping frequency.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593640","","Fish;Servomotors;Dynamics;Actuators;Two dimensional displays;Robot sensing systems","actuators;biomimetics;electroactive polymer actuators;mobile robots;motion control;muscle;propulsion;robot dynamics;servomotors;steering systems","IPMC soft actuator;two-link tail motion dynamics;body motion dynamics;servo motor;propelled fluid;actuation dynamics;ionic polymer-metal composite artificial muscle;servo-IPMC hybrid tail;flapping motion;robotic fish propulsion;steering system;turning speed","","","12","","","","","IEEE","IEEE Conferences"
"Robust Visual-Inertial State Estimation with Multiple Odometries and Efficient Mapping on an MAV with Ultra-Wide FOV Stereo Vision","M. G. Miiller; F. Steidle; M. J. Schuster; P. Lutz; M. Maier; S. Stoneman; T. Tomic; W. Stürzl","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3701","3708","The here presented flying system uses two pairs of wide-angle stereo cameras and maps a large area of interest in a short amount of time. We present a multicopter system equipped with two pairs of wide-angle stereo cameras and an inertial measurement unit (IMU) for robust visual-inertial navigation and time-efficient omni-directional 3D mapping. The four cameras cover a 240 degree stereo field of view (FOV) vertically, which makes the system also suitable for cramped and confined environments like caves. In our approach, we synthesize eight virtual pinhole cameras from four wide-angle cameras. Each of the resulting four synthesized pinhole stereo systems provides input to an independent visual odometry (VO). Subsequently, the four individual motion estimates are fused with data from an IMU, based on their consistency with the state estimation. We describe the configuration and image processing of the vision system as well as the sensor fusion and mapping pipeline on board the MAV. We demonstrate the robustness of our multi-VO approach for visual-inertial navigation and present results of a 3D-mapping experiment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594117","","Cameras;Distortion;Image resolution;Computational modeling;Navigation;Visual odometry;Hardware","autonomous aerial vehicles;cameras;distance measurement;estimation theory;image fusion;image sensors;inertial navigation;motion estimation;motion measurement;state estimation;stereo image processing;visual perception","wide-angle stereo cameras;multicopter system;inertial measurement unit;virtual pinhole cameras;independent visual odometry;vision system;sensor fusion;robust visual-inertial state estimation;ultrawide FOV stereo vision;MAV;IMU;robust visual-inertial navigation;omnidirectional 3D mapping pipeline experiment;field of view;synthesized pinhole stereo systems;motion estimation fusion;image processing;multiVO approach","","","26","","","","","IEEE","IEEE Conferences"
"Optimizing Sensor Placement: A Mixture Model Framework Using Stable Poses and Sparsely Precomputed Pose Uncertainty Predictions","T. M. Iversen; D. Kraft","University of Southern, All authors are with The Maersk Mc-Kinney Moller Institute, Denmark; University of Southern, All authors are with The Maersk Mc-Kinney Moller Institute, Denmark","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6652","6659","In many robotics tasks successful execution requires high precision pose estimates of the objects in the workcell. When the object pose is provided by a computer vision system it is therefore crucial that the vision system is configured such that the required precision is achieved. An important part of the configuration is the sensor placement, however, most work in the field of sensor placement does not take the random, semi-constrained nature of the initial object pose into account. This paper presents a framework which uses an analysis of object stable poses together with dynamic simulation to predict the probability distribution of initial object poses. The framework is highly modular and uses precomputed pose uncertainties and a mixture model to make the integration over all possible stable poses feasible. This makes the framework applicable to a wide range of sensors and uncertainty models. The framework is evaluated in simulation for a concrete example: A single PrimeSense Carmine to be placed at an optimal elevation angle in a table picking scenario where pose uncertainties are modeled using Gaussians.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594121","","Robot sensing systems;Uncertainty;Computational modeling;Task analysis;Optimization;Measurement","image sensors;mobile robots;optimisation;pose estimation;probability;robot vision;sensor placement","computer vision system;mixture model framework;sensor placement optimization;robotics tasks;pose estimation;probability distribution;primesense carmine","","","19","","","","","IEEE","IEEE Conferences"
"High-frame-rate Target Tracking with CNN-based Object Recognition","M. Jiang; Y. Gu; T. Takaki; I. Ishii","Department of System Cybernetics, Hiroshima University, 1-4-1, Kagamiyama, Higashi-Hiroshima, Hiroshima, 739-8527, Japan; Department of System Cybernetics, Hiroshima University, 1-4-1, Kagamiyama, Higashi-Hiroshima, Hiroshima, 739-8527, Japan; Department of System Cybernetics, Hiroshima University, 1-4-1, Kagamiyama, Higashi-Hiroshima, Hiroshima, 739-8527, Japan; Department of System Cybernetics, Hiroshima University, 1-4-1, Kagamiyama, Higashi-Hiroshima, Hiroshima, 739-8527, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","599","606","This paper proposes an intelligent and fast tracking method for robust trackability against appearance changes. The method hybridizes a correlation-based tracking algorithm operating at hundreds of frames per second (fps) with a deep learning-based recognition algorithm operating at dozens of fps. A prototype intelligent mechanical tracking system was developed by implementing our hybridized tracking algorithm on a 500-fps vision platform. A complex-shaped target can be robustly tracked at the center of the camera view in real time by controlling a pan-tilt active vision system with 500 Hz visual feedback. The tracking performance of our proposed algorithm was verified by showing several experimental results for pre-learned objects, which were quickly manipulated against complex backgrounds.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594300","","Target tracking;Correlation;Visualization;Cameras;Object recognition;Deep learning","cameras;computer vision;feature extraction;image motion analysis;learning (artificial intelligence);object detection;object recognition;object tracking;target tracking;tracking","vision platform;visual feedback;pre-learned objects;tracking performance;pan-tilt active vision system;complex-shaped target;hybridized tracking algorithm;prototype intelligent mechanical tracking system;deep learning-based recognition algorithm;fast tracking method;intelligent tracking method;CNN-based object recognition;high-frame-rate target tracking;frequency 500.0 Hz","","","23","","","","","IEEE","IEEE Conferences"
"Dynamic Dumbbell - Novel Muscle Training Robot with Programmable Exercise Load","C. Lee; S. Oh","DGIST, The authors are with Department of Robotics Engineering, Daegu, 711-785, Korea; DGIST, The authors are with Department of Robotics Engineering, Daegu, 711-785, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, Dynamic Dumbbell, a novel robotic device for advanced muscular exercise of upper limb is presented. The type of exercise load is classified and designed in terms of mechanical engineering to be implemented in Dynamic Dumbbell. The exercise load model, which is named as programmable exercise load, is realized by Dynamic Dumbbell. To generate the programmable exercise load, two of compact Planetary-geared Elastic Actuator, which is a rotary Series Elastic Actuator (SEA), are utilized in Dynamic Dumbbell. The SEAs are controlled using high performance force control algorithm. Experimental results verifies the effectiveness of the proposed Dynamic Dumbbell and programmable exercise load.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593779","","Dynamics;Muscles;Torque;Robots;Force;Load modeling;Gears","actuators;elasticity;force control;gears;medical robotics;muscle;patient rehabilitation","high performance force control algorithm;rotary series elastic actuator;planetary-geared elastic actuator;mechanical engineering;muscle training robot;exercise load model;advanced muscular exercise;Dynamic Dumbbell;programmable exercise load;Dynamic dumbbell","","","20","","","","","IEEE","IEEE Conferences"
"Mechanical and Perceptual Characterizations of the Localized Shearing using a Novel Haptic Display","H. Van Anh; S. Hirai","Graduate School of Advanced Science and Engineering, Japan Advanced Institute of Science and Technology (JAIST) Nomi-shi, Ishikawa, 923-1292, Japan; Department of Robotics, Ritsumeikan University, 1-1 Noji- Higashi, Shiga, Kusatsu, 525-8577, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1636","1642","Previously, we presented the concept of a novel haptic display device that could generate lateral localized displacement on a human fingertip. This device is characterized by a bundle of haptic pins whose ends gently make contact with a human fingertip. In this paper, we proposed a dynamic model of interaction between haptic pins and finger for investigation of mechanical response of stress or strain on human fingertip under operation of the proposed haptic device. We also conducted preliminary experiment to determine the possible setups that maximizes the sense of partial slippage. The results presented in this paper may help assess human slip perception for the development of haptic display devices.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593958","","Pins;Haptic interfaces;Force;Skin;Mathematical model;Numerical models;Strain","display devices;haptic interfaces","haptic pins;lateral localized displacement;localized shearing;perceptual characterizations;haptic display devices;human slip perception;mechanical response;human fingertip","","","21","","","","","IEEE","IEEE Conferences"
"Transferable Pedestrian Motion Prediction Models at Intersections","M. Shen; G. Habibi; J. P. How","Department of Mechanical Engineering Massachusetts Institute of Technology (MIT), Aerospace Controls Laboratory (ACL), 77 Massachusetts Ave., Cambridge, MA, USA; Department of Aeronautics and Astronautics, ACL, MIT; Department of Aeronautics and Astronautics, ACL, MIT","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4547","4553","One desirable capability of autonomous cars is to accurately predict the pedestrian motion near intersections for safe and efficient trajectory planning. We are interested in developing transfer learning algorithms that can be trained on the pedestrian trajectories collected at one intersection and yet still provide accurate predictions of the trajectories at another, previously unseen intersection. We first discussed the feature selection for transferable pedestrian motion models in general. Following this discussion, we developed one transferable pedestrian motion prediction algorithm based on Inverse Reinforcement Learning (IRL) that infers pedestrian intentions and predicts future trajectories based on observed trajectory. We evaluated our algorithm at three intersections. We used the accuracy of augmented semi-nonnegative sparse coding (ASNSC), trained and tested at the same intersection as a baseline. The result shows that the proposed algorithm improves the baseline accuracy by a statistically significant percentage in both non-transfer task and transfer task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593783","","Trajectory;Hidden Markov models;Semantics;Predictive models;Prediction algorithms;Feature extraction;Reinforcement learning","automobiles;feature selection;learning (artificial intelligence);mobile robots;pedestrians;road safety;statistical analysis;trajectory control","autonomous cars;transfer learning algorithms;pedestrian trajectories;transferable pedestrian motion prediction algorithm;trajectory planning;inverse reinforcement learning;feature selection;IRL;augmented seminonnegative sparse coding;ASNSC","","","15","","","","","IEEE","IEEE Conferences"
"A Plug-In Feed-Forward Control for Sloshing Suppression in Robotic Teleoperation Tasks","L. Biagiotti; D. Chiaravalli; L. Moriello; C. Melchiorri","Department of Engineering “Enzo Ferrari”, University of Modena and Reggio Emilia, via Pietro Vivarelli 10, Modena, 41125, Italy; Department of Electrical, Electronic and Information Engineering “Guglielmo Marconi”, University of Bologna, Viale del Risorgimento 2, Bologna, 40136, Italy; Department of Electrical, Electronic and Information Engineering “Guglielmo Marconi”, University of Bologna, Viale del Risorgimento 2, Bologna, 40136, Italy; Department of Electrical, Electronic and Information Engineering “Guglielmo Marconi”, University of Bologna, Viale del Risorgimento 2, Bologna, 40136, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5855","5860","In this paper, the problem of suppressing sloshing dynamics in liquid handling robotic systems has been faced by designing a dynamic filter that starting from the desired motion of the liquid container calculates the complete position/orientation trajectory for the robot end-effector. Specifically, a design philosophy mixing a filtering technique that suppresses the frequency contributions of the reference motion that may cause liquid oscillations and an active compensation of lateral accelerations by a proper container re-orientation has been adopted. In principle, the latter contribution requires the knowledge of acceleration of the reference trajectory, but because of the use of an harmonic smoother that performs a shaping of the original motion, it is possible to obtain the value of the acceleration in runtime. In this way, the proposed methods can be applied also to reference motions that are not known in advance, e.g. commands directly provided by a human operator. This possibility has been demonstrated by means of a number of experimental tests in which the user teleoperates the robot carrying the container with the liquid by simply moving in the free space its hand, whose 3D position is detected by a motion capture system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593962","","Liquids;Containers;Robots;Acceleration;Trajectory;Mathematical model;Vibrations","compensation;containers;end effectors;feedforward;industrial robots;manipulator dynamics;mobile robots;motion control;sloshing;telerobotics;trajectory control","position-orientation trajectory;dynamic filter design;sloshing dynamics suppression;lateral accelerations;active compensation;liquid oscillations;filtering technique;design philosophy;robot end-effector;liquid container;liquid handling robotic systems;robotic teleoperation tasks;feed-forward control;motion capture system;harmonic smoother","","","14","","","","","IEEE","IEEE Conferences"
"Tactile Regrasp: Grasp Adjustments via Simulated Tactile Transformations","F. R. Hogan; M. Bauza; O. Canal; E. Donlon; A. Rodriguez","Department of Mechanical Engineering, Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2963","2970","This paper presents a novel regrasp control policy that makes use of tactile sensing to plan local grasp adjustments. Our approach determines regrasp actions by virtually searching for local transformations of tactile measurements that improve the quality of the grasp. First, we construct a tactile-based grasp quality metric using a deep convolutional neural network trained on over 2800 grasps. The quality of each grasp, a continuous value between 0 and 1, is determined experimentally by measuring its resistance to external perturbations. Second, we simulate the tactile imprints associated with robot motions relative to the initial grasp by performing rigid-body transformations of the given tactile measurements. The newly generated tactile imprints are evaluated with the learned grasp quality network and the regrasp action is chosen to maximize the grasp quality. Results show that the grasp quality network can predict the outcome of grasps with an average accuracy of 85% on known objects and 75% on novel objects. The regrasp control policy improves the success rate of grasp actions by an average relative increase of 70% on a test set of 8 objects. We provide a video summarizing our approach at https://youtu.be/gjn7DmfpwDk.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593528","","Grasping;Measurement;Tactile sensors;Grippers","convolutional neural nets;grippers;manipulators;motion control;path planning;robot vision","tactile regrasp;simulated tactile transformations;tactile sensing;regrasp action;local transformations;grasp quality metric;deep convolutional neural network;rigid-body transformations;grasp quality network;grasp actions;tactile measurements;grasp adjustments;regrasp control policy;tactile imprints;robot motions","","1","37","","","","","IEEE","IEEE Conferences"
"Adaptive Sensor Bias Estimation in Nine Degree of Freedom Inertial Measurement Units: Theory and Preliminary Evaluation","A. R. Spielvogel; L. L. Whitcomb","Johns Hopkins University, Department of Mechanical Engineering, Baltimore, MD, 21218; Johns Hopkins University, Department of Mechanical Engineering, Baltimore, MD, 21218","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5555","5561","Nine degrees of freedom (DOF) inertial measurement units (IMUs) comprised of three-axis magnetometers, three-axis accelerometers, and three-axis angular rate sensors are commonly used in attitude and heading reference systems (AHRSs). Two classes of AHRSs exist: systems that estimate true-North heading and systems that estimate magnetic-North heading. True-North heading AHRSs require high-end angular rate sensors which are sensitive enough to dynamically estimate Earth-rate (typically fiber-optic and ring-laser gyros), while magnetic-North AHRSs employ gyros that are not sensitive enough to dynamically estimate Earth-rate (i.e. all MEMS gyros). Thus, magnetic-North AHRSs employ magnetometers for estimating heading. This paper will focus on this class of magnetic-North AHRSs. These systems fuse IMU measurements to generate estimates of the instrument's roll, pitch, and magnetic heading. However, their accuracy is limited by sensor measurement bias that is unknown a priori. Hence, accurate sensor bias estimation and compensation is essential for true attitude estimation. This paper reports a novel adaptive sensor bias observer for sensor measurement biases in 9-DOF IMUs. The algorithm requires smaller angular movements of the instrument than other reported sensor bias calibration methods, does not require a priori knowledge of local fields like the local magnetic field or the local gravity vector, and does not require knowledge of the attitude of the instrument. Stability proofs, preliminary simulations, and a full-scale vehicle experimental evaluation are reported.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594439","","Robot sensing systems;Magnetometers;Instruments;Accelerometers;Observers;Gyroscopes","angular measurement;attitude measurement;calibration;gyroscopes;inertial systems;magnetic field measurement;magnetic sensors;magnetometers","adaptive sensor bias estimation;three-axis magnetometers;three-axis accelerometers;three-axis angular rate sensors;high-end angular rate sensors;ring-laser gyros;MEMS gyros;compensation;attitude estimation;attitude and heading reference systems;nine degree of freedom inertial measurement units;sensor bias calibration methods;adaptive sensor bias observer;magnetic-north AHRS heading;DOF inertial measurement units;true-North heading AHRS estimation;Earth-rate estimation;9-DOF IMU measurements","","","24","","","","","IEEE","IEEE Conferences"
"HTC Vive: Analysis and Accuracy Improvement","M. Borges; A. Symington; B. Coltin; T. Smith; R. Ventura","Institute for Systems and Robotics - Lisboa, Instituto Superior Técnico, Universidade de Lisboa; SGT Inc., NASA Ames Research Center; SGT Inc., NASA Ames Research Center; NASA Ames Research Center; Institute for Systems and Robotics - Lisboa, Instituto Superior Técnico, Universidade de Lisboa","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2610","2615","HTC Vive has been gaining attention as a cost-effective, off-the-shelf tracking system for collecting ground truth pose data. We assess this system's pose estimation through a series of controlled experiments where we show its precision to be in the millimeter magnitude and accuracy to range from millimeter to meter. We also show that Vive gives greater weight to inertial measurements in order to produce a smooth trajectory for virtual reality applications. Hence, the Vive's off the shelf algorithm is poorly suited for robotics applications such as measuring ground truth poses, where accuracy and repeatability are key. Therefore we introduce a new open-source tracking algorithm and calibration procedure for Vive which address these problems. We also show that our approach improves the pose estimation repeatability and accuracy by up to two orders of magnitude.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593707","","Robots;Tracking;Photodiodes;Extraterrestrial measurements;Pose estimation;Transforms","calibration;object tracking;pose estimation;tracking;virtual reality","estimation repeatability;calibration procedure;open-source tracking algorithm;robotics applications;shelf algorithm;virtual reality applications;inertial measurements;millimeter magnitude;controlled experiments;ground truth;off-the-shelf tracking system;cost-effective;HTC Vive","","1","12","","","","","IEEE","IEEE Conferences"
"Jumping Motion Generation of a Humanoid Robot Utilizing Human-Like Joint Elasticity","T. Otani; K. Hashimoto; H. Ueta; M. Sakaguchi; Y. Kawakami; H. O. Lim; A. Takanishi","Waseda University, Department of Modern Mechanical Engineering, Tokyo, #41-304, 17 Kikui-cho, Shinjuku-ku, 162-0044, JAPAN; Meiji University, Humanoid Robotics Institute (HRI), Waseda University, School of Science and Technology; Waseda University, Graduate School of Creative Science and Engineering; Institute of Sport Science, ASICS Corporation; Waseda University, Faculty of Sport Science; Kanagawa University, Humanoid Robotics Institute (HRI), Waseda University, Faculty of Engineering; Waseda University, Humanoid Robotics Institute (HRI), Waseda University, Department of Modern Mechanical Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8707","8714","To improve the movement ability of humanoid robots, instead of traditional methods dependent on only power of actuators, there is possibility that utilizing elasticity inspired from collaboration of muscle and tendon of human is effective to achieve high-power movement. In this study, we aimed to realize a jumping motion that accumulates energy more appropriately in spring by combining active joint driving with spring behavior like human tendons and muscles. We proposed a countermovement jump method using the resonance with the leg's active pushing-off movement and leg stiffness. To achieve active pushing-off and joint stiffness, we developed a new joint mechanism using leaf springs and an actuator unit with a worm gear. We then performed experiments to evaluate the effectiveness of the proposed mechanism and methods. Finally, the robot achieved a countermovement jump using active kicking and leg's elasticity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594085","","Elasticity;Legged locomotion;Springs;Humanoid robots;Trajectory;Force","humanoid robots;legged locomotion","human-like joint elasticity;jumping motion generation;leaf springs;joint mechanism;joint stiffness;active pushing-off;countermovement jump method;spring behavior;active joint driving;high-power movement;humanoid robots","","","25","","","","","IEEE","IEEE Conferences"
"VarNet: Exploring Variations for Unsupervised Video Prediction","B. Jin; Y. Hu; Y. Zeng; Q. Tang; S. Liu; J. Ye","Chinese Academy of Sciences, State Key Laboratory of Computer Architecture, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, 100190, 101407, P.R. China; Chinese Academy of Sciences, State Key Laboratory of Computer Architecture, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, 100190, 101407, P.R. China; Chinese Academy of Sciences, State Key Laboratory of Computer Architecture, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, 100190, 101407, P.R. China; Chinese Academy of Sciences, State Key Laboratory of Computer Architecture, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, 100190, 101407, P.R. China; Chinese Academy of Sciences, State Key Laboratory of Computer Architecture, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, 100190, 101407, P.R. China; Chinese Academy of Sciences, State Key Laboratory of Computer Architecture, Institute of Computing Technology, University of Chinese Academy of Sciences, Beijing, 100190, 101407, P.R. China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5801","5806","Unsupervised video prediction is a very challenging task due to the complexity and diversity in natural scenes. Prior works directly predicting pixels or optical flows either have the blurring problem or require additional assumptions. We highlight that the crux for video frame prediction lies in precisely capturing the inter-frame variations which encompass the movement of objects and the evolution of the surrounding environment. We then present an unsupervised video prediction framework - Variation Network (VarNet) to directly predict the variations between adjacent frames which are then fused with current frame to generate the future frame. In addition, we propose an adaptively re-weighting mechanism for loss function to offer each pixel a fair weight according to the amplitude of its variation. Extensive experiments for both short-term and long-term video prediction are implemented on two advanced datasets - KTH and KITTI with two evaluating metrics - PSNR and SSIM. For the KTH dataset, the VarNet outperforms the state-of-the-art works up to 11.9% on PSNR and 9.5% on SSIM. As for the KITTI dataset, the performance boosts are up to 55.1% on PSNR and 15.9% on SSIM. Moreover, we verify that the generalization ability of our model excels other state-of-the-art methods by testing on the unseen CalTech Pedestrian dataset after being trained on the KITTI dataset. Source code and video are available at https://github.com/jinbeibei/VarNet.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594264","","Generators;Training;Predictive models;Decoding;Video sequences;Neural networks;Generative adversarial networks","image motion analysis;image sequences;object detection;video signal processing","VarNet;video frame prediction;inter-frame variations;adjacent frames;long-term video prediction;KITTI dataset;unsupervised video prediction framework-variation network;PSNR;SSIM;KTH","","","27","","","","","IEEE","IEEE Conferences"
"Optimal Redeployment of Multirobot Teams for Communication Maintenance","J. Banfi; N. Basilico; S. Carpin","department of Computer Science, University of Milan., Milan, Italy; department of Computer Science, University of Milan., Milan, Italy; Department of Computer Science and Engineering, University of California, Merced, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3757","3764","In this paper, we consider the problem of maintaining and restoring connectivity among a set of agents (humans or robots) by incrementally redeploying a team of mobile robots acting as communication relays. This problem is relevant in numerous scenarios where humans and robots are jointly deployed for tasks like urban search and rescue, surveillance, and the like. In this case, as the humans move in the environment, connectivity may be broken, and consequently, robots need to reposition themselves to restore it. We study the computational complexity of the problem, also in terms of approximation hardness, and present an Integer Linear Programming formulation to compute optimal solutions. We then analyze the performance of the proposed resolution approach against a heuristic algorithm taken from the literature, and we demonstrate how our method favorably compares in terms of solution quality and scalability.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593532","","Maintenance engineering;Relays;Task analysis;Complexity theory;Linear programming;Mobile robots","approximation theory;computational complexity;human-robot interaction;integer programming;linear programming;mobile robots;multi-robot systems","optimal redeployment;multirobot teams;communication maintenance;mobile robots;communication relays;computational complexity;Integer Linear Programming formulation;approximation hardness","","","27","","","","","IEEE","IEEE Conferences"
"Design and Implementation of Programmable Drawing Automata based on Cam Mechanisms for Representing Spatial Trajectory","T. Takahashi; H. G. Okuno","Graduate Program for Embodiment Informatics, Department of Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Shinjuku, Tokyo, 169-0072, Japan; Graduate Program for Embodiment Informatics, Department of Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Shinjuku, Tokyo, 169-0072, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","450","455","This paper presents the design and implementation of a preliminary version of a programmable drawing automaton (PDA-0) that draws a user-specified 3D trajectory. PDA-0 is strongly inspired by Jaquet Droz's a programmable drawing automaton built in the 1770s using 6,000 moving parts, which was hand-coded. PDA-0 consists of RSSR (Revolute-Spherical-S-R) linkage and cam mechanisms with three interchangeable cams. Interchangeable cams make PDA-0 programmable because a user-specified 2D/3D trajectory is encoded into the set of three cams. The user programs PDA-0 by specifying a trajectory via a GUI or 3D animation. Subsequently, the compiler estimates a 3D trajectory mathematically from the user-specified 2D/3D trajectory and calculates the shape of the three cams, i.e., a code for PDA-0 by solving kinematic constraints. Finally, PDA-0 with the 3D-printed cams executes the code to draw the user-specified trajectory. The current PDA-0 with three cams demonstrates drawing simple trajectories such as letters and symbols.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594443","","Automata;Couplings;Trajectory;Three-dimensional displays;Shape;Animation;Kinematics","cams (mechanical);computer animation;data visualisation;graphical user interfaces","spatial trajectory representation;RSSR linkage;revolute-spherical-S-R linkage;user-specified 2D/3D trajectory;GUI;3D animation;user programs PDA-0;PDA-0 programmable;programmable drawing automaton;cam mechanisms;programmable drawing automata","","","23","","","","","IEEE","IEEE Conferences"
"DLWV2: A Deep Learning-Based Wearable Vision-System with Vibrotactile-Feedback for Visually Impaired People to Reach Objects","M. Shih; Y. Chen; C. Tung; C. Sun; C. Cheng; L. Chan; S. Varadarajan; M. Sun","National Tsing Hua University, Taiwan; National Tsing Hua University, Taiwan; National Tsing Hua University, Taiwan; National Tsing Hua University, Taiwan; National Tsing Hua University, Taiwan; National Chiao Tung University, Taiwan; Intel Cooperation, California, USA; National Tsing Hua University, Taiwan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We develop a Deep Learning-based Wearable Vision-system with Vibrotactile-feedback (DLWV2)to guide Blind and Visually Impaired (BVI)people to reach objects. The system achieves high accuracy in object detection and tracking in 3-D using an extended deep learning-based 2.5-D detector and a 3-D object tracker with the ability to track 3-D object locations even outside the camera field-of-view. We train our detector with a large number of images with 2.5-D object ground-truth (i.e., 2-D object bounding boxes and distance from the camera to objects). A novel combination of HTC Vive Tracker with our system enables us to automatically obtain the ground-truth labels for training while requiring very little human effort to set up the system. Moreover, our system processes frames in real-time through a client-server computing platform such that BVI people can receive realtime vibrotactile guidance. We conduct a thorough user study on 12 BVI people in new environments with object instances which are unseen during training. Our system outperforms the non-assistive guiding strategy with statistic significance in both time and the number of contacting irrelevant objects. Finally, the interview with BVI users confirms that our system with distance-based vibrotactile feedback is mostly preferred, especially for objects requiring gentle manipulation such as a bottle with water inside.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593711","","Cameras;Target tracking;Detectors;Training;Real-time systems;Object detection","handicapped aids;learning (artificial intelligence);object detection;object tracking","BVI people;extended deep learning-based 2.5-D detector;Visually Impaired people;Vibrotactile-feedback;distance-based vibrotactile feedback;2.5-D object ground-truth;3-D object locations;3-D object tracker;object detection;DLWV2;Deep Learning-based Wearable Vision-system","","","14","","","","","IEEE","IEEE Conferences"
"Finding safe 3D robot grasps through efficient haptic exploration with unscented Bayesian optimization and collision penalty","J. Castanheira; P. Vicente; R. Martinez-Cantin; L. Jamone; A. Bernardino","Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Centro Universitario de la Defensa, Zaragoza, Spain; ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1643","1648","Robust grasping is a major, and still unsolved, problem in robotics. Information about the 3D shape of an object can be obtained either from prior knowledge (e.g., accurate models of known objects or approximate models of familiar objects) or real-time sensing (e.g., partial point clouds of unknown objects) and can be used to identify good potential grasps. However, due to modeling and sensing inaccuracies, local exploration is often needed to refine such grasps and successfully apply them in the real world. The recently proposed unscented Bayesian optimization technique can make such exploration safer by selecting grasps that are robust to uncertainty in the input space (e.g., inaccuracies in the grasp execution). Extending our previous work on 2D optimization, in this paper we propose a 3D haptic exploration strategy that combines unscented Bayesian optimization with a novel collision penalty heuristic to find safe grasps in a very efficient way: while by augmenting the search-space to 3D we are able to find better grasps, the collision penalty heuristic allows us to do so without increasing the number of exploration steps.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594009","","Grasping;Three-dimensional displays;Optimization;Robot sensing systems;Bayes methods","approximation theory;Bayes methods;collision avoidance;grippers;haptic interfaces;Kalman filters;mobile robots;optimisation;path planning","unscented Bayesian optimization;novel collision penalty;exploration steps;safe 3D robot grasps;efficient haptic exploration;robust grasping;accurate models;known objects;approximate models;familiar objects;partial point clouds;unknown objects;sensing inaccuracies;local exploration;grasp execution;3D haptic exploration strategy","","","33","","","","","IEEE","IEEE Conferences"
"A 3D Template Model for Healthy and Impaired Walking","M. A. Sharbafi; M. Zadravec; Z. Matjačić; A. Seyfarth","School of ECE, College of Engineering, University of Tehran, Tehran, Iran; University rehabilitation institute Republic of Slovenia, Linhartova 51, Ljubljana, SI-1000, Slovenia; University rehabilitation institute Republic of Slovenia, Linhartova 51, Ljubljana, SI-1000, Slovenia; TU Darmstadt, Lauflabor Locomotion Lab, Centre for Cognitive Science, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1218","1225","Several modeling studies, which address neuromuscular control in impaired unperturbed gaits, were performed to predict human strategies to cope with lateral asymmetries in the body. Experimental studies show different step length and stance time relations between limbs in walking of stroke patients. By extension of a bipedal SLIP (spring-loaded inverted pendulum) based model and the corresponding controllers to 3D space, we focus on different features of the pathologic gaits. The introduced model is based on an extension of the FMCH (force modulated compliant hip) and VBLA (velocity based leg adjustment) model to 3D space. With the proposed model, asymmetric leg and control parameters can result in similar gait patterns as observed in experiments. These parameters comprise hip stiffness and rest angles in FMCH models and the tuning parameter of VBLA for foot placement. It is shown that asymmetries in muscle properties (e.g. stiffness) and leg adjustment can play an important role in generating pathologic gaits.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594013","","Legged locomotion;Three-dimensional displays;Mathematical model;Solid modeling;Hip;Biological system modeling;Springs","biomechanics;elasticity;gait analysis;legged locomotion;motion control;muscle;nonlinear control systems;pendulums;robot dynamics;springs (mechanical)","3D template model;modeling studies;neuromuscular control;impaired unperturbed gaits;human strategies;lateral asymmetries;experimental studies;stance time relations;stroke patients;bipedal SLIP;spring-loaded inverted pendulum;pathologic gaits;modulated compliant hip;VBLA model;velocity based leg adjustment;asymmetric leg;control parameters;similar gait patterns;hip stiffness;rest angles;FMCH models","","","39","","","","","IEEE","IEEE Conferences"
"Received Signal Strength of Electromagnetic Waves Aided Integrated Inertial Navigation System for Underwater Vehicle","D. Park; J. Jung; K. Kwak; J. Kim; W. K. Chung","Korea Institute of RObot convergence(KIRO), Pohang, Korea; Department of Mechanical Engineering, Pohang University of Science and Technology(POSTECH), Pohang, Korea; Department of Mechanical and Automotive Engineering, Seoul National University of Science and Technology(SEOULTECH), Seoul, Korea; Department of Mechanical and Automotive Engineering, Seoul National University of Science and Technology(SEOULTECH), Seoul, Korea; Department of Mechanical Engineering, Pohang University of Science and Technology(POSTECH), Pohang, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1870","1876","Sensory information from an Earth-fixed reference is necessary to guarantee a high localization accuracy of an unmanned underwater vehicle (UUV). However, the implementation of these sensors in an underwater environment is challenging because of signal uncertainties and strong signal attenuation. In this paper, we propose an underwater localization scheme with a sensor fusion of inertial navigation system (INS) and received signal strength of electromagnetic (EM) waves sensors. In the proposed sensor-fusion-based localization scheme, the UUV predicts its location by using INS based on dead-reckoning and corrects the predicted position by Kalman filter using EM waves sensor information when the UUV receives the signals of EM waves sensors in underwater wireless sensor networks. The proposed scheme enables localization with high accuracy and high sampling rate during a long-term task. The results of an experiment performed in a basin environment shows the feasibility of the proposed scheme. The scheme achieved reliable localization accuracy by comparing the pre-measured ground-truth position and long-term navigation. These results show the feasibility of exploiting EM waves attenuation as Earth-fixed reference sensors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593675","","Manganese;Attenuation;Sensor fusion;Robot sensing systems;Noise measurement;Time measurement","inertial navigation;Kalman filters;mobile robots;navigation;position measurement;remotely operated vehicles;sensor fusion;underwater vehicles;wireless sensor networks","Kalman filter;Earth-fixed reference sensors;EM waves attenuation;long-term navigation;basin environment;underwater wireless sensor networks;EM waves sensors;sensor-fusion-based localization scheme;electromagnetic waves sensors;sensor fusion;underwater localization scheme;strong signal attenuation;signal uncertainties;underwater environment;unmanned underwater vehicle;sensory information;integrated inertial navigation system","","","19","","","","","IEEE","IEEE Conferences"
"PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization","P. Egger; P. V. K. Borges; G. Catt; A. Pfrunder; R. Siegwart; R. Dubé","Data61, Robotics and Autonomous Systems Group, CSIRO, Australia; Data61, Robotics and Autonomous Systems Group, CSIRO, Australia; Data61, Robotics and Autonomous Systems Group, CSIRO, Australia; ETH Zurich, Autonomous Systems Lab; ETH Zurich, Autonomous Systems Lab; ETH Zurich, Autonomous Systems Lab","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3430","3437","Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593854","","Simultaneous localization and mapping;Three-dimensional displays;Laser radar;Optimization;Feature extraction","feature extraction;mobile robots;optical radar;path planning","local views;sliding window fashion;matching current;old features;map representation;local maps;off-road environments;single localization failure;distinctive features;coined PoseMap;dynamic environments;robotic systems;long-term localization;multienvironment 3D LiDAR localization;frequency 8.0 Hz;time 18.0 month","","","21","","","","","IEEE","IEEE Conferences"
"Fast Kinodynamic Bipedal Locomotion Planning with Moving Obstacles","J. Ahn; O. Campbell; D. Kim; L. Sentis","Graduate School of Mechanical Engineering, University of Texas, Austin, U.S.; Graduate School of Mechanical Engineering, University of Texas, Austin, U.S.; Graduate School of Mechanical Engineering, University of Texas, Austin, U.S.; Aerospace Engineering and Engineering Mechanics, University of Texas, Austin, U.S.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","177","184","In this paper, we present a sampling-based kino-dynamic planning framework for a bipedal robot in complex environments. Unlike other footstep planning algorithms which typically plan footstep locations and the biped dynamics in separate steps, we handle both simultaneously. Three primary advantages of this approach are (1) the ability to differentiate alternate routes while selecting footstep locations based on the temporal duration of the route as determined by the Linear Inverted Pendulum Model (LIPM) dynamics, (2) the ability to perform collision checking through time so that collisions with moving obstacles are prevented without avoiding their entire trajectory, and (3) the ability to specify a minimum forward velocity for the biped. To generate a dynamically consistent description of the walking behavior, we exploit the Phase Space Planner (PSP) [1] [2]. To plan a collision-free route toward the goal, we adapt planning strategies from non-holonomic wheeled robots to gather a sequence of inputs for the PSP. This allows us to efficiently approximate dynamic and kinematic constraints on bipedal motion, to apply a sampling-based planning algorithm such as RRT or RRT*, and to use the Dubin's path [3] as the steering method to connect two points in the configuration space. The results of the algorithm are sent to a Whole Body Controller [1] to generate full body dynamic walking behavior. Our planning algorithm is tested in a 3D physics-based simulation of the humanoid robot Valkyrie.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594156","","Planning;Heuristic algorithms;Robot kinematics;Legged locomotion;Collision avoidance","collision avoidance;humanoid robots;legged locomotion;motion control;pendulums;robot dynamics;robot kinematics;wheels","moving obstacles;bipedal robot;complex environments;footstep planning algorithms;footstep locations;biped dynamics;temporal duration;dynamically consistent description;PSP;collision-free route;nonholonomic wheeled robots;kinematic constraints;bipedal motion;body dynamic walking behavior;3D physics-based simulation;linear inverted pendulum model dynamics;dynamic constraints;kinodynamic bipedal locomotion planning;sampling-based kino-dynamic planning;LIPM;phase space planner;steering method","","","14","","","","","IEEE","IEEE Conferences"
"Intrinsically Motivated Self-Supervised Deep Sensorimotor Learning for Grasping","T. Takahashi; M. W. Lanighan; R. A. Grupen","College of Information and Computer Sciences, Laboratory for Perceptual Robotics, University of Massachusetts, Amherst, MA, 01003, USA; College of Information and Computer Sciences, Laboratory for Perceptual Robotics, University of Massachusetts, Amherst, MA, 01003, USA; College of Information and Computer Sciences, Laboratory for Perceptual Robotics, University of Massachusetts, Amherst, MA, 01003, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3496","3502","Deep learning has been successful in a variety of applications that have high-dimensional state spaces such as object recognition, video games, and machine translation. Deep neural networks can automatically learn important features from high-dimensional state given large training datasets. However, the success of deep learning in robot systems in the realworld is limited due to the cost of obtaining these large datasets. To overcome this problem, we propose an information-theoretic, intrinsically motivated, self-labeling mechanism using closed-loop control states. Taking this approach biases exploration to informative interactions-as such, a robot requires much less training to achieve reliable performance. In this paper, we explore the impact such an approach has on learning how to grasp objects. We evaluate different intrinsic motivators present in the literature applied appropriately in our framework and discuss the benefits and drawbacks of each.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593424","","Robot sensing systems;Entropy;Training;Uncertainty;Deep learning;Biological neural networks","closed loop systems;learning (artificial intelligence);manipulators;neural nets","high-dimensional state spaces;object recognition;video games;machine translation;deep neural networks;training datasets;deep learning;robot systems;closed-loop control states;motivated self-supervised deep sensorimotor learning;intrinsic motivators","","","28","","","","","IEEE","IEEE Conferences"
"Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline","S. Breuers; L. Beyer; U. Rafi; B. Leibel","RWTH Aachen University, Visual Computing Institute; RWTH Aachen University, Visual Computing Institute; RWTH Aachen University, Visual Computing Institute; RWTH Aachen University, Visual Computing Institute","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","48","53","In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594335","","Robots;Pipelines;Skeleton;Head;Estimation;Detectors;Trajectory","feature extraction;human-robot interaction;image filtering;learning (artificial intelligence);object detection;object tracking;pose estimation;robot vision","DetTA pipeline;people detection;dynamic information;social robot-person interaction;fully modular detection-tracking-analysis pipeline;temporal filtering;person attribute;track ID;person analysis;GPU-memory;power consumption;head pose;skeleton pose;deep learning methods","","","48","","","","","IEEE","IEEE Conferences"
"Online Temporal Calibration for Monocular Visual-Inertial Systems","T. Qin; S. Shen","Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3662","3669","Accurate state estimation is a fundamental module for various intelligent applications, such as robot navigation, autonomous driving, virtual and augmented reality. Visual and inertial fusion is a popular technology for 6-DOF state estimation in recent years. Time instants at which different sensors' measurements are recorded are of crucial importance to the system's robustness and accuracy. In practice, timestamps of each sensor typically suffer from triggering and transmission delays, leading to temporal misalignment (time offsets) among different sensors. Such temporal offset dramatically influences the performance of sensor fusion. To this end, we propose an online approach for calibrating temporal offset between visual and inertial measurements. Our approach achieves temporal offset calibration by jointly optimizing time offset, camera and IMU states, as well as feature locations in a SLAM system. Furthermore, the approach is a general model, which can be easily employed in several feature-based optimization frameworks. Simulation and experimental results demonstrate the high accuracy of our calibration approach even compared with other state-of-art offline tools. The VIO comparison against other methods proves that the online temporal calibration significantly benefits visual-inertial systems. The source code of temporal calibration is integrated into our public project, VINS-Mono<sup>1</sup>.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593603","","Cameras;Sensors;Delays;Calibration;Visualization;Clocks;Three-dimensional displays","calibration;cameras;inertial systems;motion estimation;optimisation;robot vision;sensor fusion;SLAM (robots)","monocular visual-inertial systems;accurate state estimation;intelligent applications;robot navigation;autonomous driving;virtual reality;augmented reality;visual fusion;inertial fusion;sensor fusion;visual measurements;inertial measurements;IMU states;SLAM system;feature-based optimization frameworks","","1","29","","","","","IEEE","IEEE Conferences"
"PCAOT: A Manhattan Point Cloud Registration Method Towards Large Rotation and Small Overlap","P. Guo; W. Hu; H. Ren; Y. Zhang","Intel Corporation, Intel Labs China, Beijing, 100190, China; Intel Corporation, Intel Labs China, Beijing, 100190, China; Intel Corporation, Intel Labs China, Beijing, 100190, China; Intel Corporation, Intel Labs China, Beijing, 100190, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7912","7917","Point cloud registration is a popular research topic and has been widely used in many tasks, such as robot mapping and localization. It is a challenging problem when the overlap is small, or the rotation is large. The problem has not been well solved by existing methods such as the iterative closest point (ICP) and its variants. In this paper, a novel method named principal coordinate alignment with overlap tuning (PCAOT) is proposed based on the Manhattan world assumption. It solves two key problems together, the transformation estimation and the overlap estimation. The overlap is represented by a 3D cuboid and the transformation is computed only within the overlap region. Instead of finding point correspondence as in traditional methods, we estimate the rotation by principal coordinates alignment, which is faster and less sensitive than ICP and its variants to small overlaps and large rotations. Evaluations demonstrate that our method achieves much better results than the ICP and its variants when the overlap ratio is smaller than 50%, or the rotation angle is larger than 60°. Especially, it is effective when the overlap ratio is less than 30%, or the rotation angle is larger than 90°.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594514","","Three-dimensional displays;Estimation;Tuning;Iterative closest point algorithm;Mathematical model;Filtering;Task analysis","computational geometry;image registration;iterative methods;principal component analysis","Manhattan world assumption;transformation estimation;overlap estimation;ICP;rotation angle;PCAOT;Manhattan point cloud registration method;robot mapping;iterative closest point;robot localization;principal coordinate alignment with overlap tuning;3D cuboid","","","20","","","","","IEEE","IEEE Conferences"
"Torque Controlled Biped Model Through a Bio-Inspired Controller Using Adaptive Learning","C. Ferreira; T. Cunha; C. P. Santos; L. P. Reis","Center for MicroElectroMechanical Systems (CMEMS) University of Minho, Guimarães, 4800-058, Portugal; Center for MicroElectroMechanical Systems (CMEMS) University of Minho, Guimarães, 4800-058, Portugal; Center for MicroElectroMechanical Systems (CMEMS) University of Minho, Guimarães, 4800-058, Portugal; Artificial Intelligence and Computer Science Laboratory (LIACC), Porto","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4369","4374","Biped robots have not achieved the efficient and harmonious locomotion of the human beings, capable of walking and running on unstructured terrains, with obstacles, holes and slopes. With this in mind, researchers started the development of biomimetic solutions to control the locomotion of biped models. This work presents a new solution of motion control of bipedal robots with adaptable stiffness, by exploring effects of joint stiffness in modulating walking behavior. Further, torque adjustment is achieved through a biomimetic controller that mimics and adjusts the natural dynamics of the robot to the environment. Specifically, the torque adjustment is made using AFOs (adaptive frequency oscillator) to generate the correct equilibrium positions that will be applied to the impedance control that computes the torque of each joint. Results show that the biped model is capable of walking in several types of terrain, including flat terrain, ramps, stairs and flat terrain with obstacles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594160","Biped;Central Pattern Generator;Hopf;AFO;torque;stiffness","Legged locomotion;Oscillators;Biological system modeling;Adaptation models;Torque;Robot kinematics","biomimetics;legged locomotion;motion control;oscillators;robot dynamics;torque control","flat terrain;impedance control;adaptive frequency oscillator;biomimetic controller;torque adjustment;walking behavior;joint stiffness;adaptable stiffness;bipedal robots;motion control;biomimetic solutions;slopes;holes;obstacles;unstructured terrains;human beings;harmonious locomotion;efficient locomotion;biped robots;adaptive learning;bio-inspired controller;torque controlled biped model","","","22","","","","","IEEE","IEEE Conferences"
"Design and Performance Evaluation of an Infotaxis-Based Three-Dimensional Algorithm for Odor Source Localization","J. Ruddick; A. Marjovi; F. Rahbar; A. Martinoli","Ecole Polytechnique Fédérale de Lausanne (EPFL), Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Lausanne, 1015, Switzerland; Ecole Polytechnique Fédérale de Lausanne (EPFL), Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Lausanne, 1015, Switzerland; Ecole Polytechnique Fédérale de Lausanne (EPFL), Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Lausanne, 1015, Switzerland; Ecole Polytechnique Fédérale de Lausanne (EPFL), Distributed Intelligent Systems and Algorithms Laboratory, School of Architecture, Civil and Environmental Engineering, Lausanne, 1015, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1413","1420","In this paper we tackle the problem of finding the source of a gaseous leak with a robot in a three-dimensional (3-D) physical space. The proposed method extends the operational range of the probabilistic Infotaxis algorithm [1] into 3-D and makes multiple improvements in order to increase its performance in such settings. The method has been tested systematically through high-fidelity simulations and in a wind tunnel emulating realistic conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments. The algorithm shows good performance in various environmental conditions, particularly in high wind speeds and different source release rates.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593997","","Robots;Entropy;Atmospheric modeling;Mathematical model;Probabilistic logic;Numerical models;Probability","electronic noses;gases;mobile robots;probability;wind tunnels","gaseous leak source;high wind speeds;environmental conditions;environmental parameters;multiple algorithmic parameters;wind tunnel;probabilistic Infotaxis algorithm;odor source localization;infotaxis-based three-dimensional algorithm","","","29","","","","","IEEE","IEEE Conferences"
"A distributed vision-based consensus model for aerial-robotic teams","F. Poiesi; A. Cavallaro","Technologies of Vision, Fondazione Bruno Kessler, Via Sommarive 18, Trento, IT, 38123; Centre for Intelligent Sensing, Queen Mary University of London, Mile End Road, London, E1 4NS, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","169","176","We present a distributed model for a team of autonomous aerial robots to collaboratively track a target without external control. The model uses distributed consensus to coordinate actions and to maintain formation via geometric constraints. Each robot uses its ego-centric view of a target and the relative distance from its two closest neighbors to infer its steering commands. To account for noisy and missing target detections, the robots exchange their estimated target position and formation configuration through shared PID-controlled steering responses. We show that the proposed model enables the team to maintain the view of a maneuvering target with varying acceleration under noisy detections and failures up to situations when all robots but one lose the target from their field of view.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593388","","Robot kinematics;Robot sensing systems;Cameras;Task analysis;Noise measurement","autonomous aerial vehicles;geometry;mobile robots;object detection;position control;robot vision;target tracking","target position;PID-controlled steering responses;autonomous aerial robots;aerial-robotic teams;distributed vision-based consensus model;noisy detections;steering commands;ego-centric view;geometric constraints","","","34","","","","","IEEE","IEEE Conferences"
"LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain","T. Shan; B. Englot","Department of Mechanical Engineering, Stevens Institute of Technology, Castle Point on Hudson, Hoboken, NJ, 07030, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Castle Point on Hudson, Hoboken, NJ, 07030, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4758","4765","We propose a lightweight and ground-optimized lidar odometry and mapping method, LeGO-LOAM, for realtime six degree-of-freedom pose estimation with ground vehicles. LeGO-LOAM is lightweight, as it can achieve realtime pose estimation on a low-power embedded system. LeGO-LOAM is ground-optimized, as it leverages the presence of a ground plane in its segmentation and optimization steps. We first apply point cloud segmentation to filter out noise, and feature extraction to obtain distinctive planar and edge features. A two-step Levenberg-Marquardt optimization method then uses the planar and edge features to solve different components of the six degree-of-freedom transformation across consecutive scans. We compare the performance of LeGO-LOAM with a state-of-the-art method, LOAM, using datasets gathered from variable-terrain environments with ground vehicles, and show that LeGO-LOAM achieves similar or better accuracy with reduced computational expense. We also integrate LeGO-LOAM into a SLAM framework to eliminate the pose estimation error caused by drift, which is tested using the KITTI dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594299","","Feature extraction;Three-dimensional displays;Laser radar;Image segmentation;Pose estimation;Real-time systems;Iterative closest point algorithm","embedded systems;feature extraction;image segmentation;optical radar;optimisation;pose estimation;robot vision;SLAM (robots)","SLAM framework;edge features;feature extraction;point cloud segmentation;lightweight and ground-optimized lidar odometry;real-time six degree-of-freedom pose estimation;low-power embedded system;ground plane;two-step Levenberg-Marquardt optimization method;optimization steps;ground vehicles;LeGO-LOAM","","1","25","","","","","IEEE","IEEE Conferences"
"The KIT Swiss Knife Gripper for Disassembly Tasks: A Multi-Functional Gripper for Bimanual Manipulation with a Single Arm","J. Borràs; R. Heudorfer; S. Rader; P. Kaiser; T. Asfour","Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Karlsruhe, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4590","4597","This work presents the concept of a robotic gripper designed for the disassembly of electromechanical devices that comprises several innovative ideas. Novel concepts include the ability to interchange built-in tools without the need to grasp them, the ability to reposition grasped objects in-hand, the capability of performing classic dual arm manipulation within the gripper and the utilization of classic industrial robotic arms kinematics within a robotic gripper. We analyze state of the art grippers and robotic hands designed for dexterous in-hand manipulation and extract common characteristics and weak points. The presented concept is obtained from the task requirements for disassembly of electromechanical devices and it is then evaluated for general purpose grasping, in-hand manipulation and operations with tools. We further present the CAD design for a first prototype.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593567","","Grippers;Tools;Task analysis;Grasping;Manipulators;Service robots","assembling;design engineering;dexterous manipulators;grippers;industrial manipulators;manipulator kinematics","bimanual manipulation;electromechanical devices;classic dual arm manipulation;classic industrial robotic arms kinematics;general purpose grasping;KIT swiss knife gripper;disassembly tasks;robotic gripper design;dexterous in-hand manipulation","","","25","","","","","IEEE","IEEE Conferences"
"Developing a New Brand of Culturally-Aware Personal Robots Based on Local Cultural Practices in the Danish Health Care System","M. Rehm; K. Rodil; A. L. Krummheuer","Technical Faculty of IT and Design, Aalborg University, Aalborg, 9000, Denmark; Technical Faculty of IT and Design, Aalborg University, Aalborg, 9000, Denmark; Faculty of Humanities, Aalborg University, Aalborg, 9000, Denmark","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2002","2007","In earlier work it has been shown how culture can be used as a parameter influencing human robot interaction in general (e.g. [1]). While this is a good starting point, in our work with concrete application fields we encounter that culture in its usual definition as national culture (e.g. [2]; [3]) is too general a concept to be useful in these concrete applications. Thus, we shifted our focus instead to a concept of local cultural practices, which is derived from situated practices as in Wengers communities of practice [4] and grounded loosely in Sperbers idea of an epidemiology of representations [5], i.e. culture or rather cultural practices as an emergent phenomenon from learning processes in a given group. Developing this new kind of culture-aware robots can then not start from a general definition of culture like Hofstede [2], Schwartz and Sagiv [6], etc. but has to take the actual group of users (and stakeholders) into account. We exemplify this approach with our work in a residency for citizens with acquired brain damage.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594478","","Cultural differences;Global communication;Robot sensing systems;Task analysis;Conferences;Programming","brain;cultural aspects;health care;human-robot interaction;medical robotics;mobile robots","good starting point;concrete application fields;national culture;concrete applications;local cultural practices;culturally-aware personal robots;human robot interaction;Danish health care system;brain damage;learning processes","","","24","","","","","IEEE","IEEE Conferences"
"The use of dynamic sensing strategies to improve detection for a pepper harvesting robot","P. Kurtser; Y. Edan","Ben-Gurion University of the Negev, Department of Industrial Engineering and Management, Beer-Sheva, Israel; Ben-Gurion University of the Negev, Department of Industrial Engineering and Management, Beer-Sheva, Israel","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8286","8293","This paper presents the use of dynamic sensing strategies to improve detection results for a pepper harvesting robot. The algorithm decides if an additional viewpoint is needed and selects the best-fit viewpoint location from a predefined set of locations based on the predicted profitability of such an action. The suggestion of a possible additional viewpoint is based on image analysis for fruit and occlusion level detection, prediction of the expected number of additional targets sensed from that viewpoint, and final decision if choosing the additional viewpoint is beneficial. The developed heuristic was applied on 96 greenhouse images of 30 sweet peppers and resulted in up to 19% improved detection. The harvesting utility cost function decreased by up to 10% compared to the conventional single viewpoint strategy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593746","","Robot sensing systems;Heuristic algorithms;Prediction algorithms;Cameras;Manipulators","agricultural products;agriculture;feature extraction;greenhouses;industrial robots;least squares approximations;object detection;profitability;robot vision","predicted profitability;viewpoint location;pepper harvesting robot;dynamic sensing strategies;harvesting utility cost function;occlusion level detection;fruit;image analysis","","","26","","","","","IEEE","IEEE Conferences"
"Multi-timescale Feature-extraction Architecture of Deep Neural Networks for Acoustic Model Training from Raw Speech Signal","R. Takeda; K. Nakadai; K. Komatani","The Institute of Scientific and Industrial Research, Osaka University, Japan; Honda Research Institute Japan, Co. Ltd., Japan; The Institute of Scientific and Industrial Research, Osaka University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2503","2510","This paper describes a new architecture of deep neural networks (DNNs) for acoustic models. Training DNNs from raw speech signals will provide 1) novel features of signals, 2) normalization-free processing such as utterance-wise mean subtraction, and 3) low-latency speech recognition for robot audition. Exploiting the longer context of raw speech signals seems useful in improving recognition accuracy. However, naive use of longer contexts results in the loss of short-term patterns; thus, recognition accuracy degrades. We propose a multi-timescale feature-extraction architecture of DNNs with blocks of different time scales, which enable capturing long- and short-term patterns of speech signals. Each block consists of complex-valued networks that correspond to Fourier and filterbank transformations for analysis. Experiments showed that the proposed multi-timescale architecture reduced the word error rate by about 3% compared with those only with the longterm context. Analysis of the extracted features revealed that our architecture efficiently captured the slow and fast changes of speech features.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593925","","Feature extraction;Acoustics;Artificial neural networks;Splicing;Robots;Filter banks;Training","acoustic signal processing;feature extraction;neural nets;speech recognition","robot audition;normalization-free processing;speech features;multitimescale architecture;speech signals;low-latency speech recognition;utterance-wise mean subtraction;acoustic models;raw speech signal;acoustic model training;deep neural networks;multitimescale feature-extraction architecture","","","37","","","","","IEEE","IEEE Conferences"
"A Motion Planning Approach for Marsupial Robotic Systems","P. G. Stankiewicz; S. Jenkins; G. E. Mullins; K. C. Wolfe; M. S. Johannes; J. L. Moore","Johns Hopkins University Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Road, Maryland, 20723, USA; Johns Hopkins University Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Road, Maryland, 20723, USA; Johns Hopkins University Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Road, Maryland, 20723, USA; Johns Hopkins University Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Road, Maryland, 20723, USA; Johns Hopkins University Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Road, Maryland, 20723, USA; Johns Hopkins University Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Road, Maryland, 20723, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper outlines an algorithmic approach for the automatic coordination and planning of heterogeneous multi-robot teams. Specifically, this work addresses the marsupial-based subset of multi-robot teams, where “carrier” robots transport and deploy “passenger” robots. The approach starts with a high-level watershed segmentation of the world to determine the free-space regions accessible by each robot in the team. Topological graph planning then decides the high-level motion plan for each robot between these free-space regions. Finally, a low-level path planner generates optimized, dynamically-feasible trajectories for each robot along the topological path. The performance of the approach is evaluated in simulation and through hardware experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593392","","Robot kinematics;Planning;Trajectory;Robot sensing systems;Collision avoidance;Unmanned aerial vehicles","graph theory;mobile robots;multi-robot systems;path planning","free-space regions;topological graph planning;high-level motion plan;low-level path planner;motion planning approach;marsupial robotic systems;automatic coordination;heterogeneous multirobot teams;marsupial-based subset;carrier robots;passenger robots;high-level watershed segmentation","","","25","","","","","IEEE","IEEE Conferences"
"On the Robustness of Speech Emotion Recognition for Human-Robot Interaction with Deep Neural Networks","E. Lakomkin; M. A. Zamani; C. Weber; S. Magg; S. Wermter","Department of Informatics, Knowledge Technology Institute, University of Hamburg, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Department of Informatics, Knowledge Technology Institute, University of Hamburg, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Department of Informatics, Knowledge Technology Institute, University of Hamburg, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Department of Informatics, Knowledge Technology Institute, University of Hamburg, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Department of Informatics, Knowledge Technology Institute, University of Hamburg, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","854","860","Speech emotion recognition (SER) is an important aspect of effective human-robot collaboration and received a lot of attention from the research community. For example, many neural network-based architectures were proposed recently and pushed the performance to a new level. However, the applicability of such neural SER models trained only on in-domain data to noisy conditions is currently under-researched. In this work, we evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios. We hypothesize that a robot's ego noise, room conditions, and various acoustic events that can occur in a home environment can significantly affect the performance of a model. We conduct several experiments on the iCub robot platform and propose several novel ways to reduce the gap between the model's performance during training and testing in real-world conditions. Furthermore, we observe large improvements in the model performance on the robot and demonstrate the necessity of introducing several data augmentation techniques like overlaying background noise and loudness variations to improve the robustness of the neural approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593571","","Robots;Training;Emotion recognition;Data models;Speech recognition;Acoustics;Feature extraction","emotion recognition;humanoid robots;human-robot interaction;neural nets;speech recognition","acoustic events;iCub robot platform;neural approaches;speech emotion recognition;deep neural networks;human-robot collaboration;research community;neural network-based architectures;neural SER models;in-domain data;noisy conditions;state-of-the-art neural acoustic emotion recognition models;human-robot interaction scenarios;room conditions","","","31","","","","","IEEE","IEEE Conferences"
"Implementation of Augmented Teleoperation System Based on Robot Operating System (ROS)","D. Lee; Y. S. Park","U.S. Department of Energy, Korea Atomic Energy Research Institute, Research jointly supported by Office of Environmental Management, Lemont, IL, 60439; U.S. Department of Energy, Korea Atomic Energy Research Institute, Research jointly supported by Office of Environmental Management, Lemont, IL, 60439","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5497","5502","Deployment of robotics and remote systems for tasks in unstructured nuclear environment has been impeded by the severe task requirements such as high radiation and dexterous and complex manipulation of heavy materials, which cannot be addressed by the current telerobotics technology. To address such practical challenges, this paper presents an enhanced teleoperator interface incorporating multi-modal augmented reality, and new method of telerobotic operation based on perceptual overlay - `virtual fixtures'. Rather than trying to devise complex robotic systems, innovation is directed to enhancement of teleoperator interface so as to draw more performance and intuition from the human operator. Particular enhancements were made over the current technology basis in 3D sensing and reconstruction, virtual fixture generation, and operator interface. The telerobotic system was developed using ROS (Robot Operating System) to streamline system integration and resource sharing. The presented innovation is expected to allow deployment of simple and rugged robots to perform dexterous manipulation of heavy objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594482","","Three-dimensional displays;Robot sensing systems;Telerobotics;Haptic interfaces;Fixtures","augmented reality;dexterous manipulators;haptic interfaces;human computer interaction;telerobotics","augmented teleoperation System;robot operating system;rugged robots;resource sharing;system integration;telerobotic system;operator interface;virtual fixture generation;current technology basis;human operator;complex robotic systems;telerobotic operation;enhanced teleoperator interface incorporating multimodal;current telerobotics technology;complex manipulation;dexterous manipulation;severe task requirements;unstructured nuclear environment;remote systems;ROS","","","22","","","","","IEEE","IEEE Conferences"
"Semi-Supervised SLAM: Leveraging Low-Cost Sensors on Underground Autonomous Vehicles for Position Tracking","A. Jacobson; F. Zeng; D. Smith; N. Boswell; T. Peynot; M. Milford","Queensland University of Technology, Australia; Queensland University of Technology, Australia; Caterpillar, Inc.; Caterpillar, Inc.; Queensland University of Technology, Australia; Queensland University of Technology, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3970","3977","This work presents Semi-Supervised SLAM - a method for developing a map suitable for coarse localization within an underground environment with minimal human intervention, with system characteristics driven by real-world requirements of major mining companies. This work leverages existing information common within a mining environment - namely a surveyed mine map - which is used to sparsely ground map locations within the mine environment, increasing map accuracy and allowing localization within a global frame. Map creation utilizes a low cost camera sensor and minimal user information to produce a map which can be used for single camera localization within a mining environment. We evaluate the localization capabilities of the proposed approach in depth by performing data collection on operational underground mining vehicles within an active underground mine and by simulating occlusions common to the environment such as dust and water. The proposed system is capable of producing maps which have an average localization error 2.5 times smaller than the next best performing method ORB-SLAM2, comparable localization performance to a state-of-the-art deep learning approach (which is not a feasible solution due to both compute and training requirements) and is robust to simulated environmental obscurants.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593750","","Simultaneous localization and mapping;Cameras;Measurement;Grounding;Visual odometry;Lighting","cameras;learning (artificial intelligence);mining;mining industry;mobile robots;object tracking;robot vision;SLAM (robots)","ORB-SLAM2;ground map locations;deep learning;position tracking;operational underground mining vehicles;single camera localization;map creation;mine environment;mining companies;underground environment;SemiSupervised SLAM;underground autonomous vehicles;low-cost sensors","","","29","","","","","IEEE","IEEE Conferences"
"Guaranteed Coverage with a Blind Unreliable Robot","J. S. Lewis; D. A. Feshbach; J. M. O'Kane","University of South Carolina, Department of Computer Science and Engineering, Columbia, South Carolina, USA; Department of Computer Science at Haverford College, Haverford, Pennsylvania, USA; University of South Carolina, Department of Computer Science and Engineering, Columbia, South Carolina, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7383","7390","We consider the problem of coverage planning for a particular type of very simple mobile robot. The robot must be able to translate in a commanded direction (specified in a global reference frame), with bounded error on the motion direction, until reaching the environment boundary. The objective, for a given environment map, is to generate a sequence of motions that is guaranteed to cover as large a portion of that environment as possible, in spite of the severe limits on the robot's sensing and actuation abilities. We show how to model the knowledge available to this kind of robot about its own position within the environment, show how to compute the region whose coverage can be guaranteed for a given plan, and characterize regions whose coverage cannot be guaranteed by any plan. We also describe a heuristic algorithm that generates coverage plans for this robot, based on a search across a specially-constructed graph. Simulation results demonstrate the effectiveness of the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594048","","Robot sensing systems;Robot kinematics;Planning;Navigation;Computational modeling","graph theory;mobile robots;path planning","guaranteed coverage;blind unreliable robot;coverage planning;simple mobile robot;heuristic algorithm;specially-constructed graph","","","61","","","","","IEEE","IEEE Conferences"
"Model-Free Grasp Planning for Configurable Vacuum Grippers","F. You; M. Mende; D. Štogl; B. Hein; T. Kröger","Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics, Intelligent Process Automation and Robotics Lab (IAR-IPR), Karlsruhe, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4554","4561","A concept consisting of a new configurable vacuum gripper system and a corresponding method for determining optimal grasp configurations solely based on 3D vision is introduced. The robot system consists of a dynamically configurable vacuum gripper, a visual sensor, and a robot arm that are used in combination with a new grasp planner to robustly grasp unknown objects in arbitrary positions. For this purpose, formalized aspects of selecting contact surfaces for arbitrary suction cups are described; the concept involves visual detection of the objects, segmentation, iterative grasp planning, and action execution. The approach allows for a fast and efficient, yet precise execution of grasps. The core idea is a two-step 3D data acquisition approach and grasp point computation that takes advantage of the fact that the suction cups of the gripper can all be aligned axis-parallel. Therefore, an adequate sensor-based surface acquisition is done from a single viewpoint with respect to the gripper. Results of realworld experiments show that the proposed concept is suitable for a wide range of different and unknown objects in our setup.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594227","","Grippers;Three-dimensional displays;Planning;Grasping;Robot sensing systems;Force","data acquisition;dexterous manipulators;grippers;path planning;robot vision","model-free grasp planning;adequate sensor-based surface acquisition;two-step 3D data acquisition approach;action execution;iterative grasp planning;visual detection;arbitrary suction cups;contact surfaces;formalized aspects;arbitrary positions;robustly grasp unknown objects;grasp planner;robot arm;visual sensor;dynamically configurable vacuum gripper;robot system;optimal grasp configurations;configurable vacuum gripper system","","","18","","","","","IEEE","IEEE Conferences"
"Robust 6D Object Pose Estimation in Cluttered Scenes Using Semantic Segmentation and Pose Regression Networks","A. S. Periyasamy; M. Schwarz; S. Behnke","University of Bonn, Autonomous Intelligent Systems, Germany; University of Bonn, Autonomous Intelligent Systems, Germany; University of Bonn, Autonomous Intelligent Systems, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6660","6666","Object pose estimation is a crucial prerequisite for robots to perform autonomous manipulation in clutter. Real-world bin-picking settings such as warehouses present additional challenges, e.g., new objects are added constantly. Most of the existing object pose estimation methods assume that 3D models of the objects is available beforehand. We present a pipeline that requires minimal human intervention and circumvents the reliance on the availability of 3D models by a fast data acquisition method and a synthetic data generation procedure. This work builds on previous work on semantic segmentation of cluttered bin-picking scenes to isolate individual objects in clutter. An additional network is trained on synthetic scenes to estimate object poses from a cropped object-centered encoding extracted from the segmentation results. The proposed method is evaluated on a synthetic validation dataset and cluttered realworld scenes.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594406","","Pose estimation;Semantics;Three-dimensional displays;Training;Image segmentation;Solid modeling;Robots","clutter;data acquisition;image segmentation;object detection;pose estimation;regression analysis;robot vision","pose regression networks;cluttered scenes;cropped object-centered;object poses;cluttered bin-picking scenes;semantic segmentation;synthetic data generation procedure;fast data acquisition method;estimation methods;real-world bin-picking settings;object pose estimation","","","18","","","","","IEEE","IEEE Conferences"
"Algorithms for Task Allocation in Homogeneous Swarm of Robots","D. K. Jha","Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3771","3776","In this paper, we present algorithms for synthesizing controllers to distribute a swarm of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. Swarm is modeled as a homogeneous collection of irreducible Markov chains. States of the Markov chain represent the tasks performed by the swarm. The target state is a pre-defined distribution of agents over the states of the Markov chain (and thus the tasks). We make use of ergodicity property of irreducible Markov chains to ensure that as an individual agent converges to the desired behavior in time, the swarm converges to the target state. To circumvent the problems faced by a global controller and local/decentralized controllers alone, we design a controller by combining global supervision with local-feedback-based state level decisions. Some numerical experiments are shown to illustrate the performance of the proposed algorithms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594052","","Task analysis;Markov processes;Robot kinematics;Kernel;Probabilistic logic;Q measurement","control system synthesis;decentralised control;feedback;Markov processes;mobile robots;multi-robot systems","task allocation;homogeneous swarm;homogeneous robots;Markov chain;agent converges;local-decentralized controllers;controller design;local-feedback","","","17","","","","","IEEE","IEEE Conferences"
"The Power of Color: A Study on the Effective Use of Colored Light in Human-Robot Interaction","A. Pörtner; L. Schröder; R. Rasch; D. Sprute; M. Hoffmann; M. König","Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany; Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany; Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany; Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany; Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany; Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3395","3402","In times of more and more complex interaction techniques, we point out the powerfulness of colored light as a simple and cheap feedback mechanism. Since it is visible over a distance and does not interfere with other modalities, it is especially interesting for mobile robots. In an online survey, we asked 56 participants to choose the most appropriate colors for scenarios that were presented in the form of videos. In these scenarios a mobile robot accomplished tasks, in some with success, in others it failed because the task is not feasible, in others it stopped because it waited for help. We analyze in what way the color preferences differ between these three categories. The results show a connection between colors and meanings and that it depends on the participants' technical affinity, experience with robots and gender how clear the color preference is for a certain category. Finally, we found out that the participants' favorite color is not related to color preferences.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594231","","Color;Videos;Animation;Mobile robots;Task analysis;Human-robot interaction","human computer interaction;human-robot interaction;mobile robots;service robots","mobile robot;color preference;appropriate colors;cheap feedback mechanism;complex interaction techniques;human-robot interaction;colored light","","","20","","","","","IEEE","IEEE Conferences"
"Vision-Based Autonomous Underwater Swimming in Dense Coral for Combined Collision Avoidance and Target Selection","T. Manderson; J. C. G. Higuera; R. Cheng; G. Dudek","Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada; Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada; Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada; Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1885","1891","We address the problem of learning vision-based, collision-avoiding, and target-selecting controllers in 3D, specifically in underwater environments densely populated with coral reefs. Using a highly maneuverable, dynamic, six-legged (or flippered) vehicle to swim underwater, we exploit real time visual feedback to make close-range navigation decisions that would be hard to achieve with other sensors. Our approach uses computer vision as the sole mechanism for both collision avoidance and visual target selection. In particular, we seek to swim close to the reef to make observations while avoiding both collisions and barren, coral-deprived regions. To carry out path selection while avoiding collisions, we use monocular image data processed in real time. The proposed system uses a convolutional neural network that takes an image from a forward-facing camera as input and predicts unscaled and relative path changes. The network is trained to encode our desired obstacle-avoidance and reef-exploration objectives via supervised learning from human-labeled data. The predictions from the network are transformed into absolute path changes via a combination of a temporally-smoothed proportional controller for heading targets and a low-level motor controller. This system enables safe and autonomous coral reef navigation in underwater environments. We validate our approach using an untethered and fully autonomous robot swimming through coral reef in the open ocean. Our robot successfully traverses 1000 m of the ocean floor collision-free while collecting close-up footage of coral reefs.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594410","","Navigation;Cameras;Robot vision systems;Task analysis;Visualization;Neural networks","autonomous underwater vehicles;cameras;collision avoidance;convolutional neural nets;mobile robots;navigation;object detection;robot vision;supervised learning","proportional controller;vision-based autonomous underwater swimming;computer vision;visual target selection;coral-deprived regions;monocular image data;convolutional neural network;supervised learning;motor controller;collision avoidance;autonomous robot swimming;autonomous coral reef navigation;obstacle-avoidance;forward-facing camera","","","23","","","","","IEEE","IEEE Conferences"
"CPG-based Controllers can Generate Both Discrete and Rhythmic Movements","M. Jouaiti; P. Henaff","CNRS, Inria, LORIA, Universite de Lorraine, Nancy, F-54000, France; CNRS, Inria, LORIA, Universite de Lorraine, Nancy, F-54000, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1212","1217","Complex tasks require the combination of both discrete and rhythmic movements. Though scientists do not yet agree on the neural architecture involved in both types and in the transition from one to the other, the importance of having robot controllers able to behave rhythmically and discretely is universally recoanized. In this paper, a bio-inspired robot controller based on oscillating neurons is proposed to realize both discrete and rhythmic movements and easily transition from one to the other. It is shown that, under certain parameter conditions, the CPG controller behaves like a PID controller. In order to demonstrate the feasibility of controlling both discrete and rhythmic movements, the CPG is applied to the initiation of handshaking, namely, reach towards the human hand and start to shake it. Results show that this architecture is suitable for both discrete and rhythmic movements and can easily transition from one to the other.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593889","","Task analysis;Neurons;Oscillators;Manipulators;Grippers;Intelligent robots","human-robot interaction;motion control;neural net architecture;neurocontrollers;three-term control","CPG-based controllers;discrete movements;rhythmic movements;bio-inspired robot controller;oscillating neurons;PID controller;handshaking","","","30","","","","","IEEE","IEEE Conferences"
"Distributionally Robust Sampling-Based Motion Planning Under Uncertainty","T. Summers","University of Texas at Dallas","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6518","6523","We propose a distributionally robust incremental sampling-based method for kinodynamic motion planning under uncertainty, which we call distributionally robust RRT (DR-RRT). In contrast to many approaches that assume Gaussian distributions for uncertain parameters, here we consider moment-based ambiguity sets of distributions with given mean and covariance. Chance constraints for obstacle avoidance and internal state bounds are then enforced under the worst-case distribution in the ambiguity set, which gives a coherent assessment of constraint violation risks. The method generates risk-bounded trajectories and feedback control laws for robots operating in dynamic, cluttered, and uncertain environments, explicitly incorporating localization error, stochastic process disturbances, unpredictable obstacle motion, and uncertain obstacle location. We show that the algorithm is probabilistically complete under mild assumptions. Numerical experiments illustrate the effectiveness of the algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593893","","Uncertainty;Planning;Trajectory;Robots;Feedback control;Probabilistic logic;Stochastic processes","collision avoidance;feedback;Gaussian distribution;mobile robots;path planning;robot dynamics;sampling methods;stochastic processes","obstacle avoidance;unpredictable obstacle motion;uncertain obstacle location;kinodynamic motion planning;distributionally robust RRT;DR-RRT;Gaussian distributions;distributionally robust sampling;distributionally robust incremental sampling","","","33","","","","","IEEE","IEEE Conferences"
"Energetic Efficiency of a Compositional Controller on a Monoped With an Articulated Leg and SLIP Dynamics","J. Yu; D. Hong; M. Haberland","Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles (UCLA), Los Angeles, CA, 90095, USA; Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles (UCLA), Los Angeles, CA, 90095, USA; Department of Mathematics, UCLA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2221","2228","Embedding the dynamics of the Spring Loaded Inverted Pendulum (SLIP) and applying a compositional controller around it can simplify dynamic legged robot locomotion control, but what is the energetic cost of this convenience? This paper measures the magnitude of this effect in such a way that the results are applicable to a wide class of jumping robots. A three-link monoped model with revolute joints is used to compare the energetic costs of locomotion using two different control approaches: 1) SLIP-embedding with a Raibert-style controller optimized for energetic efficiency, and 2) a trajectory optimized only for energetic efficiency. By performing this comparison in simulation for a large number of different monopeds randomly sampled from a space of realistic robot designs, it is found that the SLIP-Raibert approach requires, on average, almost twice the energy of the trajectory-optimized controller to traverse a given distance. Furthermore, the increase in energetic cost does not depend much on the particulars of the robot design, as the SLIP-Raibert approach requires at least 50% more energy for approximately 88% of realistic robot designs.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593638","","Legged locomotion;Aerospace electronics;Actuators;Dynamics;Optimization;Robot kinematics","design engineering;energy conservation;legged locomotion;motion control;nonlinear control systems;optimal control;optimisation;pendulums;robot dynamics;springs (mechanical);trajectory control","energetic efficiency;compositional controller;articulated leg;SLIP dynamics;dynamic legged robot locomotion control;jumping robots;Raibert-style controller;SLIP-Raibert approach;trajectory-optimized controller;robot design;spring loaded inverted pendulum;three-link monoped model","","","30","","","","","IEEE","IEEE Conferences"
"Position-Based Time-Integrator for Frictional Articulated Body Dynamics","Z. Pan; D. Manocha","Department of Computer Science, University of North Carolina; Department of Computer Science and Electrical & Computer Engineering, University of Maryland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","We present a new time-integrator for modeling the frictional dynamics of articulated bodies. Our formulation represents the configuration of the articulated body using position variables and then uses those variables to model the friction forces between the articulated body and the environment. Our approach corresponds to a Newton-type optimization scheme that is guaranteed to converge so that it is stable with large timestep sizes. We evaluate the accuracy and stability of our time-integrator by comparing it with a conventional formulations based on the Newton-Euler equation and demonstrate the benefits on standard controller-optimization applications. We achieve 3-5 times speedup over a Newton-Euler-based simulator on a CPU. Our approach can be easily parallelized on a GPU and results in additional 4-15 times performance improvement.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593817","","Mathematical model;Friction;Dynamics;Heuristic algorithms;Optimization;Linear programming;Robots","friction;graphics processing units;Newton method;optimisation;robot dynamics","Newton-Euler-based simulator;Newton-type optimization scheme;friction forces;position variables;frictional dynamics;frictional articulated body dynamics;position-based time-integrator","","","35","","","","","IEEE","IEEE Conferences"
"Managing Off-Nominal Events in Shared Teleoperation with Learned Task Compliance","P. Owan; J. Garbini; S. Devasia","Department of Mechanical Engineering, University of Washington; Department of Mechanical Engineering, University of Washington; Department of Mechanical Engineering, University of Washington","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5509","5516","This article studies imitation learning policies that encode task compliance to provide teleoperation assistance for remote manufacturing. The central challenge is how to handle off-nominal situations, such as out-of-sequence work or unplanned obstacles, since the assistance has not been trained to handle such scenarios. In such cases, there is potential for the assistance to degrade-rather than improve-operator performance. This work proposes a method that exploits the learned task compliance to classify persistent human actions as off-nominal, and attenuate assistance in these regions. Applied to a hole-cleaning task with n = 11 subjects, the proposed method shows up to 17% reduction in task completion time and up to 68% reduction in forces in off-nominal situations as compared to assistance without the method. Additionally, the method retains the performance improvements of assistance in nominal operating regimes.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594195","","Haptic interfaces;Task analysis;Robots;Collaboration;Trajectory;Tools;Force","control engineering computing;learning (artificial intelligence);manipulator dynamics;mobile robots;telerobotics","off-nominal events;shared teleoperation;learned task compliance;teleoperation assistance;remote manufacturing;off-nominal situations;attenuate assistance;hole-cleaning task;imitation learning policies","","","29","","","","","IEEE","IEEE Conferences"
"Design of SUPERball v2, a Compliant Tensegrity Robot for Absorbing Large Impacts","M. Vespignani; J. M. Friesen; V. SunSpiral; J. Bruce","Dynamic Tensegrity Robotics Lab, Intelligent Robotics Group, NASA Ames Research Center, Moffett Field, CA, 94035, USA; UC San Diego Coordinated Robotics Lab, MC 0411, La Jolla, CA, 92093, USA; SGT/IRG, NASA Ames Research Center, Moffett Field, CA, 94035, USA; Dynamic Tensegrity Robotics Lab, Intelligent Robotics Group, NASA Ames Research Center, Moffett Field, CA, 94035, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2865","2871","In this paper, we present the system design and initial testing of SUPERball v2, a completely re-designed 2-meter spherical six-bar tensegrity robot designed to survive high-speed landings as well as locomote to desired locations. SUPERball v2 was designed to enable a host of new actuation and experimentation. The prototype features a fully actuated six-bar design (24 actuators), compliant nylon cables (up to 15% stretch), torque-control enabled motors, and a robust mechanical structure capable of surviving impact velocities upwards of 8 m/s.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594374","","Robot kinematics;Springs;Meters;NASA;Mechanical cables;Robot sensing systems","actuators;aerospace robotics;cables (mechanical);design engineering;impact (mechanical);mobile robots;planetary rovers;torque control;velocity control","SUPERball v2;spherical six-bar tensegrity robot;fully actuated six-bar design;compliant nylon cables;torque-control enabled motor;robust mechanical structure;system design;compliant tensegrity robot;impact velocities;24 actuators;actuation;high-speed landings;six-bar tensegrity robot","","","29","","","","","IEEE","IEEE Conferences"
"C-MPDM: Continuously-Parameterized Risk-Aware MPDM by Quickly Discovering Contextual Policies","D. Mehta; G. Ferrer; E. Olson","University of Michigan, Ann Arbor; CDISE department, Skolkovo Institute of Science and Technology, Moscow, Russia; University of Michigan, Ann Arbor","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7547","7554","Risk-aware Multi-Policy Decision Making (MPDM)is a powerful framework for reliable navigation in a dynamic social environment where rather than evaluating individual trajectories, a “library” of policies (reactive controllers)is evaluated by anticipating potentially dangerous future outcomes using an on-line forward roll-out process. There is a core tension in Multi-Policy Decision Making (MPDM)systems - it is desirable to add more policies to the system for flexibility in finding good policies, however, this increases computational cost. As a result, MPDM was limited to small (perhaps 5-10)discrete policies - a significant performance bottleneck. In this paper, we radically enhance the expressivity of MPDM by allowing policies to have continuous-valued parameters, while simultaneously satisfying real-time constraints by quickly discovering promising policy parameters through a novel iterative gradient-based algorithm. Our evaluation includes results from extensive simulation and real-world experiments in semi-crowded environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593642","","Robots;Cost function;Real-time systems;Trajectory;Decision making;Backpropagation","decision making;gradient methods;operations research;optimisation","continuously-parameterized risk-aware MPDM;on-line forward roll-out process;computational cost;continuous-valued parameters;iterative gradient-based algorithm;multipolicy decision making systems;social environment;promising policy parameters;contextual policies","","","27","","","","","IEEE","IEEE Conferences"
"High-Speed Stealth Walking of Underactuated Biped Utilizing Effects of Upper-Body Control and Semicircular Feet","F. Asano","Japan Advanced Institute of Science and Technology, School of Information Science, 1-1 Asahidai, Nomi, Ishikawa, 923-1292, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4375","4380","Stealth walking is a way of walking carefully and noiselessly, and is an approach to stable legged locomotion of underactuated robotic walkers on irregular terrains. This paper proposes a method for generating a high-speed stealth walking gait without including double-limb support phase, and discusses the effect of upper-body control and semicircular feet on the gait properties. First, we introduce a model of a 3-link planar underactuated biped with an upper body and semicircular feet, and derive the approximate target initial state of the upper body by using the linearized equation of motion. Second, we conduct numerical simulations of the nonlinear model to observe the typical stealth walking gaits, and analyze the changing tendency of the upper body motion with respect to the foot radius. Furthermore, we discuss the advantage of semicircular feet through parametric studies of the gait efficiencies.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593821","","Legged locomotion;Foot;Mathematical model;Trajectory;Numerical models;Stability analysis;Analytical models","gait analysis;legged locomotion;motion control;robot dynamics","high-speed stealth walking;upper-body control;semicircular feet;stable legged locomotion;underactuated robotic walkers;double-limb support phase;gait properties;typical stealth walking gaits;upper body motion;underactuated biped","","","11","","","","","IEEE","IEEE Conferences"
"Towards Event-Driven Object Detection with Off-the-Shelf Deep Learning","M. Iacono; S. Weber; A. Glover; C. Bartolozzi","iCub Facility, Istituto Italiano di Tecnologia, Italy; iCub Facility, Istituto Italiano di Tecnologia, Italy; iCub Facility, Istituto Italiano di Tecnologia, Italy; iCub Facility, Istituto Italiano di Tecnologia, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Event cameras are an emerging technology in computer vision, offering extremely low latency and bandwidth, as well as a high temporal resolution and dynamic range. Inherent data compression is achieved as pixel data is only produced by contrast changes at the edges of moving objects. However, current trends in state-of-the-art visual algorithms rely on deep-learning with networks designed to process colour and intensity information contained in dense arrays, but are notoriously computationally heavy. While the combination of these visual technologies could lead to fast, efficient, and accurate detection and recognition algorithms, it is uncertain whether the compressed event-camera data actually contain the required information for these techniques to discriminate between objects and a cluttered background. This paper presents a pilot study in which off-the-shelf deep-learning is applied to visual events for object detection on the iCub robotic platform, and analyses the impact of temporal integration of the event data. We also present a novel pipeline that bootstraps event-based dataset annotation from mature frame-based algorithms, in order to more quickly generate the required datasets.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594119","","Cameras;Robot vision systems;Visualization;Training;Object detection","cameras;computer vision;data compression;data visualisation;humanoid robots;image colour analysis;image sensors;learning (artificial intelligence);object detection;robot vision","data compression;visual algorithms;event-driven object detection;iCub robotic platform;mature frame-based algorithms;bootstraps event-based dataset annotation;temporal integration;visual events;off-the-shelf deep-learning;compressed event-camera data;recognition algorithms;visual technologies;dense arrays;moving objects;contrast changes;pixel data;dynamic range;computer vision","","","24","","","","","IEEE","IEEE Conferences"
"First Experimental Results on Motion Planning for Transportation in Aerial Long-Reach Manipulators with Two Arms","A. Caballero; A. Suarez; F. Real; V. M. Vega; M. Bejar; A. Rodriguez-Castaño; A. Ollero","University of Seville, Seville, Spain; University of Seville, Seville, Spain; University of Seville, Seville, Spain; University of Seville, Seville, Spain; University Pablo de Olavide, Seville, Spain; University of Seville, Seville, Spain; University of Seville, Seville, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8471","8477","This paper presents the motion planning of a novel aerial robotic system with a long-bar extension and two arms for long-reach manipulation in cluttered environments. The novel aerial long-reach manipulator includes a passive revolute joint between the aerial platform and the dual arm. This feature minimises the torque induced to the aerial system in case of unexpected collisions of the manipulator. The motion planning problem is addressed considering jointly the complete set of configuration variables for the aerial platform and the dual arm. Furthermore, the planner has been built over the fundamentals of RRT* algorithms in order to optimise the performance of the trajectories in terms of energy and time. The proposed planning method has been experimentally validated in a realistic industrial scenario, the transportation of a long bar through a cluttered environment consisting of several pipe structures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594123","","Manipulators;Planning;Trajectory;Transportation;Bars;Task analysis","autonomous aerial vehicles;collision avoidance;manipulators;mobile robots;search problems;transportation","aerial robotic system;RRT* algorithms;motion planning problem;dual arm;aerial platform;passive revolute joint;long-reach manipulation;long-bar extension;aerial long-reach manipulators;cluttered environment;transportation","","","15","","","","","IEEE","IEEE Conferences"
"Formally Correct Composition of Coordinated Behaviors Using Control Barrier Certificates","A. Li; L. Wang; P. Pierpaoli; M. Egerstedt","School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, 30332, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3723","3729","In multi-robot systems, although the idea of behaviors allows for an efficient solution to low-level tasks, high-level missions can rarely be achieved by the execution of a single behavior. In contrast to this, a sequence of behaviors would provide the requisite expressiveness, but there are no a priori guarantees that the sequence is composable in the sense that the robots can actually execute it. In order to guarantee a provably correct composition of behaviors, Finite-Time Convergence Control Barrier Functions are introduced in this paper to guarantee the terminal configuration of one behavior is a valid initial configuration for the following one. Nominal control inputs prescribed by the behaviors are modified in a minimally invasive fashion, in order to establish the information-exchange network required by the following behavior. The effectiveness of the proposed composition strategy is validated on a team of mobile robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594302","","Convergence;Robot kinematics;Task analysis;Multi-robot systems;Mobile robots;Robot sensing systems","convergence;mobile robots;multi-robot systems","composition strategy;mobile robots;multirobot systems;efficient solution;low-level tasks;high-level missions;single behavior;requisite expressiveness;provably correct composition;terminal configuration;valid initial configuration;nominal control inputs;control barrier certificates;finite-time convergence control barrier functions;information-exchange network","","","24","","","","","IEEE","IEEE Conferences"
"Key-frame Selection for Multi-robot Simultaneous Localization and Tracking in Robot Soccer Field","W. Fu; K. Lin; C. Shih","Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Networking and Multimedia, National Taiwan University, Taipei, Taiwan; Faculty of Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","109","116","Optical images provide rich features but require extensive computation resources to process for SLAM. When there are limited computation resources on the robots, it becomes a heavy burden to process the images in real-time. This paper presents the design and implementation of key-frame selection algorithm for multiple robots simultaneous localization and tracking on the multi-robot soccer games which have pre-defined field and objects. Compared to traditional key-frame selection algorithms, this work makes use of the temporal and spatial relationship among objects on the pre-defined field to compute the information entropy. The selection ratio can be adjusted by two parameters: entropy threshold and the maximum moving distance. The experimental results show that the developed method can effectively detect the change of scene using selected key-frames. And comparing with the localization results using all the images, using less than 20% of all images after walking 11,203mm it only increase up to 0.87% trajectory errors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593785","","Entropy;Robot sensing systems;Object detection;Sports;Cameras;Legged locomotion","entropy;mobile robots;multi-robot systems;robot vision;SLAM (robots)","traditional key-frame selection algorithms;temporal relationship;spatial relationship;pre-defined field;information entropy;selection ratio;key-frames;localization results;robot soccer field;optical images;extensive computation resources;key-frame selection algorithm;multiple robots simultaneous localization;multirobot soccer games","","","18","","","","","IEEE","IEEE Conferences"
"Grid-Based Motion Planning Using Advanced Motions for Hexapod Robots","W. Cheah; H. H. Khalili; S. Watson; P. Green; B. Lennox","University of Manchester, Robotics for Extreme Environments Lab (REEL) School of Electrical and Electronic Engineering, UK; University of Manchester, Robotics for Extreme Environments Lab (REEL) School of Electrical and Electronic Engineering, UK; University of Manchester, Robotics for Extreme Environments Lab (REEL) School of Electrical and Electronic Engineering, UK; University of Manchester, Robotics for Extreme Environments Lab (REEL) School of Electrical and Electronic Engineering, UK; University of Manchester, Robotics for Extreme Environments Lab (REEL) School of Electrical and Electronic Engineering, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3573","3578","This paper presents the motion planning framework for a hexapod, based on advanced motions, for accessing challenging spaces, namely narrow pathways and large holes, both of which are surrounded by walls. The advanced motions, wall and chimney walking, utilise environment surfaces that are perpendicular to the ground plane to support the robot motion. Such techniques have not yet been studied in the literature. The hierarchical planning framework proposed here is an extension to existing approaches which have only considered ground walking where foothold contacts are confined to the ground plane. During the pre-processing phase of the 2.5D grid map, the motion primitives employed are assessed for each cell and stacked to the graph if valid. The A* algorithm is then used to find a path to the goal position. Following that, the path is post-processed to smoothen the motions and generate a continuous path. Footholds are then selected along the path. The framework has been evaluated in simulation on the custom-designed Corin hexapod. The resulting path enables access to areas that are previously thought to be inaccessible and reduces the travelling distance compared to previous studies.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593964","","Legged locomotion;Planning;Trajectory;Collision avoidance;Robot motion","graph theory;legged locomotion;motion control;path planning","grid-based motion planning;advanced motions;hexapod robots;motion planning framework;chimney walking;robot motion;hierarchical planning framework;custom-designed Corin hexapod;environment surfaces","","","15","","","","","IEEE","IEEE Conferences"
"Hands and Faces, Fast: Mono-Camera User Detection Robust Enough to Directly Control a UAV in Flight","S. MohaimenianPour; R. Vaughan","Simon Fraser University, Autonomy Lab, School of Computing Science; Simon Fraser University, Autonomy Lab, School of Computing Science","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5224","5231","We present a robust real-time system for simultaneous detection of hands and faces in RGB and gray-scale images, and a novel dataset used for training. Our goal is to provide a robust sensor front-end suitable for real-time human-robot interaction using face-engagement and gestures. Using hand-labelled videos obtained from real human-UAV interaction experiments, we re-trained the YOLOv2 Deep Convolutional Neural Network to detect only hands and faces. This model was then used to automatically label several much larger third-party datasets. After manual correction of these results, we modified and re-trained the model on all this labelled data. We obtain qualitatively good detection results at 60Hz on a commodity GPU: our simultaneous hand-and-face detector gives state of the art accuracy and speed in a hand detection benchmark and competitive results in a face detection benchmark. To demonstrate its effectiveness for human-robot interaction we describe its use as the input to a simple but practical gestural human-UAV interface for entertainment or industrial applications. All software, training and test data are freely available.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593709","","Detectors;Feature extraction;Proposals;Training;Object detection;Face detection;Cameras","autonomous aerial vehicles;cameras;control engineering computing;convolutional neural nets;face recognition;feature extraction;gesture recognition;human-robot interaction;image colour analysis;image segmentation;object detection;robust control;video signal processing","YOLOv2 deep convolutional neural network;hand-and-face detector;gestural human-UAV interface;robust control;hand-labelled videos;face-engagement;robust sensor front-end;gray-scale images;robust real-time system;mono-camera user detection;human-robot interaction;human-UAV interaction experiments","","","37","","","","","IEEE","IEEE Conferences"
"Passive Nonlinear Impedance Control for Port-Hamiltonian Systems","Y. Okura; K. Fujimoto","Kyoto University, Department of Aeronautics and Astronautics, Kyoto, Kyotodaigakukatsura, Nishikyo-ku, 615-8540, Japan; Kyoto University, Department of Aeronautics and Astronautics, Kyoto, Kyotodaigakukatsura, Nishikyo-ku, 615-8540, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7983","7988","This paper describes a procedure to design a passive nonlinear impedance control for port-Hamiltonian systems. By expressing the system with the port-Hamiltonian system, the proposed method can be applied to the nonholonomic system as well as fully actuated mechanical systems. The feedback controller for nonlinear impedance control is acquired by utilizing the results of generalized canonical transformation for port-Hamiltonian system. In addition, we investigate the passivity of the closed loop system and discuss the characteristics of the controlled system. A numerical simulation of two-wheeled vehicle shows the effectiveness of the proposed control method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594087","","Impedance;Control systems;Mechanical systems;Symmetric matrices;Man-machine systems;Mathematical model;Robots","closed loop systems;control system synthesis;feedback;nonlinear control systems;numerical analysis","controlled system;passive nonlinear impedance control;port-Hamiltonian system;nonholonomic system;fully actuated mechanical systems;closed loop system;numerical simulation;two-wheeled vehicle;feedback controller;generalized canonical transformation","","","18","","","","","IEEE","IEEE Conferences"
"Model Predictive Trajectory Tracking and Collision Avoidance for Reliable Outdoor Deployment of Unmanned Aerial Vehicles","T. Baca; D. Hert; G. Loianno; M. Saska; V. Kumar","Czech Technical University in Prague, Faculty of Electrical Engineering, Prague, Technicka 2, 6; Czech Technical University in Prague, Faculty of Electrical Engineering, Prague, Technicka 2, 6; New York University New York, 6 MetroTech Center, Tandon School of Engineering, Brooklyn, NY, 11201, USA; Czech Technical University in Prague, Faculty of Electrical Engineering, Prague, Technicka 2, 6; University of Pennsylvania, GRASP lab, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6753","6760","We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594266","","Trajectory;Collision avoidance;Unmanned aerial vehicles;Robot kinematics;Planning;Robot sensing systems","autonomous aerial vehicles;collision avoidance;feedback;mobile robots;multi-robot systems;predictive control;state feedback;trajectory control","prediction horizon;decentralized collision avoidance system;fast nonlinear feedback;virtual UAV;translational dynamics;nonlinear state feedback;linear model predictive controller;optimal trajectory tracking;unmanned aerial vehicles;model predictive trajectory tracking;priority-based collision resolution strategy;tracking mechanism;in-advance collision-free planning;linear MPC","","","25","","","","","IEEE","IEEE Conferences"
"Coupling Mobile Base and End-Effector Motion in Task Space","T. Welschehold; C. Dornhege; F. Paus; T. Asfour; W. Burgard","University of Freiburg, The authors are with the Institute of Computer Science, Germany; University of Freiburg, The authors are with the Institute of Computer Science, Germany; University of Freiburg, The authors are with the Institute of Computer Science, Germany; Karlsruhe Institute of Technology, The Institute for Anthropomatics and Robotics, Germany; University of Freiburg, The authors are with the Institute of Computer Science, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Dynamic systems are a practical alternative to motion planning in executing robot actions. They are of particular interest in Learning from Demonstration, as here we aim to carry out actions in a certain fashion, without a model or in-depth knowledge about the world, which might be difficult to achieve with a planner. Using model-based dynamic systems in task space enables robots to flexibly reproduce demonstrated actions. Nevertheless, when dealing with mobile manipulators, we face the challenge of including the kinematic constraints of the robot in the action models. In this paper we propose to couple robot base and end-effector motions generated by arbitrary dynamical systems modulating the base velocity, while respecting the robots kinematic design. To this end we learn an approximation of the inverse reachability in closed form. In real-world robot experiments we demonstrate that we are able to maintain kinematically feasible trajectories in the presence of obstacles and in configurations differing profoundly from the training scene.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593534","","End effectors;Trajectory;Task analysis;Grippers;Dynamics;Planning","approximation theory;collision avoidance;end effectors;manipulator dynamics;manipulator kinematics;mobile robots","couple robot base;kinematic constraints;mobile manipulators;model-based dynamic systems;in-depth knowledge;motion planning;task space;end-effector motion;coupling mobile base;kinematically feasible trajectories;robots kinematic design;arbitrary dynamical systems","","","14","","","","","IEEE","IEEE Conferences"
"Underwater Robot Navigation for Maintenance and Inspection of Flooded Mine Shafts","O. Álvarez-Tuñón; Á. Rodríguez; A. Jardón; C. Balaguer","Automation and System Engineering, Universidad Carlos III de Madrid, Madrid, Leganes, 28911, Spain; Automation and System Engineering, Universidad Carlos III de Madrid, Madrid, Leganes, 28911, Spain; Automation and System Engineering, Universidad Carlos III de Madrid, Madrid, Leganes, 28911, Spain; Automation and System Engineering, Universidad Carlos III de Madrid, Madrid, Leganes, 28911, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1482","1487","The maintenance and inspection of the flooded shafts, specially coal ones, is an important environmental problem. There are thousands of shafts of this type in Europe with the danger of pollution, flood and collapse. This paper presents some of the main ongoing works of the EU project STAMS that develop an autonomous underwater robotic system for periodic monitoring of flooded shafts in hazardous and complex conditions. The accurate navigation is very cluttered at 1.000 m depth conditions, where minimum visibility and unexpected obstacles are some of the difficulties to overcome. We are going beyond classical navigation approaches using only few sensor information. Another innovation is the installation of Reference Points (RPs) in the shaft's walls by the robot using a special fixation mechanism. The specially designed cases of the RPs allow to house specific sensors and help in the navigation, and will be used in periodic monitoring and assessment of the mine shafts. The positioning and attachment of these RPs is another contribution of this paper.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594445","","Robot sensing systems;Shafts;Three-dimensional displays;Sonar;Navigation;Visual odometry","coal;floods;inspection;maintenance engineering;mining;mobile robots;navigation;path planning;sensors;shafts;underwater vehicles","flooded shafts;EU project STAMS;autonomous underwater robotic system;periodic monitoring;underwater robot navigation;flooded mine shafts inspection;flooded mine shafts maintenance;sensor information","","","23","","","","","IEEE","IEEE Conferences"
"Proxemics and Approach Evaluation by Service Robot Based on User Behavior in Domestic Environment","S. M. Bhagya; P. Samarakoon; H. P. Chapa Sirithunge; M. A. Viraj; J. Muthugala; A. G. Buddhika; P. Jayasekara","Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400; Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400; Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400; Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400; Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400; Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400; Department of Electrical Engineering, University of Moratuwa, Intelligent Service Robotics Group, Moratuwa, 10400","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8192","8199","Intelligent service robots are used at a significant level to uplift the living standards of domestic users. These robots are expected to possess human-friendly interactive features. Service robots should be able to provide a variety of tasks to support independent living of users in domestic environments. Therefore, a service robot often needs to approach users to execute these services and the approach toward the users should be human friendly. In order to achieve this, proxemics planner of a service robot should be cable of deciding the approaching proxemics based on user behavior. This paper proposes a method to decide the approaching proxemics based on the behavior of the user. A fuzzy interference system has been designed to decide the proxemics based on the user behavior identified through body parameters. This leads to an effective interaction mechanism initiated by a robot in such a way that the approaching scenario looks more humanlike. The proposed concept has been implemented on MIRob platform and experiments were conducted in an artificially created domestic environment. The experimental results of the proposed system have been compared with results of a human study to evaluate the performance of the system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593713","Proxemics;Human behavior;Human-robot interaction;Service robots;Human-centered robotics","Service robots;Robot sensing systems;Navigation;Robot kinematics;Wrist;Task analysis","control engineering computing;fuzzy reasoning;human-robot interaction;intelligent robots;interactive systems;service robots","user behavior;intelligent service robots;human-friendly interactive features;MIRob platform;fuzzy interference system;domestic environment;proxemics","","","27","","","","","IEEE","IEEE Conferences"
"Ultrasonic and Electrostatic Self-Cleaning Microstructured Adhesives for Robotic Grippers","V. Alizadehyazdi; E. McQueney; K. Tanaka; M. Spenko","Materials and Aerospace Engineering Department, Illinois Institute of Technology, The Mechanical, Chicago, IL, 60616, USA; Materials and Aerospace Engineering Department, Illinois Institute of Technology, The Mechanical, Chicago, IL, 60616, USA; Materials and Aerospace Engineering Department, Illinois Institute of Technology, The Mechanical, Chicago, IL, 60616, USA; Materials and Aerospace Engineering Department, Illinois Institute of Technology, The Mechanical, Chicago, IL, 60616, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7083","7088","This paper introduces electrostatic and ultrasonic techniques to clean dust and other contaminants from the surface of a gecko-like, microstrutured adhesive. The result is a non-destructive, non-contact cleaning method that will afford robotic grippers, climbing robots, and perching robots the ability to operate in real-world environments. Experimental results show that the cleaning efficiency for three different sizes of glass beads, 53-75 μm, 75-90 μm, and 90-106 μm, ranges between 75-99% when using a combination of electrostatic and ultrasonic cleaning. This is a far higher efficiency than when using electrostatic repulsion alone. Experiments also demonstrate an approximately 33% recovery in shear stress on a flat glass for a contaminated directional gecko-like adhesive after contact with a dusty table when electrostatic/ultrasonic cleaning was used. Finally, by applying this method on a robotic gripper, we observed an 18% recovery in normal adhesion on a flat glass substrate.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594091","","Cleaning;Electrostatics;Surface contamination;Grippers;Electrodes;Substrates;Rough surfaces","adhesion;adhesives;cleaning;dust;electrostatics;glass;grippers;industrial robots;mobile robots;ultrasonic cleaning","perching robots;electrostatic cleaning;electrostatic repulsion;climbing robots;ultrasonic cleaning;noncontact cleaning method;robotic gripper;contaminated directional gecko-like adhesive","","","14","","","","","IEEE","IEEE Conferences"
"Soft Curvature and Contact Force Sensors for Deep-Sea Grasping via Soft Optical Waveguides","C. B. Teeple; K. P. Becker; R. J. Wood","John A. Paulson School of Engineering and Applied Sciences, Harvard University, 60 Oxford St., Cambridge, MA, 02138, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, 60 Oxford St., Cambridge, MA, 02138, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, 60 Oxford St., Cambridge, MA, 02138, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1621","1627","In this work, we show that sensors based on soft, intentionally-lossy optical waveguides are well-suited for soft robotic grasping applications in the deep-sea. Each finger of a soft robotic hand is outfitted with a 2×1 array of optical sensing elements to enable proprioception and contact force sensing. Curvature sensing elements are integrated directly into the structure of a finger, while contact force sensors are fabricated as standalone units and attached afterward. Along with considerations for interfacing with deep-sea remotely operated vehicles (ROVs), models for the effect of bending on light loss and the effect of normal force on strain were used to inform sensor design decisions. Our sensors show sensitivity to curvature over a range of diameters from 8 mm to 76 mm, and sub-Newton force sensitivity. Additionally, sensors were characterized in simulated deep-sea environments at temperatures from -10°C to 50°C and hydrostatic pressures up to 4000 psi. The sensitivity of our curvature sensors is invariant to the temperatures and pressure ranges tested, though contact force sensors decreased in sensitivity as temperatures decreased. Finally, we successfully demonstrate that sensors onboard soft finger actuators can provide informative state feedback during grasping operations in air and water.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594270","","Optical waveguides;Optical sensors;Optical device fabrication;Optical losses;Optical refraction;Optical variables control","actuators;force sensors;grippers;optical sensors;optical waveguides;remotely operated vehicles","soft robotic hand;optical sensing elements;proprioception;curvature sensing elements;contact force sensors;normal force;sensor design decisions;simulated deep-sea environments;curvature sensors;soft finger actuators;soft curvature;deep-sea grasping;intentionally-lossy optical waveguides;soft robotic grasping applications;subNewton force sensitivity;temperature -10.0 degC to 50.0 degC","","","18","","","","","IEEE","IEEE Conferences"
"Stable, Autonomous, Unknown Terrain Locomotion for Quadrupeds Based on Visual Feedback and Mixed-Integer Convex Optimization","M. S. Ahn; H. Chae; D. W. Hong","Department of Mechanical and Aerospace Engineering at the University of California, Los Angeles, CA, 90095, USA; Department of Mechanical and Aerospace Engineering at the University of California, Los Angeles, CA, 90095, USA; Department of Mechanical and Aerospace Engineering at the University of California, Los Angeles, CA, 90095, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3791","3798","This paper presents a complete motion planning approach for quadruped locomotion across an unknown terrain using a framework based on mixed-integer convex optimization and visual feedback. Vision data is used to find convex polygons in the surrounding environment, which acts as potentially feasible foothold regions. Then, a goal position is initially provided, which the best feasible destination planner uses to solve for an actual feasible goal position based on the extracted polygons. Next, a footstep planner uses the feasible goal position to plan a fixed number of footsteps, which may or may not result in the robot reaching the position. The center of mass (COM) trajectory planner using quadratic programming is extended to solve for a trajectory in 3D space while maintaining convexity, which reduces the computation time, allowing the robot to plan and execute motions online. The suggested method is implemented as a policy rather than a path planner, but its performance as a path planner is also shown. The approach is verified on both simulation and on a physical robot, ALPHRED, walking on various unknown terrains.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594015","","Optimization;Trajectory;Legged locomotion;Planning;Three-dimensional displays","convex programming;integer programming;legged locomotion;motion control;path planning;quadratic programming;robot vision","visual feedback;mixed-integer convex optimization;complete motion planning approach;quadruped locomotion;convex polygons;potentially feasible foothold regions;feasible destination planner;extracted polygons;footstep planner;mass trajectory planner;path planner;stable terrain locomotion;autonomous terrain locomotion;unknown terrain locomotion;quadrupeds;feasible goal position;ALPHRED","","","27","","","","","IEEE","IEEE Conferences"
"Analytically-Guided Design of a Tailed Bipedal Hopping Robot","A. Shamsah; A. De; D. E. Koditschek","Mechanical Engineering and Applied Mechanics; Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2237","2244","We present the first fully spatial hopping gait of a 12 DoF tailed biped driven by only 4 actuators. The control of this physical machine is built up from parallel compositions of controllers for progressively higher DoF extensions of a simple 2 DoF, 1 actuator template. These template dynamics are still not themselves integrable, but a new hybrid averaging analysis yields a conjectured closed form representation of the approximate hopping limit cycle as a function of its physical and control parameters. The resulting insight into the role of the machines kinematic and dynamical design choices affords a redesign leading to the newly achieved behavior.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593677","","Actuators;Legged locomotion;Damping;Kinematics;Limit-cycles;Stability analysis","actuators;design engineering;legged locomotion;robot dynamics;robot kinematics","hybrid averaging analysis;conjectured closed form representation;approximate hopping limit cycle;physical control;dynamical design choices affords;tailed bipedal hopping robot;template dynamics;actuator template;spatial hopping gait","","","34","","","","","IEEE","IEEE Conferences"
"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).","F. Ramos; C. O. Scrob; A. S. Vázquez; R. Fernández; A. Olivares-Alarcos","School of Engineering of the University of Castilla-La Mancha, Ciudad Real, Spain; Indra Systems S.A., Madrid, Spain; School of Engineering of the University of Castilla-La Mancha, Ciudad Real, Spain; School of Engineering of the University of Castilla-La Mancha, Ciudad Real, Spain; University of Catalonia, Institute of Robotics and Industrial Informatics of the Polytechnic, Barcelona, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5679","5684","This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593856","","Robot sensing systems;Ontologies;Legged locomotion;Semantics;Taxonomy;Morphology","control engineering computing;ontologies (artificial intelligence);robots","ontology;robotic skills;structural part;base configuration;abstract structure;modular robotic platform;skill-oriented designer;conceptual robotic structures","","","13","","","","","IEEE","IEEE Conferences"
"PRISM: Pose Registration for Integrated Semantic Mapping","J. W. Hart; R. Shah; S. Kirmani; N. Walker; K. Baldauf; N. John; P. Stone","Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Computer Science, University of Texas at Austin, Austin, Texas, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","896","902","Many robotics applications involve navigating to positions specified in terms of their semantic significance. A robot operating in a hotel may need to deliver room service to a named room. In a hospital, it may need to deliver medication to a patient's room. The Building-Wide Intelligence Project at UT Austin has been developing a fleet of autonomous mobile robots, called BWIBots, which perform tasks in the computer science department. Tasks include guiding a person, delivering a message, or bringing an object to a location such as an office, lecture hall, or classroom. The process of constructing a map that a robot can use for navigation has been simplified by modern SLAM algorithms. The attachment of semantics to map data, however, remains a tedious manual process of labeling locations in otherwise automatically generated maps. This paper introduces a system called PRISM to automate a step in this process by enabling a robot to localize door signs - a semantic markup intended to aid the human occupants of a building - and to annotate these locations in its map.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593681","","Robots;Semantics;Three-dimensional displays;Cameras;Two dimensional displays;Computational modeling;Navigation","mobile robots;multi-robot systems;navigation;pose estimation;service robots;SLAM (robots)","computer science department;modern SLAM algorithms;map data;tedious manual process;automatically generated maps;PRISM;semantic markup;pose registration;integrated semantic;robotics applications;hotel;room service;hospital;medication;patient;UT Austin;autonomous mobile robots;BWIBots;building-wide intelligence project","","","22","","","","","IEEE","IEEE Conferences"
"A Self-Tuning Impedance Controller for Autonomous Robotic Manipulation","P. Balatti; D. Kanoulas; G. F. Rigano; L. Muratore; N. G. Tsagarakis; A. Ajoudani","HRII Lab; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HHCM Lab, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HHCM Lab, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HHCM Lab, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HHCM Lab, Genoa, Italy; HRII Lab","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5885","5891","Complex interactions with unstructured environments require the application of appropriate restoring forces in response to the imposed displacements. Impedance control techniques provide effective solutions to achieve this, however, their quasi-static performance is highly dependent on the choice of parameters, i.e. stiffness and damping. In most cases, such parameters are previously selected by robot programmers to achieve a desired response, which limits the adaptation capability of robots to varying task conditions. To improve the generality of interaction planning through task-dependent regulation of the parameters, this paper introduces a novel self-regulating impedance controller. The regulation of the parameters is achieved based on the robot's local sensory data, and on an interaction expectancy value. This value combines the interaction values from the robot state machine and visual feedback, to authorize the autonomous tuning of the impedance parameters in selective Cartesian axes. The effectiveness of the proposed method is validated experimentally in a debris removal task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593860","","Impedance;Task analysis;Robot sensing systems;Three-dimensional displays;Grasping;Damping","control system synthesis;feedback;manipulators;mobile robots;path planning;robot programming;robot vision","appropriate restoring forces;unstructured environments;complex interactions;autonomous robotic manipulation;self-tuning impedance controller;debris removal task;selective Cartesian axes;impedance parameters;autonomous tuning;robot state machine;interaction values;interaction expectancy value;novel self-regulating impedance controller;task-dependent regulation;task conditions;robot programmers;damping;stiffness;quasistatic performance;impedance control techniques;imposed displacements","","","23","","","","","IEEE","IEEE Conferences"
"Stereo Visual Odometry and Semantics based Localization of Aerial Robots in Indoor Environments","H. Bavle; S. Manthe; P. de la Puente; A. Rodriguez-Ramos; C. Sampedro; P. Campoy","Computer Vision and Aerial Robotics (CVAR) Group, Centre for Automation and Robotics (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Universidad Politecnica de Madrid, Spain; Institute for Computational Visualistics, University of Koblenz-Landau, Universitatsstr, 1, Koblenz, 56070, Germany; Computer Vision and Aerial Robotics (CVAR) Group, Centre for Automation and Robotics (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Universidad Politecnica de Madrid, Spain; Computer Vision and Aerial Robotics (CVAR) Group, Centre for Automation and Robotics (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Universidad Politecnica de Madrid, Spain; Computer Vision and Aerial Robotics (CVAR) Group, Centre for Automation and Robotics (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Universidad Politecnica de Madrid, Spain; Computer Vision and Aerial Robotics (CVAR) Group, Centre for Automation and Robotics (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Universidad Politecnica de Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1018","1023","In this paper we propose a particle filter localization approach, based on stereo visual odometry (VO) and semantic information from indoor environments, for mini-aerial robots. The prediction stage of the particle filter is performed using the 3D pose of the aerial robot estimated by the stereo VO algorithm. This predicted 3D pose is updated using inertial as well as semantic measurements. The algorithm processes semantic measurements in two phases; firstly, a pre-trained deep learning (DL) based object detector is used for real time object detections in the RGB spectrum. Secondly, from the corresponding 3D point clouds of the detected objects, we segment their dominant horizontal plane and estimate their relative position, also augmenting a prior map with new detections. The augmented map is then used in order to obtain a drift free pose estimate of the aerial robot. We validate our approach in several real flight experiments where we compare it against ground truth and a state of the art visual SLAM approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593426","","Semantics;Three-dimensional displays;Unmanned aerial vehicles;Robots;Atmospheric measurements;Particle measurements;Prediction algorithms","distance measurement;image colour analysis;image segmentation;indoor environment;learning (artificial intelligence);mobile robots;neural nets;object detection;particle filtering (numerical methods);pose estimation;robot vision;SLAM (robots);stereo image processing","indoor environments;particle filter localization approach;semantic information;mini-aerial robots;stereo VO algorithm;semantic measurements;pre-trained deep learning based object detector;3D point clouds;visual SLAM approach;stereo visual odometry;semantics based localization;DL;RGB spectrum;drift free pose estimation","","","26","","","","","IEEE","IEEE Conferences"
"A Monocular Indoor Localiser Based on an Extended Kalman Filter and Edge Images from a Convolutional Neural Network","J. Unicomb; R. Ranasinghe; L. Dantanarayana; G. Dissanayake","University of Technology Sydney, Centre for Autonomous Systems, Australia; University of Technology Sydney, Centre for Autonomous Systems, Australia; University of Technology Sydney, Centre for Autonomous Systems, Australia; University of Technology Sydney, Centre for Autonomous Systems, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","The main contribution of this paper is an extended Kalman filter (EKF)based algorithm for estimating the 6 DOF pose of a camera using monocular images of an indoor environment. In contrast to popular visual simultaneous localisation and mapping algorithms, the technique proposed relies on a pre-built map represented as an unsigned distance function of the ground plane edges. Images from the camera are processed using a Convolutional Neural Network (CNN)to extract a ground plane edge image. Pixels that belong to these edges are used in the observation equation of the EKF to estimate the camera location. Use of the CNN makes it possible to extract ground plane edges under significant changes to scene illumination. The EKF framework lends itself to use of a suitable motion model, fusing information from any other sensors such as wheel encoders or inertial measurement units, if available, and rejecting spurious observations. A series of experiments are presented to demonstrate the effectiveness of the proposed technique.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594337","","Image edge detection;Cameras;Robot vision systems;Feature extraction;Convolution;Image segmentation","cameras;convolutional neural nets;edge detection;image fusion;Kalman filters;mobile robots;nonlinear filters;pose estimation;robot vision;SLAM (robots)","camera location estimation;extended Kalman filter;6 DOF pose estimation;visual simultaneous localisation-and-mapping algorithms;prebuilt map;ground plane edge image extraction;motion model;unsigned distance function;indoor environment;monocular images;monocular indoor localiser;EKF framework;CNN;convolutional neural network","","","26","","","","","IEEE","IEEE Conferences"
"Scan Similarity-based Pose Graph Construction method for Graph SLAM","W. Yoo; H. Kim; H. Hong; B. H. Lee","Department of Electrical and Computer Engineering, Seoul National University, Republic of Korea; Department of Electrical and Computer Engineering, Seoul National University, Republic of Korea; Department of Electrical and Computer Engineering, Seoul National University, Republic of Korea; Department of Electrical and Computer Engineering, Seoul National University, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","131","136","Scan similarity-based pose graph construction method for graph SLAM is proposed. To perform delicate pose graph SLAM, front-end that constructs a graph as well as back-end that optimizes the constructed graph is an important task. Generally, there is an error accumulation phenomenon during the odometry estimation process. This paper focuses on the method of creating a high quality graph by suggesting ways to improve the graph accuracy since the accumulated errors in the graph might degrade the performance of the entire graph SLAM. We deal with one of our previous works, dynamic keyframe selection technique, based on scan similarity computation method more precisely and suggest a loop closure detection method by exploiting previously proposed 2-D laser scan descriptor. To verify objective performance of the proposed method, the experimental results of the odometry estimation are shown by using the benchmark dataset and the real world dataset. Additionally, results of the pose graph SLAM are shown for the real world dataset which include the loop clorues.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593605","","Simultaneous localization and mapping;Lasers;Estimation;Heuristic algorithms;Optimization","graph theory;mobile robots;pose estimation;robot vision;SLAM (robots)","scan similarity-based pose graph construction method;constructed graph;loop closure detection method;real world dataset;benchmark dataset;odometry estimation process;error accumulation phenomenon;pose graph SLAM;scan similarity computation method;graph accuracy;high quality graph","","","25","","","","","IEEE","IEEE Conferences"
"Conceptualization of Object Compositions Using Persistent Homology","C. A. Mueller; A. Birk","Robotics Group of the Computer Science & Electrical Engineering Department, Jacobs University Bremen, Germany; Robotics Group of the Computer Science & Electrical Engineering Department, Jacobs University Bremen, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1095","1102","A topological shape analysis is proposed and utilized to learn concepts that reflect shape commonalities. Our approach is two-fold: i) a spatial topology analysis of point cloud segment constellations within objects. Therein constellations are decomposed and described in an hierarchical manner - from single segments to segment groups until a single group reflects an entire object. ii) a topology analysis of the description space in which segment decompositions are exposed in. Inspired by Persistent Homology, hidden groups of shape commonalities are revealed from object segment decompositions. Experiments show that extracted persistent groups of commonalities can represent semantically meaningful shape concepts. We also show the generalization capability of the proposed approach considering samples of external datasets.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594516","","Shape;Three-dimensional displays;Visualization;Topology;Dictionaries;Prototypes;Training","image segmentation;learning (artificial intelligence);object recognition;shape recognition;topology","topological shape analysis;shape commonalities;spatial topology analysis;point cloud segment constellations;description space;object segment decompositions;persistent homology","","","23","","","","","IEEE","IEEE Conferences"
"New Approach of Cycling Phases Detection to Improve FES-Pedaling in SCI Individuals","R. Baptista; B. Sijobert; C. A. Coste","INRIA, Université de Montpellier, Montpellier, France; INRIA, Université de Montpellier, Montpellier, France; INRIA, Université de Montpellier, Montpellier, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5181","5186","FES allows spinal cord injured individuals to propel tricycles by means of their own leg power. The stimulation patterns are in most of the cases predefined and muscle activation triggered on the basis of the pedal position. This requires an empirical tuning to fit the pattern to the pilot sitting position and distance to crank with no possible generalization and no adaptive properties. The aim of the present article is to introduce a new approach of motion segmentation based on inertial measurement units located on the cyclist legs with the final aim to predict the optimal pedaling force evolution. Results obtained with one healthy subject in different cycling conditions are presented and the application to FES-cycling discussed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594162","","Knee;Superluminescent diodes;Hidden Markov models;Adaptation models;Switches;Legged locomotion;Muscles","bioelectric phenomena;biomechanics;neuromuscular stimulation;patient rehabilitation","functional electrical stimulation;optimal pedaling force evolution;cyclist legs;inertial measurement units;motion segmentation;adaptive properties;muscle activation;tricycles;spinal cord;FES-pedaling","","","21","","","","","IEEE","IEEE Conferences"
"3D Shape Perception from Monocular Vision, Touch, and Shape Priors","S. Wang; J. Wu; X. Sun; W. Yuan; W. T. Freeman; J. B. Tenenbaum; E. H. Adelson","Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1606","1613","Perceiving accurate 3D object shape is important for robots to interact with the physical world. Current research along this direction has been primarily relying on visual observations. Vision, however useful, has inherent limitations due to occlusions and the 2D-3D ambiguities, especially for perception with a monocular camera. In contrast, touch gets precise local shape information, though its efficiency for reconstructing the entire shape could be low. In this paper, we propose a novel paradigm that efficiently perceives accurate 3D object shape by incorporating visual and tactile observations, as well as prior knowledge of common object shapes learned from large-scale shape repositories. We use vision first, applying neural networks with learned shape priors to predict an object's 3D shape from a single-view color image. We then use tactile sensing to refine the shape; the robot actively touches the object regions where the visual prediction has high uncertainty. Our method efficiently builds the 3D shape of common objects from a color image and a small number of tactile explorations (around 10). Our setup is easy to apply and has potentials to help robots better perform grasping or manipulation tasks on real-world objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593430","","Shape;Three-dimensional displays;Image reconstruction;Surface reconstruction;Robot sensing systems","cameras;computational geometry;feature extraction;image colour analysis;image reconstruction;image segmentation;learning (artificial intelligence);manipulators;neural nets;object detection;object recognition;robot vision;shape recognition;solid modelling;tactile sensors;visual perception","3D object shape;precise local shape information;monocular camera;visual observations;physical world;perceiving accurate 3D object shape;touch;monocular vision;real-world objects;visual prediction;object regions;learned shape priors;large-scale shape repositories;common object shapes;tactile observations","","","49","","","","","IEEE","IEEE Conferences"
"Improving Reinforcement Learning Pre-Training with Variational Dropout","T. Blau; L. Ott; F. Ramos","School of Information Technologies The University of Sydney; School of Information Technologies The University of Sydney; School of Information Technologies The University of Sydney","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4115","4122","Reinforcement learning has been very successful at learning control policies for robotic agents in order to perform various tasks, such as driving around a track, navigating a maze, and bipedal locomotion. One significant drawback of reinforcement learning methods is that they require a large number of data points in order to learn good policies, a trait known as poor data efficiency or poor sample efficiency. One approach for improving sample efficiency is supervised pre-training of policies to directly clone the behavior of an expert, but this suffers from poor generalization far from the training data. We propose to improve this by using Gaussian dropout networks with a regularization term based on variational inference in the pre-training step. We show that this initializes policy parameters to significantly better values than standard supervised learning or random initialization, thus greatly reducing sample complexity compared with state-of-the-art methods, and enabling an RL algorithm to learn optimal policies for high-dimensional continuous control problems in a practical time frame.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594341","","Task analysis;Training;Reinforcement learning;Training data;Cloning;Supervised learning;Robots","control engineering computing;Gaussian processes;legged locomotion;supervised learning","reinforcement learning pre-training;control policies;robotic agents;bipedal locomotion;data points;Gaussian dropout networks;variational inference;policy parameters;standard supervised learning;optimal policies;variational dropout;regularization term;RL algorithm;high-dimensional continuous control problems","","","26","","","","","IEEE","IEEE Conferences"
"Accounting for Directional Rigidity and Constraints in Control for Manipulation of Deformable Objects without Physical Simulation","M. Ruan; D. M. Conachie; D. Berenson","Robotics Institute, University of Michigan, Ann Arbor, MI, 48105, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, 48105, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, 48105, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","512","519","Deformable objects like cloth and rope are challenging to manipulate because it is difficult to predict the state of the object given a motion of the gripper(s) holding it. In much previous work, physical models (such as Mass-Spring or Finite-Element) have been used to model such affects. However, these models often require significant parameter tuning for each scenario and can be expensive to simulate inside a control loop. Furthermore, it is difficult to create a practical controller for deformable object manipulation that preserves constraints, especially avoiding overstretching the object. In this paper, we developed a more effective controller than previous work by (1) constructing a more accurate geometric model of how the direction of gripper motion and obstacles affect deformable objects; and (2) specifying a novel stretching avoidance constraint to prevent the object from being overstretched by the robot. Experiments comparing our new method to the previous method in simulation and on a physical robot suggest that our new model captures the behavior of the object more accurately. We also find that our controller is able to prevent tearing that would occur when using the previous method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594520","","Grippers;Deformable models;Computational modeling;Robots;Predictive models;Finite element analysis;Adaptation models","biomechanics;collision avoidance;deformation;finite element analysis;grippers;motion control;physiological models;shear modulus;springs (mechanical);stress analysis","directional rigidity;deformable objects;physical simulation;physical models;control loop;practical controller;deformable object manipulation;effective controller;accurate geometric model;gripper motion;novel stretching avoidance constraint;physical robot","","","22","","","","","IEEE","IEEE Conferences"
"UX 1 system design - A robotic system for underwater mining exploration","A. Martins; J. Almeida; C. Almeida; A. Dias; N. Dias; J. Aaltonen; A. Heininen; K. T. Koskinen; C. Rossi; S. Dominguez; C. Vörös; S. Henley; M. McLoughlin; H. van Moerkerk; J. Tweedie; B. Bodo; N. Zajzon; E. Silva","INESC TEC-INESC Technology and Science and with ISEP, School of Engineering, Polytechnic Institute of Porto, Porto, Portugal; INESC TEC-INESC Technology and Science and with ISEP, School of Engineering, Polytechnic Institute of Porto, Porto, Portugal; INESC TEC-INESC Technology and Science, Porto, Portugal; INESC TEC-INESC Technology and Science and with ISEP, School of Engineering, Polytechnic Institute of Porto, Porto, Portugal; INESC TEC-INESC Technology and Science and with ISEP, School of Engineering, Polytechnic Institute of Porto, Porto, Portugal; TUT-Tampere, University of Technology, Tampere, Finland; TUT-Tampere, University of Technology, Tampere, Finland; TUT-Tampere, University of Technology, Tampere, Finland; Centre for Automation and Robotics, Universidad Politecnica de Madrid-CSIC, Madrid, Spain; Centre for Automation and Robotics, Universidad Politecnica de Madrid-CSIC, Madrid, Spain; Institute of Mineralogy-Geology, University of Miskolc, Miskolc, Hungary; Resources Computing International Ltd (RCI), Matlock, United Kingdom; Resources Computing International Ltd (RCI), Matlock, United Kingdom; Resources Computing International Ltd (RCI), Matlock, United Kingdom; Resources Computing International Ltd (RCI), Matlock, United Kingdom; La Palma Research Center, Isla de La Palma, Spain; Institute of Mineralogy-Geology, University of Miskolc, Miskolc, Hungary; INESC TEC-INESC Technology and Science and with ISEP, School of Engineering, Polytechnic Institute of Porto, Porto, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1494","1500","This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593999","","Robot sensing systems;Sonar;Cameras;Payloads;Three-dimensional displays","cameras;control system synthesis;innovation management;mining;mobile robots;robot vision;sonar;underwater vehicles","UX 1 system design;underwater mining exploration;UX-1 underwater mine exploration robotic system;UNEXMIN project;international innovation action;EU H2020 program;flooded underground mines;UX-1 robot prototype;recovery system;post-processing computational infrastructure;spherical robot;rotating laser line structured light systems;comprehensive mine model;robot design;UV-light;natural gamma-ray detector;multi-spectral camera;electro-conductivity;magnetic field sensors;high resolution imagery","","1","17","","","","","IEEE","IEEE Conferences"
"Cable-Driven Actuation for Highly Dynamic Robotic Systems","J. Hwangbo; V. Tsounis; H. Kolvenbach; M. Hutter","ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8543","8550","This paper presents the design and experimental evaluations of an articulated robotic limb called Capler-Leg. The key element of Capler-Leg is its single-stage cable-pulley transmission combined with a high-gap radius motor. Our cable-pulley system is designed to be as light-weight as possible and to additionally serve as the primary cooling element, thus significantly increasing the power density and efficiency of the overall system. The total weight of active elements on the leg, i.e. the stators and the rotors, contribute more than 60 % of the total leg weight, which is an order of magnitude higher than most existing robots. The resulting robotic leg has low inertia, high torque transparency, low manufacturing cost, no backlash, and a low number of parts. The Capler-Leg system itself, serves as an experimental setup for evaluating the proposed cable-pulley design in terms of robustness and efficiency. A continuous jump experiment shows a remarkable 96.5 % recuperation rate, measured at the battery output. This means that almost all the mechanical energy output during push-off is returned back to the battery during touch-down.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593569","","Torque;Legged locomotion;Pulleys;Mechanical cables;Creep;Resistance","actuators;cables (mechanical);control engineering computing;cooling;legged locomotion;pulleys;robot dynamics;torque control","cable-pulley system;light-weight;primary cooling element;power density;active elements;total leg weight;resulting robotic leg;low inertia;high torque transparency;low manufacturing cost;Capler-Leg system;experimental setup;cable-pulley design;cable-driven actuation;highly dynamic robotic systems;articulated robotic limb;single-stage cable-pulley transmission;high-gap radius motor","","","17","","","","","IEEE","IEEE Conferences"
"Estimating Metric Poses of Dynamic Objects Using Monocular Visual-Inertial Fusion","K. Qiu; T. Qin; H. Xie; S. Shen","Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Pattern Recognition Center of WeChat, Tencent Inc, Beijing, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","62","68","A monocular 3D object tracking system generally has only up-to-scale pose estimation results without any prior knowledge of the tracked object. In this paper, we propose a novel idea to recover the metric scale of an arbitrary dynamic object by optimizing the trajectory of the objects in the world frame, without motion assumptions. By introducing an additional constraint in the time domain, our monocular visual-inertial tracking system can obtain continuous six degree of freedom (6-DoF) pose estimation without scale ambiguity. Our method requires neither fixed multi-camera nor depth sensor settings for scale observability, instead, the IMU inside the monocular sensing suite provides scale information for both camera itself and the tracked object. We build the proposed system on top of our monocular visual-inertial system (VINS) to obtain accurate state estimation of the monocular camera in the world frame. The whole system consists of a 2D object tracker, an object region-based visual bundle adjustment (BA), VINS and a correlation analysis-based metric scale estimator. Experimental comparisons with ground truth demonstrate the tracking accuracy of our 3D tracking performance while a mobile augmented reality (AR) demo shows the feasibility of potential applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593748","","Cameras;Three-dimensional displays;Visualization;Estimation;Two dimensional displays;Tracking","augmented reality;cameras;feature extraction;image fusion;image sequences;mobile robots;object detection;object tracking;pose estimation;robot vision;state estimation","metric pose estimation;state estimation;3D tracking performance;tracking accuracy;correlation analysis-based metric scale estimator;2D object tracker;monocular camera;visual-inertial system;monocular sensing suite;scale observability;fixed multicamera;visual-inertial tracking system;arbitrary dynamic object;monocular 3D object tracking system;monocular visual-inertial fusion;dynamic objects","","1","20","","","","","IEEE","IEEE Conferences"
"An Optimization-Based Approach to Dual-Arm Motion Planning with Closed Kinematics","A. Völz; K. Graichen","Control, and Microtechnology, University of Ulm, Institute of Measurement, Germany; Control, and Microtechnology, University of Ulm, Institute of Measurement, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8346","8351","This paper addresses the optimization-based planning of collision-free motions for a dual-arm robot with kinematic constraints. Such problems arise, for example, when the robot has to move an object with both arms, whereby the two arms and the gripped object form a closed kinematic chain. Such constrained problems are hard to solve with sampling-based planners, because the probability that a random sample satisfies the closure constraint is practically zero. In contrast, the solution of optimization problems with equality constraints is a well-understood field of research. This paper formulates the motion planning task as optimization problem and proposes a numerical solution using the augmented Lagrangian method for handling constraints. The planner is compared to RRTs, CHOMP and TrajOpt on a set of randomly generated problems for a dual-arm robot with twelve degrees of freedom highlighting the advantages of optimization-based planning.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593927","","Kinematics;Planning;Collision avoidance;Manipulators;Optimization;Trajectory","collision avoidance;constraint handling;humanoid robots;manipulator kinematics;mobile robots;optimisation;probability","dual-arm motion planning;collision-free motions;dual-arm robot;kinematic constraints;closed kinematic chain;constrained problems;sampling-based planners;random sample;closure constraint;equality constraints;gripped object;optimization-based planning approach;probability;augmented Lagrangian method;constraints handling;RRT;CHOMP;TrajOpt;trajectory optimization approach;twelve degrees of freedom","","","23","","","","","IEEE","IEEE Conferences"
"Uncertainty-based Online Mapping and Motion Planning for Marine Robotics Guidance","È. Pairet; J. D. Hernández; M. Lahijanian; M. Carreras","VICOROB, University of Girona, Spain; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, University of Oxford, UK; VICOROB, University of Girona, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2367","2374","In real-world robotics, motion planning remains to be an open challenge. Not only robotic systems are required to move through unexplored environments, but also their manoeuvrability is constrained by their dynamics and often suffer from uncertainty. One approach to overcome this problem is to incrementally map the surroundings while, simultaneously, planning a safe and feasible path to a desired goal. This is especially critical in underwater environments, where autonomous vehicles must deal with both motion and environment uncertainties. In order to cope with these constraints, this work proposes an uncertainty-based framework for mapping and planning3 feasible motions online with probabilistic safety-guarantees. The proposed approach deals with the motion, probabilistic safety, and online computation constraints by (i) incrementally representing the environment as a collection of local maps, and (ii) iteratively (re)planning kinodynamically-feasible and probabilistically-safe paths to goal. The proposed framework is evaluated on the Sparus II, a nonholonomic torpedo-shaped AUV, by conducting simulated and real-world trials, thus proving the efficacy of the method and its suitability even for systems with limited on-board computational power.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593394","","Uncertainty;Safety;Planning;Probabilistic logic;Robot sensing systems;Vehicle dynamics","autonomous underwater vehicles;path planning;probability;robot dynamics;vehicle dynamics","uncertainty-based framework;online computation constraints;motion planning;marine robotics guidance;robotic systems;safe path;underwater environments;autonomous vehicles;probabilistic safety;online mapping","","","28","","","","","IEEE","IEEE Conferences"
"Vision-Aided Absolute Trajectory Estimation Using an Unsupervised Deep Network with Online Error Correction","E. J. Shamwell; S. Leung; W. D. Nothwang","US Army Research Laboratory, Adelphi, MD, 20783; US Army Research Laboratory, Adelphi, MD, 20783; US Army Research Laboratory, Adelphi, MD, 20783","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2524","2531","Adstract- We present an unsupervised deep neural network approach to the fusion of RGB-D imagery with inertial measurements for absolute trajectory estimation. Our network, dubbed the Visual-Inertial-Odometry Learner (VIOLearner), learns to perform visual-inertial odometry (VIO) without inertial measurement unit (IMU) intrinsic parameters (corresponding to gyroscope and accelerometer bias or white noise) or the extrinsic calibration between an IMU and camera. The network learns to integrate IMU measurements and generate hypothesis trajectories which are then corrected online according to the Jacobians of scaled image projection errors with respect to a spatial grid of pixel coordinates. We evaluate our network against state-of-the-art (SOA) visual-inertial odometry, visual odometry, and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI Odometry dataset [1] and demonstrate competitive odometry performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593573","","Cameras;Jacobian matrices;Image reconstruction;Trajectory;Simultaneous localization and mapping;Training","accelerometers;calibration;cameras;distance measurement;gyroscopes;inertial navigation;learning (artificial intelligence);mobile robots;neural nets;pose estimation;robot vision;SLAM (robots)","vision-aided absolute trajectory estimation;unsupervised deep network;online error correction;unsupervised deep neural network approach;RGB-D imagery;inertial measurements;Visual-Inertial-Odometry Learner;inertial measurement unit intrinsic parameters;white noise;extrinsic calibration;camera;IMU measurements;hypothesis trajectories;scaled image projection errors;visual odometry;visual simultaneous localization;KITTI Odometry dataset;competitive odometry performance;visual-inertial odometry","","","20","","","","","IEEE","IEEE Conferences"
"Design and Experiments of a Novel Hydraulic Wheel-Legged Robot (WLR)","X. Li; H. Zhou; H. Feng; S. Zhang; Y. Fu","Harbin Institute of Technology, State Key Laboratory of Robotics and System, Harbin, Heilongjiang Province, 150001, China; Harbin Institute of Technology, State Key Laboratory of Robotics and System, Harbin, Heilongjiang Province, 150001, China; Harbin Institute of Technology, State Key Laboratory of Robotics and System, Harbin, Heilongjiang Province, 150001, China; Harbin Institute of Technology, State Key Laboratory of Robotics and System, Harbin, Heilongjiang Province, 150001, China; Harbin Institute of Technology, State Key Laboratory of Robotics and System, Harbin, Heilongjiang Province, 150001, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3292","3297","Wheel-legged hybrid robot with multi-modal locomotion can efficiently adapt to different terrain environments, as well as realize rapid maneuver on flat ground. We have developed a novel hydraulic wheel-legged robot (WLR) combined with a humanoid structural design. This robot can assist to emergency scenarios where the high mobility, adaptability and robustness are required. The paper introduces the details of the WLR, highlighting the innovative design and optimization of physical construction which is considered to maximize the mobile abilities, enhance the environmental adaptability and improve the reliability of hydraulic system. Firstly, maximizing the mobile abilities includes optimizing the configuration of each actuator and integrating them with the structure, so as to achieve a large range of movement and also reduce the mass and inertia of the legs. Secondly, the environmental adaptability can be ensured with a magnetorheological (MR) fluid-based damper and direct-drive wheels. Thirdly, improving the reliability of hydraulic system involves using the selective laser melting (SLM) technology to integrate hydraulic system and reducing the number of exposed tubes. The maneuverability of the WLR is demonstrated with a series of experiments. At present, the WLR can perform the following operations, including moving on the flat ground, squatting, and picking up a heavy load.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594484","","Conferences;Intelligent robots","humanoid robots;hydraulic control equipment;hydraulic systems;legged locomotion;magnetorheology;robust control;vibration control;wheels","magnetorheological fluid-based damper;hydraulic wheel-legged robot;terrain environments;direct-drive wheels;hydraulic system;environmental adaptability;mobile abilities;innovative design;robustness;humanoid structural design;multimodal locomotion;wheel-legged hybrid robot;WLR","","1","24","","","","","IEEE","IEEE Conferences"
"Multi-Stage Learning of Selective Dual-Arm Grasping Based on Obtaining and Pruning Grasping Points Through the Robot Experience in the Real World","S. Kitagawa; K. Wada; S. Hasegawa; K. Okada; M. Inaba","The University of Tokyo, JSK Laboratory, Graduate School of Information Science and Technology, Hongo, Bunkyo-ku, Tokyo, 7-3-1, Japan; The University of Tokyo, JSK Laboratory, Graduate School of Information Science and Technology, Hongo, Bunkyo-ku, Tokyo, 7-3-1, Japan; The University of Tokyo, JSK Laboratory, Graduate School of Information Science and Technology, Hongo, Bunkyo-ku, Tokyo, 7-3-1, Japan; The University of Tokyo, JSK Laboratory, Graduate School of Information Science and Technology, Hongo, Bunkyo-ku, Tokyo, 7-3-1, Japan; The University of Tokyo, JSK Laboratory, Graduate School of Information Science and Technology, Hongo, Bunkyo-ku, Tokyo, 7-3-1, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7123","7130","Recently, self-supervised approach is common for robot grasping. Although this approach improves success rate, it requires a long time to execute a number of grasp trials, and single-arm grasping is only considered. However, robots can grasp more various objects with two arms, and dual-arm robots such as humanoid robots are expected to execute dual-arm manipulation and overcome the single-arm limitation. In this paper, we introduce dual-arm grasping as another possible strategy and propose a multi-stage learning method for selective dual-arm grasping using Convolutional Neural Networks (CNN)for grasping point prediction and semantic segmentation. In the first stage, the network learns grasping points with the automatic annotation. Although a robot learns both single-arm and dual-arm grasping efficiently with the annotation, the robot may not be able to grasp it because the annotation algorithm is designed by human. Therefore, for the second stage, the robot samples various grasping points with both grasping strategies and learns how to grasp in the real world. In this stage, the robot obtains new possible grasping points and prunes unsuccessful ones for both grasping strategies through the robot experience. In the experiments in the real world, the adapted network achieved high success rate 76.7% in 90 trials. Since the network trained with no adaptation stage resulted in lower success rate 56.7%, this result also shows the network was refined with less than 250 times of grasp sampling. As an application of our method, we demonstrated that our system worked well in warehouse picking task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593752","","Grasping;Semantics;Image segmentation;Manipulators;Task analysis;Learning systems","control engineering computing;convolutional neural nets;humanoid robots;learning (artificial intelligence);manipulators;robot vision","selective dual-arm grasping;pruning grasping points;robot experience;robot grasping;dual-arm robots;humanoid robots;dual-arm manipulation;single-arm limitation;multistage learning method;self-supervised approach;convolutional neural networks;CNN;semantic segmentation;automatic annotation","","","14","","","","","IEEE","IEEE Conferences"
"User-specific Gaussian Process Model of Wheelchair Drivers with a Haptic Joystick Interface","A. Hünternann; E. Demeester; E. V. Poorten","Alexander Hüntemann and Eric Demeester are with KU Leuven, Faculty of Engineering Technology, Department of Mechanical Engineering, Campus Diepenbeek, ACRO Research Group, Wetenschapspark 27, Diepenbeek, 3590, Belgium; Alexander Hüntemann and Eric Demeester are with KU Leuven, Faculty of Engineering Technology, Department of Mechanical Engineering, Campus Diepenbeek, ACRO Research Group, Wetenschapspark 27, Diepenbeek, 3590, Belgium; Emmanuel Vander Poorten is with KU Leuven, Faculty of Engineering Technology, Department of Mechanical Engineering, Campus Groep T, RAS Research Group, Andreas Vesaliusstraat 13, Leuven, 3000, Belgium","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2457","2463","In collaborative human-robot navigation such as when driving semi-autonomous robotic wheelchairs, intuitive control of the mobile robot is only possible if the robot understands its user. This becomes especially important as users present varying levels of abilities and heterogeneous driving styles. Furthermore, the robot needs to consider the inherent uncertainty on its navigation task because the user may not be able to communicate his or her plans explicitly. In order to address these requirements, we have adopted a probabilistic framework to recognise navigation plans. A key component in this framework is a personalised driver model, which captures how a particular user transforms his or her mental navigation plan into inputs to the robot. In this work, we evaluate the use of Gaussian Processes to implement and calibrate this probabilistic, user-specific driver model, and this for use with haptic joysticks. Furthermore, special care was taken to obtain fast online evaluation of this user model through sparse approximation and parallel computation on a GPU. This resulted in an achievable user model evaluation frequency of 40 Hz, which is far above the navigation assistance frequency we aimed for, i.e. 5 Hz. We illustrate the validity of the approach by recognising the navigation plans of a spastic wheelchair user.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593931","","Wheelchairs;Navigation;Mobile robots;Probabilistic logic;Gaussian processes;Hidden Markov models","Gaussian processes;handicapped aids;haptic interfaces;human-robot interaction;interactive devices;man-machine systems;mobile robots;navigation;path planning;user modelling;wheelchairs","Gaussian process;spastic wheelchair user;navigation assistance frequency;achievable user model evaluation frequency;haptic joysticks;probabilistic user-specific driver model;mental navigation plan;particular user;personalised driver model;navigation plans;probabilistic framework;navigation task;inherent uncertainty;heterogeneous driving styles;mobile robot;intuitive control;driving semiautonomous;collaborative human-robot navigation;haptic joystick interface;wheelchair drivers;user-specific Gaussian process model","","","17","","","","","IEEE","IEEE Conferences"
"Tracking-Based Depth Estimation of Metallic Pieces for Robotic Guidance","M. Di Castro; C. V. Almagro; G. Lunghi; R. Marin; M. Ferre; A. Masi","European Organization for Nuclear Research, Geneva 23, CH-1211, Switzerland; European Organization for Nuclear Research, Geneva 23, CH-1211, Switzerland; European Organization for Nuclear Research, Geneva 23, CH-1211, Switzerland; Computer Science and Engineering Department, Jaume I University, Castellon, Spain; Centro de Automatica y Robotica-CAR UPM-CSIC, Universidad Politecnica de Madrid, Madrid, 28006, Spain; European Organization for Nuclear Research, Geneva 23, CH-1211, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5503","5508","In order to perform safe robotic interventions in harsh environments it is necessary to help the robotic operator with a Human-Robot Interface that provides multimodal interactions, from low level interaction methods to bilateral teleoperation with force feedback. These interaction modalities, though, rely purely on the operator's skills. With the objective of providing a safer system, higher-level applications can be integrated in the interface in order to provide some help to the operator, without relying uniquely on his/her capacities. This paper presents a novel object recognition and tracking system which runs in real-time on the robot while the operator is operating it. The tracking system enters in the teleoperation loop and helps the operator to achieve the requested goals. The system is optimized to track featureless objects such as metallic plates, metallic connectors and monochromatic objects. Moreover, the algorithm provides improvements with respect to previous tracking experiments, including depth estimation in order to better interact with the velocity control of the robotic arm when approaching the target, as well as high reliability with partial occlusions. This vision-based control system is used in real interventions in hazardous environments, in order to track and manipulate metallic parts of scientific and engineering machines, giving a performance success over 95%, and reaching the 100% under the remote human supervision.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594229","","Cameras;Estimation;Robot vision systems;Correlation;Object recognition;Target tracking","force feedback;human computer interaction;human-robot interaction;manipulators;mobile robots;object recognition;robot vision;telerobotics;velocity control","human-robot interface;tracking experiments;metallic parts;vision-based control system;robotic arm;monochromatic objects;metallic connectors;metallic plates;featureless objects;teleoperation loop;tracking system;object recognition;higher-level applications;safer system;interaction modalities;force feedback;bilateral teleoperation;low level interaction methods;multimodal interactions;robotic operator;harsh environments;safe robotic interventions;robotic guidance;metallic pieces;depth estimation","","","32","","","","","IEEE","IEEE Conferences"
"Unsupervised Object Proposal Using Depth Boundary Density and Density Uniformity","T. Hosono; S. Tarashima; J. Shimamura; T. Kinebuchi","NTT Corporation, NTT Media Intelligence Laboratories, Kanagawa; NTT Corporation, NTT Media Intelligence Laboratories, Kanagawa; NTT Corporation, NTT Media Intelligence Laboratories, Kanagawa; NTT Corporation, NTT Media Intelligence Laboratories, Kanagawa","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7866","7871","Object proposal that detects candidate bounding boxes of objects in images is an effective way of accelerating object recognition in the robot/computer vision area. We propose an accurate and fast object proposal method using depth images. Existing proposal methods can be roughly divided into two categories: window scoring and object region extraction. The window scoring methods usually have higher efficiency than object region extraction methods. The previous methods using RGB images detect an excessive number of boxes due to edges of texture objects. These methods also may misdetect overlapping objects as one candidate bounding box. To tackle these problems, we propose a novel and effective objectness measure using depth images. The proposed method evaluates objectness by using depth boundary density difference between inner and outer regions of a candidate bounding box. We also consider the uniformity of the outer boundary density in a candidate bounding box to divide overlapping objects into individual candidate bounding boxes. Our reasonable assumption here is that the depth boundary of an object has a closed loop. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging toy-dataset [1] of complex crowded scenes.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594408","","Proposals;Computational efficiency;Microsoft Windows;Object detection;Feature extraction;Search problems;Image edge detection","feature extraction;image colour analysis;image texture;learning (artificial intelligence);object detection;object recognition","RGB-D object proposal methods;robot-computer vision area;bounding box;object recognition;density uniformity;unsupervised object proposal;depth boundary density difference;depth images;overlapping objects;texture objects;RGB images;object region extraction methods;window scoring","","","23","","","","","IEEE","IEEE Conferences"
"GPU-Accelerated Next-Best-View Coverage of Articulated Scenes","S. Obwald; M. Bennewitz","University of Bonn, Humanoid Robots Lab, Germany; University of Bonn, Humanoid Robots Lab, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","603","610","Next-best-view algorithms are commonly used for covering known scenes, for example in search, maintenance, and mapping tasks. In this paper, we consider the problem of planning a strategy for covering articulated environments where the robot also has to manipulate objects to inspect obstructed areas. This problem is particularly challenging due to the many degrees of freedom resulting from the articulation. We propose to exploit graphics processing units present in many embedded devices to parallelize the computations of a greedy next-best-view approach. We implemented algorithms for costmap computation, path planning, as well as simulation and evaluation of viewpoint candidates in OpenGL for Embedded Systems and benchmarked the implementations on multiple device classes ranging from smartphones to multi-GPU servers. We introduce a heuristic for estimating a utility map from images rendered with strategically placed spherical cameras and show in simulation experiments that robots can successfully explore complex articulated scenes with our system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594054","","Graphics processing units;Task analysis;Cameras;Robot sensing systems;Planning;Solid modeling","embedded systems;graphics processing units;mobile robots;path planning;rendering (computer graphics);robot vision","costmap computation;path planning;simulation;viewpoint candidates;multiple device classes;multiGPU servers;utility map;robots;complex articulated scenes;GPU-accelerated next-best-view coverage;next-best-view algorithms;mapping tasks;articulated environments;obstructed areas;degrees of freedom;embedded devices;next-best-view approach;embedded systems;graphics processing units;OpenGL","","","21","","","","","IEEE","IEEE Conferences"
"A Novel Autonomous Robot for Greenhouse Applications","L. Grimstad; R. Zakaria; T. Dung Le; P. J. From","Norwegian University of Life Sciences, Faculty of Science and Technology, Ås, Drobakveien 31, 1433, Norway; Norwegian University of Life Sciences, Faculty of Science and Technology, Ås, Drobakveien 31, 1433, Norway; Norwegian University of Life Sciences, Faculty of Science and Technology, Ås, Drobakveien 31, 1433, Norway; Norwegian University of Life Sciences, Faculty of Science and Technology, Ås, Drobakveien 31, 1433, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents a novel agricultural robot for greenhouse applications. In many greenhouses, including the greenhouse used in this work, sets of pipes run along the floor between plant rows. These pipes are components of the greenhouse heating system, and doubles as rails for trolleys used by workers. A flat surface separates the start of each rail set at the greenhouse headland. If a robot is to autonomously drive along plant rows, and also be able to move from one set of rails to the next, it must be able to locomote both on rails and on flat surfaces. This puts requirements on mechanical design and navigation, as the robot must cope with two very different operational environments. The robot presented in this paper has been designed to overcome these challenges and allows for autonomous operation both in open environments and on rails by using only low-cost sensors. The robot is assembled using a modular system created by the authors and tested in a greenhouse during ordinary operation. Using the robot, we map the environment and automatically determine the starting point of each rail in the map. We also show how we are able to identify rails and estimate the robots pose relative to theses using only a low-cost 3D camera. When a rail is located, the robot makes the transition from floor to rail and travels along the row of plants before it moves to the next rail set which it has identified in the map. The robot is used for UV treatment of cucumber plants.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594233","","Green products;Rails;Mobile robots;Tools;Wheels;Task analysis","agriculture;cameras;greenhouses;mobile robots;robot vision","autonomous robot;low-cost 3D camera;greenhouse headland;greenhouse heating system;agricultural robot;greenhouse applications","","","22","","","","","IEEE","IEEE Conferences"
"ArthroSLAM: Multi-Sensor Robust Visual Localization for Minimally Invasive Orthopedic Surgery","A. Marmol; P. Corke; T. Peynot","ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4000, Australia; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4000, Australia; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4000, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3882","3889","Minimally invasive arthroscopic surgery is a very challenging procedure that requires the manipulation of instruments in limited intraarticular space using distorted and sometimes uninformative images. Localizing the arthroscope reliably and at all times w.r.t. surrounding tissue is of fundamental importance to prevent unintended injury to patients. However, even highly-trained surgeons can struggle to localize the arthro-scope using poor image feedback. In this paper, we propose and demonstrate for the first time a visual Simultaneous Localisation and Mapping (SLAM) system, termed ArthroSLAM, capable of robustly and reliably localizing an arthroscope inside a human knee joint. The proposed system fuses the information obtained from the arthroscope, an external camera mounted on an arthroscope holder, and the odometry of a robotic arm manipulating the scope, in an Extended Kalman Filter framework. Also for the first time, we implement five alternative strategies for localization and compare them to our method in a realistic setup with a human cadaver knee joint. ArthroSLAM is shown to outperform the alternative strategies under various challenging conditions, localizing reliably and at all times with a mean Relative Pose Error of up to 1.4mm and 0.7°. Additional experiments conducted with degraded odometry data also validate the robustness of the method. An initial evaluation of the sparse map of a knee section computed by our method exhibits good morphological agreement. All results suggest that ArthroSLAM is a viable component for the robotic orthopedic surgical assistant of the future.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593501","","Cameras;Robot vision systems;Visualization;Reliability","biomedical optical imaging;cameras;endoscopes;image sensors;Kalman filters;medical image processing;medical robotics;orthopaedics;SLAM (robots);surgery","image feedback;ArthroSLAM;Simultaneous Localisation and Mapping system;SLAM system;external camera;robotic arm;minimally invasive arthroscopic surgery;minimally invasive orthopedic surgery;robotic orthopedic surgical assistant;knee section;human cadaver knee joint;Extended Kalman Filter framework;arthroscope holder;intraarticular space","","1","21","","","","","IEEE","IEEE Conferences"
"Learning-Based Modular Task-Oriented Grasp Stability Assessment","J. Xu; A. Bhardwaj; G. Sun; T. Aykut; N. Alt; M. Karimi; E. Steinbach","Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3468","3475","Assessing grasp stability is essential to prevent the failure of robotic manipulation tasks due to sensory data and object uncertainties. Learning-based approaches are widely deployed to infer the success of a grasp. Typically, the underlying model used to estimate the grasp stability is trained for a specific task, such as lifting, hand-over, or pouring. Since every task has individual stability demands, it is important to adapt the trained model to new manipulation actions. If the same trained model is directly applied to a new task, unnecessary grasp adaptations might be triggered, or in the worst case, the manipulation might fail. To address this issue, we divide the manipulation task used for training into seven sub-tasks, defined as modular tasks. We deploy a learning-based approach and assess the stability for each modular task separately. We further propose analytical features to reduce the dimensionality and the redundancy of the tactile sensor readings. A main task can thereby be represented as a sequence of relevant modular tasks. The stability prediction of the main task is computed based on the inferred success labels of the modular tasks. Our experimental evaluation shows that the proposed feature set lowers the prediction error up to 5.69% compared to other sets used in state-of-the-art methods. Robotic experiments demonstrate that our modular task-oriented stability assessment avoids unnecessary grasp force adaptations and regrasps for various manipulation tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594412","","Task analysis;Stability analysis;Force;Tactile sensors;Feature extraction;Friction;Adaptation models","learning (artificial intelligence);manipulators;stability;tactile sensors","modular task-oriented stability assessment;stability prediction;relevant modular tasks;unnecessary grasp adaptations;manipulation actions;trained model;individual stability demands;specific task;underlying model;learning-based approach;object uncertainties;sensory data;robotic manipulation tasks;modular task-oriented grasp stability assessment;manipulation task;unnecessary grasp force adaptations","","","28","","","","","IEEE","IEEE Conferences"
"A Compact Wheeled Robot that Can Jump while Rolling","K. Misu; A. Yoshii; H. Mochiyama","Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, Ibaraki, 305-8573, Japan; Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, Ibaraki, 305-8573, Japan; Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, Ibaraki, 305-8573, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7507","7512","In this paper, we study a compact wheeled robot that can jump while rolling. Some robots are capable of jumping or rolling, but as far as we know, those robots are not focused on jumping while rolling. We know that animals jump while running to escape from predators. Robots can move quickly by jumping while rolling. We consider a model of a robot jumping while rolling and evaluate the proposed robot. The proposed robot has two wheels and a jumping mechanism based on snap-through buckling of an elastic strip. The proposed robot can jump about 5.9 cm high and 22 cm wide on average while maintaining a traveling speed of about 1.2 m/s. The proposed robot can change the jumping angle without greatly decreasing the impulse for the moving speed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593895","","Mobile robots;Strips;Blades;Wheels;Force;Steel","buckling;elasticity;mobile robots;robot dynamics;strips;wheels","elastic strip;snap-through buckling;jumping angle;jumping mechanism;wheels;robot jumping;animals jump;rolling;compact wheeled robot","","","16","","","","","IEEE","IEEE Conferences"
"Data-Driven Discrete Planning for Targeted Hopping of Compliantly Actuated Robotic Legs","D. Seidel; D. Lakatos; A. Albu-Schäffer","Chair of Sensor Based Robotic Systems and Intelligent Assistance Systems, Department of Informatics, Technical University Munich, Garching, D-85748, Germany; Robotic Mechatronic Center (RMC), Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Oberpfaffenhofen, D-82234, Germany; Robotic Mechatronic Center (RMC), Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Oberpfaffenhofen, D-82234, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2261","2266","Motion planning for fast locomotion of compliantly actuated robotic legs is generally considered to be a challenging issue, posing considerable real-time problems. This is at least the case if time-continuous trajectories need to be generated online. In this paper we take advantage of a simple controller structure, which reduces the motion planning to a discrete-time planning problem, in which only a small set of input parameters need to be determined for each step. We show that for a planar leg with serial elastic actuation, hopping on a ground with stairs of irregular length and height can be planned online, based on a parameter mapping which has been learned in a data-driven manner by performing hopping trials with an adaptive exploration algorithm to evenly sample the parameter space. Experiments on a planar hopping leg prototype validate the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593819","","Legged locomotion;Planning;Springs;Switches;Hardware","actuators;elasticity;legged locomotion;mobile robots;motion control;path planning;robot dynamics","planar hopping leg prototype validate;hopping trials;data-driven manner;serial elastic actuation;planar leg;discrete-time planning problem;simple controller structure;time-continuous trajectories;considerable real-time problems;fast locomotion;motion planning;compliantly actuated robotic legs;targeted hopping;data-driven discrete planning","","","17","","","","","IEEE","IEEE Conferences"
"Collaborative Planning for Mixed-Autonomy Lane Merging","S. Bansal; A. Cosgun; A. Nakhaei; K. Fujimura","Georgia Institute of Technology, Atlanta, GA, USA; Monash University, Clayton, VIC, Australia; Honda Research Institute, Mountain View, CA, USA; Honda Research Institute, Mountain View, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4449","4455","Driving is a social activity: drivers often indicate their intent to change lanes via motion cues. We consider mixed-autonomy traffic where a Human-driven Vehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a planning framework where the degree to which the AV considers the other agent's reward is controlled by a selfishness factor. We test our approach on a simulated two-lane highway where the AV and HV merge into each other's lanes. In a user study with 21 subjects and 6 different selfishness factors, we found that our planning approach was sound and that both agents had less merging times when a factor that balances the rewards for the two agents was chosen. Our results on double lane merging suggest it to be a non-zero-sum game and encourage further investigation on collaborative decision making algorithms for mixed-autonomy traffic.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594197","","Automobiles;Planning;Merging;Collaboration;Robots;Autonomous vehicles","control engineering computing;decision making;driver information systems;game theory;mobile robots;multi-agent systems;path planning;road traffic;road vehicles","collaborative planning;social activity;mixed-autonomy traffic;Human-driven Vehicle;HV;Autonomous Vehicle drive;AV;planning framework;two-lane highway;double lane merging;collaborative decision making;mixed-autonomy lane merging","","","21","","","","","IEEE","IEEE Conferences"
"Capacitive Proximity Sensor Skin for Contactless Material Detection","Y. Ding; H. Zhang; U. Thomas","Chemnitz University of Technology, The Lab of Robotics and Human-Machine-Interaction, 09126 SN Chemnitz, Germany; Chemnitz University of Technology, The Lab of Robotics and Human-Machine-Interaction, 09126 SN Chemnitz, Germany; Chemnitz University of Technology, The Lab of Robotics and Human-Machine-Interaction, 09126 SN Chemnitz, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7179","7184","In this paper, we present a method for contactless material detection with capacitive proximity sensing skins. Our new approach extends the current state-of-the-art proximity and distance sensing methods and measures the characteristic impedance spectrum of an object to obtain material properties. By this, we gain further material information besides of the near field information in a contactless and non-destructive way. The measurement method requires sensors that provide absolute distance and frequency based capacitance measurement capabilities and can be applied to similar systems. The sensor system described in this paper measures proximity with a capacitance based sensor and absolute distance based on time-of-flight (ToF)sensors. Attached on a robot, we gain information about the robot's near field environment. The information is important not only for human- machine- interaction, but also for grasping and manipulation. We focus on signal processing and evaluate our method with measurements of numerous different materials and present a solution to differentiate between them.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594376","","Robot sensing systems;Impedance;Frequency measurement;Electrodes;Current measurement;Impedance measurement","capacitance measurement;capacitive sensors;distance measurement;electric impedance measurement;frequency measurement;signal processing","time-of-flight sensors;capacitance based sensor system;characteristic impedance spectrum measurement;absolute distance based capacitance measurement capabilities;ToF sensors;human-machine-interaction;signal processing;frequency based capacitance measurement capabilities;distance sensing methods;capacitive proximity sensing skins;contactless material detection","","","16","","","","","IEEE","IEEE Conferences"
"Workspace Aware Online Grasp Planning","I. Akinola; J. Varley; B. Chen; P. K. Allen","Department of Computer Science, Columbia University, New York, NY, 10027, USA; Department of Computer Science, Columbia University, New York, NY, 10027, USA; Department of Computer Science, Columbia University, New York, NY, 10027, USA; Department of Computer Science, Columbia University, New York, NY, 10027, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2917","2924","This work provides a framework for a workspace aware online grasp planner. This framework greatly improves the performance of standard online grasp planning algorithms by incorporating a notion of reachability into the online grasp planning process. Offline, a database of hundreds of thousands of unique end-effector poses were queried for feasibility. At runtime, our grasp planner uses this database to bias the hand towards reachable end-effector configurations. The bias keeps the grasp planner in accessible regions of the planning scene so that the resulting grasps are tailored to the situation at hand. This results in a higher percentage of reachable grasps, a higher percentage of successful grasp executions, and a reduced planning time. We also present experimental results using simulated and real environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593644","","Planning;Robots;Trajectory;Measurement;Kinematics;Grasping;Databases","end effectors;path planning","reachable end-effector configurations;unique end-effector poses;workspace aware online grasp planning;reachable grasps","","","23","","","","","IEEE","IEEE Conferences"
"Tarzan: Design, Prototyping, and Testing of a Wire-Borne Brachiating Robot","E. Davies; A. Garlow; S. Farzan; J. Rogers; A. Hu","Georgia Institute of Technology, Woodruff School of Mechanical Engineering, Atlanta, GA, 30332, USA; Georgia Institute of Technology, Woodruff School of Mechanical Engineering, Atlanta, GA, 30332, USA; Georgia Institute of Technology, School of Electrical and Computer Engineering, Atlanta, GA, 30332, USA; Georgia Institute of Technology, Woodruff School of Mechanical Engineering, Atlanta, GA, 30332, USA; Georgia Tech Research Institute, Atlanta, GA, 30332, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7609","7614","A novel brachiating robot design is presented for the purpose of traversing elevated wire networks. The robot is capable of moving along a single wire and between parallel wires, thereby enabling traversal of a two-dimensional space. Several novel features distinguish this design compared to previous brachiating robots. These include the ability to transition to and from both “rope” and “ladder” brachiation modes through an integrated wrist, a locking hand design for minimal power consumption, and distributed electronics packages that communicate wirelessly. A payload mounting point is installed, offering space for a variety of remote sensing packages. Experimental results using a prototype robot demonstrate that the system can reliably brachiate along a single wire, and can also reliably perform a swing-up maneuver after failed swing attempts or when transitioning between the rope and ladder locomotion modes. Energy expenditure for a single swing is quantified using experimental data. Overall, the proposed robot design is shown to provide a promising platform for traversal of wire networks in two dimensions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593823","","Wires;Grippers;Wrist;Thumb;Robot sensing systems","legged locomotion;motion control","swing-up maneuver;distributed electronics packages;brachiating robot design;prototype robot;remote sensing packages;payload mounting point;minimal power consumption;locking hand design;ladder brachiation modes;parallel wires;elevated wire networks;wire-borne brachiating robot;ladder locomotion modes","","","18","","","","","IEEE","IEEE Conferences"
"VARO-Fi: A Variable Orientable Gripper to Obtain In-Hand Manipulation","N. Rahman; D. Caldwell; F. Cannella","Advanced Robotics Department of Istituto Italiano di Technologia, Genoa, 16163, Italy; Advanced Robotics Department of Istituto Italiano di Technologia, Genoa, 16163, Italy; Advanced Robotics Department of Istituto Italiano di Technologia, Genoa, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4568","4575","This paper proposes a novel gripper or end-effector named VARO-fi (VARiable Orientable fingers with translation), with the aim of obtaining human like prehensile manoeuvre such as, in-hand manipulation. The 4 fingered VARO-fi consists of 9 degrees of freedom and it can perform several in-hand manipulation tasks which have been described in this paper. Moreover, the gripper is a simplification of previously proposed gripper platform called Dexclar. The derivation of VARO-fi has been presented and its capabilities have been demonstrated by experiments. Although a generic convex payload is considered as a primitive in the design of VARO-fi however, it is capable to address manipulation for other regular shaped payloads, which has been proven by experiments. A comparison is also illustrated in order to underline the strength of the novel gripper with respect to the state of the art.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594380","","Payloads;Grippers;Grasping;Kinematics;Fasteners;End effectors;Two dimensional displays","control engineering computing;design engineering;end effectors;grippers","variable orientable gripper;obtain in-hand manipulation;variable orientable fingers;VARO-fi;gripper platform;in-hand manipulation tasks","","","23","","","","","IEEE","IEEE Conferences"
"Smoother Position-Drift Compensation for Time Domain Passivity Approach Based Teleoperation","A. Coelho; H. Singh; T. Muskardin; R. Balachandran; K. Kondak","Institute of Robotics and Mechatronics of the German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Institute of Robotics and Mechatronics of the German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Institute of Robotics and Mechatronics of the German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Institute of Robotics and Mechatronics of the German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Institute of Robotics and Mechatronics of the German Aerospace Center (DLR), Oberpfaffenhofen, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5525","5532","Despite being one of the most robust methods in bilateral teleoperation, Time Domain Passivity Approach (TDPA)presents the drawback of accumulating position drift between master and slave devices. The lack of position synchronization poses an obstacle to the performance of teleoperation and may prevent the successful accomplishment of such tasks. Several techniques have been developed in order to solve the position-drift problem in TDPA-based teleoperation. However, they either present poor transparency by over-conservatively constraining force feedback or add high impulse-like force signals that can be harmful to the hardware and to the human operator. We propose a new approach to compensate position drift in TDPA-based teleoperation in a smoother way, which keeps the forces within the normal range of the teleoperation task while preserving the level of transparency and the robust stability of energy-based TDPA. We also add a way of tuning the compensator to behave in accordance with the task being performed, whether it requires faster or smoother compensation. The feasibility and performance of the method were experimentally validated. Good position tracking and regular-amplitude forces are demonstrated with up to 500 ms round-trip constant and variable delays for hard-wall contacts.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594125","","Force;Task analysis;Delays;Communication channels;Time-domain analysis;Delay effects;Admittance","compensation;delays;force feedback;motion control;position control;robust control;synchronisation;telerobotics","robust methods;bilateral teleoperation;position drift;slave devices;position synchronization;position-drift problem;TDPA-based teleoperation;force feedback;high impulse-like force signals;teleoperation task;energy-based TDPA;compensator;regular-amplitude forces;time domain passivity approach;position tracking;position-drift compensation;master devices;robust stability;time 500.0 ms","","","11","","","","","IEEE","IEEE Conferences"
"Apple Counting using Convolutional Neural Networks","N. Häni; P. Roy; V. Isler","Department of Computer Science & Engineering, University of Minnesota, Minneapolis, MN, 55455, United States of America; Department of Computer Science & Engineering, University of Minnesota, Minneapolis, MN, 55455, United States of America; Department of Computer Science & Engineering, University of Minnesota, Minneapolis, MN, 55455, United States of America","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2559","2565","Estimating accurate and reliable fruit and vegetable counts from images in real-world settings, such as orchards, is a challenging problem that has received significant recent attention. Estimating fruit counts before harvest provides useful information for logistics planning. While considerable progress has been made toward fruit detection, estimating the actual counts remains challenging. In practice, fruits are often clustered together. Therefore, methods that only detect fruits fail to offer general solutions to estimate accurate fruit counts. Furthermore, in horticultural studies, rather than a single yield estimate, finer information such as the distribution of the number of apples per cluster is desirable. In this work, we formulate fruit counting from images as a multi-class classification problem and solve it by training a Convolutional Neural Network. We first evaluate the per-image accuracy of our method and compare it with a state of the art method based on Gaussian Mixture Models over four test datasets. Even though the parameters of the Gaussian Mixture Model based method are specifically tuned for each dataset, our network outperforms it in three out of four datasets with a maximum of 94% accuracy. Next, we use the method to estimate the yield for two datasets for which we have ground truth. Our method achieved 96-97% accuracies. For additional details please see our video here: https://www.youtube.com/watch?v=Le0mb5P-SYc.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594304","","Image color analysis;Yield estimation;Agriculture;Image segmentation;Clustering algorithms;Task analysis;Vegetation","agricultural products;convolutional neural nets;Gaussian processes;horticulture;image classification;object detection","horticultural studies;logistics planning;Gaussian mixture model;convolutional neural network;yield estimate;per-image accuracy;fruit counting;fruit detection;vegetable counts;apple counting","","","18","","","","","IEEE","IEEE Conferences"
"Proprioception-Based Grasping for Unknown Objects Using a Series-Elastic-Actuated Gripper","T. Chen; M. Ciocarlie","Department of Mechanical Engineering, Columbia University, New York, NY 10027, USA; Department of Mechanical Engineering, Columbia University, New York, NY 10027, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6675","6681","Grasping unknown objects has been an active research topic for decades. Approaches range from using various sensors (e.g. vision, tactile) to gain information about the object, to building passively compliant hands that react appropriately to contacts. In this paper, we focus on grasping unknown objects using proprioception (the combination of joint position and torque sensing). Our hypothesis is that proprioception alone can be the basis for versatile performance, including multiple types of grasps for objects with multiple shapes and sizes, and transitions between grasps. Using a series-elastic-actuated gripper, we propose a method for performing stable fingertip grasps for unknown objects with unknown contacts, formulated as multi-input-multi-output (MIMO) control. We also show that the proprioceptive gripper can perform enveloping grasps, as well as the transition from fingertip grasps to enveloping grasps.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593787","","Robot sensing systems;Grippers;Grasping;Pulleys;Springs;Sea measurements","actuators;dexterous manipulators;elasticity;force control;grippers;mechanoception;MIMO systems;motion control","series-elastic-actuated gripper;stable fingertip grasps;proprioceptive gripper;proprioception-based grasping;multi-input-multi-output control;MIMO control;sensors","","","21","","","","","IEEE","IEEE Conferences"
"Humanoid Robot COM Kinematics Estimation based on Compliant Inverted Pendulum Model and Robust State Estimator","H. Bae; H. Jeong; J. Oh; K. Lee; J. Oh","Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Robot Research Center; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Robot Research Center; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Robot Research Center; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Robot Research Center; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Robot Research Center, 291Daehak-ro, Yuseong-gu, Daejeon, 34141, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","747","753","This work proposes a humanoid robot center of mass (COM) estimation framework based on the compliant inverted pendulum model and the robust estimator. Humanoids' limited structural stiffness and relatively long legs result in undesired flexibility, and this undesired motion hinders the state estimation. The models used in previous studies were either not suitable for estimation or too simple to express these key characteristics of humanoid robots. Here, to enhance the estimation performance, the compliant inverted pendulum model, which is developed by attaching a spring and damper to the original pendulum, is adopted. The additional elements can represent the mechanical deformation and undesired flexibility. This model can reflect the important characteristics of the humanoid robot while taking advantage of the merits of the sing-mass model. In addition, a robust state estimator that was proposed in our previous work is adopted to compensate for an estimation error caused by a modeling error. Using these two factors, an improved COM kinematics estimates could be obtained.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593966","","Humanoid robots;Mathematical model;State estimation;Kinematics;Computational modeling","elastic constants;estimation theory;humanoid robots;mobile robots;pendulums;robot kinematics;state estimation","mechanical deformation;damper;limited structural stiffness;humanoid robot COM kinematics estimation;center of mass;sing-mass model;robust state estimator;compliant inverted pendulum model","","","24","","","","","IEEE","IEEE Conferences"
"Continuous Shape Changing Locomotion of 32-legged Spherical Robot","H. Nozaki; Y. Kujirai; R. Niiyama; Y. Kawahara; T. Yonezawa; J. Nakazawa","Graduate School of Media and Governance, Keio University, Japan; Department of System Design Engineering, Keio University, Japan; Graduate School of Information Science and Technology, University of Tokyo, Japan; Department of Information and Communication Engineering, The University of Tokyo; Graduate School of Media and Governance, Keio University, Japan; Faculty of Environment and Information Studies, Keio University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2721","2726","Shape changing robot is an approach towards locomotion on uncertain terrain due to its omni-directional features. However, the current locomotion method for such robots rely on discontinuous rolling. We propose a free form locomotion: an omni directional continuous crawling for deformable robots. This method introduce continuous shifting of contact surface similar to amoeba movement. A Mochibot that has thirty two telescopic legs is developed to verify the proposed locomotion method. Through the experiments, we have confirmed that the robot can track smooth paths: straight, smooth, and hand written curves. We also evaluate errors between desired and measured trajectories of the robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593791","","Shape;Legged locomotion;Actuators;Skeleton;Rails","legged locomotion;trajectory control","amoeba movement;Mochibot;trajectory control;deformable robots;omni directional continuous crawling;free form locomotion;32-legged spherical robot;continuous shape changing locomotion","","","15","","","","","IEEE","IEEE Conferences"
"Encoding Guidelines for a Culturally Competent Robot for Elderly Care","A. Sgorbissa; I. Papadopoulos; B. Bruno; C. Koulouglioti; C. Recchiuto","DIBRIS, University of Genova, Via Opera Pia 13, Genova, 16145, Italy; Middlesex University, The Burroughs, London, NW4 4BT, UK; DIBRIS, University of Genova, Via Opera Pia 13, Genova, 16145, Italy; Middlesex University, The Burroughs, London, NW4 4BT, UK; DIBRIS, University of Genova, Via Opera Pia 13, Genova, 16145, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1988","1995","The functionalities and behaviours of socially assistive robots for the care of older people are usually defined by the robot's designers with limited room for runtime adaptation to meet the preferences, expectations and needs of the assisted person. However, adaptation plays a crucial role for the robot's acceptability and ultimately for its effectiveness. Culture, which deeply influences a person's preferences and habits, can be viewed as an invaluable “enabling technology” to achieve such level of adaptation. This paper discusses how guidelines describing culturally competent assistive behaviours can be encoded in a robot to effectively tune its actions, gestures and words. The proposed system is implemented on a Pepper robot and tested with an Indian persona, whose habits and preferences the robot discovers and adapts to at runtime.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594089","","Guidelines;Cultural differences;Robot sensing systems;Motion pictures;Medical services;Encoding","geriatrics;handicapped aids;human-robot interaction;man-machine systems;service robots","encoding guidelines;culturally competent robot;elderly care;socially assistive robots;older people;runtime adaptation;assisted person;invaluable enabling technology;culturally competent assistive behaviours;pepper robot;Indian persona","","","20","","","","","IEEE","IEEE Conferences"
"An Extended Bayesian User Model (BUM) for Capturing Cultural Attributes with a Social Robot","L. Santos; G. S. Martins; J. Dias","Institute of Systems and Robotics, University of Coimbra, Coimbra, 3030-290, Portugal; Institute of Systems and Robotics, University of Coimbra, Coimbra, 3030-290, Portugal; Institute of Systems and Robotics, University of Coimbra, Coimbra, 3030-290, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","320","325","In this work we propose a Bayesian User Model which is able capture a unified representation of cultural attributes from heterogeneous information in the context of Human-Robot Interaction. Despite the latest advances in robotic technologies, virtually no robots are able to cope with the specificities of the “modus vivendi” of different cultures. We start by proposing Bayesian classifiers to capture unitary attributes of different users, clustering them in a n-dimensional semantic attribute space, aggregating groups of persons that share similar attributes. Results show a highly accurate classification framework, both capable of detecting specific subtleties in user's properties, and generalizing them into representative profiles. We then discuss its application towards adapting the actions of a robot and its potential impact on culture-awareness, demonstrating how the proposed framework can enable culture-awareness, exploring this new frontier in social robotics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593970","Culture Aware Social Robots;Robot Perception;Multimodal Human-Robot Interaction;User Models","Robot sensing systems;Cultural differences;Bayes methods;Statistics;Indexes;Computational modeling","Bayes methods;belief networks;decision making;human-robot interaction;pattern classification;pattern clustering;service robots;user modelling","human-robot interaction;extended Bayesian User Model;social robotics;culture-awareness;specific subtleties;highly accurate classification framework;share similar attributes;n-dimensional semantic attribute space;capture unitary attributes;Bayesian classifiers;robotic technologies;latest advances;heterogeneous information;unified representation;cultural attributes","","","16","","","","","IEEE","IEEE Conferences"
"Efficient State Estimation with Constrained Rao-Blackwellized Particle Filter","S. Li; S. Lyu; J. Trinkle","GE Global Research Center, Niskayuna, 1 Research Circle, NY, 12309, USA; University at Albany, SUNY, Faculty of Computer Science, Albany, NY, 12222, USA; Rensselaer Polytechnic Institute, Faculty of Computer Science, Troy, NY, 12180, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6682","6689","Due to the limitations of the robotic sensors, during a robotic manipulation task, the acquisition of the object's state can be unreliable and noisy. Combining an accurate model of multi-body dynamic system with Bayesian filtering methods has been shown to be able to filter out noise from the object's observed states. However, efficiency of these filtering methods suffers from samples that violate the physical constraints, e.g., no penetration constraint. In this paper, we propose a Rao-Blackwellized Particle Filter (RBPF) that samples the contact states and updates the object's poses using Kalman filters. This RBPF also enforces the physical constraints on the samples by solving a quadratic programming problem. By comparing our method with methods that does not consider physical constraints, we show that our proposed RBPF is not only able to estimate the object's states, e.g., poses, more accurately but also able to infer unobserved states, e.g., velocities, with higher precision.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594268","","Robot sensing systems;Mathematical model;Kalman filters;State estimation;Dynamics","Bayes methods;Kalman filters;manipulators;particle filtering (numerical methods);quadratic programming;state estimation","RBPF;contact states;Kalman filters;constrained Rao-Blackwellized Particle Filter;robotic sensors;robotic manipulation task;multibody dynamic system;Bayesian filtering methods;state estimation;quadratic programming problem","","","13","","","","","IEEE","IEEE Conferences"
"Learning Trajectories for Real- Time Optimal Control of Quadrotors","G. Tang; W. Sun; K. Hauser","department of Mechanical Engineering and Material Science, Duke University, Durham, NC, 27708, USA; department of Mechanical Engineering and Material Science, Duke University, Durham, NC, 27708, USA; Departments of Electrical and Computer Engineering and of Mechanical Engineering and Materials Science, Duke University, Durham, NC, 27708, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3620","3625","Nonlinear optimal control problems are challenging to solve efficiently due to non-convexity. This paper introduces a trajectory optimization approach that achieves realtime performance by combining machine learning to predict optimal trajectories with refinement by quadratic optimization. First, a library of optimal trajectories is calculated offline and used to train a neural network. Online, the neural network predicts a trajectory for a novel initial state and cost function, and this prediction is further optimized by a sparse quadratic programming solver. We apply this approach to a fly-to-target movement problem for an indoor quadrotor. Experiments demonstrate that the technique calculates near-optimal trajectories in a few milliseconds, and generates agile movement that can be tracked more accurately than existing methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593536","","Trajectory;Neural networks;Optimal control;Training;Cost function;Real-time systems","control engineering computing;helicopters;learning (artificial intelligence);neurocontrollers;nonlinear control systems;optimal control;quadratic programming","optimal trajectories;learning trajectories;quadrotors;agile movement;machine learning;trajectory optimization approach;nonlinear optimal control problems;fly-to-target movement problem;sparse quadratic programming solver;neural network;quadratic optimization","","","18","","","","","IEEE","IEEE Conferences"
"RG-Trees: Trajectory-Free Feedback Motion Planning Using Sparse Random Reference Governor Trees","F. Golbol; M. M. Ankarali; A. Saranli","Middle East Technical University, Department of Electrical and Electronics Engineering, Ankara, 06800, Turkey; Middle East Technical University, Department of Electrical and Electronics Engineering, Ankara, 06800, Turkey; Middle East Technical University, Department of Electrical and Electronics Engineering, Ankara, 06800, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6506","6511","Sampling based methods resulted in feasible and effective motion planning algorithms for high dimensional configuration spaces and complex environments. A vast majority of such algorithms as well as their application rely on generating a set of open-loop trajectories first, which are then tracked by feedback control policies. However, controlling a dynamic robot to follow the planned path, while respecting the spatial constraints originating from the obstacles is still a challenging problem. There are some studies which combine statistical sampling techniques and feedback control methods which address this challenge using different approaches. From the feedback control theory perspective, Reference Governors proved to be a useful framework for constraint enforcement. Very recently, Arslan and Koditschek (2017) introduced a feedback motion planner that utilizes Reference Governors that provably solves the motion planning problem in simplified spherical worlds. In this context, here we propose a “trajectory-free” novel feedback motion planning algorithm which combines the two ideas: random trees and reference governors. Random tree part of the algorithm generates a collision-free region as a set of connected simple polygonal regions. Then, reference governor part navigates the dynamic robot from one region to the adjacent region in the tree structure, ensuring it stays inside the current region and asymptotically reaches to the connected region. Eventually, our algorithm robustly routes the robot from the start location to the goal location without collision. We demonstrate the validity and feasibility of the algorithm on simulation studies.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594447","","Robots;Heuristic algorithms;Planning;Collision avoidance;Dynamics;Aerospace electronics;Navigation","collision avoidance;feedback;mobile robots;motion control;robust control;sampling methods;trajectory control;trees (mathematics)","trajectory-free feedback motion planning;high dimensional configuration spaces;complex environments;open-loop trajectories;feedback control policies;dynamic robot;planned path;spatial constraints;statistical sampling techniques;control methods;feedback control theory perspective;constraint enforcement;feedback motion planner;trajectory-free novel feedback motion planning algorithm;random trees;tree part;collision-free region;connected simple polygonal regions;reference governor part;tree structure;RG-trees;sparse random reference governor;sampling based methods","","","22","","","","","IEEE","IEEE Conferences"
"Towards Autonomous Auto Calibration of Unregistered RGB-D Setups: The Benefit of Plane Priors","G. Halmetschlager-Funek; J. Prankl; M. Vincze","ACIN, Faculty of Electrical Engineering, TU Wien, V4RLab, Vienna, 1040, Austria; ACIN, Faculty of Electrical Engineering, TU Wien, V4RLab, Vienna, 1040, Austria; ACIN, Faculty of Electrical Engineering, TU Wien, V4RLab, Vienna, 1040, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5547","5554","In the last few years novel color and depth (RGB-D) sensors have greatly pushed robot perception. To enable a precise pixel-wise fusion of color and depth information good calibration is needed. The calibration determines the intrinsic parameters, the extrinsic parameters, and corrects for depth errors. While classic calibration approaches involve a dedicated calibration target and a trained expert, the autonomous calibration of such camera systems for robots operating in unknown environments is still an open problem. It demands for robust methods that do not need an expert to set up or tune the algorithm. Hence, we present a robust calibration algorithm that utilizes structure from motion (SfM) reconstructions as a calibration target and incorporates plane priors in the optimization to improve the convergence behavior and improve the calibration robustness. We evaluate our method against the state of the art performing over 300 experiments on ten different datasets, and show a significant improvement of the calibration accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593715","","Calibration;Cameras;Sensors;Robots;Image color analysis;Image reconstruction;Three-dimensional displays","calibration;cameras;image colour analysis;image reconstruction;optimisation;spatial variables measurement","autonomous autocalibration;color sensor;depth sensor;camera system;structure from motion reconstructions;SfM reconstructions;optimization;robust calibration algorithm;robot perception;unregistered RGB-D setups","","","19","","","","","IEEE","IEEE Conferences"
"Robust and Adaptive Robot Self-Assembly Based on Vascular Morphogenesis","M. Divband Soorati; J. Ghofrani; P. Zahadat; H. Hamann","University of Lübeck, Institute of Computer Engineering, Germany; Department of Computer Science and Mathematics, Dresden University of Applied Sciences, Germany; Department of Zoology, Artificial Life Lab, Karl-Franzens University Graz, Austria; University of Lübeck, Institute of Computer Engineering, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4282","4287","Self-assembly is the aggregation of simple parts into complex patterns as frequently observed in nature. Following this inspiration, creating programmable systems of self-assembly that achieve similar complexity and robustness with robots is challenging. As a role model we pick the growth of natural plants that adapts to environmental conditions and is robust enough to withstand disturbances such as changes due to dynamic environments and cut parts. We program a robot swarm to self-assemble into tree-like shapes and to adapt efficiently to the environment. Our approach is inspired by the vascular morphogenesis of plants, the patterned formation of vascular tissue to transport fluids and nutrients internally. The aggregated robots establish an internal network of resource sharing, allowing them to make rational decisions collectively about where to add and where to remove robots. As a result, the growth is adaptive to an environmental feature (here, light) and robust to changes in a dynamic environment. The robot swarm is able to self-repair by regrowing lost parts. We successfully validate and benchmark our approach in a number of robot swarm experiments showing adaptivity, robustness, and self-repair.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594093","","Legged locomotion;Robot sensing systems;Collision avoidance;Self-assembly;Shape;Resource management","mobile robots;multi-robot systems;self-adjusting systems;self-assembly;trees (mathematics)","complex patterns;programmable systems;similar complexity;role model;natural plants;environmental conditions;dynamic environments;patterned formation;vascular tissue;aggregated robots;dynamic environment;robot swarm experiments","","","18","","","","","IEEE","IEEE Conferences"
"A Partially Filled Jamming Gripper for Underwater Recovery of Objects Resting on Soft Surfaces","S. Licht; E. Collins; G. Badlissi; D. Rizzo","University of Rhode Island Narragansett, Department of Ocean Engineering, Rhode, 02882, Island; University of Rhode Island Narragansett, Department of Ocean Engineering, Rhode, 02882, Island; University of Rhode Island Narragansett, Department of Ocean Engineering, Rhode, 02882, Island; University of Rhode Island Narragansett, Department of Ocean Engineering, Rhode, 02882, Island","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6461","6468","In this paper we demonstrate a universal jamming gripper with a partially filled membrane that can pick up submerged objects resting on soft substrates. Jamming grippers take advantage of the phenomenon of particle jamming to control the compliance of an end effector membrane. Changes in internal membrane pressure are used to transition the membrane between hard and soft states. The effort was motivated by the need for tools to sample artifacts on deep sea shipwrecks, which are often found resting on waterlogged timbers, or partially buried in fine, loose sediment. Limiting downward force protects the target, and reduces the likelihood that it will be pushed down in to the substrate, which could lead to a failed grasp. In benchtop tests, the downward force, and the ratio of maximum lifting force to downward force, are shown to be strongly dependent on the initial volume of particles and fluid in the gripper membrane. The gripper achieves lifting forces 6.7 times the downward force on targets with high aspect ratios. Experiments in a fresh water tank demonstrate the ability to grasp objects resting on soft sediment, and compliant foam. Finally, experiments at sea demonstrate that the end effector functions at depths of more than 1000m seawater, successfully grasping a range of irregular objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593361","soft robotics;universal jamming grippers;marine archeology","Grippers;Jamming;Force;Manifolds;Solids;Substrates;Sediments","compliance control;end effectors;grippers;seawater;sediments;underwater vehicles","partially filled jamming gripper;soft surfaces;partially filled membrane;submerged objects;soft substrates;jamming grippers;particle jamming;end effector membrane;internal membrane pressure;deep sea shipwrecks;downward force;maximum lifting force;gripper membrane;soft sediment;irregular objects;grasping;fresh water tank experiment;seawater;compliant foam;fine loose sediment;waterlogged timbers;compliance control;underwater object recovery","","","8","","","","","IEEE","IEEE Conferences"
"Exploration and Reconstruction of Unknown Objects using a Novel Normal and Contact Sensor","S. Ottenhaus; P. Weiner; L. Kaul; A. Tulbure; T. Asfour","Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1614","1620","Tactile sensing of surface normals is essential for exploration of unknown objects. Many tactile sensors have been developed for contact measurement. However, few of these sensors provide surface orientation, and only up to a limited degree. This paper presents a novel contact and surface orientation sensor concept and its application for surface reconstruction of unknown objects. The sensor is comprised of an Inertial Measurement Unit (IMU) and a pressure sensor to accurately estimate the surface orientation in a wide range, while at the same time measuring contact force. We describe the developed sensor prototype and evaluate its performance regarding contact detection capability and normal estimation accuracy. We use this to reconstruct the surface of unknown objects using the humanoid robot ARMAR-III resulting in a mean reconstruction accuracy of 3.6 mm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594272","","Surface reconstruction;Surface treatment;Tactile sensors;Force","humanoid robots;manipulators;object recognition;pressure sensors;tactile sensors","tactile sensors;contact measurement;surface orientation;surface reconstruction;unknown objects;pressure sensor;contact force;developed sensor prototype;contact detection capability;normal estimation accuracy;contact sensor;surface normals;inertial measurement unit;IMU;mean reconstruction accuracy","","","45","","","","","IEEE","IEEE Conferences"
"Robust Optimization-Based Calculation of Invariant Trajectory Representations for Point and Rigid-body Motion","M. Vochten; T. De Laet; J. De Schutter","KU Leuven & Flanders Make, Department of Mechanical Engineering, Leuven, 3001, Belgium; KU Leuven, Faculty of Engineering Science, Leuven, 3001, Belgium; KU Leuven & Flanders Make, Department of Mechanical Engineering, Leuven, 3001, Belgium","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5598","5605","Invariant representations of demonstrated motion trajectories provide context-independent motion models that can be used in motion recognition and generalization applications such as robot programming by demonstration. In practice, the use of invariant representations is still limited because their numerical calculation from a demonstrated trajectory is complicated by sensitivity to measurement noise and singularities, yielding inaccurate invariant functions that do not correspond well with the original trajectory. This paper improves the calculation of invariant representations for point and rigid-body motions by reformulating their calculation as an optimization problem that minimizes the error between the trajectory reconstructed from the invariant representation and the measured trajectory. Robustness against noise and singularities is ensured through the addition of regularization terms on the invariants. Simulations and real motion experiments show that the accuracy of the calculated invariant representations greatly improves with respect to standard smoothing methods. These results encourage future developments of motion recognition and generalization applications based on invariant trajectory representations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593540","","Trajectory;Sensitivity;Smoothing methods;Context modeling;Fasteners;Noise measurement;Programming","image motion analysis;image recognition;image reconstruction;image representation;optimisation;smoothing methods","standard smoothing methods;measurement noise;motion trajectories;robust optimization-based calculation;invariant trajectory representations;motion experiments;motion recognition;context-independent motion models;rigid-body motion","","","16","","","","","IEEE","IEEE Conferences"
"Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum Robot in SE(3)","R. Grassmann; V. Modes; J. Burgner-Kahrs","Faculty of Mechanical Engineering, Leibniz Universität Hannover, Laboratory for Continuum Robotics, Hanover, 30167, Germany; Faculty of Mechanical Engineering, Leibniz Universität Hannover, Laboratory for Continuum Robotics, Hanover, 30167, Germany; Faculty of Mechanical Engineering, Leibniz Universität Hannover, Laboratory for Continuum Robotics, Hanover, 30167, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5125","5132","Recent physics-based models of concentric tube continuum robots are able to describe pose of the tip, given the preformed translation and rotation in joint space of the robot. However, such model-based approaches are associated with high computational load and highly non-linear modeling effort. A data-driven approach for computationally fast estimation of the kinematics without requiring the knowledge and the uncertainties in the physics-based model would be an asset. This paper introduces an approach to solve the forward kinematics as well as the inverse kinematics of concentric tube continuum robots with 6-DOF in three dimensional space SE(3). Two artificial neural networks with ReLU (rectified linear unit) activation functions are designed in order to approximate the respective kinematics. Measured data from a robot prototype are used in order to train, validate, and test the proposed approach. We introduce a representation of the rotatory joints by trigonometric functions that improves the accuracy of the approximation. The results with experimental measurements show higher accuracy for the forward kinematics compared to the state of the art mechanics modeling. The tip error is less then 2.3 mm w.r.t. position (1 % of total robot length) and 1.1° w.r.t. orientation. The single artificial neural network for the inverse kinematics approximation achieves a translation and rotation actuator error of 4.0 mm and 8.3 0, respectively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594451","","Electron tubes;Robots;Kinematics;Neural networks;Quaternions;Computational modeling;Load modeling","actuators;approximation theory;neural nets;position control;robot kinematics","forward kinematics;concentric tube continuum robot;high computational load;nonlinear modeling effort;data-driven approach;physics-based model;robot prototype;inverse kinematics approximation;artificial neural network;ReLU;rectified linear unit;rotation actuator error;trigonometric function;mechanics modeling;position control","","","22","","","","","IEEE","IEEE Conferences"
"A Bio-inspired Reinforcement Learning Rule to Optimise Dynamical Neural Networks for Robot Control","T. Wei; B. Webb","Insect Robotics Group, Institute of Perception, Action and Behaviour, School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; Institute of Perception, Action and Behaviour, School of Informatics, University of Edinburgh, Edinburgh, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","556","561","Most approaches for optimisation of neural networks are based on variants of back-propagation. This requires the network to be time invariant and differentiable; neural networks with dynamics are thus generally outside the scope of these methods. Biological neural circuits are highly dynamic yet clearly able to support learning. We propose a reinforcement learning approach inspired by the mechanisms and dynamics of biological synapses. The network weights undergo spontaneous fluctuations, and a reward signal modulates the centre and amplitude of fluctuations to converge to a desired network behaviour. We test the new learning rule on a 2D bipedal walking simulation, using a control system that combines a recurrent neural network, a bio-inspired central pattern generator layer and proportional-integral control, and demonstrate the first successful solution to this benchmark task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594017","","Neurons;Robots;Synapses;Oscillators;Task analysis;Biological neural networks","humanoid robots;learning (artificial intelligence);legged locomotion;motion control;neurocontrollers;recurrent neural nets","back-propagation;2D bipedal walking simulation;biological neural circuits;robot control;optimise dynamical neural networks;bio-inspired reinforcement;bio-inspired central pattern generator layer;recurrent neural network;learning rule;network weights;biological synapses;reinforcement learning approach","","","18","","","","","IEEE","IEEE Conferences"
"Robotic Sewing and Knot Tying for Personalized Stent Graft Manufacturing","Y. Hu; L. Zhang; W. Li; G. Yang","The Hamlyn Centre for Robotic Surgery, Institute of Global Health Innovation, Imperial College London, SW7 2AZ, UK; The Hamlyn Centre for Robotic Surgery, Institute of Global Health Innovation, Imperial College London, SW7 2AZ, UK; The Hamlyn Centre for Robotic Surgery, Institute of Global Health Innovation, Imperial College London, SW7 2AZ, UK; The Hamlyn Centre for Robotic Surgery, Institute of Global Health Innovation, Imperial College London, SW7 2AZ, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","754","760","This paper presents a versatile robotic system for sewing a 3D structured object. Leveraging on using a customized robotic sewing device and closed-loop visual servoing control, an all-in-one solution for sewing personalized stent graft is demonstrated. Stitch size planning and automated knot tying are proposed as two key functions of the system. By using effective stitch size planning, sub-millimetre sewing accuracy is achieved for stitch sizes ranging from 2mm to 5mm. In addition, a thread manipulator for thread management and tension control is also proposed to perform successive knot tying to secure each stitch. Detailed laboratory experiments have been performed to evaluate the proposed instruments and allied algorithms. The proposed framework can be generalised to a wide range of applications including 3D industrial sewing, as well as transferred to other clinical areas such as surgical suturing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594021","","Needles;Robot kinematics;Cameras;Yarn;Robot vision systems","closed loop systems;medical robotics;robot vision;servomechanisms;stents;surgery;textile technology;visual servoing","robotic system;stitch size planning;3D industrial sewing;successive knot;tension control;thread management;thread manipulator;stitch sizes;sewing accuracy;automated knot tying;closed-loop visual servoing control;customized robotic sewing device;3D structured object;personalized stent graft manufacturing;size 2.0 mm to 5.0 mm","","1","27","","","","","IEEE","IEEE Conferences"
"Light-Weight Object Detection and Decision Making via Approximate Computing in Resource-Constrained Mobile Robots","P. Pandey; Q. He; D. Pompili; R. Tron","Rutgers University-New, Department of Electrical and Computer Engineering, Brunswick, NJ; Boston University, Department of Mechanical Engineering, MA; Rutgers University-New, Department of Electrical and Computer Engineering, Brunswick, NJ; Boston University, Department of Mechanical Engineering, MA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6776","6781","Most of the current solutions for autonomous flights in indoor environments rely on purely geometric maps (e.g., point clouds). There has been, however, a growing interest in supplementing such maps with semantic information (e.g., object detections) using computer vision algorithms. Unfortunately, there is a disconnect between the relatively heavy computational requirements of these computer vision solutions, and the limited computation capacity available on mobile autonomous platforms. In this paper, we propose to bridge this gap with a novel Markov Decision Process framework that adapts the parameters of the vision algorithms to the incoming video data rather than fixing them a priori. As a concrete example, we test our framework on a object detection and tracking task, showing significant benefits in terms of energy consumption without considerable loss in accuracy, using a combination of publicly available and novel datasets.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594200","","Object detection;Proposals;Roads;Support vector machines;Computer vision;Cameras","decision making;Markov processes;mobile robots;object detection;path planning;robot vision","light-weight object detection;approximate computing;resource-constrained mobile robots;autonomous flights;indoor environments;point clouds;computer vision algorithms;mobile autonomous platforms;video data;decision making;geometric maps;Markov decision process framework","","","18","","","","","IEEE","IEEE Conferences"
"A Cable-Driven Redundant Spatial Manipulator with Improved Stiffness and Load Capacity","T. Liu; Z. Mu; H. Wang; W. Xu; Y. Li","Harbin Institute of Technology, School of Mechanical Engineering and Automation, Shenzhen, 518055, China; Harbin Institute of Technology, School of Mechanical Engineering and Automation, Shenzhen, 518055, China; Harbin Institute of Technology, School of Mechanical Engineering and Automation, Shenzhen, 518055, China; Harbin Institute of Technology, School of Mechanical Engineering and Automation, Shenzhen, 518055, China; Hong Kong Polytechnic University, Department of Industrial and Systems Engineering, Hong Kong, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6628","6633","With a light and slender body, a cable-driven redundant spatial manipulator (CRSM) has flexible manipulability and high maneuverability in confined environment. However, compared with revolute rigid manipulators, such type of manipulators generally has low stiffness and weak load capacity. In this paper, we propose a new mechanism design to improve the stiffness and load capacity without sacrificing the manipulator dexterity and the end-effector accuracy. The manipulator is composed of 3 active-passive-linkage segments and 1 active tool end-effector. Each active-passive segment has 2 degrees of freedom (DOFs) driven by three evenly distributed cables. Pretension mechanism and linkage cables are designed to keep strict equal angles of adjacent joints. A separable control box, which contains all the motors and cable transmission mechanisms is also designed with a quick release-and-lock mechanism. Therefore, the robotic arm can be easily removed and installed. Based on the equal angle characteristic, kinematic equations of manipulator are established with Denavit-Hartenberg (D-H) method and the Jacobian matrix is also simplified. Further analysis of the workspace supplies the guidance for the task design and motion planning. Finally, a prototype system is developed to perform the stiffness and load capacity experiments. Experimental results show that the developed CRSM has relatively high stiffness and load capacity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593679","Cable-driven;Redundant manipulator;Stiffness;Load capacity;Kinematic","Couplings;Kinematics;Springs;Task analysis;End effectors","control system synthesis;dexterous manipulators;end effectors;flexible manipulators;Jacobian matrices;manipulator kinematics;motion control;path planning;redundant manipulators","cable transmission mechanisms;load capacity experiments;relatively high stiffness;cable-driven redundant spatial manipulator;flexible manipulability;revolute rigid manipulators;mechanism design;manipulator dexterity;end-effector accuracy;active-passive-linkage segments;active-passive segment;manipulator kinematic equations;motion planning;Jacobian matrix;Denavit-Hartenberg method;D-H method;CRSM","","","20","","","","","IEEE","IEEE Conferences"
"The HRC Model Set for Human-Robot Collaboration Research","S. Zeylikman; S. Widder; A. Roncone; O. Mangin; B. Scassellati","Center for Engineering, Innovation and Design, Yale University, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA; Computer Science Department, Yale University, Social Robotics Lab, New Haven, CT, 06511, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1845","1852","In this paper, we present a model set for designing human-robot collaboration (HRC) experiments. It targets a common scenario in HRC, which is the collaborative assembly of furniture, and it consists of a combination of standard components and custom designs. With this work, we aim at reducing the amount of work required to set up and reproduce HRC experiments, and we provide a unified framework to facilitate the comparison and integration of contributions to the field. The model set is designed to be modular, extendable, and easy to distribute. Importantly, it covers the majority of relevant research in HRC, and it allows tuning of a number of experimental variables that are particularly valuable to the field. Additionally, we provide a set of software libraries for perception, control and interaction, with the goal of encouraging other researchers to proactively contribute to our work.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593858","","Robots;Task analysis;Collaboration;Robotic assembly;Complexity theory;Standards","human-robot interaction","HRC model set;human-robot collaboration research;human-robot collaboration experiments;HRC experiments","","","50","","","","","IEEE","IEEE Conferences"
"Map-based Deep Imitation Learning for Obstacle Avoidance","Y. Liu; A. Xu; Z. Chen","Segway Robotics Inc., Beijing, 100192, China; Tsinghua University, Department of Electronic Engineering, Beijing, 100084, China; Segway Robotics Inc., Beijing, 100192, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8644","8649","Making an optimal decision to avoid obstacles while heading to the goal is one of the fundamental challenges for mobile robots equipped with limited computational resources. In this paper, we present a deep imitation learning algorithm that develops a computationally efficient obstacle avoidance policy based on egocentric local occupancy maps. The trained model embedded with a variant of the value iteration networks is able to provide near-optimal continuous action commands through fast feed-forward inferences and generalize well to unseen planning-based scenarios. To improve the policy robustness, we augment the training data set with artificially generated maps, which effectively alleviates the shortage of catastrophic samples in normal demonstrations. Extensive experiments on a Segway robot show the effectiveness of the proposed approach in terms of solution optimality, robustness as well as computation time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593683","","Collision avoidance;Robot kinematics;Mobile robots;Training;Neural networks;Trajectory","collision avoidance;decision making;inference mechanisms;learning (artificial intelligence);mobile robots;optimisation;robot vision;SLAM (robots)","mobile robots;deep imitation learning algorithm;egocentric local occupancy maps;fast feed-forward inferences;policy robustness;optimal decision making;obstacle avoidance policy;map-based deep imitation learning;value iteration networks;near-optimal continuous action commands;planning-based scenarios","","","20","","","","","IEEE","IEEE Conferences"
"Kitting in the Wild through Online Domain Adaptation","M. Mancini; H. Karaoguz; E. Ricci; P. Jensfelt; B. Caputo","Sapienza University of Rome, Rome, Italy; KTH Royal Institute of Technology, Stockholm, Sweden; Fondazione Bruno Kessler, Trento, Italy; KTH Royal Institute of Technology, Stockholm, Sweden; Sapienza University of Rome, Rome, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1103","1109","Technological developments call for increasing perception and action capabilities of robots. Among other skills, vision systems that can adapt to any possible change in the working conditions are needed. Since these conditions are unpredictable, we need benchmarks which allow to assess the generalization and robustness capabilities of our visual recognition algorithms. In this work we focus on robotic kitting in unconstrained scenarios. As a first contribution, we present a new visual dataset for the kitting task. Differently from standard object recognition datasets, we provide images of the same objects acquired under various conditions where camera, illumination and background are changed. This novel dataset allows for testing the robustness of robot visual recognition algorithms to a series of different domain shifts both in isolation and unified. Our second contribution is a novel online adaptation algorithm for deep models, based on batch-normalization layers, which allows to continuously adapt a model to the current working conditions. Differently from standard domain adaptation algorithms, it does not require any image from the target domain at training time. We benchmark the performance of the algorithm on the proposed dataset, showing its capability to fill the gap between the performances of a standard architecture and its counterpart adapted offline to the given target domain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593862","","Robots;Adaptation models;Task analysis;Training;Data models;Visualization;Standards","learning (artificial intelligence);object recognition;robot vision;visual perception","online adaptation algorithm;standard domain adaptation algorithms;batch-normalization layers;deep models;robot visual recognition algorithms;standard object recognition datasets;visual dataset;robotic kitting;vision systems;online domain adaptation","","","39","","","","","IEEE","IEEE Conferences"
"Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids","K. Kawaharazuka; S. Makino; M. Kawamura; A. Fujii; Y. Asano; K. Okada; M. Inaba","Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1711","1717","Tendon-driven musculoskeletal humanoids have many benefits in terms of the flexible spine, multiple degrees of freedom, and variable stiffness. At the same time, because of its body complexity, there are problems in controllability. First, due to the large difference between the actual robot and its geometric model, it cannot move as intended and large internal muscle tension may emerge. Second, movements which do not appear as changes in muscle lengths may emerge, because of the muscle route changes caused by softness of body tissue. To solve these problems, we construct two models: ideal joint-muscle model and muscle-route change model, using a neural network. We initialize these models by a man-made geometric model and update them online using the sensor information of the actual robot. We validate that the tendon-driven musculoskeletal humanoid Kengoro is able to obtain a correct self-body image through several experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593428","","Muscles;Robot sensing systems;Humanoid robots;Solid modeling;Training","biomechanics;bone;data acquisition;humanoid robots;muscle;robot vision","body tissue;joint-muscle model;muscle-route change model;geometric model;tendon-driven musculoskeletal humanoid Kengoro;muscle routes;tendon-driven musculoskeletal humanoids;flexible spine;body complexity;muscle lengths;muscle route changes;internal muscle tension;online self-body image acquisition;multiple degrees of freedom;controllability;neural network","","1","10","","","","","IEEE","IEEE Conferences"
"Smooth Point-to-Point Trajectory Planning in $SE$ (3)with Self-Collision and Joint Constraints Avoidance","R. Grassmann; L. Johannsmeier; S. Haddadin","Faculty of Mechanical Engineering, Gottfried Wilhelm Leibniz Universität Hannover, Laboratory for Continuum Robotics, Hannover, 30167, Germany; Chair of Robotics Science and Systems Intelligence, Department of Electrical and Computer Engineering, Technical University of Munich, School of Robotics and Machine Intelligence, Munich, 80797, Germany; Chair of Robotics Science and Systems Intelligence, Department of Electrical and Computer Engineering, Technical University of Munich, School of Robotics and Machine Intelligence, Munich, 80797, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper we introduce a novel point-to-point trajectory planner for serial robotic structures that combines the ability to avoid self-collisions and to respect motion constraints, while complying with the requirement of being C<sup>4</sup> continuous. The latter property makes our approach also suited for 4th order dynamics flexible joint robots, which gained significant practical relevance recently. In particular, we address the problem of generating a smooth, kinematically nearly time-optimal SE(3) trajectory while simultaneously avoiding potential collisions of the robot end-effector with its base as well as respecting the Cartesian unreachable states induced by the joint limits of the proximal kinematic structure.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594339","","Trajectory;End effectors;Interpolation;Planning;Collision avoidance","collision avoidance;end effectors;manipulator dynamics;manipulator kinematics","smooth point-to-point trajectory planning;joint constraints avoidance;serial robotic structures;time-optimal SE(3) trajectory;robot end-effector;4th order dynamics flexible joint robots;self-collision avoidance;point-to-point trajectory planner","","","22","","","","","IEEE","IEEE Conferences"
"A Comparison of Assistive Methods for Suturing in MIRS","G. A. Fontanelli; G. Yang; B. Siciliano","University of Naples Federico II, Interdepartmental Center for Advances in Robotic Surgery (ICAROS); Imperial College London, Hamlyn Centre for Robotic Surgery; University of Naples Federico II, Interdepartmental Center for Advances in Robotic Surgery (ICAROS)","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4389","4395","In Minimally Invasive Robotic Surgery (MIRS) a robot is interposed between the surgeon and the surgical site to increase the precision, dexterity, and to reduce surgeon's effort and cognitive load with respect to the standard laparoscopic interventions. However, the modern robotic systems for MIRS are still based on the traditional telemanipulation paradigm, e.g. the robot behaviour is fully under surgeon's control, and no autonomy or assistance is implemented. In this work, supervised and shared controllers have been developed in a vision-free, human-in-the-Ioop, control framework to help surgeon during a surgical suturing procedure. Experiments conducted on the da Vinci Research Kit robot proves the effectiveness of the method indicating also the guidelines for improving results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593607","","Robots;Needles;Surgery;Force;Trajectory;Force measurement;Task analysis","dexterous manipulators;medical robotics;surgery;telerobotics","human-in-the-Ioop;vision-free;telemanipulation paradigm;surgeons control;minimally invasive robotic surgery;robotic systems;laparoscopic interventions;assistive methods;da Vinci Research Kit robot;robot behaviour;MIRS;cognitive load;dexterity;surgical site","","","18","","","","","IEEE","IEEE Conferences"
"Appearance-Based Along-Route Localization for Planetary Missions","I. Grixa; P. Schulz; W. Stürzl; R. Triebel","German Aerospace Center (DLR), The Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), The Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), The Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), The Institute of Robotics and Mechatronics, Wessling, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6327","6334","We propose an appearance-based along-route localization algorithm that relies on robust place recognition by matching image sequences instead of individual frames. Our approach extends state of the art place recognition framework SeqSLAM in several aspects to realize real-time localization along routes for autonomous navigation. First, our method is online in that we only rely on the recently observed image frames. Second, we provide a homing mechanism based on rotations computed from frame matches. And third, we use a more flexible mechanism to search for matching locations, not restricting the search to straight lines in the cost matrix as in SeqSLAM, but allowing for a wide variety of route traversal conditions such as varying velocities or rotational and translational viewpoint differences. We investigate different image preprocessing steps as well as image similarity metrics wrt. their influence on illumination and viewpoint invariance for a more robust place recognition. On a new challenging dataset, recorded in real world experiments with a planetary rover, in the course of a Moon-analogue mission on Sicily's Mount Etna, we show the feasibility of our direct, sequence-based approach to along-route localization.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594518","mobile robotics;field robotics;place-recognition;autonomous route navigation","Navigation;Lighting;Cameras;Moon;Simultaneous localization and mapping;Visualization","image matching;image registration;image sequences;mobile robots;object recognition;planetary rovers;robot vision;SLAM (robots)","image preprocessing steps;recognition framework SeqSLAM;appearance-based along-route localization algorithm;planetary missions;direct sequence-based approach;Moon-analogue mission;planetary rover;image similarity metrics wrt;translational viewpoint differences;rotational viewpoint differences;route traversal conditions;matching locations;flexible mechanism;frame matches;homing mechanism;autonomous navigation;real-time localization;individual frames;image sequences;robust place recognition","","","30","","","","","IEEE","IEEE Conferences"
"Kernel-Based Human-Dynamics Inversion for Precision Robot Motion-Primitives","R. B. Warrier; S. Devasia","Department of Mechanical Engineering, University of Washington, Seattle, WA, 98195, USA; Faculty of Mechanical Engineering, University of Washington, Seattle, WA, 98195, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6037","6042","Learning motion primitives from demonstration requires the human demonstrator to effectively relay the task intent to the robot controller. When the task intent is not reflected sufficiently by the demonstration, multiple iterations are required to recover the underlying intent of the demonstrations. However, a large number of iterations can be expensive and might not be practical for each new task. A challenge is that human-in-the-loop demonstrations can be affected by the human motor dynamics (e.g., from visual observation to hand motion), which can lead to differences between the demonstration and intent. The main contribution of this article is to correct for the human motor dynamics and infer the intended action (motion primitive) from the human demonstrations. The proposed approach uses a kernel-based regression approach to learn the inverse human-dynamics response. These models are then used to correct for human-motor-dynamics and infer the intent of the human-in-the-loop demonstrator. Experimental validation is performed with an assisted teleoperation setup where the underlying intent is specified using an augmented reality display. Results indicate that the proposed approach leads to more precise intent estimation as compared to the actual human demonstrations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594164","","Task analysis;Robots;Trajectory;Gaussian processes;Biological system modeling;Kernel;Estimation","augmented reality;iterative methods;learning (artificial intelligence);mobile robots;motion control;regression analysis;robot dynamics;robot programming;telerobotics","human motor dynamics;kernel-based regression approach;inverse human-dynamics response;human-in-the-loop demonstrator;kernel-based human-dynamics inversion;precision robot motion-primitives;human demonstrator;robot controller;multiple iterations;assisted teleoperation;augmented reality display","","","25","","","","","IEEE","IEEE Conferences"
"Friendly Motion Learning towards Sustainable Human Robot Interaction","S. Sato; H. Kamide; Y. Mae; M. Kojima; T. Arai","Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, 1–3 Machikaneyama, Toyonaka, Osaka, 560-8531, JAPAN; Department of Institute of Innovation for Future Society, Nagoya University, Nagoya, Japan; Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, 1–3 Machikaneyama, Toyonaka, Osaka, 560-8531, JAPAN; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, 5 South Zhongguancun Street, Haidian District, Beijing, 100081, CHINA; Global Alliance Lab., The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, 182-8585, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","848","853","For generating interactive behavior of robot to build a long-term relationship between humans and robots, we focus on the difference in familiarity of the human behaviors during conversation. It is difficult to extract interaction motion features correlated to such familiarity as a model in manual. Therefore, we use a machine learning technique: convolution neural network to learn and generate interaction behavior with different familiarity. In the evaluation experiment, we generated interaction behavior using a convolution neural network, which learned from the behaviors of friendship and unknown relationship, who have high and low familiarity respectively. We evaluated how much such interaction behavior affect the human impression by questionnaire survey.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593432","","Robots;Convolution;Neural networks;Decoding;Feature extraction;Mathematical model;Human-robot interaction","convolutional neural nets;human-robot interaction;learning (artificial intelligence)","sustainable human robot interaction;interaction motion features;machine learning technique;convolution neural network;interaction behavior;human impression;friendly motion learning","","","10","","","","","IEEE","IEEE Conferences"
"Atmospheric-Operable 3D Printed Walking Bio-Robot Powered by Muscle-Tissue of Earthworm* Resrach supported by Grants-in-Aid for Scientific Research from Japan Society for the Promotion of Science (JSPS).","Y. Yalikun; Y. Noguchi; N. Kamamichi; Y. Tanaka","RIKEN, Quantitative Biology Center (QBiC), Osaka, 1–3 Yamadaoka, Suita, 565-0871, Japan; Tokyo Denki University, Department of Robotics and Mechatronics, Tokyo, 5 Senju-asahi-cho, Adachi-ku, 120-8551, Japan; Tokyo Denki University, Department of Robotics and Mechatronics, Tokyo, 5 Senju-asahi-cho, Adachi-ku, 120-8551, Japan; RIKEN, Quantitative Biology Center (QBiC), Osaka, 1–3 Yamadaoka, Suita, 565-0871, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7595","7600","Muscle-tissue of earthworms is an excellent actuator due to its membranous structure, strong force, short response time, and controllability. In this paper, we first investigated the output force, control property including stimulation voltage, stimulation frequency, and duty. Secondly, we designed, fabricated, and demonstrated an atmospheric-operable walking robot by using a muscle-tissue of earthworms. The maximum walking speed was about 0.56 mm/s, which is about 2 times faster than other types of bio actuated walker. The maximum atmospheric driven time was over 45 minutes. These demonstrated results indicated that the muscle-tissue of earthworm has a high potential for using as a biological micro bio-actuator for multiple purposes.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594343","","Legged locomotion;Force;Muscles;Actuators;Strain measurement;Force measurement","microactuators;microrobots;mobile robots;muscle;robot dynamics","stimulation frequency;atmospheric-operable walking robot;maximum walking speed;bio actuated walker;biological microbio-actuator;grants-in-aid;output force;stimulation voltage;muscle-tissue of earthworm;Japan society;atmospheric-operable 3d printed walking bio-robot;control property","","","18","","","","","IEEE","IEEE Conferences"
"Bayesian-inferred Flexible Path Generation in Human-Robot Collaborative Networks","W. Bentz; D. Panagou","Department of Aerospace Engineering, University of Michigan, Ann Arbor; Department of Aerospace Engineering, University of Michigan, Ann Arbor","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1816","1822","This paper presents a novel method for generating the trajectory of a robot assisting a human in servicing a set of tasks embedded in a convex 2-D domain. This method makes use of Bayesian inference to predict human intent in task selection. Rather than following optimal trajectory towards a single task, the robot computes a set of potentially optimal tasks each weighted by the human's posterior probability and superimposes them into a cost function that is designed to minimize the weighted Euclidean distance relative to set. The effect is a flexible path human-robot collaborative network that is shown in simulation to complete all tasks in a given domain in less time than existing methods for a certain class of highly impulsive humans, i.e., humans that tend to randomly switch tasks at times generated by a Poisson counting process. The algorithm is also illustrated through an experimental demonstration.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593611","","Task analysis;Trajectory;Robot kinematics;Bayes methods;Collaboration;Cost function","Bayes methods;computational geometry;human-robot interaction;inference mechanisms;mobile robots;optimisation;path planning;position control;probability;stochastic processes","flexible path human-robot collaborative network;weighted Euclidean distance;potentially optimal tasks;single task;optimal trajectory;task selection;human intent;Bayesian inference;human-robot collaborative networks;Bayesian-inferred flexible path generation;highly impulsive humans","","","20","","","","","IEEE","IEEE Conferences"
"Guidance Laws for Partially-Observable Interception Based on Linear Covariance Analysis","J. Arneberg; E. Tal; S. Karaman","NA; Department of Aeronautics and Astronautics, Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, 02139, USA; Department of Aeronautics and Astronautics, Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4185","4191","We consider pursuit-evasion games in which the pursuer is tasked with intercepting the evader using only partial measurements. Motivated by the utilization of visual sensing on board the pursuer, we focus on the case when only bearing measurements are available to the pursuer. The resulting partially-observable interception problem is computationally challenging, and the separation principle does not hold in general. In this paper, we identify a set of maneuvers that improve observability, and we propose an algorithm that utilizes these maneuvers to move the pursuer so that the expected payoff of the differential game is maximized. The algorithm uses in-the-loop uncertainty propagation based on linear covariance analysis to assess the effect of the maneuvers. We evaluate the resulting guidance law in experiments involving a quadcopter in flight representing the pursuer, and a simulated evader.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593929","","Observability;Games;Uncertainty;Mathematical model;Vehicle dynamics;Extraterrestrial measurements;Task analysis","aerospace control;autonomous aerial vehicles;covariance analysis;differential games;optimal control","differential game;linear covariance analysis;maneuvers;resulting guidance law;guidance laws;pursuit-evasion games;partial measurements;visual sensing;bearing measurements;partially-observable interception problem;observability","","","24","","","","","IEEE","IEEE Conferences"
"Attitude Estimation from Polarimetric Cameras","M. Rastgoo; C. Demonceaux; R. Seulin; O. Morel","Le2i VIBOT ERL-CNRS, Université de Bourgogne Franche-Comté, 6000, France; Le2i VIBOT ERL-CNRS, Université de Bourgogne Franche-Comté, 6000, France; Le2i VIBOT ERL-CNRS, Université de Bourgogne Franche-Comté, 6000, France; Le2i VIBOT ERL-CNRS, Université de Bourgogne Franche-Comté, 6000, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8397","8403","In the robotic field, navigation and path planning applications benefit from a wide range of visual systems (e.g, perspective cameras, depth cameras, catadioptric cameras, etc.). In outdoor conditions, these systems capture information in which sky regions cover a major segment of the images acquired. However, sky regions are discarded and are not considered as visual cue in vision applications. In this paper, we propose to estimate attitude of Unmanned Aerial Vehicle (UAV) from sky information using a polarimetric camera. Theoretically, we provide a framework estimating the attitude from the skylight polarized patterns. We showcase this formulation on both simulated and real-word data sets which proved the benefit of using polarimetric sensors along with other visual sensors in robotic applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593575","","Cameras;Scattering;Robot vision systems;Sun;Estimation;Atmospheric modeling","attitude control;autonomous aerial vehicles;cameras;image sensors;mobile robots;path planning;robot vision","robotic applications;attitude estimation;polarimetric camera;path planning applications;visual systems;perspective cameras;depth cameras;catadioptric cameras;systems capture information;sky regions;visual cue;vision applications;sky information;polarimetric sensors;visual sensors;navigation applications;unmanned aerial vehicle","","","32","","","","","IEEE","IEEE Conferences"
"Robust Camera Pose Estimation via Consensus on Ray Bundle and Vector Field","H. Li; J. Zhao; J. Bazin; L. Luo; J. Wu; J. Yao","CVRS Lab, Wuhan University, China; ReadSense Ltd., Shanghai, China; KAIST, Computational Media Lab, South Korea; CVRS Lab, Wuhan University, China; CVRS Lab, Wuhan University, China; CVRS Lab, Wuhan University, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2624","2631","Estimating the camera pose requires point correspondences. However, in practice, correspondences are inevitably corrupted by outliers, which affects the pose estimation. We propose a general and accurate outlier removal strategy for robust camera pose estimation. The proposed strategy can detect outliers by leveraging the fact that only inliers comply with two effective consensuses, i.e., 3D ray bundle consensus and 2D vector field consensus. Our strategy has a nested structure. First, the outer module utilizes the 3D ray bundle consensus. We define the likelihood based on the probabilistic mixture model and maximize it by the expectation-maximization (EM) algorithm. The inlier probability of each correspondence and the camera pose are determined alternately. Second, the inner module exploits the 2D vector field consensus to refine the probabilities obtained by the outer module. The refinement based on the Bayesian rule facilitates the convergence of the outer module and improves the accuracy of the entire framework. Our strategy can be integrated into various existing camera pose estimation methods which are originally vulnerable to outliers. Experiments on both synthesized data and real images have shown that our approach outperforms state-of-the-art outlier rejection methods in terms of accuracy and robustness.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594486","","Cameras;Pose estimation;Two dimensional displays;Three-dimensional displays;Robot vision systems;Robustness;Probabilistic logic","Bayes methods;expectation-maximisation algorithm;image matching;pose estimation;probability;vectors","robust camera pose estimation;point correspondences;general outlier removal strategy;3D ray bundle consensus;2D vector field consensus;expectation-maximization algorithm;inlier probability;outlier rejection methods","","","23","","","","","IEEE","IEEE Conferences"
"A robust pose graph approach for city scale LiDAR mapping","S. Yang; X. Zhu; X. Nian; L. Feng; X. Qu; T. Mal","NA; NA; NA; NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1175","1182","This paper presents a method for reconstructing globally consistent 3D High-Definition (HD) maps at city scale. Current approaches for eliminating cumulative drift are mainly based on the pose graph optimization under the constraint of scan-matching factors. The misaligned edges in the graph may have negative impacts on the results. To address this problem and further handle inconsistency caused by multi-task acquisitions in urban environments, we introduce a refined structure of the factor graph considering systematical initialization bias, where the scan-matching factors are twice validated through a novel classifier and a robust optimization strategy. In addition, we incorporate a multi-hypothesis extended Kalman filter (MH-EKF) to remove dynamic objects. Quantitative experimental results demonstrate that the proposed method outperforms state-of-the-art techniques in terms of map quality.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593754","","Optimization;Three-dimensional displays;Laser radar;Global Positioning System;Feature extraction;Sensors;Urban areas","graph theory;image filtering;image reconstruction;Kalman filters;mobile robots;nonlinear filters;optical radar;optimisation;pose estimation;radar imaging;robot vision;SLAM (robots)","map quality;quantitative experimental results;robust optimization strategy;systematical initialization bias;factor graph;refined structure;urban environments;multitask acquisitions;scan-matching factors;graph optimization;cumulative drift;city scale LiDAR mapping;robust pose graph approach","","","41","","","","","IEEE","IEEE Conferences"
"Domain Randomization and Generative Models for Robotic Grasping","J. Tobin; L. Biewald; R. Duan; M. Andrychowicz; A. Handa; V. Kumar; B. McGrew; A. Ray; J. Schneider; P. Welinder; W. Zaremba; P. Abbeel","OpenAI; Weights and Biases, Inc; Embodied Intelligence; OpenAI; NVIDIA; UC Berkeley; OpenAI; OpenAI; OpenAI; OpenAI; OpenAI; UC Berkeley","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3482","3489","Deep learning-based robotic grasping has made significant progress thanks to algorithmic improvements and increased data availability. However, state-of-the-art models are often trained on as few as hundreds or thousands of unique object instances, and as a result generalization can be a challenge. In this work, we explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of domain randomization to object synthesis. We generate millions of unique, unrealistic procedurally generated objects, and train a deep neural network to perform grasp planning on these objects. Since the distribution of successful grasps for a given object can be highly multimodal, we propose an autoregressive grasp planning model that maps sensor inputs of a scene to a probability distribution over possible grasps. This model allows us to sample grasps efficiently at test time (or avoid sampling entirely). We evaluate our model architecture and data generation pipeline in simulation and the real world. We find we can achieve a >90% success rate on previously unseen realistic objects at test time in simulation despite having only been trained on random objects. We also demonstrate an 80% success rate on real-world grasp attempts despite having only been trained on random simulated objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593933","","Grasping;Training;Data models;Computational modeling;Robot sensing systems;Neural networks","grippers;learning (artificial intelligence);neural nets;planning (artificial intelligence);probability","domain randomization;generative models;deep learning-based robotic grasping;significant progress thanks;algorithmic improvements;increased data availability;state-of-the-art models;unique object instances;result generalization;novel data generation pipeline;deep neural network;successful grasps;autoregressive grasp planning model;probability distribution;possible grasps;sample grasps;test time;model architecture;unseen realistic objects;random objects;real-world grasp;random simulated objects","","","54","","","","","IEEE","IEEE Conferences"
"Coverage Control for Multi-Robot Teams with Heterogeneous Sensing Capabilities Using Limited Communications*","M. Santos; M. Egerstedt","Georgia Institute of Technology, School of Electrical and Computer Engineering, Atlanta, Georgia, USA; Georgia Institute of Technology, School of Electrical and Computer Engineering, Atlanta, Georgia, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5313","5319","This paper presents a coverage algorithm for multi-robot systems where the robots are equipped with qualitatively different sensing modalities. Unlike previous approaches to the problem of coverage for teams with heterogeneous sensing capabilities, in this paper the robots have access to information about their neighbors' specific sensor modalities. This knowledge affords the ability of ensuring that no robot is tasked with covering features in a region without the required sensing modalities. With this information, a robot can determine which of its neighbors it should coordinate with to cover the environmental features in a region while ignoring robots that are not equipped with that particular sensory capability. We derive a distributed control algorithm that allows the robots to move in a direction of descent relative to a novel locational cost, in order to minimize it. The performance of the algorithm is evaluated on a real robotic platform.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594056","","Robot sensing systems;Robot kinematics;Monitoring;Temperature sensors;Density functional theory","distributed control;mobile robots;multi-robot systems","multirobot teams;heterogeneous sensing capabilities;coverage algorithm;multirobot systems;qualitatively different sensing modalities;required sensing modalities;particular sensory capability;distributed control algorithm;robotic platform","","","18","","","","","IEEE","IEEE Conferences"
"Towards Minimal Intervention Control with Competing Constraints","Y. Huang; J. Silvério; D. G. Caldwell","Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","733","738","As many imitation learning algorithms focus on pure trajectory generation in either Cartesian space or joint space, the problem of considering competing trajectory constraints from both spaces still presents several challenges. In particular, when perturbations are applied to the robot, the underlying controller should take into account the importance of each space for the task execution, and compute the control effort accordingly. However, no such controller formulation exists. In this paper, we provide a minimal intervention control strategy that simultaneously addresses the problems of optimal control and competing constraints between Cartesian and joint spaces. In light of the inconsistency between Cartesian and joint constraints, we exploit the robot null space from an information-theory perspective so as to reduce the corresponding conflict. An optimal solution to the aforementioned controller is derived and furthermore a connection to the classical finite horizon linear quadratic regulator (LQR) is provided. Finally, a writing task in a simulated robot verifies the effectiveness of our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594235","","Aerospace electronics;Trajectory;Null space;Task analysis;Probabilistic logic;End effectors","control engineering computing;control system synthesis;learning (artificial intelligence);linear quadratic control;optimal control;robot programming;trajectory control","task execution;trajectory constraints;information-theory;finite horizon linear quadratic regulator;Cartesian space;pure trajectory generation;imitation learning algorithms;simulated robot;robot null space;optimal control;minimal intervention control strategy","","","23","","","","","IEEE","IEEE Conferences"
"Group emotion recognition strategies for entertainment robots","S. Cosentino; E. I. S. Randria; J. Lin; T. Pellegrini; S. Sessa; A. Takanishi","Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Université Paul Sabatier (Upssitech), Toulouse, France; Faculty of Science and Engineering, Waseda University, Tokyo, Japan; UPS, IRIT, Université de Toulouse, Toulouse, France; Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","813","818","In this paper, a system to determine the emotion of a group of people via facial expression analysis is proposed for the Waseda Entertainment Robots. General models and standard methods for emotion definition and recognition are briefly described, as well as strategies for computing the group global emotion, knowing the individual emotions of group members. This work is based on Ekman's extended “Big Six” emotional model, popular in Computer Science and Affective Computing. Emotion recognition via facial expression analysis is performed with a cloud-computing based solution, using Microsoft Azure Cognitive services. First, the performances of both the Face API to detect faces, and Emotion API, to compute emotion via face expression analysis, are tested. After that, a solution to compute the emotion of a group of people has been implemented and its performances compared to human perceptions. This work presents concepts and strategies which can be generalized for applications within the scope of assistive robotics and, more broadly, affective computing, wherever it will be necessary to determine the emotion of a group of people.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593503","humanoid robot;entertainment robot;assistive robotics;emotion recognition","Face;Emotion recognition;Entertainment industry;Cameras;Humanoid robots;Mood","affective computing;cloud computing;emotion recognition;face recognition;humanoid robots;mobile robots","face API;human perceptions;assistive robotics;emotion API;Microsoft Azure cognitive services;Waseda entertainment robots;computer science;Ekman's extended Big Six emotional model;group emotion recognition strategies;affective computing;cloud-computing based solution;facial expression analysis","","","36","","","","","IEEE","IEEE Conferences"
"Precise Localization in High-Definition Road Maps for Urban Regions","F. Poggenhans; N. O. Salscheider; C. Stiller","FZI Research Center for Information Technology, Karlsruhe, 76131, Germany; FZI Research Center for Information Technology, Karlsruhe, 76131, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology, Karlsruhe, 76131, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2167","2174","The future of automated driving in urban areas will most probably rely on highly accurate road maps. However, the necessary precision of a localization in such maps has so far only been reached using extra, sensor specific feature layers for localization. In this paper we want to show that it is possible to achieve sufficient accuracy without a separate localization layer. Instead, elements are used that are already contained in high-resolution road maps, such as markings and road borders. For this, we introduce a modular approach in which detections from different detection algorithms are associated with elements in the map and then fused to an absolute pose using an Unscented Kalman Filter. We evaluate our approach using a sensor setup that employs a stereo camera, vehicle odometry and a low-cost GNSS module on a 5km test route covering both narrow urban roads and multi-lane main roads under varying weather conditions. The results show that this approach is capable to be used for highly automated driving, showing an accuracy of 0.08m in typical road scenarios and a is available 98% of the time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594414","","Roads;Global navigation satellite system;Simultaneous localization and mapping;Semantics;Urban areas;Receivers","cameras;image resolution;Kalman filters;nonlinear filters;road vehicles;satellite navigation;stereo image processing;traffic engineering computing","high-resolution road maps;road borders;Unscented Kalman Filter;narrow urban roads;highly automated driving;precise localization;high-definition road maps;sensor specific feature layers;stereo camera;vehicle odometry;low-cost GNSS module;size 5.0 km;size 0.08 m","","","27","","","","","IEEE","IEEE Conferences"
"PiRat: An Autonomous Framework for Studying Social Behaviour in Rats and Robots","S. Heath; C. A. Ramirez-Brinez; J. Arnold; O. Olsson; J. Taufatofua; P. Pounds; J. Wiles; E. Leonardis; E. Gygi; E. Leija; L. K. Quinn; A. A. Chiba","School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; School of ITEE at the University of Queensland, St Lucia, Queensland, Australia; University of California, Neuroscientists are with the Department of Cognitive Science, San Diego La Jolla, San Diego, CA; University of California, Neuroscientists are with the Department of Cognitive Science, San Diego La Jolla, San Diego, CA; University of California, Neuroscientists are with the Department of Cognitive Science, San Diego La Jolla, San Diego, CA; University of California, Neuroscientists are with the Department of Cognitive Science, San Diego La Jolla, San Diego, CA; University of California, Neuroscientists are with the Department of Cognitive Science, San Diego La Jolla, San Diego, CA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7601","7608","The use of robots, as a social stimulus, provides several advantages over using another animal. In particular, for rat-robot studies, robots can produce social behaviour that is reproducible across trials. In the current work, we outline a framework for rat-robot interaction studies, that consists of a novel rat-sized robot (PiRat), models of robotic behavior, and a position tracking system for both robot and rat. We present the design of the framework, including constraints on autonomy, latency, and control. We pilot tested our framework by individually running the robot rat with eight different rats, first through a habituation stage, and then with PiRat performing two different types of behaviour - avoiding and frequently approaching. We evaluate the performance of the framework on latency and autonomy, and on the ability to influence the behaviour of individual rats. We find that the framework performs well on its constraints, engages some of the rats (according to the number of meetings), and features a control scheme that produces reproducible behaviour in rats. These features represent a first demonstration of a closed-loop rat-robot framework.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594060","","Rats;Robot sensing systems;Brushless DC motors","mobile robots;position control","social stimulus;rat-robot studies;social behaviour;rat-robot interaction studies;novel rat-sized robot;PiRat;robotic behavior;robot rat;reproducible behaviour;closed-loop rat-robot framework;autonomous framework","","1","15","","","","","IEEE","IEEE Conferences"
"Modeling and Fuzzy Control of One-legged Somersaulting Robot","M. Zabihi; A. Alasty","Department of Mechanical Engineering, Sharif University of Technology, Azadi Ave., Tehran, Iran; Department of Mechanical Engineering, Sharif University of Technology, Azadi Ave., Tehran, Iran","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2701","2706","Research on legged robots has developed rapidly in the recent decades. One-legged robots, unlike multi-legged ones, have only one type of motion, called hopping. Hopping motion is generally divided into stance and flight phases. Switching between these two phases represents a hybrid dynamic model. Dynamic stabilization of hopping motion is a challenging control issue. Most of one-legged hopping robots studied in the past are able to hop with their one springy leg. In this paper, a novel one-legged robot is introduced and studied with two springs on the two sides. The one-legged somersaulting robot is able to hop with both springy sides. This ability causes lower energy consumption in passing obstacles and a longer step length in comparison with well-known SLIP robots with hopping motion stemming from the fact that it only has one rotary actuator. Fuzzy logic control is applied to achieve a stable limit cycle in the robot's somersaulting motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593897","","Legged locomotion;Actuators;Mathematical model;Torque;Wheels","fuzzy control;legged locomotion;motion control;robot dynamics;robot kinematics;springs (mechanical)","flight phases;hybrid dynamic model;challenging control issue;one-legged hopping robots;springy leg;fuzzy logic control;one-legged somersaulting robot;multilegged ones;hopping motion;SLIP robots","","","22","","","","","IEEE","IEEE Conferences"
"Unpowered Lower-Body Exoskeleton with Torso Lifting Mechanism for Supporting Sit-to-Stand Transitions","D. F. P. Granados; H. Kadone; K. Suzuki","Department of Intelligent Interaction Technologies, University of Tsukuba, Artificial Intelligence Laboratory, 1-1-1 Tennodai, Tsukuba, 305-8573, Japan; Center for Innovative Medicine and Engineering, University of Tsukuba Hospital, Japan; Faculty of Engineering, Center for Cybernics Research, University of Tsukuba, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2755","2761","In this paper, we propose the design of an exoskeleton with support at the knee joint and lower torso for sit-to-stand and stand-to-sit (STS) posture transitions; devised for users with spinal cord injury and other complete lower-body impairments. The STS transitions assistance is achieved through a power transfer mechanism that synchronizes knees and lumbar motion through a cable-driven pulley system. We analyze the human body dynamics in the posture transition with a rigid link model and the interaction interface with the exoskeleton through an impedance model for producing a passive system voluntarily controlled by natural motions of the upper body. Therefore, allowing the potential users to achieve STS transitions with their body residual capabilities without an external power source. Instead, transferring power from their upper-body to lower-body, herewith, controlling a passive energy storage. A prototype was constructed and evaluated with seven healthy subjects observing the proposed motion and muscle activity during the STS transitions. The results show a significant reduction in the muscle activity evaluated, at the erector spinae, gluteus maximus and rectus femoris, with reductions between 30% to 50% at the p <; 0.01 level comparing STS transitions with and without the exoskeleton support. Concluding that the STS transitions support is feasible with the passive exoskeleton envisioned for applications in upright locomotion, STS training, and rehabilitation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594199","Passive exoskeleton;human dynamics modeling;physical human-robot interaction;rehabilitation robotics","Exoskeletons;Biological system modeling;Torso;Torque;Robots;Wheelchairs;Dynamics","biomechanics;bone;injuries;muscle;patient rehabilitation;pulleys","unpowered lower-body exoskeleton;torso lifting mechanism;knee joint;lower torso;spinal cord injury;lower-body impairments;power transfer mechanism;lumbar motion;cable-driven pulley system;human body dynamics;rigid link model;impedance model;passive system;natural motions;upper body;body residual capabilities;external power source;upper-body;passive energy storage;muscle activity;exoskeleton support;passive exoskeleton;STS training;STS posture transitions;sit-to-stand posture transitions;STS transition support;upright locomotion;patient rehabilitation","","","15","","","","","IEEE","IEEE Conferences"
"A Robust Time-Stepping Scheme for Quasistatic Rigid Multibody Systems","T. Pang; R. Tedrake","Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, 77 Cambridge, Massachusetts Avenue, MA, 02139; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, 77 Cambridge, Massachusetts Avenue, MA, 02139","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5640","5647","An effective scheme to simulate low-speed, contact-rich manipulation tasks is to assume quasistatic physics and advance system states by solving linear complementarity problems (LCPs). However, the existing LCP-based quasistatic time-stepping scheme fails to simulate grasping-an essential motion primitive in manipulation-due to two drawbacks specific to quasistatic systems. Firstly, inputs to quasistatic systems are velocity commands instead of torques. This can lead to penetration, and thus an infeasible LCP, when two rigid bodies in contact are commanded to push against each other. Secondly, as multiple force solutions exist for a given velocity command, a grasping velocity command is not guaranteed to generate sufficient grasping forces. In this paper, we reformulate the quasistatic time-stepping scheme as an optimization problem with complementarity constraints and a quadratic objective. By minimizing the difference between actual and commanded velocities, linearized non-penetration constraints can always be satisfied. Moreover, undesirable solutions with insufficient normal forces can be removed by considering elasticity, which is modeled by comparing actual and commanded velocities. The resulting optimization problem is a mixed-integer quadratic program, which can be solved reasonably quickly for small-to-medium-sized systems. The effectiveness of the proposed reformulation is validated by simulation results of systems with different levels of complexity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594378","","Grippers;Friction;Force;Kinematics;Grasping;Manipulators","grippers;integer programming;manipulator kinematics;quadratic programming;robust control;torque","robust time-stepping scheme;quasistatic rigid multibody systems;quasistatic physics;linear complementarity problems;grasping velocity command;small-to-medium-sized systems;manipulation;motion primitive;LCP;optimization problem;mixed-integer quadratic program;torque","","","21","","","","","IEEE","IEEE Conferences"
"Geometric-based Line Segment Tracking for HDR Stereo Sequences","R. Gomez-Ojeda; J. Gonzalez-Jimenez","Machine Perception and Intelligent Robotics (MAPIR) Group, University of Malaga; Machine Perception and Intelligent Robotics (MAPIR) Group, University of Malaga","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","69","74","In this work, we propose a purely geometrical approach for the robust matching of line segments for challenging stereo streams with severe illumination changes or High Dynamic Range (HDR) environments. To that purpose, we exploit the univocal nature of the matching problem, i.e. every observation must be corresponded with a single feature or not corresponded at all. We state the problem as a sparse, convex, ℓ<sub>1</sub>-minimization of the matching vector regularized by the geometric constraints. This formulation allows for the robust tracking of line segments along sequences where traditional appearance-based matching techniques tend to fail due to dynamic changes in illumination conditions. Moreover, the proposed matching algorithm also results in a considerable speed-up of previous state of the art techniques making it suitable for real-time applications such as Visual Odometry (VO). This, of course, comes at expense of a slightly lower number of matches in comparison with appearance-based methods, and also limits its application to continuous video sequences, as it is rather constrained to small pose increments between consecutive frames. We validate the claimed advantages by first evaluating the matching performance in challenging video sequences, and then testing the method in a benchmarked point and line based VO algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593646","","Image segmentation;Lighting;Tracking;Feature extraction;Video sequences;Motion segmentation;Simultaneous localization and mapping","compressed sensing;convex programming;image matching;image segmentation;image sequences;stereo image processing;video signal processing","robust tracking;art techniques;appearance-based methods;High Dynamic Range environments;HDR stereo sequences;geometric-based line segment tracking;stereo streams;appearance-based matching techniques;video sequences","","","27","","","","","IEEE","IEEE Conferences"
"Socially-Aware Navigation Using Non-Linear Multi-Objective Optimization","S. Forer; S. B. Banisetty; L. Yliniemi; M. Nicolescu; D. Feil-Seifer","University of Nevada, Department of Mechanical Engineering, Reno, N. Virginia Street, Reno, NV 89557-0171, 1664, USA; University of Nevada, Department of Computer Science and Engineering, Reno, N. Virginia Street, Reno, NV 89557-0171, 1664, USA; University of Nevada, Department of Computer Science and Engineering, Reno, N. Virginia Street, Reno, NV 89557-0171, 1664, USA; University of Nevada, Department of Computer Science and Engineering, Reno, N. Virginia Street, Reno, NV 89557-0171, 1664, USA; University of Nevada, Department of Computer Science and Engineering, Reno, N. Virginia Street, Reno, NV 89557-0171, 1664, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","For socially assistive robots (SAR)to be accepted into complex and stochastic human environments, it is important to account for subtle social norms. In this paper, we propose a novel approach to socially-aware navigation (SAN)which garnered an immense interest in the Human-Robot Interaction (HRI)community. We use a multi-objective optimization tool called the Pareto Concavity Elimination Transformation (PaC-cET)to capture the non-linear human navigation behavior, a novel contribution to the community. A candidate point on a trajectory is scored (1)for its progress towards the goal, and (2)based on autonomously-sensed distance-based features that capture the social norms and associated social costs. Rather than use a finely-tuned linear combination of these costs, we use PaCcET to select an optimized future trajectory point, associated with a non-linear combination of the costs. Existing research in this domain concentrates on geometric reasoning, model-based, and learning approaches, which have their own pros and cons. This approach is distinct from prior work in this area. We showed in a simulation that the PaCcET-based trajectory planner not only is able to avoid collisions and reach the intended destination in static and dynamic environments but also considers a human's personal space i.e. rules of proxemics in the trajectory selection process.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593825","","Navigation;Trajectory;Optimization;Robot sensing systems;Reinforcement learning","human-robot interaction;iterative methods;learning (artificial intelligence);mobile robots;Pareto optimisation;path planning","nonlinear multiobjective optimization;socially assistive robots;complex environments;stochastic human environments;subtle social norms;socially-aware navigation;multiobjective optimization tool;PaC-cET;nonlinear human navigation behavior;autonomously-sensed distance-based features;social costs;finely-tuned linear combination;optimized future trajectory point;PaCcET-based trajectory planner;human-robot interaction community;Pareto concavity elimination transformation;model-based approaches","","1","29","","","","","IEEE","IEEE Conferences"
"Proactive Collision Avoidance for ASVs using A Dynamic Reciprocal Velocity Obstacles Method","D. K. M. Kufoalor; E. F. Brekke; T. A. Johansen","Department of Engineering Cybernetics, Norwegian University of Science and Technology (NTNU), Center for Autonomous Marine Operations and Systems (AMOS), O.S. Bragstads plass 2D, Trondheim, N-7491, Norway; Department of Engineering Cybernetics, Norwegian University of Science and Technology (NTNU), Center for Autonomous Marine Operations and Systems (AMOS), O.S. Bragstads plass 2D, Trondheim, N-7491, Norway; Department of Engineering Cybernetics, Norwegian University of Science and Technology (NTNU), Center for Autonomous Marine Operations and Systems (AMOS), O.S. Bragstads plass 2D, Trondheim, N-7491, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2402","2409","We propose a collision avoidance method that incorporates the interactive behavior of agents and is proactive in dealing with the uncertainty of the future behavior of obstacles. The proposed method considers interactions that will be experienced by an autonomous surface vessel (ASV) in an environment governed by the international regulations for preventing collisions at sea (COLREGs). Our approach aims at encouraging dynamic obstacles to cooperate according to COLREGs. Therefore, we propose a strategy for assessing the cooperative behavior of obstacles, and the result of the assessment is used to adapt collision avoidance decisions within the Reciprocal Velocity Obstacles (RVO) framework. Moreover, we propose a predictive approach to solving known limitations of the RVO framework, and we present computationally feasible extensions that enable the use of complex dynamic models and objectives suitable for ASVs. We demonstrate the performance and potentials of our method through a simulation study, and the results show that the proposed method leads to proactive and more predictable ASV behavior compared with both Velocity Obstacles (VO) and RVO, especially when obstacles cooperate by following COLREGs.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594382","","Collision avoidance;Decision making;Propulsion;Uncertainty;Sensor systems;Computational modeling","collision avoidance;marine vehicles;mobile robots;velocity control","reciprocal velocity obstacles framework;dynamic obstacles;collision avoidance decisions;international regulations;autonomous surface vessel;future behavior;interactive behavior;collision avoidance method;dynamic reciprocal velocity obstacles method;proactive collision avoidance;COLREGs;ASV behavior;complex dynamic models;RVO framework;predictive approach","","","16","","","","","IEEE","IEEE Conferences"
"Multimodal Environment Dynamics for Interactive Robots: Towards Fault Detection and Task Monitoring","K. Haninger; D. Surdilovic","Fraunhofer Institut fr Produktionsanlagen und Konstruktionstechnik; Fraunhofer Institut fr Produktionsanlagen und Konstruktionstechnik","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6932","6937","Interactive robots offer improved performance in tasks with environmental uncertainty, but accommodating environment input weakens predictions of contact force or position trajectories, making the identification of subtask completion or faults difficult. This paper develops a task monitoring approach for complex assembly tasks that involve transitions between discrete environment dynamic modes. In semi-structured environments, these dynamic modes and their transitions are approximately known a priori, allowing task monitoring through estimation of the current mode and fault detection as a deviation from expected, desired dynamic mode transitions. This allows a more natural description of many interactive tasks, improving robustness to variations in force or position trajectories that impedance control seeks to address. The ability of impedance and admittance controlled robots to identify their environment is investigated, making consideration of joint and end-effector physical compliance. Prior information on environment dynamics and mode transitions allow recursive estimates of dynamic mode suitable for online use, under both full state knowledge and only force/position measurements. Experiments with an admittance controlled robot in a gear assembly task validate the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593650","","Dynamics;Task analysis;Force;Robot sensing systems;Admittance;Estimation","end effectors;fault diagnosis;fault tolerant control;force control;industrial manipulators;robotic assembly;trajectory control","multimodal environment dynamics;interactive robots;environmental uncertainty;contact force;subtask completion;task monitoring approach;complex assembly tasks;discrete environment dynamic modes;semistructured environments;interactive tasks;impedance control;admittance controlled robots;force/position measurements;admittance controlled robot;gear assembly task;fault detection;force trajectories;position trajectories;end-effector physical compliance","","","26","","","","","IEEE","IEEE Conferences"
"Evaluating Methods for End-User Creation of Robot Task Plans","C. Paxton; F. Jonathan; A. Hundt; B. Mutlu; G. D. Hager","Department of Computer Science, Johns Hopkins University, 3400 N Charles Street, Baltimore, MD 21218, USA; Department of Computer Science, Johns Hopkins University, 3400 N Charles Street, Baltimore, MD 21218, USA; Department of Computer Science, Johns Hopkins University, 3400 N Charles Street, Baltimore, MD 21218, USA; Department of Computer Sciences, University of Wisconsin–Madison, 1210 W Dayton Street, Madison, WI 53706, USA; Department of Computer Science, Johns Hopkins University, 3400 N Charles Street, Baltimore, MD 21218, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6086","6092","How can we enable users to create effective, perception-driven task plans for collaborative robots? We conducted a 35-person user study with the Behavior Tree-based CoSTAR system to determine which strategies for end user creation of generalizable robot task plans are most usable and effctive. CoSTAR allows domain experts to author complex, perceptually grounded task plans for collaborative robots. As a part of CoSTAR's wide range of capabilities, it allows users to specify SmartMoves: abstract goals such as “pick up component A from the right side of the table.” Users were asked to perform pick-and-place assembly tasks with either SmartMoves or one of three simpler baseline versions of CoSTAR. Overall, participants found CoSTAR to be highly usable, with an average System Usability Scale score of 73.4 out of 100. SmartMove also helped users perform tasks faster and more effectively; all SmartMove users completed the first two tasks, while not all users completed the tasks using the other strategies. SmartMove users showed better performance for incorporating perception across all three tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594127","","Task analysis;Planning;User interfaces;Service robots;Grippers;Collaboration","manipulators;multi-robot systems;path planning","end-user creation;perception-driven task plans;collaborative robots;generalizable robot task plans;behavior tree-based CoSTAR system;pick-and-place assembly tasks;SmartMove","","","24","","","","","IEEE","IEEE Conferences"
"A Real- Time Solver for Time-Optimal Control of Omnidirectional Robots with Bounded Acceleration","D. Balaban; A. Fischer; J. Biswas","University of Massachusetts, Amherst, USA; University of Massachusetts, Amherst, USA; University of Massachusetts, Amherst, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8027","8032","We are interested in the problem of time-optimal control of omnidirectional robots with bounded acceleration (TOC-ORBA). While there exist approximate solutions for such problems, and exact solutions with unbounded acceleration, exact solvers to the TOC-ORBA problem have remained elusive until now. In this paper, we present a real-time solver for true time-optimal control of omnidirectional robots with bounded acceleration. We first derive the general parameterized form of the solution to the TOC-ORBA problem by application of Pontryagin's maximum principle. We then frame the boundary value problem of TOC-ORBA as an optimization problem over the parameterized control space. To overcome local minima and poor initial guesses to the optimization problem, we introduce a two-stage optimal control solver (TSOCS): The first stage computes an upper bound to the total time for the TOC-ORBA problem and holds the time constant while optimizing the parameters of the trajectory to approach the boundary value conditions. The second stage uses the parameters found by the first stage, and relaxes the constraint on the total time to solve for the parameters of the complete TOC-ORBA problem. Furthermore, we implement TSOCS as a closed loop controller to overcome actuation errors on real robots in realtime. We empirically demonstrate the effectiveness of TSOCS in simulation and on real robots, showing that 1) it runs in real time, generating solutions in less than 0.5ms on average; 2) it generates faster trajectories compared to an approximate solver; and 3) it is able to solve TOC-ORBA problems with nonzero final velocities that were previously unsolvable in real-time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594306","","Acceleration;Robot kinematics;Trajectory;Mobile robots;Optimal control;Real-time systems","approximation theory;boundary-value problems;closed loop systems;maximum principle;mobile robots;optimisation","bounded acceleration;boundary value problem;optimization problem;parameterized control space;two-stage optimal control solver;real- time solver;time-optimal control;omnidirectional robots;TOC-ORBA problem;approximate solutions;exact solutions;Pontryagin's maximum principle;closed loop controller;TSOCS","","","21","","","","","IEEE","IEEE Conferences"
"Ego-Motion Estimate Corruption Due to Violations of the Range Flow Constraint","C. D. Monaco; S. N. Brennan","Department of Mechanical and Nuclear Engineering, Pennsylvania State University, State College, PA, 16801, USA; Department of Mechanical and Nuclear Engineering, Pennsylvania State University, State College, PA, 16801, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3964","3969","Visual odometry methods are increasingly being used to estimate a vehicle's ego-motion from range data due to the decreasing cost of range sensors and the impressive speed and accuracy of visual odometry techniques. Dense geometry-based visual odometry methods are fundamentally based on the range flow constraint equation, an equation which depends on the temporal and spatial derivatives of range images. However, these derivatives are calculated with the fundamental assumption that the range flow is magnitude-limited. When scaling this method for faster vehicles, this assumption could be violated, invaliding the range flow constraint equation and thus corrupting the resulting ego-motion estimates. This paper derives the sensor, motion, environment, and sampling frequency conditions that would mathematically violate the range flow constraint. This information is useful for defining the operational limits of dense geometry-based visual odometry methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594131","","Mathematical model;Cameras;Optical imaging;Visual odometry;Optical sensors;Adaptive optics;Optical variables control","distance measurement;image sensors;image sequences;mobile robots;motion estimation;robot vision","range sensors;visual odometry techniques;dense geometry-based visual odometry methods;range flow constraint equation;temporal derivatives;spatial derivatives;range images;ego-motion estimation;range data","","","25","","","","","IEEE","IEEE Conferences"
"Efficient Long-term Mapping in Dynamic Environments","M. T. Lázaro; R. Capobianco; G. Grisetti","Dipartimento di Ingegneria Informatica Automatica e Gestionale “An-tonio Ruberti”, Sapienza University of Rome, Italy; Dipartimento di Ingegneria Informatica Automatica e Gestionale “An-tonio Ruberti”, Sapienza University of Rome, Italy; Dipartimento di Ingegneria Informatica Automatica e Gestionale “An-tonio Ruberti”, Sapienza University of Rome, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","153","160","As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594310","","Simultaneous localization and mapping;Cloud computing;Three-dimensional displays;Two dimensional displays;Merging;Optimization","graph theory;mobile robots;robot vision;SLAM (robots)","mapping problem;longterm SLAM datasets;graph coherency;intra-session loop closure detections;out-dated nodes;graph complexity;nonstatic entities;merging procedure;efficient ICP-based alignment;up-to-date state;2D point cloud data;local maps;graph SLAM paradigm;multiple mapping sessions;single mapping sessions;SLAM system;autonomous robots;dynamic environments;long-term robot operation","","1","24","","","","","IEEE","IEEE Conferences"
"Material Recognition Using a Capacitive Proximity Sensor with Flexible Spatial Resolution","H. Alagi; A. Heiligl; S. E. Navarro; T. Kroegerl; B. Hein","Intelligent Process Control and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics; Intelligent Process Control and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics; Team Defrost at Inria Lille-Nord, Europe; Intelligent Process Control and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics; Intelligent Process Control and Robotics Lab (IAR-IPR), Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6284","6290","In this paper we present an approach for material recognition using capacitive tactile and proximity sensors. By variating the spatial resolution and the exciter frequency during the measurement in mutual capacitive mode, information about the dielectrical properties of different objects was captured and provided as data frames. For material recognition an artificial neural network was set up and fed with various data sets of different electrode combinations and exciter frequencies. The influence of the electrode combinations and shapes on the recognition accuracy was investigated. It is shown that seven objects of conductive and non-conductive dielectric materials have been ranged with an overall accuracy of about 71%-94%.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593789","","Electrodes;Robot sensing systems;Permittivity;Spatial resolution;Permittivity measurement;Shape","capacitive sensors;dielectric materials;mobile robots;neural nets;tactile sensors","conductive dielectric materials;artificial neural network;data frames;electrode combinations;flexible spatial resolution;capacitive proximity sensor;nonconductive dielectric materials;data sets;material recognition;exciter frequency;capacitive tactile","","","16","","","","","IEEE","IEEE Conferences"
"Implementation of a Versatile 3D ZMP Trajectory Optimization Algorithm on a Multi-Modal Legged Robotic Platform","J. Hooks; D. Hong","Department of Mechanical and Aeronautical Engineering, University of California Los Angeles; Department of Mechanical and Aeronautical Engineering, University of California Los Angeles","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3777","3782","This paper presents a multi-functioning light weight robotic system, the Autonomous Legged Personal Helper Robot with Enhanced Dynamics (ALPHRED), capable of both locomotion and manipulation. In addition, we extended a 2D zero moment point (ZMP) trajectory optimization (TO) algorithm to a 3D implementation. As well as adding the acceleration of the center of mass to the TO cost in order to smooth out the motion of the robot during trajectories with support polygons that do not intersect. By implementing this versatile TO algorithm on a multi-modal robotic platform we showed that many different forms of stable locomotion and manipulation were possible including a dynamic 0.7 m/s trot gait.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593968","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593968","","Legged locomotion;Foot;Trajectory;Heuristic algorithms;Task analysis","humanoid robots;legged locomotion;manipulators;robot dynamics","autonomous legged personal helper robot;enhanced dynamics;multimodal legged robotic platform;versatile 3D ZMP trajectory optimization algorithm;stable locomotion;multimodal robotic platform;2D zero moment point trajectory optimization;manipulation;light weight robotic system","","","13","","","","","IEEE","IEEE Conferences"
"Active Structure-from-Motion for 3d Straight Lines","A. Mateus; O. Tahri; P. Miraldo","LARSyS, Instituto Superior Tecnico, Univ. Lisboa, Institute for Systems and Robotics (lSRlIST), Portugal; Université d'Orléans, PRISME EA 4229, INSA Centre Val de Loire, Bourges, France; LARSyS, Instituto Superior Tecnico, Univ. Lisboa, Institute for Systems and Robotics (lSRlIST), Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5819","5825","A reliable estimation of 3D parameters is a must for several applications like planning and control, in which is included Image-Based Visual Servoing. This control scheme depends directly on 3D parameters, e.g. depth of points, and/or depth and direction of 3D straight lines. Recently, a framework for Active Structure-from-Motion was proposed, addressing the former feature type. However, straight lines were not addressed. These are 1D objects, which allow for more robust detection, and tracking. In this work, the problem of Active Structure-from-Motion for 3D straight lines is addressed. An explicit representation of these features is presented, and a change of variables is proposed. The latter allows the dynamics of the line to respect the conditions for observability of the framework. A control law is used with the purpose of keeping the control effort reasonable, while achieving a desired convergence rate. The approach is validated first in simulation for a single line, and second using a real robot setup. The latter set of experiments are conducted first for a single line, and then for three lines.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593793","","Three-dimensional displays;Cameras;Convergence;Eigenvalues and eigenfunctions;Robots;Observers","mobile robots;observability;robot vision;visual servoing","Active Structure-from-Motion;planning;Image-Based Visual Servoing;control scheme;straight lines;control law;control effort;3D straight lines;convergence rate;3D parameter estimation","","","36","","","","","IEEE","IEEE Conferences"
"A New Robot Fly Design That is Easier to Fabricate and Capable of Flight and Ground Locomotion","Y. M. Chukewad; A. T. Singh; J. M. James; S. B. Fuller","Department of Mechanical Engineering, University of Washington, Seattle, WA, 98195; Department of Mechanical Engineering, University of Washington, Seattle, WA, 98195; Department of Mechanical Engineering, University of Washington, Seattle, WA, 98195; Department of Mechanical Engineering, University of Washington, Seattle, WA, 98195","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4875","4882","Efforts to engineer insect-sized (~100 mg) robots are motivated by their potential advantages relative to larger robots, such as greater deployment numbers at the same cost. Previous iterations have demonstrated controlled flight, but were limited in terms of locomotion capabilities outside of flight. They also consisted of many parts, making them difficult to fabricate. Here we present a re-design that lowers the center of mass, allowing the robot to additionally land without the need for long legs. Furthermore, we show that the new design allows for wing-driven ground locomotion. This is achieved by varying the speed of downstroke relative to the upstroke of the flapping wings, which also allows for steering. By landing and subsequently moving along the ground, the robot can negotiate extremely confined spaces and underneath obstacles, as well as navigate to precise locations for sensing operations. The new design also drastically reduces the number of parts, simplifying fabrication. We describe the new design in detail and present results demonstrating these capabilities, as well as feedback-stabilized flights.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593972","","Actuators;Legged locomotion;Fabrication;Laminates;Laser beam cutting;Solid lasers","aerodynamics;aerospace components;aerospace robotics;feedback;microrobots;mobile robots;stability","new robot fly design;insect-sized;potential advantages;larger robots;greater deployment numbers;previous iterations;locomotion capabilities;additionally land;long legs;wing-driven ground locomotion;flapping wings;landing;extremely confined spaces;simplifying fabrication;feedback-stabilized flights","","1","30","","","","","IEEE","IEEE Conferences"
"Effects of Integrated Intent Recognition and Communication on Human-Robot Collaboration","M. Lee Chang; R. A. Gutierrez; P. Khante; E. Schaertl Short; A. Lockerd Thomaz","Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, 78705, USA; Department of Computer Science, University of Texas at Austin, Austin, TX, 78705, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, 78705, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, 78705, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, 78705, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3381","3386","Human-robot interaction research to date has investigated intent recognition and communication separately. In this paper, we explore the effects of integrating both the robot's ability to generate intentional motion and predict the human's motion in a collaborative physical task. We implemented an intent recognition system to recognize the human partner's hand motion intent and a motion planner system to enable the robot to communicate its intent by using legible and predictable motion. We tested this bi-directional intent system in a 2-way within-subjects user study. Results suggest that an integrated intent recognition and communication system may facilitate more collaborative behavior among team members.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593359","","Collaboration;Task analysis;Trajectory;Motion segmentation;Containers;Manipulators","human-robot interaction;image motion analysis;mobile robots","human-robot interaction;human partners hand motion intent;communication system;bi-directional intent system;predictable motion;legible motion;motion planner system;intent recognition system;collaborative physical task;intentional motion;human-robot collaboration;integrated intent recognition","","","14","","","","","IEEE","IEEE Conferences"
"Rubik's Cube Handling Using a High-Speed Multi-Fingered Hand and a High-Speed Vision System","R. Higo; Y. Yamakawa; T. Senoo; M. Ishikawa","Graduate School of Information Science and Technology, University of Tokyo, Dept. of Information Physics and Computing, Tokyo, 113-8656, Japan; The University of Tokyo, Institute of Industrial Science, Tokyo, 153-8505, Japan; Graduate School of Information Science and Technology, University of Tokyo, Dept. of Information Physics and Computing, Tokyo, 113-8656, Japan; Graduate School of Information Science and Technology, University of Tokyo, Dept. of Information Physics and Computing, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6609","6614","The regrasping function of a robotic hand and arm has been investigated by many studies. Dynamic regrasping is performed by accelerating objects and it has the advantage of being able to perform the regrasp function at high speed. However, the difficulty of increasing the success rate is a persistent problem. In this study, we aimed to realize this continuous high-speed operation by increasing the success rate of the regrasping function. The handling of the Rubik's cube was used as the specific task to be performed. The action that was required to handle the Rubik's cube consisted of two types of regrasping motion and one type of one-face turn motion. In this study, a Rubik's cube was placed in a plane and manipulated by combining these three types of motion. Continuous operation was realized with a robotic hand and high-speed vision by utilizing environmental constraints in order to minimize the error. As a result, we succeeded 3 times in turning and regrasping in 1 s. Additionally, we were able to succeed 30 times in turning and regrasping in 10 s, with a success rate of 70%.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593538","","Gravity;Face;Robot sensing systems;Turning;Trajectory;Orbits","dexterous manipulators;manipulator dynamics;robot vision","continuous high-speed operation;one-face turn motion;high-speed multifingered hand;high-speed vision system;Rubiks cube handling;robotic hand regrasping function;time 1.0 s;time 10.0 s","","","10","","","","","IEEE","IEEE Conferences"
"Towards View-Invariant Intersection Recognition from Videos using Deep Network Ensembles","A. Kumar; G. Gupta; A. Sharma; K. M. Krishna","KCIS, Center of Visual Information Technology, International Institute of Information Technology, Hyderabad, India; KCIS, Robotics Research Center, International Institute of Information Technology, Hyderabad, India; KCIS, Center of Visual Information Technology, International Institute of Information Technology, Hyderabad, India; KCIS, Robotics Research Center, International Institute of Information Technology, Hyderabad, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1053","1060","This paper strives to answer the following question: Is it possible to recognize an intersection when seen from different road segments that constitute the intersection? An intersection or a junction typically is a meeting point of three or four road segments. Its recognition from a road segment that is transverse to or 180 degrees apart from its previous sighting is an extremely challenging and yet a very relevant problem to be addressed from the point of view of both autonomous driving as well as loop detection. This paper formulates this as a problem of video recognition and proposes a novel LSTM based Siamese style deep network for video recognition. For what is indeed a challenging problem and the limited annotated dataset available we show competitive results of recognizing intersections when approached from diverse viewpoints or road segments. Specifically, we tabulate effective recognition accuracy even as the approaches to the intersection being compared are disparate both in terms of viewpoints and weather/illumination conditions. We show competitive results on both synthetic yet highly realistic data mined from the gaming platform GTA as well as on real world data made available through Mapillary.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594449","","Videos;Trajectory;Visualization;Task analysis;Roads;Image recognition;Training","data mining;image recognition;learning (artificial intelligence);neural nets;object recognition;video signal processing","recognition accuracy;road segments;LSTM based Siamese style deep network;meeting point;deep network ensembles;videos;view-invariant intersection recognition;video recognition","","","34","","","","","IEEE","IEEE Conferences"
"Prediction of Manipulation Action Classes Using Semantic Spatial Reasoning","F. Ziaeetabar; T. Kulvicius; M. Tamosiunaite; F. Wörgötter","University of Göttingen, III. Physics Institute, Friedrich-Hund-Platz 1, Göttingen, 37077, Germany; University of Göttingen, III. Physics Institute, Friedrich-Hund-Platz 1, Göttingen, 37077, Germany; University of Göttingen, III. Physics Institute, Friedrich-Hund-Platz 1, Göttingen, 37077, Germany; University of Göttingen, III. Physics Institute, Friedrich-Hund-Platz 1, Göttingen, 37077, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3350","3357","Human-robot interaction strongly benefits from fast, predictive action recognition. For us this is relatively easy but difficult for a robot. To address this problem, here we present a novel prediction algorithm for manipulation action classes in video sequences. Manipulations are first represented using the Enriched Semantic Event Chain (ESEC) framework. This creates a temporal sequence of static and dynamic spatial relations between the objects that take part in the manipulation by which an action can be quickly recognized. We measured performance on 32 ideal as well as real manipulations and compared our method also against a state of the art trajectory-based HMM method for action recognition. We observe that manipulations can be correctly predicted after only (on average) 45% of action's total time and that we are almost twice as fast as the HMM-based method. Finally, we demonstrate the advantage of this framework in a simple robot demonstration comparing two different approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593717","","Robots;Three-dimensional displays;Predictive models;Semantics;Human-robot interaction;Prediction algorithms;Image segmentation","hidden Markov models;human-robot interaction;image sequences;manipulators;spatial reasoning;video signal processing","trajectory-based HMM method;simple robot demonstration;dynamic spatial relations;static relations;temporal sequence;Enriched Semantic Event Chain framework;video sequences;predictive action recognition;human-robot interaction;Semantic spatial reasoning;manipulation action classes","","","23","","","","","IEEE","IEEE Conferences"
"Interaction-Aware Probabilistic Behavior Prediction in Urban Environments","J. Schulz; C. Hubmann; J. Löchner; D. Burschka","BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; Department of Computer Science, Technical University of Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3999","4006","Planning for autonomous driving in complex, urban scenarios requires accurate prediction of the trajectories of surrounding traffic participants. Their future behavior depends on their route intentions, the road-geometry, traffic rules and mutual interaction, resulting in interdependencies between their trajectories. We present a probabilistic prediction framework based on a dynamic Bayesian network, which represents the state of the complete scene including all agents and respects the aforementioned dependencies. We propose Markovian, context-dependent motion models to define the interaction-aware behavior of drivers. At first, the state of the dynamic Bayesian network is estimated over time by tracking the single agents via sequential Monte Carlo inference. Secondly, we perform a probabilistic forward simulation of the network's estimated belief state to generate the different combinatorial scene developments. This provides the corresponding trajectories for the set of possible, future scenes. Our framework can handle various road layouts and number of traffic participants. We evaluate the approach in online simulations and real-world scenarios. It is shown that our interaction-aware prediction outperforms interaction-unaware physics- and map-based approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594095","","Trajectory;Estimation;Vehicles;Probabilistic logic;Hidden Markov models;Predictive models;Bayes methods","Bayes methods;belief networks;control engineering computing;driver information systems;inference mechanisms;Markov processes;mobile robots;Monte Carlo methods;probability;road vehicles;traffic engineering computing","combinatorial scene developments;road layouts;future scenes;probabilistic forward simulation;sequential Monte Carlo inference;single agents;context-dependent motion models;complete scene;dynamic Bayesian network;probabilistic prediction framework;mutual interaction;traffic rules;road-geometry;route intentions;traffic participants;urban scenarios;complex scenarios;autonomous driving;urban environments;interaction-aware probabilistic behavior prediction;interaction-unaware physics;real-world scenarios","","","21","","","","","IEEE","IEEE Conferences"
"Improving Trajectory Optimization Using a Roadmap Framework","S. Dai; M. Orton; S. Schaffert; A. Hofmann; B. Williams","Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Boston Dynamics, Waltham, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8674","8681","We present an evaluation of several representative sampling-based and optimization-based motion planners, and then introduce an integrated motion planning system which incorporates recent advances in trajectory optimization into a sparse roadmap framework. Through experiments in 4 common application scenarios with 5000 test cases each, we show that optimization-based or sampling-based planners alone are not effective for realistic problems where fast planning times are required. To the best of our knowledge, this is the first work that presents such a systematic and comprehensive evaluation of state-of-the-art motion planners, which are based on a significant amount of experiments. We then combine different stand-alone planners with trajectory optimization. The results show that the combination of our sparse roadmap and trajectory optimization provides superior performance over other standard sampling-based planners' combinations. By using a multi-query roadmap instead of generating completely new trajectories for each planning problem, our approach allows for extensions such as persistent control policy information associated with a trajectory across planning problems. Also, the sub-optimality resulting from the sparsity of roadmap, as well as the unexpected disturbances from the environment, can both be overcome by the real-time trajectory optimization process.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594274","","Planning;Trajectory optimization;Robots;Dynamics;Task analysis;Collision avoidance","mobile robots;optimisation;path planning;sampling methods;trajectory control","trajectory optimization process;sampling-based planners;motion planning system;multiquery roadmap;sparse roadmap framework;optimization-based motion planners","","","21","","","","","IEEE","IEEE Conferences"
"Adaptive Admittance Control in Task-Priority Framework for Contact Force Control in Autonomous Underwater Floating Manipulation* This work is part of a project titled “Force/position control system to enable compliant manipulation from a floating I-AUV”, which received funding from the European Union's Horizon 2020 research and innovation programme, under the Marie Sklodowska-Curie grant agreement no. 750063.","P. Cieślak; P. Ridao","Scientific and Technological Park, University of Girona, CIRS lab, Computer Vision and Robotics Research Institute, Girona, 17003, Spain; Scientific and Technological Park, University of Girona, CIRS lab, Computer Vision and Robotics Research Institute, Girona, 17003, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6646","6651","This paper presents a control architecture for an underwater vehicle-manipulator system (UVMS) to enable simultaneous tracking of end-effector configuration and contact force during floating-base manipulation. The main feature of the architecture is its combination of a task-priority (TP) kinematic control algorithm with a custom force control strategy, based on impedance (admittance) control. The TP algorithm used in the work includes recent treatment of equality and inequality tasks as well as original concepts to handle operation in singular configurations of the system. In the force control part the impedance concept is extended to allow for direct control over the value of exerted force and torque. Additional feed-forward signal is used to ensure stable contact. The performance of the control architecture is demonstrated by experiments in a test tank, with GIRONA500 I-AUV performing pipe inspection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593542","","Force control;Task analysis;Force;Impedance;Robots;Heuristic algorithms;Inspection","autonomous underwater vehicles;cooperative systems;end effectors;force control;manipulator dynamics;manipulator kinematics;manipulators;mobile robots;position control","task-priority kinematic control algorithm;custom force control strategy;impedance control;TP algorithm;inequality tasks;singular configurations;force control part;impedance concept;exerted force;stable contact;control architecture;adaptive admittance control;task-priority framework;contact force control;underwater vehicle-manipulator system;end-effector configuration;floating-base manipulation","","","23","","","","","IEEE","IEEE Conferences"
"Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation","G. Todoran; M. Bader","Vienna University of Technology, Institute of Computer Engineering, Vienna, 1040, Austria; Vienna University of Technology, Institute of Computer Engineering, Vienna, 1040, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3422","3429","Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593721","","Trajectory;Safety;Navigation;Robots;Vehicle dynamics;Planning;Collision avoidance","collision avoidance;emergency management;mobile robots;motion control;multi-robot systems;trajectory control","safe navigation;safe motion controls;emergency trajectory candidates;just-in-time emergency trajectories;autonomous navigation;vehicle operation;safe system state;MHTP;moving horizon trajectory planner;safety requirements;vehicle's local control system;differential-drive mobile agent;nonstatic environment;robot","","","12","","","","","IEEE","IEEE Conferences"
"Exploring Vestibulo-Ocular Adaptation in a Closed-Loop Neuro-Robotic Experiment Using STDP. A Simulation Study","F. Naveros; J. A. Garrido; A. Arleo; E. Ros; N. R. Luque","The research Centre for Information and Communication Technologies (CITIC) Department of Computer Architecture and Technology, University of Granada, Granada, 18014, Spain; The research Centre for Information and Communication Technologies (CITIC) Department of Computer Architecture and Technology, University of Granada, Granada, 18014, Spain; Univcrsite Pierre et Marie Curie Paris 06, The Institut de la Vision Institut National de la Sante et de la Recherche Medicale U968 and Centre National de la Recherche Scientifique Sorbonne Universites, UMR _7210, Paris, France; The research Centre for Information and Communication Technologies (CITIC) Department of Computer Architecture and Technology, University of Granada, Granada, 18014, Spain; The research Centre for Information and Communication Technologies (CITIC) Department of Computer Architecture and Technology, University of Granada, Granada, 18014, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Studying and understanding the computational primitives of our neural system requires for a diverse and complementary set of techniques. In this work, we use the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar adaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms located at the cerebellar molecular layer and the vestibular nuclei respectively. This simulation study adopts an experimental setup (rotatory VOR)widely used by neuroscientists to better understand the contribution of certain specific cerebellar properties (i.e. distributed STDP, neural properties, coding cerebellar topology, etc.)to r-VOR adaptation. The work proposes and describes an embodiment solution for which we endow a simulated humanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and we face the humanoid to an r-VOR task. The results validate the adaptive capabilities of the spiking cerebellar model (with STDP)in a perception-action closed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594019","","Robot sensing systems;Neurons;Adaptation models;Transfer functions;Task analysis;Optical fiber networks","brain models;closed loop systems;control engineering computing;humanoid robots;neural nets","neural system;Neuro-robotic Platform;NRP;vestibulo ocular cerebellar adaptatIon;STDP mechanisms;cerebellar molecular layer;r-VOR adaptation;spiking cerebellar model;r-VOR task;perception-action closed-loop;vestibulo-ocular reflex;humanoid robot;iCub robot;cerebellar properties","","","27","","","","","IEEE","IEEE Conferences"
"Geometric Optimization of a Large Scale CDPR Operating on a Building Facade","H. Hussein; J. C. Santos; M. Gouttefarde","LIRMM, CNRS, Universite de Montpellier, Montpellier, France; LIRMM, CNRS, Universite de Montpellier, Montpellier, France; LIRMM, CNRS, Universite de Montpellier, Montpellier, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5117","5124","This paper deals with the optimization of the geometry of a Cable-Driven Parallel Robot (CDPR) dedicated to large-scale construction applications. Since the maximum cable tension is a critical parameter in the design of the CDPR components, the geometry of the CDPR is optimized by minimizing the lowest maximum cable tension that ensures the validity of wrench-feasibility constraints. The geometric design procedure used in this paper consists of two phases, the CDPR cable connections is selected in the first phase followed by a second phase where the geometric parameters are optimized. The result of this procedure is an original fully-constrained CDPR geometry.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593900","","Geometry;Optimization;Indexes;Buildings;Robots;Trajectory;Payloads","buildings (structures);cables (mechanical);construction industry;design engineering;mobile robots;optimisation","geometric design procedure;geometric optimization;building facade;large-scale construction applications;wrench-feasibility constraints;cable-driven parallel robot;cable tension","","","34","","","","","IEEE","IEEE Conferences"
"A Phase Variable Approach to Volitional Control of Powered Knee-Ankle Prostheses","S. Rezazadeh; D. Quintero; N. Divekar; R. D. Gregg","Departments of Bioengineering and Mechanical Engineering, The University of Texas at Dallas, Locomotor Control Systems Laboratory, Richardson, TX, 75080, USA; Departments of Bioengineering and Mechanical Engineering, The University of Texas at Dallas, Locomotor Control Systems Laboratory, Richardson, TX, 75080, USA; Departments of Bioengineering and Mechanical Engineering, The University of Texas at Dallas, Locomotor Control Systems Laboratory, Richardson, TX, 75080, USA; Departments of Bioengineering and Mechanical Engineering, The University of Texas at Dallas, Locomotor Control Systems Laboratory, Richardson, TX, 75080, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2292","2298","Although there has been recent progress in control of multi-joint prosthetic legs for periodic tasks such as walking, volitional control of these systems for non-periodic maneuvers is still an open problem. In this paper, we develop a new controller that is capable of both periodic walking and common volitional leg motions based on a piecewise holonomic phase variable through a finite state machine. The phase variable is constructed by measuring the thigh angle, and the transitions in the finite state machine are formulated through sensing foot contact together with attributes of a nominal reference gait trajectory. The controller was implemented on a powered knee-ankle prosthesis and tested with a transfemoral amputee subject, who successfully performed a wide range of periodic and non-periodic tasks, including low- and high-speed walking, quick start and stop, backward walking, walking over obstacles, and kicking a soccer ball. The proposed approach is expected to provide better understanding of volitional motions and lead to more reliable control of multi-joint prostheses for a wider range of tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594023","","Legged locomotion;Thigh;Trajectory;Task analysis;Prosthetics;Sensors;Foot","artificial limbs;finite state machines;gait analysis;legged locomotion;medical robotics;motion control;trajectory control","volitional control;powered knee-ankle prostheses;multijoint prosthetic legs;periodic walking;piecewise holonomic phase variable;finite state machine;nominal reference gait trajectory;high-speed walking;backward walking;phase variable approach;volitional leg motions","","","26","","","","","IEEE","IEEE Conferences"
"Methods for Autonomous Wristband Placement with a Search-and-Rescue Aerial Manipulator","J. M. Gómez-de-Gabriel; J. M. Gandarias; F. J. Pérez-Maldonado; F. J. García-Núñcz; E. J. Fernández-García; A. J. García-Cerezo","University of Málaga, System Engineering and Automation Department, Málaga, Spain; University of Málaga, System Engineering and Automation Department, Málaga, Spain; University of Málaga, System Engineering and Automation Department, Málaga, Spain; University of Málaga, System Engineering and Automation Department, Málaga, Spain; University of Málaga, System Engineering and Automation Department, Málaga, Spain; University of Málaga, System Engineering and Automation Department, Málaga, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7838","7844","A new robotic system for Search And Rescue (SAR) operations based on the automatic wristband placement on the victims' arm, which may provide identification, beaconing and remote sensor readings for continuous health monitoring. This paper focuses on the development of the automatic target localization and the device placement using an unmanned aerial manipulator. The automatic wrist detection and localization system uses an RGB-D camera and a convolutional neural network based on the region faster method (Faster R-CNN). A lightweight parallel delta manipulator with a large workspace has been built, and a new design of a wristband in the form of a passive detachable gripper, is presented, which, under contact, automatically attaches to the human, while disengages from the manipulator. A new trajectory planning method has been used to minimize the torques caused by the external forces during contact, which cause attitude perturbations. Experiments have been done to evaluate the machine learning method for detection and location, and for the assessment of the performance of the trajectory planning method. The results show how the VGG-16 neural network provides a detection accuracy of 67.99%. Moreover, simulation experiments have been done to show that the new trajectories minimize the perturbations to the aerial platform.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594202","","Manipulators;Wrist;Cameras;Grippers;Robot kinematics;Robot sensing systems","aerospace control;autonomous aerial vehicles;convolutional neural nets;grippers;image colour analysis;learning (artificial intelligence);manipulators;path planning;rescue robots;robot vision;SLAM (robots)","autonomous wristband placement;robotic system;automatic wristband placement;remote sensor readings;continuous health monitoring;unmanned aerial manipulator;automatic wrist detection;RGB-D camera;convolutional neural network;Faster R-CNN;passive detachable gripper;VGG-16 neural network;target localization;trajectory planning;machine learning;parallel delta manipulator;search-and-rescue aerial manipulator;search and rescue operations;unmanned aerial vehicles","","","24","","","","","IEEE","IEEE Conferences"
"Riding and Speed Governing for Parallel Two-Wheeled Scooter Based on Sequential Online Learning Control by Humanoid Robot","K. Kimura; S. Nozawa; H. Mizohana; K. Okada; M. Inaba","The University of Tokyo, Department of Mechano- Infomatics, Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; The University of Tokyo, Department of Mechano- Infomatics, Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; The University of Tokyo, Department of Mechano- Infomatics, Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; The University of Tokyo, Department of Mechano- Infomatics, Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; The University of Tokyo, Department of Mechano- Infomatics, Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","The sequential online tuning for controller gains is required for the continuous action of the riding into parallel two-wheeled scooter and the speed governing after riding by humanoid robot. The implemented controllers are different between the riding and the speed governing, and these tuning strategies are also different. In particular, the riding requires the immediate tuning in the short riding phase and the speed governing requires the accurate tuning to regulate the speed of humanoid robot. To the above requirements, this paper proposes the Sequential Online Learning Control (SOLC)method composed of the cascade connection of SGD-based open-loop Learning Control (SLC)and Mini-batch-based closed-loop Learning Control (MLC). SLC contributes the damping gain online tuning for the foot torque control during execution of riding, and MLC contributes the PID gains online tuning for the speed governing control. Finally, we show the validity of SOLC through the sequential experiment of riding and speed governing for parallel two-wheeled scooter by life-sized humanoid robot HRP2-JSK.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593685","","Motorcycles;Tuning;Foot;Humanoid robots;Damping;Control systems;Torque","cascade control;closed loop systems;control engineering computing;humanoid robots;learning (artificial intelligence);mobile robots;motion control;motorcycles;torque control;velocity control;wheels","foot torque control;speed governing control;parallel two-wheeled scooter;sequential online tuning;controller gains;sequential online learning control method;SGD-based open-loop learning control;HRP2-JSK humanoid robot;cascade connection;minibatch-based closed-loop learning control","","","16","","","","","IEEE","IEEE Conferences"
"UnDEMoN: Unsupervised Deep Network for Depth and Ego-Motion Estimation","V. Madhu Babu; K. Das; A. Majumdar; S. Kumar","TATA Consultancy Services, Bangalore, India; TATA Consultancy Services, Bangalore, India; TATA Consultancy Services, Bangalore, India; TATA Consultancy Services, Bangalore, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1082","1088","This paper presents a deep network based unsupervised visual odometry system for 6-DoF camera pose estimation and finding dense depth map for its monocular view. The proposed network is trained using unlabeled binocular stereo image pairs and is shown to provide superior performance in depth and ego-motion estimation compared to the existing state-of-the-art. This is achieved by introducing a novel objective function and training the network using temporally alligned sequences of monocular images. The objective function is based on the Charbonnier penalty applied to spatial and bi-directional temporal reconstruction losses. The overall novelty of the approach lies in the fact that the proposed deep framework combines a disparity-based depth estimation network with a pose estimation network to obtain absolute scale-aware 6-DoF camera pose and superior depth map. According to our knowledge, such a framework with complete unsupervised end-to-end learning has not been tried so far, making it a novel contribution in the field. The effectiveness of the approach is demonstrated through performance comparison with the state-of-the-art methods on KITTI driving dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593864","","Image reconstruction;Cameras;Pose estimation;Training;Meters;Linear programming","cameras;distance measurement;feature extraction;image reconstruction;image sequences;learning (artificial intelligence);motion estimation;pose estimation;stereo image processing;unsupervised learning","unsupervised deep network;ego-motion estimation;unsupervised visual odometry system;monocular view;objective function;temporally alligned sequences;monocular images;disparity-based depth estimation network;dense depth map;UnDEMoN;binocular stereo image pairs;temporal reconstruction losses;pose estimation network;6DoF camera pose estimation","","","29","","","","","IEEE","IEEE Conferences"
"A Multisegment Electro-Active Polymer Based Milli-Continuum Soft Robots","A. Benouhiba; K. Rabenorosoa; P. Rougeot; M. Ouisse; N. Andreff","Univ. Bourgogne Franche-Comté/CNRS, FEMTO-ST Institute, Besançon, 25000, France; Univ. Bourgogne Franche-Comté/CNRS, FEMTO-ST Institute, Besançon, 25000, France; Univ. Bourgogne Franche-Comté/CNRS, FEMTO-ST Institute, Besançon, 25000, France; Univ. Bourgogne Franche-Comté/CNRS, FEMTO-ST Institute, Besançon, 25000, France; Univ. Bourgogne Franche-Comté/CNRS, FEMTO-ST Institute, Besançon, 25000, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7500","7506","This paper presents the design, modeling and fabrication of a millimeter-size Continuum Soft Robot (CSR). The robot consists of active flexible polymer actuator-based multisegment robot. A multiphysics model based on multilayer cantilever for large displacement is established between the input voltages to the distal tip position of a single segment robot. The extension of the model to multisegment CSR is derived. The proposed model is validated experimentally then a two-segment CSR and three-segment CSR in 3D arrangement are investigated, demonstrating the model efficiency for obtaining complex configuration. Moreover, various configurations can be explored to derive complex kinematics then increasing the robot capability.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593609","","Strain;Nonhomogeneous media;Soft robotics;Fabrication;Deformable models;Microactuators","cantilevers;electroactive polymer actuators;manipulator kinematics;polymers","millicontinuum soft robots;active flexible polymer actuator;multisegment robot;3D arrangement;robot capability;three-segment CSR;two-segment CSR;single segment robot;multiphysics model;millimeter-size Continuum Soft Robot;multisegment electro-active polymer","","","22","","","","","IEEE","IEEE Conferences"
"Single-Grasp, Model-Free Object Classification using a Hyper-Adaptive Hand, Google Soli, and Tactile Sensors","Z. Flintoff; B. Johnston; M. Liarokapis","Department of Mechanical Engineering, Faculty of Engineering, The University of Auckland, New Dexterity research group, 20 Symonds St, Auckland, 1010, New Zealand; Department of Mechanical Engineering, Faculty of Engineering, The University of Auckland, New Dexterity research group, 20 Symonds St, Auckland, 1010, New Zealand; Department of Mechanical Engineering, Faculty of Engineering, The University of Auckland, New Dexterity research group, 20 Symonds St, Auckland, 1010, New Zealand","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1943","1950","Robots need to use their end-effectors not only to grasp and manipulate objects but also to understand the environment surrounding them. Object identification is of paramount importance in robotics applications, as it facilitates autonomous object handling, sorting, and quality inspection. In this paper, we present a new hyper-adaptive robot hand that is capable of discriminating between different everyday objects, as well as `model' objects with the same external geometry but varying material, density, or volume, with a single grasp. This work leverages all the benefits of simple, adaptive grasping mechanisms (robustness, simplicity, low weight, adaptability), a Random Forests classifier, tactile modules based on barometric sensors, and radar technology offered by the Google Soli sensor. Unlike prior work, the method does not rely on object exploration, object release or re-grasping and works for a wide variety of everyday objects. The feature space used consists of the Google Soli readings, the motor positions and the contact forces measured at different time instances of the grasping process. The whole approach is model-free and the hand is controlled in an open-loop fashion, achieving stable grasps with minimal complexity. The efficiency of the designs, sensors, and methods has been experimentally validated with experimental paradigms involving model and everyday objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594166","","Robot sensing systems;Thumb;Google;Pins","end effectors;force measurement;grippers;position control;tactile sensors","object exploration;Google Soli readings;grasping process;stable grasps;single-grasp;model-free object classification;hyper-adaptive hand;tactile sensors;end-effectors;object identification;robotics applications;autonomous object;quality inspection;hyper-adaptive robot hand;model objects;adaptive grasping mechanisms;tactile modules;barometric sensors;Google Soli sensor;everyday objects;random forests classifier","","","26","","","","","IEEE","IEEE Conferences"
"Semantic Grid Estimation with a Hybrid Bayesian and Deep Neural Network Approach","Ö. Erkent; C. Wolf; C. Laugier; D. S. Gonzalez; V. R. Cano","INRIA, Chroma Team, Rhône-Alpes, France; INRIA, Chroma Team, Rhône-Alpes, France; INRIA, Chroma Team, Rhône-Alpes, France; INRIA, Chroma Team, Rhône-Alpes, France; Departamento de Automática y Electrónica, Universidad Autónoma de Occidente, Cali, Colombia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","888","895","In an autonomous vehicle setting, we propose a method for the estimation of a semantic grid, i.e. a bird's eye grid centered on the car's position and aligned with its driving direction, which contains high-level semantic information about the environment and its actors. Each grid cell contains a semantic label with divers classes, as for instance {Road, Vegetation, Building, Pedestrian, Car...}. We propose a hybrid approach, which combines the advantages of two different methodologies: we use Deep Learning to perform semantic segmentation on monocular RGB images with supervised learning from labeled groundtruth data. We combine these segmentations with occupancy grids calculated from LIDAR data using a generative Bayesian particle filter. The fusion itself is carried out with a deep neural network, which learns to integrate geometric information from the LIDAR with semantic information from the RGB data. We tested our method on two datasets, namely the KITTI dataset, which is publicly available and widely used, and our own dataset obtained with our own platform, equipped with a LIDAR and various sensors. We largely outperform baselines which calculate the semantic grid either from the RGB image alone or from LIDAR output alone, showing the interest of this hybrid approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593434","","Semantics;Image segmentation;Bayes methods;Laser radar;Neural networks;Three-dimensional displays;Sensors","Bayes methods;belief networks;image colour analysis;image segmentation;learning (artificial intelligence);neural nets;optical radar;particle filtering (numerical methods)","semantic grid estimation;hybrid Bayesian;deep neural network;autonomous vehicle setting;high-level semantic information;grid cell;semantic label;hybrid approach;semantic segmentation;monocular RGB images;supervised learning;labeled groundtruth data;occupancy grids;LIDAR data;generative Bayesian particle filter;geometric information;RGB data","","","36","","","","","IEEE","IEEE Conferences"
"A Probabilistic Approach to Benchmarking and Performance Evaluation of Robot Systems","P. U. Lima","Institute for Systems and Robotics of IST, U. Lisboa, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7231","7236","Problem benchmarks are used in experimental science as a reference against which results of experiments using distinct approaches to solve the problem are compared and evaluated in relative terms. In Robotics, just formulating a general performance assessment problem is difficult per se, as robot systems are composed of very diverse subsystems (e.g., localisation, human-robot interaction, task planning, motion planning). This paper introduces a probabilistic approach to benchmarking and evaluating performance of robot systems, which uses probability theory as the common language to quantify the performance of distinct functionalities of a robot system and their impact on the performance of a task carried out by that system. The approach can be used to analyse the performance of a task plan from the performances if its composing functionalities, or to (re)plan when a performance degradation in functionality is predicted to cause performance degradation of the task plan beyond acceptable limits.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594345","","Task analysis;Robots;Benchmark testing;Reliability;Measurement;Approximation algorithms;Probabilistic logic","path planning;probability;robots","performance degradation;probabilistic approach;performance evaluation;robot system;human-robot interaction;task planning;robotics;benchmarking evaluation;performance assessment problem","","","14","","","","","IEEE","IEEE Conferences"
"Enhanced Non-Steady Gliding Performance of the MultiMo-Bat through Optimal Airfoil Configuration and Control Strategy","H. Kim; M. A. Woodward; M. Sitti","Physical Intelligence Department, Max Planck Institute for Intelligent Systems, SC Sim Tech, University of Stuttgart, Stuttgart, 70569, Germany; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, 70569, Germany; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, SC Sim Tech, University of Stuttgart, Stuttgart, 70569, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1382","1388","Many robots make use of gravitational potential energy, generated by another mode, to enhance mobility through gliding locomotion. However, unstructured environments can create situations in which the initial conditions for steady-state gliding cannot be achieved; for example, jumping out of a hole, where the obstacle is very close to the robot. This paper suggests an optimization methodology for finding airfoil configurations and control strategies to maximize the effective non-steady-state gliding ratio for the most challenging initial condition, that of zero velocity. Parameters for the optimization are a location of a robot's center-of-mass in relation to its center-of-pressure and, through the addition of a tail, an active pitch control strategy. The optimal center-of-mass location produces the best passive gliding performance (morphological intelligence), and the optimal control strategy improves the gliding distance. Due to the aerodynamic complexities of modeling the collapsible airfoils, we find the optimal location of the center-of-mass from gliding experiments performed on the robot at different center-of-mass locations and initial pitch angles. An optimal location of the center-of-mass was found to be 40% of the wing chord for our robotic platform; measured from the wing's leading edge. The optimal location has a wide range of initial pitch angles which result in stable, yet non-steady-state, gliding behaviors. The morphological intelligence built into our robotic platform creates two observable dynamic behaviors, that of horizontal velocity gain and sink rate minimization. We then estimate the drag coefficients from the experiments, and conduct dynamic simulations to optimize the pitch control strategy. The design methodology presented here can enhance the non-steady-state gliding performance of a broad range of gliding robots, and the control strategy can further enhance performance on those which utilize an active tail.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593613","","Robots;Automotive components;Aerodynamics;Optimization;Atmospheric modeling;Trajectory;Springs","aerodynamics;aerospace components;autonomous aerial vehicles;design engineering;drag;mobile robots;optimal control;pitch control (position);robot dynamics","active pitch control strategy;center-of-mass location;morphological intelligence;optimal control strategy;collapsible airfoils;nonsteady-state gliding performance;gliding robots;drag coefficients;aerodynamic complexities","","","21","","","","","IEEE","IEEE Conferences"
"Key-Frame Strategy During Fast Image-Scale Changes and Zero Motion in VIO Without Persistent Features","E. Allak; A. Hardt-Stremayr; S. Weiss","Department of Smart Systems Technologies in the Control of Networked Systems Group, Alpen-Adria-Universitat Klagenfurt, Klagenfurt, 9020, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, Alpen-Adria-Universitat Klagenfurt, Klagenfurt, 9020, Austria; Department of Smart Systems Technologies in the Control of Networked Systems Group, Alpen-Adria-Universitat Klagenfurt, Klagenfurt, 9020, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6872","6879","Many of today's Visual-Inertial Odometry (VIO) frameworks work well under regular motion but have issues and need special treatment under special motion. Here, special does not imply bad or corrupted data but stands for increased difficulty to treat clean data. Common special motion for VIO are large feature displacement due to fast motion close to a scene and zero motion phases not providing sufficient baseline. In this paper we present a feature and frame selection approach which seamlessly handles all motion scenarios without the need of (error prone) motion case identification and subsequent case-specific heuristics. We further show that this approach allows to eliminate features in the state vector (persistent features)altogether while still being able to inherently handle zero motion phases. This reduces computational complexity while maintaining the ability to hover in place. We integrate our frame selection approach into our own VIO algorithm and compare its performance against three state-of-the-art algorithms with real data on a real platform. While our approach shows slightly higher global drift it is the only algorithm that can reliably estimate the pose over a large motion spectrum from fast scale change down to zero motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594170","","Computational complexity;Cameras;Computed tomography;Feature extraction;Kalman filters;Quaternions;Covariance matrices","computational complexity;distance measurement;feature extraction;image sequences;inertial navigation;Kalman filters;motion estimation;robot vision;video signal processing","common special motion;feature displacement;fast motion;zero motion phases;frame selection approach;motion scenarios;motion case identification;subsequent case-specific heuristics;state vectoraltogether;persistent features;VIO algorithm;motion spectrum;fast scale change;frame strategy;fast image-scale changes;regular motion;special treatment;bad data;corrupted data;clean data;visual-inertial odometry frameworks","","","19","","","","","IEEE","IEEE Conferences"
"Detecting and Picking of Folded Objects with a Multiple Sensor Integrated Robot Hand","S. Hasegawa; K. Wada; K. Okada; M. Inaba","JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1138","1145","Robotic picking of folded objects such as books is required for picking various objects. As a folded object is easily unfolded, it is difficult to carry it stably and place it in a desired pose due to its dangling part. For overcoming this difficulty, we propose a trial-and-error picking system using our Suction Pinching Hand, which can push the dangling part up with pinch grasp until the object lifted with suction grasp is folded. That system utilizes proximity sensors on the hand to predict whether folding will succeed with a current hand pose and decide whether to retry with another pose. Also, proximity sensors, flex sensors and an air pressure sensor are used to deal with uncertainty of the image recognition, the hand hardware and suction grasp. We evaluate our proposed system with experiments of picking and placing folded objects. It is confirmed that our proposed system realizes picking with the ability of our Suction Pinching Hand to carry folded objects stably and place them in desired poses. It is also proved that our proposed system is robust against the uncertainty.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593398","","Robot sensing systems;Uncertainty;Image recognition;Grippers;Hardware","control engineering computing;dexterous manipulators;image recognition;object detection;pressure sensors;robot vision","folded object;robotic picking;Suction Pinching Hand;proximity sensors;multiple sensor integrated robot hand;trial-and-error picking system;suction grasp;flex sensors;air pressure sensor;image recognition","","","24","","","","","IEEE","IEEE Conferences"
"An Efficient and Time-Optimal Trajectory Generation Approach for Waypoints Under Kinematic Constraints and Error Bounds","J. Lin; N. Somani; B. Hu; M. Rickert; A. Knoll","An-Institut Technische, Universität München, fortiss, Munich, Germany; Department of Informatics, Technische Universität München, Robotics and Embedded Systems, Munich, Germany; Beijing University of Chemical Technology, College of Information Science and Technology, Beijing, China; An-Institut Technische, Universität München, fortiss, Munich, Germany; Department of Informatics, Technische Universität München, Robotics and Embedded Systems, Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5869","5876","This paper presents an approach to generate the time-optimal trajectory for a robot manipulator under certain kinematic constraints such as joint position, velocity, acceleration, and jerk limits. This problem of generating a trajectory that takes the minimum time to pass through specified waypoints is formulated as a nonlinear constraint optimization problem. Unlike prior approaches that model the motion of consecutive waypoints as a Cubic Spline, we model this motion with a seven-segment acceleration profile, as this trajectory results in a shorter overall motion time while staying within the bounds of the robot manipulator's constraints. The optimization bottleneck lies in the complexity that increases exponentially with the number of waypoints. To make the optimization scale well with the number of waypoints, we propose an approach that has linear complexity. This approach first divides all waypoints to consecutive batches, each with an overlap of two waypoints. The overlapping waypoints then act as a bridge to concatenate the optimization results of two consecutive batches. The whole trajectory is effectively optimized by successively optimizing every batch. We conduct experiments on practical scenarios and trajectories generated by motion planners to evaluate the effectiveness of our proposed approach over existing state-of-the-art approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593577","","Trajectory;Splines (mathematics);Optimization;Manipulators;Acceleration;Kinematics","manipulator kinematics;nonlinear programming;path planning;time optimal control;trajectory control","motion planners;optimization scale;trajectory results;seven-segment acceleration profile;nonlinear constraint optimization problem;robot manipulator;error bounds;kinematic constraints;time-optimal trajectory generation approach","","","23","","","","","IEEE","IEEE Conferences"
"Optimal Input Waveform for an Indirectly Controlled Limit Cycle Walker","L. Li; I. Tokuda; F. Asano","Japan Advanced Institute of Science and Technology, School of Information Science, Nomi, Ishikawa, 923-1292, Japan; Department of Mechanical Engineering, Rit-sumeikan University, Kusatsu, Shiga, 525-8577, Japan; Japan Advanced Institute of Science and Technology, School of Information Science, Nomi, Ishikawa, 923-1292, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7454","7459","Precisely manipulating the center of mass (CoM) of the underactuated locomotion robot can't be easily achieved by common control mechanisms which apply only joint torques. A novel and indirect method has been recently introduced using an active wobbling mass attached to limit cycle walkers. The next important issue is to design an optimal control input to reduce the forcing energy. In this paper, we use combined rimless wheels as a simplified example to apply our method, which is based on the theory of phase oscillators. First, we introduce the typical modeling and control of this underactuated robot. Second, we obtain the phase response curve by numerically applying perturbations at different phases of the walker's gait interval and calculating the deviations from the unperturbed. Third, we analytically derive an optimal forcing waveform for the wobbling mass to entrain the combined rimless wheel based on the phase response curve. As an ecological extension, an ideal forcing waveform for m: 1 entrainment was further generated. Finally, the proposed method was evaluated by locking range of the Arnold tongues. The results show that the optimal forcing waveform we derived achieves the best performance for 1:1 entrainment among all the candidates. One of the strongest advantages of our method is the easiness of its implementation, prompting its applicability to a wide variety of locomotion systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594488","","Wheels;Perturbation methods;Limit-cycles;Legged locomotion;Trajectory;Mathematical model","control system synthesis;gait analysis;legged locomotion;limit cycles;numerical analysis;optimal control;oscillators;robot dynamics;torque;wheels","control mechanisms;limit cycle walker;forcing energy reduction;gait interval;Arnold tongues;optimal control design;numerical analysis;phase response curve;phase oscillators;rimless wheels;active wobbling mass;joint torques;underactuated locomotion robot;optimal input waveform;optimal forcing waveform","","","14","","","","","IEEE","IEEE Conferences"
"Capturing Deformations of Interacting Non-rigid Objects Using RGB-D Data","A. Petit; S. Cotin; V. Lippiello; B. Siciliano","Inria, Mimesis Group, 1 place de l'hopital, Strasbourg, 67000, France; Inria, Mimesis Group, 1 place de l'hopital, Strasbourg, 67000, France; Dipartimento di Ingegneria Elettrica e Tecnologie dell'Informazione, Università degli Studi di Napoli Federico II, via Claudio 21, Napoli, 80125, Italy; Dipartimento di Ingegneria Elettrica e Tecnologie dell'Informazione, Università degli Studi di Napoli Federico II, via Claudio 21, Napoli, 80125, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","491","497","This paper presents a method for tracking multiple interacting deformable objects undergoing rigid motions, elastic deformations and contacts, using image and point cloud data provided by an RGB-D sensor. A joint registration frame-work is proposed, based on physical Finite Element Method (FEM) elastic and interaction models. It first relies on a visual segmentation of the considered objects in the RGB images. The different segmented point clouds are then processed to estimate rigid transformations with on an ICP algorithm, and to determine geometrical point-to-point correspondences with the meshes. External forces resulting from these correspondences and between the current and the rigidly transformed mesh can then be derived. It provides both non-rigid and rigid data cues. A classical collision detection and response model is also integrated, giving contact forces between the objects. The deformations of the objects are estimated by solving a dynamic system balancing these external and contact forces with the internal or regularization forces computed through the FEM elastic model. This approach has been here tested on different scenarios involving two or three interacting deformable objects of various shapes, with promising results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593756","","Strain;Three-dimensional displays;Finite element analysis;Deformable models;Computational modeling;Collision avoidance;Visualization","computational geometry;finite element analysis;image colour analysis;image registration;image segmentation;image sequences","segmented point clouds;collision detection;joint registration framework;RGB-D sensor;point cloud data;elastic deformations;RGB-D data;interacting nonrigid objects;FEM elastic model;geometrical point-to-point correspondences;ICP algorithm;rigid transformations;RGB images;visual segmentation","","","36","","","","","IEEE","IEEE Conferences"
"KnowRobSIM — Game Engine-Enabled Knowledge Processing Towards Cognition-Enabled Robot Control","A. Haidu; D. Beßler; A. K. Bozcuoğlu; M. Beetz","University of Bremen, Institute for Artificial Intelligence; University of Bremen, Institute for Artificial Intelligence; University of Bremen, Institute for Artificial Intelligence; University of Bremen, Institute for Artificial Intelligence","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4491","4498","AI knowledge representation and reasoning methods consider actions to be blackboxes that abstract away from how they are executed. This abstract view does not suffice for the decision making capabilities required by robotic agents that are to accomplish manipulation tasks. Such robots have to reason about how to pour without spilling, where to grasp a pot, how to open different containers, and so on. To enable such reasoning it is necessary to consider how objects are perceived, how motions can be executed and parameterized, and how motion parameterization affects the physical effects of actions. To this end, we propose to complement and extend symbolic reasoning methods with KnowRob<sub>SIM</sub>, an additional reasoning infrastructure based on modern game engine technology, including the subsymbolic world modeling through data structures, action simulation based on physics engine, and world scene rendering. We demonstrate how KnowRob<sub>SIM</sub> can perform powerful reasoning, prediction, and learning tasks that are required for informed decision making in object manipulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593935","","Cognition;Games;Engines;Robots;Force;Data structures","cognitive systems;computer games;control engineering computing;data structures;decision making;inference mechanisms;knowledge representation;manipulators;motion control;rendering (computer graphics)","action simulation;physics engine;AI knowledge representation;decision making capabilities;robotic agents;motion parameterization;symbolic reasoning methods;modern game engine technology;game engine-enabled knowledge processing;cognition-enabled robot control;KnowRobSIM;reasoning methods;manipulation tasks;data structures;world scene rendering;object manipulation","","","24","","","","","IEEE","IEEE Conferences"
"DREGON: Dataset and Methods for UAV-Embedded Sound Source Localization","M. Strauss; P. Mordel; V. Miguet; A. Deleforge","Martin Strauss is with Friedrich-Alexander University, Erlangen, Germany; Pol Mordel is with CNRS/IRISA Rennes - Bretagne Atlantique, Rennes, France; Victor Miguet is with ENS Rennes, France; Antoine Deleforge is with Inria Rennes- Bretagne Atlantique, Rennes, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","This paper introduces DREGON, a novel publicly-available dataset that aims at pushing research in sound source localization using a microphone array embedded in an unmanned aerial vehicle (UAV). The dataset contains both clean and noisy in-flight audio recordings continuously annotated with the 3D position of the target sound source using an accurate motion capture system. In addition, various signals of interests are available such as the rotational speed of individual rotors and inertial measurements at all time. Besides introducing the dataset, this paper sheds light on the specific properties, challenges and opportunities brought by the emerging task of UAV-embedded sound source localization. Several baseline methods are evaluated and compared on the dataset, with real-time applicability in mind. Very promising results are obtained for the localization of a broad-band source in loud noise conditions, while speech localization remains a challenge under extreme noise levels.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593581","","Microphone arrays;Propellers;Drones;Robots;White noise","acoustic noise;acoustic signal processing;aerospace computing;audio signal processing;autonomous aerial vehicles;control engineering computing;microphone arrays","broad-band source localization;microphone array;noisy in-flight audio recordings;3D position;rotor rotational speed;loud noise conditions;extreme noise levels;accurate motion capture system;target sound source;UAV-embedded sound source localization;DREGON","","","26","","","","","IEEE","IEEE Conferences"
"Affordance Wayfields for Task and Motion Planning","T. McMahon; O. C. Jenkins; N. Amato","Department of Electrical Engineering Computer Science, Robotics Institute, University of Michigan, 2260 Hayward Street, Ann Arbor, MI, 48109-2121; Department of Electrical Engineering Computer Science, Robotics Institute, University of Michigan, 2260 Hayward Street, Ann Arbor, MI, 48109-2121; Department of Computer Science and Engineering, Texas A&M University, Parasol Laboratory, College Station, TX, 77843-3112","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2955","2962","Affordances provide a natural means for a robot to describe its agency as actions it can perform on objects. Further, affordances can enable robots to reason complicated, multi-step tasks that involve proper use of a diversity of objects. This paper proposes the concept of affordance wayfields for representing manipulation affordances as objective functions in configuration space. Affordance wayfields quantify how well a path, or sequence of motions, will accomplish an afforded action on an object. Paths that enact affordances can be located by performing a randomized form of gradient descent over affordance wayfields. Incorporating obstacles, or other constraints into wayfields allows our method to adaptively generate valid motions for executing afforded actions. We demonstrate that affordance wayfields can enable robots, such as the Michigan Progress Fetch mobile manipulator, to solve complex real-world tasks such as assembling a table, or loading and unloading objects from a storage chest.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594492","","Planning;Task analysis;End effectors;Trajectory;Cost function","gradient methods;manipulators;path planning","manipulation affordances;affordance wayfields;motion planning;gradient descent;Michigan Progress Fetch mobile manipulator","","","34","","","","","IEEE","IEEE Conferences"
"Public perception of android robots: Indications from an analysis of YouTube comments","E. Vlachos; Z. Tan","University of Southern Denmark, Campusvej 55, Odense M, 5230, Denmark; Department of Electronic Systems, Aalborg University, Fredrik Bajers Vej 7B, Aalborg, 9220, Denmark","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1255","1260","The public perception of android robots is a field of growing applied relevance. Currently, most androids are confined within controlled environments rendering interactions between potential end-users, and robots challenging. Even more challenging is for researchers to investigate end-users' perception of androids. We exploit pre-existing YouTube comments as artifacts for quantitative content analysis to gain an indication of social perception on androids. We perform a content analysis of 10301 YouTube comments from four different videos, and reflect on the textual reactions to video stimuli of four extremely human-like android robots. We use text mining and machine learning techniques to process and analyze our corpus. Our findings reveal three equally important topics that should be considered for paving the way towards a robotic society: human-robot relationships, technical specifications, and the science fiction valley. Considering people's attitudes, fears and wishes towards androids, researchers can increase citizen awareness, and engagement.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594058","","YouTube;Videos;Androids;Humanoid robots;Clustering algorithms;Text mining","control engineering computing;data mining;humanoid robots;human-robot interaction;learning (artificial intelligence);public administration;social networking (online);text analysis","end-users;Youtube comments;social perception indication;machine learning;text mining;rendering interactions;textual reactions;video stimuli;technical specification;science fiction valley;public perception;human-robot relationships;robotic society;quantitative content analysis;android robots","","","56","","","","","IEEE","IEEE Conferences"
"Timestamp Offset Calibration for an IMU-Camera System Under Interval Uncertainty","R. Voges; B. Wagner","Real Time Systems Group (RTS), Institute for Systems Engineering, Leibniz Universität Hannover, Hannover, D-30167, Germany; Real Time Systems Group (RTS), Institute for Systems Engineering, Leibniz Universität Hannover, Hannover, D-30167, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","377","384","To properly fuse IMU and camera information for robotics applications, the relative timestamp offset between both sensors' data streams has to be considered. However, finding the exact timestamp offset is often impossible. Thus, it is necessary to additionally consider the offset's uncertainty if we want to produce reliable results. In order to find the offset and its uncertainty, we determine orientation estimates from IMU and camera under interval uncertainty. Subsequently, these intervals are used as a common representation for our bounded-error approach that finds an interval enclosing the true offset while also modeling the uncertainty. Calibration data can be acquired in a few seconds using a simple setup of IMU, camera and camera target. Results using both simulated and real data demonstrate that we are able to determine the offset to an accuracy of 20 ms with a computation time that is suitable for future online applications. Here, our approach could be used to monitor the timestamp offset in a guaranteed way. Additionally, our method can be adapted to determine an interval for the rotation between both sensors. While this increases the computation time drastically, it also enhances the accuracy of the timestamp offset to less than 10 ms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594237","","Cameras;Calibration;Uncertainty;Sensor fusion;Electron tubes;Sensor systems","calibration;cameras;data acquisition;inertial systems;measurement uncertainty;time measurement","orientation estimation determination;data acqusition;sensors;robotics applications;IMU-camera system;timestamp offset calibration;calibration data;bounded-error approach;interval uncertainty;time 20.0 ms","","","20","","","","","IEEE","IEEE Conferences"
"Exploiting Points and Lines in Regression Forests for RGB-D Camera Relocalization","L. Meng; F. Tung; J. J. Little; J. Valentin; C. W. de Silva","Information and Cognitive Systems (ICICS), The University of British Columbia, Institute for Computing, Vancouver, Canada; Information and Cognitive Systems (ICICS), The University of British Columbia, Institute for Computing, Vancouver, Canada; Information and Cognitive Systems (ICICS), The University of British Columbia, Institute for Computing, Vancouver, Canada; Perceptive10 Inc, United States; Information and Cognitive Systems (ICICS), The University of British Columbia, Institute for Computing, Vancouver, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6827","6834","Camera relocalization plays a vital role in many robotics and computer vision applications, such as self-driving cars and virtual reality. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these point features are only sampled randomly in images, without considering geometric information such as lines, leading to large errors with the existence of poorly textured areas or in motion blur. Line segments are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593505","","Cameras;Forestry;Image segmentation;Three-dimensional displays;Robot vision systems;Training;Two dimensional displays","cameras;computer vision;feature extraction;image colour analysis;image segmentation;image texture;learning (artificial intelligence);optimisation;pose estimation;regression analysis;virtual reality","RGB-D;computer vision applications;self-driving cars;virtual reality;recent random forests;pixel comparison features;3D world locations;2D image locations;point features;geometric information;motion blur;line segments;uncertainty driven regression forests","","","48","","","","","IEEE","IEEE Conferences"
"Weighted Total Least Squares based Online Calibration Method for RSS based Localization","J. Kim; D. Kim","Center for Intelligent Robotics Research, Robotics and Media Institute, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent Robotics Research, Robotics and Media Institute, Korea Institute of Science and Technology, Seoul, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","117","122","In the received signal strength (RSS) based localization, a model-based calibration approach has been usually done by relating RSS-to-distance among anchor nodes. In this paper, an improved calibration method is proposed. For that purpose, RSS and estimated distance between any pairs of an-chor/unknown nodes is considered under the linear regression model. Unfortunately in this model, partial input elements are erroneous due to the inaccurate localization of unknown nodes. To obtain its solution under consideration of such an error, the weighted total least squares (WTLS) techniques are employed here. With the help of the WTLS techniques, several errors involved in the model can be effectively compensated. To show the efficiency of the proposed calibration, it is combined with several localization algorithms and its performance is verified by various simulations. The results show that the proposed calibration can give a very similar localization performance to that of each localization algorithm when true model parameters are known.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594416","","Calibration;Linear regression;Estimation;Shadow mapping;Measurement uncertainty;Taylor series;Convergence","calibration;distance measurement;error compensation;least squares approximations;regression analysis","linear regression model;partial input elements;weighted total least squares techniques;WTLS techniques;received signal strength based localization algorithm;RSS-to-distance based localization algorithm;improved online model-based calibration approach;distance estimation;error compensation","","","17","","","","","IEEE","IEEE Conferences"
"An Adaptive Landing Gear for Extending the Operational Range of Helicopters","B. Stolz; T. Brödermann; E. Castiello; G. Englberger; D. Erne; J. Gasser; E. Hayoz; S. Müller; L. Muhlebach; T. Löw; D. Scheuer; L. Vandeventer; M. Bjelonic; F. Günther; H. Kolvenbach; M. Hopflinger; M. Hutter","ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland; ETH Zurich, Robotic Systems Lab, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1757","1763","Conventional skid or wheel based helicopter landing gears severely limit off-field landing possibilities, which are crucial when operating in scenarios such as mountain rescue. In this context, slopes beyond 8° and small obstacles can already pose a substantial hazard. An adaptive landing gear is proposed to overcome these limitations. It consists of four legs with one degree of freedom each. The total weight was minimized to demonstrate economic practicability. This was achieved by an innovative actuation, composed of a parallel arrangement of motor and brake, which relieves the motor from large impact loads during hard landings. The loads are alleviated by a spring-damper system acting in series to the actuation. Each leg is individually force controlled for optimal load distribution on compliant ground and to avoid tipping. The operation of the legs is fully autonomous during the landing phase. A prototype was designed and successfully tested on an unmanned helicopter with a maximum take-off weight of 78 kg. Finally, the implementation of the landing gear concept on aircraft of various scales was discussed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594062","","Legged locomotion;Gears;Helicopters;Foot;Brakes;Rotors;Damping","actuators;adaptive control;aircraft landing guidance;autonomous aerial vehicles;force control;gears;helicopters;legged locomotion;shock absorbers;springs (mechanical);vibration control","off-field landing;skid based helicopter landing gears;mountain rescue;economic practicability;innovative actuation;brake;motor;spring-damper system;force control;tipping;aircraft;unmanned helicopter;landing phase;optimal load distribution;leg;wheel based helicopter landing gears;adaptive landing gear","","","16","","","","","IEEE","IEEE Conferences"
"A Workbench for Quantitative Comparison of Databases in Multi-Robot Applications","R. Ravichandran; E. Prassler; N. Huebel; S. Blumenthal","Bonn-Rhein-Sieg University of Applied Science, Sankt Augustin, Germany; Bonn-Rhein-Sieg University of Applied Science, Sankt Augustin, Germany; Robotics Research Group, KU Leuven, Belgium; Locomotec GmbH, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3744","3750","Robots generate large amounts of data which need to be stored in a meaningful way such that they can be used and interpreted later. Such data can be written into log files, but these files lack the querying features and scaling capabilities of modern databases - especially when dealing with multi-robot systems, where the trade-off between availability and consistency has to be resolved. However, there is a plethora of existing databases, each with its own set of features, but none designed with robotic use cases in mind. This work presents three main contributions: (a) structures for benchmarking scenarios with a focus on networked multi-robot architectures, (b) an extensible workbench for benchmarking databases for different scenarios that makes use of Docker containers and (c) a comparison of existing databases given a set of multi-robot use cases to showcase the usage of the framework. The comparison gives indications for choosing an appropriate database.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594241","","Databases;Robot sensing systems;Benchmark testing;Containers;Systems architecture","database management systems;multi-robot systems","multirobot applications;robots;log files;querying features;scaling capabilities;modern databases;multirobot systems;robotic use cases;benchmarking scenarios;networked multirobot architectures;extensible workbench;benchmarking databases","","","16","","","","","IEEE","IEEE Conferences"
"Learning a Local Feature Descriptor for 3D LiDAR Scans","A. Dewan; T. Caselitz; W. Burgard","Department of Computer Science at the University of Freiburg, Germany; Department of Computer Science at the University of Freiburg, Germany; Department of Computer Science at the University of Freiburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4774","4780","Robust data association is necessary for virtually every SLAM system and finding corresponding points is typically a preprocessing step for scan alignment algorithms. Traditionally, handcrafted feature descriptors were used for these problems but recently learned descriptors have been shown to perform more robustly. In this work, we propose a local feature descriptor for 3D LiDAR scans. The descriptor is learned using a Convolutional Neural Network (CNN). Our proposed architecture consists of a Siamese network for learning a feature descriptor and a metric learning network for matching the descriptors. We also present a method for estimating local surface patches and obtaining ground-truth correspondences. In extensive experiments, we compare our learned feature descriptor with existing 3D local descriptors and report highly competitive results for multiple experiments in terms of matching accuracy and computation time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594420","","Three-dimensional displays;Measurement;Laser radar;Feature extraction;Streaming media;Task analysis;Gray-scale","convolutional neural nets;feature extraction;image matching;image representation;learning (artificial intelligence);robot vision;SLAM (robots)","learned feature descriptor;3D local descriptors;local feature descriptor;3D LiDAR scans;robust data association;scan alignment algorithms;handcrafted feature descriptors;metric learning network;local surface patches;convolutional neural network;ground-truth correspondences;SLAM system;CNN;Siamese network","","","21","","","","","IEEE","IEEE Conferences"
"Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot","Z. Yan; L. Sun; T. Duckctr; N. Bellotto","University of Technology of Belfort-Montbeliard, LE2I-CNRS, France; University of Lincoln, Lincoln Centre for Autonomous Systems, UK; University of Lincoln, Lincoln Centre for Autonomous Systems, UK; University of Lincoln, Lincoln Centre for Autonomous Systems, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7635","7640","Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593899","","Three-dimensional displays;Laser radar;Detectors;Robot sensing systems;Cameras","image classification;image colour analysis;learning (artificial intelligence);mobile robots;object detection;object tracking;optical radar;probability;radar tracking;robot vision;service robots;stereo image processing","online transfer learning;3D LiDAR-based human detection;mobile robot;service robots;multisensor tracking system;2D LiDAR;human trajectory;3D LiDAR-based human classification;trajectory probability;RGB-D camera","","","30","","","","","IEEE","IEEE Conferences"
"Towards Peak Torque Minimization for Modular Self-Folding Robots","M. Yao; H. Cui; X. Xiao; C. H. Belke; J. Paik","Harbin Institute of Technology, China; Harbin Institute of Technology, China; Changchun University of Science and Technology, China; École Polytechnique Fédérale de Lausanne (EPFL), Switzerland; École Polytechnique Fédérale de Lausanne (EPFL), Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7975","7982","Modular self-folding robots are versatile systems that can change their own shape from two-dimensional patterns at instant commands. This reconfigurability is commonly restrained by power limitation in autonomous environments, The robotic systems with insufficient torque may lead to inaccurate movements and even transformation failures. This paper presents methodology for optimized reconfiguration planning with torque limitation in modular self-folding robots. We determine reconfiguration schemes with optimal initial pattern and robotic base that result in minimal peak torque by minimizing robotic inertia of the modular architecture. We present minimal bounding box and capacitated spanning tree heuristic algorithms to generate optimal initial patterns and propose 3 heuristic rules for robotic base selection. Our approach is demonstrated in simulation by applying the algorithms to the robotic concept of Mori, a modular origami robot. The simulation results show that the proposed algorithms yield reconfiguration schemes with low peak torque, thereby appropriate for real-time applications in modular robotic systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593648","","Robots;Torque;Planning;Shape;Heuristic algorithms;Computer architecture;Force","mobile robots;torque;trees (mathematics)","two-dimensional patterns;robotic inertia;modular architecture;minimal bounding box;robotic base selection;modular origami robot;modular robotic systems;peak torque minimization;modular self-folding robots;capacitated spanning tree heuristic algorithms;Mori","","","26","","","","","IEEE","IEEE Conferences"
"A Transient-Goal Driven Communication-Aware Navigation Strategy for Large Human-Populated Environments","V. K. Narayanan; T. Miyashita; Y. Horikawa; N. Hagita","ATR Intelligent Robotics and Communication Labs., Kyoto, Japan; ATR Intelligent Robotics and Communication Labs., Kyoto, Japan; ATR Intelligent Robotics and Communication Labs., Kyoto, Japan; ATR Intelligent Robotics and Communication Labs., Kyoto, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Robots deployed in large human-populated indoor environments such as shopping malls, airports etc., inadvertently communicate via wireless networks for enhanced perception and decision making capabilities. Owing to highly dynamic signal attenuation characteristics in such environments, connectivity issues may arise during robotic navigation, leading to disruption in information flow causing potential danger. Exact modeling of signal propagation for estimating spatial signal variation is usually challenging. Moreover, the presence of dynamic humans also add a layer of temporal signal variation complexities. Thus, this paper introduces a generative approach for embedding radio signal strength constraints within networked service/social robot navigation in large human-populated environments. Initially, we propose a Gaussian Process based online spatio-temporal signal strength prediction model that, as opposed to the current state of the art, also aims to take into account the temporal fading arising due to the presence of human crowds. We then devise a transient-goal driven navigation strategy to realize a sub-optimal path towards a goal, that is aimed at resolving both communication-aware and human-aware planning constraints. Evaluations of the proposed signal prediction model demonstrate the advantages of our approach with respect to the current state of the art. The efficacy of the navigation strategy in also demonstrated simulations and using hardware experiments conducted on a robotic wheelchair operating in a large shopping mall.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593827","","Robot sensing systems;Navigation;Transient analysis;Mobile robots;Fading channels;Wireless communication","decision making;Gaussian processes;indoor navigation;mobile robots;path planning;signal processing;wireless sensor networks","social robot navigation;networked service;wireless networks;Gaussian Process;robotic wheelchair operation;sub-optimal path;communication-aware planning constraints;connectivity issues;human-populated indoor environments;transient-goal driven communication-aware navigation strategy;human-aware planning constraints;radio signal strength constraints;decision making capabilities;shopping mall","","","32","","","","","IEEE","IEEE Conferences"
"Steering of an Underactuated Legged Robot through Terrain Contact with an Active Tail","C. S. Casarez; R. S. Fearing","Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2739","2746","This paper analyzes and implements two novel turning strategies for underactuated legged robots that leverage contact of an active tail against terrain. The first strategy produces a sustained turn with a tail dragging against the ground during forward locomotion. The second strategy produces a rapid point turn by impacting the tail against the ground. LoadRoACH, a 55 g palm-sized legged robot, is developed to carry the active tail payload used in turning experiments. A steady-state turning model predicts the achievable turn speed of the robot on carpet, and open-loop turning experiments characterize the performance of the two tail contact turning strategies. Tail drag turning provides comparable turning maneuverability to differential drive turning gaits on carpet and gravel surfaces. Tail impact turning can produce rapid point turns on carpet, tarp, and gravel, but has a large variability in turn angle and time to recover from the turn. Finally, tail drag and tail impact turning control methods are implemented in an aggressive closed-loop corner steering maneuver.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594384","","Turning;Legged locomotion;Force;Steady-state;Drag;Aerodynamics","closed loop systems;drag;gait analysis;legged locomotion;motion control;robot dynamics;robot kinematics;steering systems","underactuated legged robot;terrain contact;rapid point turn;active tail payload;steady-state turning model;differential drive turning gaits;tail impact turning;tail drag;palm-sized legged robot;LoadRoACH;tail contact turning strategies;closed-loop corner steering maneuver;mass 55.0 g","","","21","","","","","IEEE","IEEE Conferences"
"Hybrid Multi-camera Visual Servoing to Moving Target","H. Cuevas-Velasquez; N. Li; R. Tylecek; M. Saval-Calvo; R. B. Fisher","School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; Dept. Computer Technology, University of Alicante; School of Informatics, University of Edinburgh","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1132","1137","Visual servoing is a well-known task in robotics. However, there are still challenges when multiple visual sources are combined to accurately guide the robot or occlusions appear. In this paper we present a novel visual servoing approach using hybrid multi-camera input data to lead a robot arm accurately to dynamically moving target points in the presence of partial occlusions. The approach uses four RGBD sensors as Eye-to-Hand (EtoH) visual input, and an arm-mounted stereo camera as Eye-in-Hand (EinH). A Master supervisor task selects between using the EtoH or the EinH, depending on the distance between the robot and target. The Master also selects the subset of EtoH cameras that best perceive the target. When the EinH sensor is used, if the target becomes occluded or goes out of the sensor's view-frustum, the Master switches back to the EtoH sensors to re-track the object. Using this adaptive visual input data, the robot is then controlled using an iterative planner that uses position, orientation and joint configuration to estimate the trajectory. Since the target is dynamic, this trajectory is updated every time-step. Experiments show good performance in four different situations: tracking a ball, targeting a bulls-eye, guiding a straw to a mouth and delivering an item to a moving hand. The experiments cover both simple situations such as a ball that is mostly visible from all cameras, and more complex situations such as the mouth which is partially occluded from some of the sensors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593652","","Three-dimensional displays;Cameras;Visualization;Robot vision systems","cameras;image sensors;position control;robot vision;stereo image processing;tracking;visual servoing","hybrid multicamera visual servoing;moving target;robotics;multiple visual sources;visual servoing approach;hybrid multicamera input data;robot arm;RGBD sensors;arm-mounted stereo camera;Eye-in-Hand;EtoH cameras;EinH sensor;EtoH sensors;adaptive visual input data;eye-to-hand visual input","","","22","","","","","IEEE","IEEE Conferences"
"A Variational Feature Encoding Method of 3D Object for Probabilistic Semantic SLAM","H. W. Yu; B. H. Lee","Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3605","3612","This paper presents a feature encoding method of complex 3D objects for high-level semantic features. Recent approaches to object recognition methods become important for semantic simultaneous localization and mapping (SLAM). However, there is a lack of consideration of the probabilistic observation model for 3D objects, as the shape of a 3D object basically follows a complex probability distribution. Furthermore, since the mobile robot equipped with a range sensor observes only a single view, much information of the object shape is discarded. These limitations are the major obstacles to semantic SLAM and view-independent loop closure using 3D object shapes as features. In order to enable the numerical analysis for the Bayesian inference, we approximate the true observation model of 3D objects to tractable distributions. Since the observation likelihood can be obtained from the generative model, we formulate the true generative model for 3D object with the Bayesian networks. To capture these complex distributions, we apply a variational auto-encoder. To analyze the approximated distributions and encoded features, we perform classification with maximum likelihood estimation and shape retrieval.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593831","","Shape;Simultaneous localization and mapping;Three-dimensional displays;Semantics;Solid modeling;Bayes methods;Probabilistic logic","Bayes methods;belief networks;feature extraction;maximum likelihood estimation;object recognition;probability;robot vision;SLAM (robots)","object recognition methods;true generative model;semantic simultaneous localization and mapping;maximum likelihood estimation;shape retrieval;Bayesian inference;Bayesian networks;approximated distributions;variational auto-encoder;complex distributions;observation likelihood;tractable distributions;3D object shapes;view-independent loop closure;object shape;range sensor;mobile robot;complex probability distribution;probabilistic observation model;high-level semantic features;complex 3D objects;probabilistic semantic SLAM;variational feature encoding method","","","30","","","","","IEEE","IEEE Conferences"
"Flamen − 7 DOF Robotic Arm to Manipulate a Spanish Fan","M. Harikrishnan Nair; T. Ghanshsyam Singh; G. Chourasia; A. Das; A. Shrivastava; Z. S. Bhatt","SRMIST, KTR Campus, Dept of ECE, Kanchipuram Dist., India; SRMIST, KTR Campus, Dept of ECE, Kanchipuram Dist., India; SRMIST, KTR Campus, Dept of ECE, Kanchipuram Dist., India; SRMIST, KTR Campus, Dept of ECE, Kanchipuram Dist., India; SRMIST, KTR Campus, Dept of ECE, Kanchipuram Dist., India; SRMIST, KTR Campus, Dept of ECE, Kanchipuram Dist., India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4152","4157","A Spanish fan is a hand held traditional fan which is used as an accessory and also by Flamenco dancers. The manipulation of the fan is quite difficult as it involves dynamic motion which includes opening, flapping and closing the fan along a pivotal point. The key points include the motion to be quick and the fan to be opened to the maximum degree possible without human intervention. A robotic arm with 7 Degrees of Freedom (DOF) is used to manipulate the autonomous motion. The fan placed on the table is localized and detected using a camera by background subtraction, masking and filtering; post which the contour of the fan is detected. The pixels obtained is then transformed into real life coordinates. The Dynamixel motors then traverses to the coordinates of the fan's position to grasp, open, flap, close and put the fan down.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594129","Actuation;Automation;Background subtraction;Contour Detection;Coordinate extraction;Filtering;Mapping;Masking;Robotic Arm;Spanish Fan","Fans;Manipulators;Robot kinematics;Actuators;Grasping;Cameras","control engineering computing;fans;manipulators;mobile robots;motion control;position control","7-DOF robotic arm;Flamen;Flamenco dancers;manipulation;traditional fan;Spanish fan","","","10","","","","","IEEE","IEEE Conferences"
"Analysis of Dynamic Response of an MRI-Guided Magnetically-Actuated Steerable Catheter System","E. Erdem Tuna; T. Liu; R. C. Jackson; N. Lombard Poirot; M. Russell; M. C. Çavuşoğlu","Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, 44106, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, 44106, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, 44106, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, 44106, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, 44106, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, 44106, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents a free-space open-loop dynamic response analysis for an MRI -guided magnetically-actuated steerable intra-vascular catheter system. The catheter tip is embedded with a set of current carrying micro-coils. The catheter is directly actuated via the magnetic torques generated on these coils by the magnetic field of the magnetic resonance imaging (MRI)scanner. The relationship between the input current commands and catheter tip deflection angle presents an inherent nonlinearity in the proposed catheter system. The system nonlinearity is analyzed by utilizing a pendulum model. The pendulum model is used to describe the system nonlinearity and to perform an approximate input-output linearization. Then, a black-box system identification approach is performed for frequency response analysis of the linearized dynamics. The optimal estimated model is reduced by observing the modes and considering the Nyquist frequency of the camera system that is used to track the catheter motion. The reduced model is experimentally validated with 3D open-loop Cartesian free-space trajectories. This study paves the way for effective and accurate free-space closed-loop control of the robotic catheter with real-time feedback from MRI guidance in subsequent research.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594308","","Catheters;Coils;Magnetic resonance imaging;Torque;Robots;Chirp;Trajectory","biomedical MRI;catheters;closed loop systems;control nonlinearities;dynamic response;frequency response;linearisation techniques;magnetic actuators;medical image processing;medical robotics;open loop systems;robot vision","MRI-guided magnetically-actuated steerable catheter system;free-space open-loop dynamic response analysis;magnetically-actuated steerable intra-vascular catheter system;current carrying microcoils;magnetic torques;system nonlinearity;pendulum model;approximate input-output linearization;black-box system identification approach;frequency response analysis;camera system;free-space trajectories;robotic catheter;MRI guidance;magnetic resonance imaging scanner;free-space closed-loop control;Nyquist frequency","","","35","","","","","IEEE","IEEE Conferences"
"Robust Robot Learning from Demonstration and Skill Repair Using Conceptual Constraints","C. Mueller; J. Venicx; B. Hayes","University of Colorado Boulder, Department of Computer Science, Engineering Drive, Boulder, CO, 1111, USA; University of Colorado Boulder, Department of Computer Science, Engineering Drive, Boulder, CO, 1111, USA; University of Colorado Boulder, Department of Computer Science, Engineering Drive, Boulder, CO, 1111, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6029","6036","Learning from demonstration (LfD) has enabled robots to rapidly gain new skills and capabilities by leveraging examples provided by novice human operators. While effective, this training mechanism presents the potential for sub-optimal demonstrations to negatively impact performance due to unintentional operator error. In this work we introduce Concept Constrained Learning from Demonstration (CC-LfD), a novel algorithm for robust skill learning and skill repair that incorporates annotations of conceptually-grounded constraints (in the form of planning predicates) during live demonstrations into the LfD process. Through our evaluation, we show that CC-LfD can be used to quickly repair skills with as little as a single annotated demonstration without the need to identify and remove low-quality demonstrations. We also provide evidence for potential applications to transfer learning, whereby constraints can be used to adapt demonstrations from a related task to achieve proficiency with few new demonstrations required.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594133","","Trajectory;Maintenance engineering;Task analysis;Training;Service robots;Planning","learning (artificial intelligence);robots","concept constrained learning from demonstration;robust robot learning;constrained learning;LfD process;conceptually-grounded constraints;robust skill learning;CC-LfD;conceptual constraints;skill repair","","","33","","","","","IEEE","IEEE Conferences"
"Nonlinear Analysis of an Indirectly Controlled Sliding Locomotion Robot","L. Li; F. Asano; I. Tokuda","Japan Advanced Institute of Science and Technology, School of Information Science, 1-1 Asahidai, Nomi, Ishikawa 923-1292, Japan; Japan Advanced Institute of Science and Technology, School of Information Science, 1-1 Asahidai, Nomi, Ishikawa 923-1292, Japan; Department of Mechanical Engineering, Rit-sumeikan University, 1-1-1 Nojihigashi, Kusatsu, Shiga 525-8577, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","With the purpose of achieving stable and energy efficient locomotion on the slippery road surface, a sliding locomotion robot without joint torque but indirectly controlled by an active wobbling mass is recently proposed. In this paper, we deepen the analysis of the mechanism of the indirectly controlled sliding locomotion for further optimization and generalization. First, we derive the equations of dynamics and control. Second, we estimate the natural frequency of the robot, the moving speed and energy efficiency are also evaluated with respect to forcing amplitude and frequency of the wobbling mass. Third, the Arnol'd tongue is introduced to analyze the relationship between achieving efficient locomotion and being entrained. In addition, phase oscillation and synchronization phenomenon are analyzed via hysteresis plot to further interpret the unusual shapes of the Arnol'd tongues. Finally, we analyze the entrained, however, inefficient locomotion by reconfirming the rolling constraints from the mechanical energy dissipation point of view. Our results help better understanding of the indirectly controlling mechanism, and the methods can be applied to other indirectly controlled locomotion robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593401","","Force;Legged locomotion;Tongue;Robot kinematics;Frequency estimation;Friction","legged locomotion;motion control;robot dynamics;vibrations;wheels","indirectly controlling mechanism;indirectly controlled locomotion robots;inefficient locomotion;Arnold tongue;energy efficiency;indirectly controlled sliding locomotion;active wobbling mass;slippery road surface;stable energy efficient locomotion;sliding locomotion robot;nonlinear analysis","","","11","","","","","IEEE","IEEE Conferences"
"Policy Shaping with Supervisory Attention Driven Exploration","T. K. Faulkner; E. S. Short; A. L. Thomaz","Department of Computer Science, University of Texas at Austin, Austin, TX, 78705, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, 78705, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, 78705, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","842","847","Robots deployed for long periods of time need to be able to explore and learn from their environment. One approach to this problem has been reinforcement learning (RL), in which robots receive rewards from the environment that allow them to choose optimal actions. To speed learning when human supervision is available, interactive reinforcement learning solicits feedback from a human teacher. However, this approach typically assumes that learning takes place under continuous supervision, which is unlikely to hold in long-term scenarios. We propose an extension to a method of interactive reinforcement learning, policy shaping, that takes into account human attention. Our approach enables better performance while unattended by favoring information-gathering actions when attended and actions that have received positive feedback when unattended. We test our approach in both simulation and on a robot, finding that our method learns faster than policy shaping and performs more safely than policy shaping while no one is paying attention to the robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594312","","Reinforcement learning;Task analysis;Negative feedback;Markov processes;Prediction algorithms;Intelligent robots","interactive systems;learning (artificial intelligence);mobile robots","policy shaping;robots;human supervision;human teacher;information-gathering actions;interactive reinforcement learning;interactive RL","","","23","","","","","IEEE","IEEE Conferences"
"Hybrid Bayesian Eigenobjects: Combining Linear Subspace and Deep Network Methods for 3D Robot Vision","B. Burchfiel; G. Konidaris","Duke University, Durham, NC; Brown University, Providence, RI","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6843","6850","We introduce Hybrid Bayesian Eigenobjects (HBEOs), a novel representation for 3D objects designed to allow a robot to jointly estimate the pose, class, and full 3D geometry of a novel object observed from a single viewpoint in a single practical framework. By combining both linear subspace methods and deep convolutional prediction, HBEOs efficiently learn nonlinear object representations without directly regressing into high-dimensional space. HBEOs also remove the onerous and generally impractical necessity of input data voxelization prior to inference. We experimentally evaluate the suitability of HBEOs to the challenging task of joint pose, class, and shape inference on novel objects and show that, compared to preceding work, HBEOs offer dramatically improved performance in all three tasks along with several orders of magnitude faster runtime performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593795","","Three-dimensional displays;Robots;Bayes methods;Pose estimation;Databases;Principal component analysis;Task analysis","Bayes methods;eigenvalues and eigenfunctions;image representation;neural nets;regression analysis;robot vision;stereo image processing","linear subspace methods;deep convolutional prediction;nonlinear object representations;Hybrid Bayesian Eigenobjects;deep network methods;3D robot vision;HBEO;3D geometry","","","35","","","","","IEEE","IEEE Conferences"
"Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction","N. T. Viet Tuyen; S. Jeong; N. Y. Chong","School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2008","2013","Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593974","","Robot kinematics;Neurons;Self-organizing feature maps;Trajectory;Training;Collision avoidance","emotion recognition;human-robot interaction;learning (artificial intelligence)","multiculture society;incremental learning model;habitual emotional behaviors;social robot;emotional bodily expressions;imitated robot motions;cultural background;culturally competent robots;long term human-robot interaction","","","30","","","","","IEEE","IEEE Conferences"
"Coverage Path Planning with Adaptive Viewpoint Sampling to Construct 3D Models of Complex Structures for the Purpose of Inspection","R. Almadhoun; T. Taha; D. Gan; J. Dias; Y. Zweiri; L. Seneviratne","Khalifa University of Science Technology and Research, Abu Dhabi, UAE; Khalifa University of Science Technology and Research, Abu Dhabi, UAE; Khalifa University of Science Technology and Research, Abu Dhabi, UAE; Khalifa University of Science Technology and Research, Abu Dhabi, UAE; Khalifa University of Science Technology and Research, Abu Dhabi, UAE; Khalifa University of Science Technology and Research, Abu Dhabi, UAE","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7047","7054","In this paper, we introduce a coverage path planning algorithm with adaptive viewpoint sampling to construct accurate 3D models of complex large structures using Unmanned Aerial Vehicle (UAV). The developed algorithm, Adaptive Search Space Coverage Path Planner (ASSCPP), utilizes an existing 3D reference model of the complex structure and the onboard sensors' noise models to generate paths that are evaluated based on the traveling distance and the quality of the model. The algorithm generates a set of viewpoints by performing adaptive sampling that directs the search towards areas with low accuracy and low coverage. The algorithm predicts the coverage percentage obtained by following the generated coverage path using the reference model. A set of experiments were conducted in real and simulated environments with structures of different complexities to test the validity of the proposed algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593719","","Sensors;Adaptation models;Path planning;Solid modeling;Entropy;Clustering algorithms;Octrees","autonomous aerial vehicles;image sampling;mobile robots;path planning;robot vision;search problems","adaptive search space coverage path planner;unmanned aerial vehicle;coverage path planning;adaptive sampling;onboard sensors;reference model;accurate 3D models;complex structure;adaptive viewpoint sampling","","","20","","","","","IEEE","IEEE Conferences"
"Submap-Based Pose-Graph Visual SLAM: A Robust Visual Exploration and Localization System* The work in this paper is supported by the National Natural Science Foundation of China (61603103, 61673125), the Natural Science Foundation of Guangdong of China (2016A030310293), and the Major Scientific and Technological Special Project of Guangdong of China (2016B090910003).","W. Chen; L. Zhu; Y. Guan; C. R. Kube; H. Zhang","Guangdong University of Technology, Biomimetic and Intelligent Robotics Lab, Guangzhou, China; Guangdong University of Technology, Biomimetic and Intelligent Robotics Lab, Guangzhou, China; Guangdong University of Technology, Biomimetic and Intelligent Robotics Lab, Guangzhou, China; University of Alberta, Department of Computing Science, Edmonton, Canada; Guangdong University of Technology, Biomimetic and Intelligent Robotics Lab, Guangzhou, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6851","6856","For VSLAM (Visual Simultaneous Localization and Mapping), localization is a challenging task, especially for some challenging situations: textureless frames, motion blur, etc. To build a robust exploration and localization system in a given space, a submap-based VSLAM system is proposed in this paper. Our system uses a submap back-end and a visual front-end. The main advantage of our system is its robustness with respect to tracking failure, a common problem in current VSLAM algorithms. The robustness of our system is compared with the state-of-the-art in terms of average tracking percentage. The precision of our system is also evaluated in terms of ATE (absolute trajectory error) RMSE (root mean square error) comparing the state-of-the-art. The ability of our system in solving the “kidnapped” problem is demonstrated. Our system can improve the robustness of visual localization in challenging situations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594097","Monocular VSLAM;Submap-based Backend;Robustness","Image edge detection;Optimization;Robustness;Visualization;Merging;Robots;Tracking","graph theory;mean square error methods;pose estimation;robot vision;SLAM (robots)","VSLAM algorithms;robust visual exploration;visual simultaneous localization and mapping;submap-based pose-graph visual SLAM;robust exploration;visual front-end;submap-based VSLAM system","","","18","","","","","IEEE","IEEE Conferences"
"Heterogeneous Vehicles Routing for Water Canal Damage Assessment","D. Deng; P. Palli; F. Shu; K. Shimada; T. Pang","Faculty of Mechanical Engineering, Carniege Mellon University, 5000 Forbes Ave, Pirrshurgh, PA, 15213, USA; Faculty of Mechanical Engineering, Carniege Mellon University, 5000 Forbes Ave, Pirrshurgh, PA, 15213, USA; Faculty of Mechanical Engineering, Carniege Mellon University, 5000 Forbes Ave, Pirrshurgh, PA, 15213, USA; Faculty of Mechanical Engineering, Carniege Mellon University, 5000 Forbes Ave, Pirrshurgh, PA, 15213, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA, 02139","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2375","2382","In Japan, inspection of irrigation water canals has been mostly conducted manually. However, the huge demand for more regular inspections as infrastructure ages, coupled with the limited time window available for inspection, has rendered manual inspection increasingly insufficient. With shortened inspection time and reduced labor cost, automated inspection using a combination of unmanned aerial vehicles (UAVs) and ground vehicles (cars) has emerged as an attractive alternative to manual inspection. In this paper, we propose a path planning framework that generates optimal plans for UAVs and cars to inspect water canals in a large agricultural area (tens of square kilometers). In addition to optimality, the paths need to satisfy several constraints, in order to guarantee UAV navigation safety and to abide by local traffic regulations. In the proposed framework, the canal and road networks are first modeled as two graphs, which are then partitioned into smaller subgraphs that can be covered by a given fleet of UAVs within one battery charge. The problem of finding optimal paths for both UAVs and cars on the graphs, subject to the constraints, is formulated as a integer quadratic program (IQP). The proposed framework can also quickly generate new plans when a current plan is interrupted. The effectiveness of the proposed framework is validated by simulation results showing the successful generation of plans covering all given canal segments, and the ability to quickly revise the plan when conditions change.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593365","","Irrigation;Automobiles;Inspection;Roads;Planning;Batteries;Routing","autonomous aerial vehicles;canals;graph theory;inspection;integer programming;irrigation;path planning;quadratic programming;vehicle routing","water canal damage assessment;irrigation water canals;manual inspection;shortened inspection time;reduced labor cost;automated inspection;road networks;path planning;UAV;unmanned aerial vehicles;ground vehicles;integer quadratic program;IQP;heterogeneous vehicle routing","","","17","","","","","IEEE","IEEE Conferences"
"An Ensemble with Shared Representations Based on Convolutional Networks for Continually Learning Facial Expressions","H. Siqueira; P. Barros; S. Magg; S. Wermter","Knowledge Technology, Department of Informatics, University of Hamburg, Vogt-Koelln-Str. 30, Hamburg, 22527, Germany; Knowledge Technology, Department of Informatics, University of Hamburg, Vogt-Koelln-Str. 30, Hamburg, 22527, Germany; Knowledge Technology, Department of Informatics, University of Hamburg, Vogt-Koelln-Str. 30, Hamburg, 22527, Germany; Knowledge Technology, Department of Informatics, University of Hamburg, Vogt-Koelln-Str. 30, Hamburg, 22527, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1563","1568","Social robots able to continually learn facial expressions could progressively improve their emotion recognition capability towards people interacting with them. Semi-supervised learning through ensemble predictions is an efficient strategy to leverage the high exposure of unlabelled facial expressions during human-robot interactions. Traditional ensemble-based systems, however, are composed of several independent classifiers leading to a high degree of redundancy, and unnecessary allocation of computational resources. In this paper, we proposed an ensemble based on convolutional networks where the early layers are strong low-level feature extractors, and their representations shared with an ensemble of convolutional branches. This results in a significant drop in redundancy of low-level features processing. Training in a semi-supervised setting, we show that our approach is able to continually learn facial expressions through ensemble predictions using unlabelled samples from different data distributions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594276","","Training;Feature extraction;Robots;Computer architecture;Face recognition;Convolution;Redundancy","convolutional neural nets;emotion recognition;face recognition;feature extraction;human-robot interaction;robot vision;supervised learning","ensemble-based systems;human-robot interactions;unlabelled facial expressions;emotion recognition capability;social robots;continually learning facial expressions;shared representations;ensemble predictions;convolutional branches;low-level feature extractors;convolutional networks","","1","22","","","","","IEEE","IEEE Conferences"
"Compact & Comprehensive Canonical Appearances Discovered Autonomously","K. Türksoy; H. Iṣll Bozma","Electrical and Electronics Eng. Dept., Bogazici University, Intelligent Systems Laboratory, Istanbul, Turkey; Electrical and Electronics Eng. Dept., Bogazici University, Intelligent Systems Laboratory, Istanbul, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1118","1123","This paper presents an exploration approach for discovering canonical appearances in unknown environments using an autonomous ground robot equipped with a depth sensor. This approach is based on the previously proposed two-stage algorithm that alternates between local and global decision making for efficient topological mapping based on bubble space representation. Differing from it, the approach aims to identify vantage viewpoints with characterizing views for subsequent appearance-based learning as well as achieving complete coverage. This is demonstrated by a series of experiments using an outdoor benchmark data set including a comparative study with evaluation metrics including the exploration path length and number of canonical appearances discovered.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593544","","Robot sensing systems;Decision making;Robot kinematics;Cognition;Lasers;Measurement","decision making;image representation;image sensors;learning (artificial intelligence);mobile robots;path planning;robot vision","exploration approach;autonomous ground robot;depth sensor;bubble space representation;exploration path length;topological mapping;canonical appearances;appearance-based learning","","","26","","","","","IEEE","IEEE Conferences"
"Underwater Modeling, Experiments and Control Strategies of FroBot","Y. Yi; F. Zhenhui; Z. Zhongjing; Z. Jianqing","Beijing Institute of Technology, School of Automation, Beijing, China; Beijing Institute of Technology, School of Automation, Beijing, China; Beijing Institute of Technology, School of Automation, Beijing, China; Beijing Institute of Technology, School of Automation, Beijing, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6397","6403","FroBot can locomote both on land and underwater based on its dual swing-legs propulsion mechanism. This paper presents the dynamic model, experimental studies, and control strategies of FroBot underwater. In this work, an experimental setup consisting of two-degree-of-freedom(2DOF) robotic swing-legs is built to study the model of FroBot underwater. We first improve the dynamic model of caudal fins based on the Morison equation. Combined with experimental data, we optimize the model parameters and then obtain the optimal control strategy of uniform swing. In addition, we apply the CPGs control strategy and improve it based on the FroBot model. These two control strategies have their advantages and demonstrate the potential for future use in control applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594455","","Legged locomotion;Mathematical model;Dynamics;Propulsion;Force;Acceleration","legged locomotion;mobile robots;motion control;optimal control;propulsion;robot dynamics;underwater vehicles","two-degree-of-freedom robotic swing-legs;2DOF;Frobot model;Frobot underwater;caudal fins;Morison equation;control applications;CPGs control strategy;optimal control strategy;dynamic model;dual swing-legs propulsion mechanism","","","21","","","","","IEEE","IEEE Conferences"
"Reactive Collision Avoidance Using Real-Time Local Gaussian Mixture Model Maps","A. Dhawale; X. Yang; N. Michael","Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, 15213, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3545","3550","In unknown, cluttered environments, robots require online real-time mapping and collision checking in order to navigate robustly. Discrete map representations are inefficient for collision checking as they are expensive in terms of memory and computation. This paper takes a probabilistic approach to local mapping by representing the environment as a Gaussian Mixture Model (GMM) and leverages its geometric properties to enable efficient collision checking given a time-parameterized trajectory. In contrast to current discretization-based methods, a GMM preserves geometric coverage of the environment without losing representation accuracy with varying map resolutions. We introduce a novel GMM local mapping algorithm that can be used with a single depth camera processed on a single CPU, and provide algorithms for collision avoidance given arbitrary trajectory representations. Finally, we provide experimentation results demonstrating safety, efficiency, and data coverage for real-time collision avoidance with a quadrotor navigating in a cluttered environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593723","","Trajectory;Collision avoidance;Robot sensing systems;Real-time systems;Current measurement;Gaussian mixture model","cameras;collision avoidance;Gaussian processes;geometry;helicopters;mobile robots;probability;trajectory control","collision avoidance;discrete map;GMM local mapping algorithm;gaussian mixture model maps;robots;CPU;quadrotor navigation;depth camera processing;time-parameterized trajectory;geometric properties;probabilistic approach;cluttered environments","","","19","","","","","IEEE","IEEE Conferences"
"Personal Mobility Vehicle Autonomous Navigation Through Pedestrian Flow: A Data Driven Approach for Parameter Extraction","Y. Morales; N. Akai; H. Murase","Institute of Innovation for Future Society, Nagoya University, Nagoya, 464-8603, Japan; Institute of Innovation for Future Society, Nagoya University, Nagoya, 464-8603, Japan; Institute of Innovation for Future Society, Nagoya University, Nagoya, 464-8603, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3438","3444","In this paper we present a data driven approach for safe and smooth autonomous navigation of a personal mobility vehicle (PMV) when facing moving obstacles such as people and bicycles in public pedestrian paths. In a period of three months, data from five different persons driving the robotic PMV in an outdoor environment while facing pedestrians were collected. 2465 clean tracks around the vehicle together with PMVs trajectories were collected. We performed an analysis of the parameters involved for human-driven smooth navigation. Relevant parameters regarding PMV-Human interaction included distance to moving objects, passing side and velocities. Moreover, data suggests the existence of a social navigational distance for the PWv. For autonomous navigation we implemented a Frenet planner to achieve safe and smooth navigation for the passenger and pedestrians around. Experimental results in real pedestrian paths show that the PMV is capable of smoothly following its path while facing pedestrians and bicycles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593902","","Navigation;Legged locomotion;Trajectory;Three-dimensional displays;Wheelchairs;Bicycles","collision avoidance;human computer interaction;mobile robots;navigation;pedestrians;road vehicles;vehicles","personal mobility vehicle autonomous navigation;pedestrian flow;data driven approach;parameter extraction;safe navigation;moving obstacles;public pedestrian paths;robotic PMV;human-driven smooth navigation;PMV-Human interaction","","","37","","","","","IEEE","IEEE Conferences"
"Catenary Tether Shape Analysis for a UAV - USV Team","K. A. Talke; M. De Oliveira; T. Bewley","Unmanned Systems Advanced Development group, Space and Naval Warfare Systems Center Pacific, San Diego, CA, 92110, USA; MC 041, UC San Diego, Dept. of MAE, La Jolla, CA, 92093, USA; MC 041, UC San Diego, Dept. of MAE, La Jolla, CA, 92093, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7803","7809","The quasi-static catenary curve of a semi-slack tether between an essentially stationary unmanned air vehicle (UAV) and a small unmanned surface vehicle (USV) is investigated and characterized. An empirical analysis, performed over a discretized space of vertical and horizontal separations of the two vehicles, determines an optimum cable length & tension for maximizing system robustness during the vertical heave of the USV due to high seas. Operating at this optimum condition allows for equal displacements of the USV in the up and down directions, minimizing the possibility of both fouling (with the tether touching the water) and excessive downforce on the UAV (with the tether pulled taut) during dynamic heave events. Scaling the horizontal offset, tether length, and tension by the flying height collapses all empirical results into convenient curves depending only on a nondimensional relative position parameter (Δx/Δy), accurately fit by low order polynomials. This eliminates the need for a lookup table, and decreases computation time during implementation. The heave robustness analysis results in a recommended operating relative position of Δx/Δy ≈ .46. Experimental results are presented and confirm the catenary analysis for the proposed tether.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594280","","Unmanned aerial vehicles;Winches;Robustness;Mathematical model;Shape;Vehicle dynamics;Sea surface","aerodynamics;autonomous aerial vehicles;hydrodynamics;marine vehicles;polynomials;position control","dynamic heave events;tether length;convenient curves;nondimensional relative position parameter;catenary analysis;catenary tether shape analysis;UAV - USV team;quasistatic catenary curve;semislack tether;unmanned surface vehicle;empirical analysis;system robustness;vertical heave;optimum condition;cable length;stationary unmanned air vehicle;heave robustness analysis;lookup table","","","20","","","","","IEEE","IEEE Conferences"
"A Practical Method to Speed-Up the Experimental Procedure of Iterative Learning Controllers","O. Koçan; A. Manecy; C. Poussot-Vassal","Info, Processing and Systems, ONERA, The French Aerospace Lab, DTIS, Toulouse, France; Info, Processing and Systems, ONERA, The French Aerospace Lab, DTIS, Toulouse, France; Info, Processing and Systems, ONERA, The French Aerospace Lab, DTIS, Toulouse, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6411","6416","This paper proposes a practical approach for fastening the lengthy experimentational processes that may occur with iterative learning control (ILC) upto a certain level using simple low-order identified models. The traditional practice in ILC experiments is to update the ILC signal by directly using the experimental data after each run of the process which corresponds to one ILC update per one run. When considered from the point of experimental time, even conducting a moderate number of ILC updates can take quite long with this procedure. Since an accurate linear model can adequately represent the actual system upto a certain amplitude and/or frequency of the desired reference, we propose that the total experimental time can be reduced by updating the ILC signal via predicted system data until the limits of the linear model. This approach allows one to carry out large number of ILC updates while not needing to carry out the same amount of real experiments. Consequently, a significant number of experiments that would be needed for achieving the same results can be skipped with a simulation approach. The efficiency of the proposed method was tested through experimentation with three different UAV reference trajectories and the results demonstrated that it is possible to attain significant amount of tracking precision in several flight experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594025","","Trajectory;Data models;Optimization;Attitude control;Process control;Predictive models;Tracking","adaptive control;autonomous aerial vehicles;control system synthesis;iterative learning control;vehicle dynamics","traditional practice;ILC experiments;ILC signal;experimental data;accurate linear model;total experimental time;predicted system data;practical method;experimental procedure;iterative learning controllers;practical approach;lengthy experimentational processes;iterative learning control;low-order identified models","","","10","","","","","IEEE","IEEE Conferences"
"Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation","A. Kouris; C. Bouganis","Imperial College, Department of Electrical and Electronic Engineering, London; Imperial College, Department of Electrical and Electronic Engineering, London","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594204","","Robots;Navigation;Sensors;Drones;Cameras;Task analysis;Trajectory","autonomous aerial vehicles;collision avoidance;convolutional neural nets;feature extraction;indoor navigation;learning (artificial intelligence);learning systems;mobile robots;motion control;neurocontrollers;regression analysis;robot vision;sensor fusion;velocity control","indoor flights;unmanned aerial vehicles;civilian applications;indoor-flight dataset;agent distance-to-collision prediction;drone safe deployment;on-board monocular camera;external sensors;spatio-temporal feature extraction;static appearance information;motion information;robot distance estimation;linear velocity;navigation policy learning;real-distance labels;raw visual input;regression CNN;real-time obstacle avoidance;indoor robot navigation;autonomous navigation methods;UAV;self-supervised CNN-based approach;navigation policy","","","28","","","","","IEEE","IEEE Conferences"
"A Novel Design of Extended Coaxial Spherical Joint Module for a New Modular Type-Multiple DOFs Robotic Platform","J. Lee; J. Noh; J. Yang; W. Yang","Kwangwoon University, Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea; Hankook Mirae Technology Co., Ltd., Gunpo, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","955","960","In this study, we propose an extended coaxial spherical joint module (E-CoSMo) with three to four degrees of freedom (DOFs) for a multi-DOF robot platform. The E-CoSMo consists of a coaxial spherical parallel mechanism (CSPM) with three DOFs and one extended DOF based on a universal joint mechanism (UJM) coaxially connected to the CSPM. This structure enables the application of serial link configuration (such as shoulder-elbow) with wide and universal ROMs while allowing all four actuators to be placed in the base. This makes the inertia of the moving link part to be dramatically reduced and thus contributes to decreasing the mechanical impedance of the multi-DOF robot system. In addition, through the effective design of the coaxial spherical joint module, the output rotational torque in a specific axial direction reaches approximately three times then the torque of a single actuator. To optimally implement this, we applied an optimal design approach that considers the mechanical performance and design constraints. The mechanical impedance reduction effect through the proposed module is discussed. The feasibility of the E-CoSMo is also verified through a dynamic simulation. Finally, the proposed mechanism is verified using a fabricated prototype.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593687","","Conferences;Intelligent robots","actuators;biomechanics;motion control;robot dynamics;robot kinematics;torque","design constraints;mechanical impedance reduction effect;E-CoSMo;extended coaxial spherical joint module;robot platform;coaxial spherical parallel mechanism;universal joint mechanism;mechanical performance;modular type-multiple DOFs robotic platform;single actuator","","","25","","","","","IEEE","IEEE Conferences"
"Enhancing the Command-Following Bandwidth for Transparent Bilateral Teleoperation","H. Singh; A. Jafari; A. Peer; J. Ryu","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, 82234, Germany; University of the West of England, Bristol, United Kingdom; University of the West of England, Bristol, United Kingdom; School of Mechanical Engineering, Korea University of Technology and Education, Cheonan, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4972","4979","Enhancing transparency of a teleoperation system by increasing the command-following bandwidth has not received lots of attention so far. This is considered a challenging task since in a teleoperation system the command-following bandwidth of the slave robot motion controller cannot be increased with a conventional motion controller as the desired trajectory is instantaneously commanded by the human user and thus, cannot be considered to be given in a pre-computed, smooth second order derivative form. We propose a method to increase the command-following bandwidth by extending the previously introduced Successive Stiffness Increment (SSI) approach to bilateral teleoperation. The approach allows realizing a very high motion controller gain, which cannot be realized with a conventional bilateral teleoperation controller as confirmed by experimental results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593866","","Pressing;Force;Bandwidth;Haptic interfaces;Trajectory;Manipulators","mobile robots;motion control;telerobotics","command-following bandwidth;transparent bilateral teleoperation;slave robot motion controller;high motion controller gain;human user;successive stiffness increment approach;SSI approach;bilateral teleoperation controller","","","15","","","","","IEEE","IEEE Conferences"
"DS-SLAM: A Semantic Visual SLAM towards Dynamic Environments","C. Yu; Z. Liu; X. Liu; F. Xie; Y. Yang; Q. Wei; Q. Fei","Department of Mechanical Engineering, Tsinghua University, Beijing, China; School of Instrumentation Science and Opto-electronics Engineering, Beihang University, Beijing, China; Department of Mechanical Engineering, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1168","1174","Simultaneous Localization and Mapping (SLAM) is considered to be a fundamental capability for intelligent mobile robots. Over the past decades, many impressed SLAM systems have been developed and achieved good performance under certain circumstances. However, some problems are still not well solved, for example, how to tackle the moving objects in the dynamic environments, how to make the robots truly understand the surroundings and accomplish advanced tasks. In this paper, a robust semantic visual SLAM towards dynamic environments named DS-SLAM is proposed. Five threads run in parallel in DS-SLAM: tracking, semantic segmentation, local mapping, loop closing and dense semantic map creation. DS-SLAM combines semantic segmentation network with moving consistency check method to reduce the impact of dynamic objects, and thus the localization accuracy is highly improved in dynamic environments. Meanwhile, a dense semantic octo-tree map is produced, which could be employed for high-level tasks. We conduct experiments both on TUM RGB-D dataset and in real-world environment. The results demonstrate the absolute trajectory accuracy in DS-SLAM can be improved one order of magnitude compared with ORB-SLAM2. It is one of the state-of-the-art SLAM systems in high-dynamic environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593691","","Semantics;Simultaneous localization and mapping;Image segmentation;Feature extraction;Heuristic algorithms;Three-dimensional displays;Optical flow","mobile robots;object detection;path planning;robot vision;SLAM (robots)","high-dynamic environments;ORB-SLAM2;dense semantic octo-tree map;dynamic objects;DS-SLAM combines semantic segmentation network;dense semantic map creation;local mapping;robust semantic visual SLAM;impressed SLAM systems","","","19","","","","","IEEE","IEEE Conferences"
"Hierarchical Path Planner Using Workspace Decomposition and Parallel Task-Space RRTs","G. Mesesan; M. A. Roa; E. Icer; M. Althoff","Institute of Robotics and Mechatronics German Aerospace Center (DLR), 82234 Wessling, Germany; Institute of Robotics and Mechatronics German Aerospace Center (DLR), 82234 Wessling, Germany; Department of Informatics, Technische Universitat Munchen, 85748 Garching, Germany; Department of Informatics, Technische Universitat Munchen, 85748 Garching, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents a hierarchical path planner consisting of two stages: a global planner that uses workspace information to create collision-free paths for the robot end-effector to follow, and multiple local planners running in parallel that verify the paths in the configuration space by expanding a task-space rapidly-exploring random tree (RRT). We demonstrate the practicality of our approach by comparing it with state-of-the-art planners in several challenging path planning problems. While using a single tree, our planner outperforms other single tree approaches in task-space or configuration space (C-space), while its performance and robustness are comparable to or better than that of parallelized bidirectional C-space planners.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593870","","Task analysis;Path planning;End effectors;Partitioning algorithms;Collision avoidance","collision avoidance;end effectors;trees (mathematics)","path planning problems;C-space planners;configuration space;robot end-effector;collision-free paths;workspace information;global planner;task-space RRTs;workspace decomposition;hierarchical path planner","","","25","","","","","IEEE","IEEE Conferences"
"Learning Sample-Efficient Target Reaching for Mobile Robots","A. Khan; V. Kumar; A. Ribeiro","GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, 19104","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3080","3087","In this paper, we propose a novel architecture and a self-supervised policy gradient algorithm, which employs unsupervised auxiliary tasks to enable a mobile robot to learn how to navigate to a given goal. The dependency on the global information is eliminated by providing only sparse range-finder measurements to the robot. The partially observable planning problem is addressed by splitting it into a hierarchical process. We use convolutional networks to plan locally, and a differentiable memory to provide information about past time steps in the trajectory. These modules, combined in our network architecture, produce globally consistent plans. The sparse reward problem is mitigated by our modified policy gradient algorithm. We model the robots uncertainty with unsupervised tasks to force exploration. The novel architecture we propose with the modified version of the policy gradient algorithm allows our robot to reach the goal in a sample efficient manner, which is orders of magnitude faster than the current state of the art policy gradient algorithm. Simulation and experimental results are provided to validate the proposed approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594168","","Task analysis;Robot sensing systems;Planning;Encoding;Uncertainty;Training","gradient methods;learning (artificial intelligence);mobile robots;path planning","self-supervised policy gradient algorithm;unsupervised auxiliary tasks;sparse range-finder measurements;convolutional networks;network architecture;sparse reward problem;robots uncertainty;unsupervised tasks;mobile robots;planning problem;sample-efficient target reaching learning","","","19","","","","","IEEE","IEEE Conferences"
"Development of High-Speed Type Peristaltic Crawling Robot for Long-Distance and Complex-Line Sewer Pipe Inspection","Y. Mano; R. Ishikawa; Y. Yamada; T. Nakamura","Faculty of Science and Engineering, Chuo University, Department of Precision Mechanics, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Chuo University, Department of Precision Mechanics, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Chuo University, Department of Precision Mechanics, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Chuo University, Department of Precision Mechanics, Tokyo, 112-8551, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8177","8183","Currently, serious accidents are caused frequently by the aging of sewer pipes. Therefore, to inspect sewer pipes, we developed a peristaltic crawling robot that reproduces the locomotion of an earthworm. This robot can drive for more than 100m, and it can be used for the maintenance of sewer pipes (100A pipes). However, the speed of the robot is low. There are two causes. First, the units of the previous robot have steps of artificial muscle fastening. These steps increase the diameter of the artificial muscles. A smaller diameter of the artificial muscles is advantageous for the speed of the robot inside the pipes. Second, the previous robot has slow air response. In this study, we used large-sized solenoid valves to overcome this drawback.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593436","","Muscles;Cameras;Robot vision systems;Mathematical model;Inspection;Contracts","electroactive polymer actuators;inspection;mobile robots;pipelines;sanitary engineering","sewer pipe inspection;locomotion;artificial muscle fastening;high-speed type peristaltic crawling robot","","","13","","","","","IEEE","IEEE Conferences"
"Strategic-Tactical Planning for Autonomous Underwater Vehicles over Long Horizons","D. Buksz; M. Cashmore; B. Krarup; D. Magazzeni; B. Ridder","Department of Informatics, King's College London, London, WC2R 2LS; Department of Informatics, King's College London, London, WC2R 2LS; Department of Informatics, King's College London, London, WC2R 2LS; Department of Informatics, King's College London, London, WC2R 2LS; Department of Informatics, King's College London, London, WC2R 2LS","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3565","3572","In challenging environments where human intervention is expensive, robust and persistent autonomy is a key requirement. AI Planners can efficiently construct plans to achieve this long-term autonomous behaviour. However, in plans which are expected to last over days, or even weeks, the size of the state-space becomes too large for current planners to solve as a single problem. These problems are well-suited to decomposition and abstraction planning techniques. We present a novel approach in the context of persistent autonomy in autonomous underwater vehicles, in which tasks are complex and diverse and plans cannot be precomputed. Our approach performs a decomposition into a two-level hierarchical structure, which dynamically constructs planning problems at the upper level of the hierarchy using solution plans from the lower level. Solution plans are then executed and monitored simultaneously at both levels. We evaluate the approach, showing that compared to strictly top-down hierarchical decompositions, our approach leads to more robust solution plans of higher quality.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594347","","Task analysis;Planning;Manifolds;Batteries;Inspection;Robots;Valves","autonomous underwater vehicles;control engineering computing;mobile robots;planning (artificial intelligence);robot dynamics;vehicle dynamics","strategic-tactical planning;autonomous underwater vehicles;long horizons;persistent autonomy;AI Planners;long-term autonomous behaviour;abstraction planning techniques;two-level hierarchical structure;hierarchical decompositions","","","26","","","","","IEEE","IEEE Conferences"
"Virtual Borders: Accurate Definition of a Mobile Robot's Workspace Using Augmented Reality","D. Sprute; K. Tönnies; M. König","Bielefeld University of Applied Sciences., Campus Minden, Minden, 32427, Germany; Otto-von-Guericke University Magdeburg, Faculty of Computer Science, Magdeburg, 39106, Germany; Bielefeld University of Applied Sciences., Campus Minden, Minden, 32427, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8574","8581","We address the problem of interactively controlling the workspace of a mobile robot to ensure a human-aware navigation. This is especially of relevance for non-expert users living in human-robot shared spaces, e.g. home environments, since they want to keep the control of their mobile robots, such as vacuum cleaning or companion robots. Therefore, we introduce virtual borders that are respected by a robot while performing its tasks. For this purpose, we employ a RGB-D Google Tango tablet as human-robot interface in combination with an augmented reality application to flexibly define virtual borders. We evaluated our system with 15 non-expert users concerning accuracy, teaching time and correctness and compared the results with other baseline methods based on visual markers and a laser pointer. The experimental results show that our method features an equally high accuracy while reducing the teaching time significantly compared to the baseline methods. This holds for different border lengths, shapes and variations in the teaching process. Finally, we demonstrated the correctness of the approach, i.e. the mobile robot changes its navigational behavior according to the user-defined virtual borders.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593615","","Education;Navigation;Robot kinematics;Visualization;Robot sensing systems;Mobile robots","augmented reality;human-robot interaction;mobile robots;navigation;path planning;service robots","mobile robot;human-aware navigation;nonexpert users;vacuum cleaning;human-robot interface;augmented reality application;teaching time;baseline methods;user-defined virtual borders","","","21","","","","","IEEE","IEEE Conferences"
"Ground Disturbance Rejection Approach for Mobile Robotic Manipulators with Hydraulic Actuators","M. Rigotti-Thompson; M. Torres-Torriti; F. A. Cheein; G. Troni","Pontificia Universidad Católica de Chile, Department of Electrical Engineering, Macul, Santiago, Av. Vicuña Mackenna, 4860, Chile; Pontificia Universidad Católica de Chile, Department of Electrical Engineering, Macul, Santiago, Av. Vicuña Mackenna, 4860, Chile; Universidad Técnica Federico Santa María, Department of Electronic Engineering, Valparaiso, Av. España, 1680, Chile; Pontificia Universidad Católica de Chile, Department of Mechanical Engineering, Macul, Santiago, Av. Vicuña Mackenna, 4860, Chile","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5980","5986","Reducing material spillage by robotic mining mobile manipulators, such as front-end loaders, is necessary to improve mining operations. To this end, the present work proposes an approach to reduce disturbances on the end-effector induced by the terrain and propagated through the wheels and arm links of the machine. The proposed approach is based on an H<sub>∞</sub> control strategy that includes a feedforward action, computed using the pitch rate of the mobile base, and considers the hydraulic arm dynamics, as well as the reaction forces in the contact points of the mobile base, which is modeled as a floating body with non-permanent ground contacts. Alternative control schemes based on the classic proportional-derivative (PD) control, and the Active Disturbance Rejection Control (ADRC), with and without feedforward action, were also implemented and experimentally evaluated using a semiautonomous Cat<sup>®</sup> 262C compact skid-steer loader equipped with inclination and inertial sensors. The proposed method reduces disturbances by at least 70% when climbing ramps at 25% of the machine's maximum speed, and by at least 20% when driving over speed bumps which produce disturbances similar to that caused by stones. The proposed disturbance attenuation strategy should help reducing the spillage of material when driving over mounds, inclines or spilled rocks, especially considering that even if existing autonomous machines are able to drive with little operator supervision along mining galleries, they are often unable to avoid disturbing material on the ground or the characteristic unevenness of mining terrains.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594172","","Manipulator dynamics;Force;Dynamics;Mathematical model;Hydraulic actuators;Wheels","active disturbance rejection control;end effectors;feedforward;H∞ control;hydraulic actuators;loading equipment;mining;mobile robots;PD control;vehicle dynamics;wheels","active disturbance rejection control;skid-steer loader;H∞ control;PD control;ADRC;inertial sensors;hydraulic arm dynamics;wheels;end-effector;front-end loaders;robotic mining mobile manipulators;material spillage;hydraulic actuators;autonomous machines;feedforward action;proportional-derivative control","","","18","","","","","IEEE","IEEE Conferences"
"Contact Localization and Force Estimation of Soft Tactile Sensors Using Artificial Intelligence","D. Kim; Y. Park","Seoul National University, The Department of Mechanical and Aerospace Engineering, Seoul, 08826, Republic of Korea; Seoul National University, The Department of Mechanical and Aerospace Engineering, Seoul, 08826, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7480","7485","Soft artificial skin sensors that can detect contact forces as well as their locations are attractive in various soft robotics applications. However, soft sensors made of polymer materials have inherent limitations of hysteresis and nonlinearity in response, which makes it highly difficult to implement traditional calibration techniques and yields poor estimation performance. In this paper, we propose intelligent algorithms based on machine learning and logics that can improve the performance of soft sensors. The proposed methods in this paper could be solutions to the aforementioned long-standing problems. They can also be used to simplify the system complexity by reducing the number of signal wires. Three machine learning techniques are discussed in this paper: an artificial neural network (ANN), the k-nearest neighbors (k-NN) algorithm, and a recurrent neural network (RNN). The Preisach model of hysteresis and simple logics were used to support these algorithms. We proved that classifying contact locations on a soft sensor is possible using simple algorithms in real time. Also, force estimation of a single contact was possible using an ANN with the Preisach method. Finally, we successfully estimated forces of multiple contact locations by predicting the outputs of mixed RNN results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593440","","Sensors;Force;Hysteresis;Microchannels;Estimation;Wires;Real-time systems","intelligent sensors;nearest neighbour methods;recurrent neural nets;skin;tactile sensors","recurrent neural network;Preisach model;multiple contact locations;k-nearest neighbors algorithm;artificial neural network;machine learning techniques;soft robotics applications;soft artificial skin sensors;artificial intelligence;soft tactile sensors","","","17","","","","","IEEE","IEEE Conferences"
"Real-Time Quad-Rotor Path Planning for Mobile Obstacle Avoidance Using Convex Optimization","M. Szmuk; C. A. Pascucci; B. AÇikmeşe","University of Washington, The Autonomous Controls Laboratory of the Department of Aeronautics and Astronautics, Seattle, WA 98105, USA; University of Washington, The Autonomous Controls Laboratory of the Department of Aeronautics and Astronautics, Seattle, WA 98105, USA; University of Washington, The Autonomous Controls Laboratory of the Department of Aeronautics and Astronautics, Seattle, WA 98105, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, we employ convex optimization to perform real-time 3-dimensional path planning on-board a quad-rotor and demonstrate its real-time capabilities. Building on our previous work, we make the following modifications: (1)we assume the obstacles are mobile, and (2)we introduce a simple framework to continuously recompute and update the trajectory. The contribution of this paper is to demonstrate the feasibility of real-time on-board convex-optimization-based path planning. For multi-rotors with fixed-pitch propellers, this path planning problem has two sources of non-convexity. First, since fixed-pitch actuators produce uni-directional thrust, the commanded total thrust must be maintained above a non-zero minimum in order to retain sufficient independent attitude control authority. The second source of non-convexity is due to the keep-out zones that envelop each obstacle. To circumvent the non-convexities introduced by these control and state constraints, we employ lossless and successive con-vexification, respectively. Consequently, we cast the original problem as a sequence of Second-Order Cone Programming problems, which can be solved quickly and reliably on-board. We conclude by presenting indoor flight demonstration and timing results of a scenario with three mobile obstacles. In this scenario, our algorithm assumes that the obstacles move with constant acceleration, and is re-executed regularly to account for uncertainties in the motion of the obstacles. The results show that new trajectories can be computed at rates in excess of 10 Hz, quickly enough to adapt to the uncertainty introduced in our flight demonstration.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594351","","Trajectory;Real-time systems;Software;Acceleration;Vehicle dynamics;Attitude control","attitude control;collision avoidance;convex programming;helicopters;propellers","mobile obstacle avoidance;on-board convex-optimization-based path planning;multirotors;fixed-pitch propellers;fixed-pitch actuators;uni-directional thrust;commanded total thrust;sufficient independent attitude control authority;indoor flight demonstration;second-order cone programming problems;real-time quad-rotor path planning;real-time 3-dimensional path planning","","","25","","","","","IEEE","IEEE Conferences"
"LandmarkBoost: Efficient visualContext Classifiers for Robust Localization","M. Dymczyk; I. Gilitschenski; J. Nieto; S. Lynen; B. Zeisl; R. Siegwart","ETH, Autonomous Systems Lab, Zürich; CSAIL, MIT; ETH, Autonomous Systems Lab, Zürich; Google Inc., Zürich; Google Inc., Zürich; ETH, Autonomous Systems Lab, Zürich","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","677","684","The growing popularity of autonomous systems creates a need for reliable and efficient metric pose retrieval algorithms. Currently used approaches tend to rely on nearest neighbor search of binary descriptors to perform the 2D-3D matching and guarantee realtime capabilities on mobile platforms. These methods struggle, however, with the growing size of the map, changes in viewpoint or appearance, and visual aliasing present in the environment. The rigidly defined descriptor patterns only capture a limited neighborhood of the keypoint and completely ignore the overall visual context. We propose LandmarkBoost - an approach that, in contrast to the conventional 2D-3D matching methods, casts the search problem as a landmark classification task. We use a boosted classifier to classify landmark observations and directly obtain correspondences as classifier scores. We also introduce a formulation of visual context that is flexible, efficient to compute, and can capture relationships in the entire image plane. The original binary descriptors are augmented with contextual information and informative features are selected by the boosting framework. Through detailed experiments, we evaluate the retrieval quality and performance of Landmark-Boost, demonstrating that it outperforms common state-of-the-art descriptor matching methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594100","","Visualization;Feature extraction;Measurement;Robots;Three-dimensional displays;Pose estimation;Context modeling","image capture;image classification;image matching;image retrieval;nearest neighbour methods;pose estimation;search problems;stereo image processing","metric pose retrieval algorithms;image plane;state-of-the-art descriptor matching methods;visualContext classifiers;binary descriptors;robust localization;Landmark-Boost;boosting framework;contextual information;landmark observations;boosted classifier;landmark classification task;2D-3D matching methods;visual context;mobile platforms;nearest neighbor search;reliable pose retrieval algorithms","","","44","","","","","IEEE","IEEE Conferences"
"Optimal Time Allocation for Quadrotor Trajectory Generation","F. Gao; W. Wu; J. Pan; B. Zhou; S. Shen","Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4715","4722","In this paper, we present a framework to do optimal time allocation for quadrotor trajectory generation. Using this method, we can generate minimum-time piecewise polynomial trajectories for quadrotor flights. We decouple the quadrotor trajectory generation problem into two folds. Firstly we generate a smooth and safe curve which is parameterized by a virtual variable. This curve named spatial trajectory is independent of time and has fixed spatial properties. Then a mapping function which decides how the quadrotor moves along the spatial trajectory respecting kinodynamic limits is found by minimizing total trajectory time. The mapping function maps the virtual variable to time is named temporal trajectory. We formulate the minimum-time temporal trajectory generation problem as a convex program which can be efficiently solved. We show that the proposed method can corporate with various types of previous trajectory generation method to obtain the optimal time allocation. The proposed method is integrated into a customized light-weight quadrotor platform and is validated by presenting autonomous flights in indoor and outdoor environments. We release our code for time optimization as an open-source ros-package.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593579","","Trajectory;Resource management;Safety;Optimization;Acceleration;Time-domain analysis;Shape","autonomous aerial vehicles;convex programming;helicopters;mobile robots;optimal control;polynomials;robot dynamics;trajectory control","optimal time allocation;quadrotor flights;quadrotor trajectory generation problem;spatial trajectory;time optimization;polynomial trajectories;quadrotor platform;kinodynamic limits;autonomous flights;open-source ROS-package;temporal trajectory;convex program;mapping function","","1","18","","","","","IEEE","IEEE Conferences"
"Multi-Agent Imitation Learning for Driving Simulation","R. P. Bhattacharyya; D. J. Phillips; B. Wulfe; J. Morton; A. Kuefler; M. J. Kochenderfer","Stanford Intelligent Systems Laboratory, Stanford University, Stanford, CA, 94305, USA; Stanford Intelligent Systems Laboratory, Stanford University, Stanford, CA, 94305, USA; Stanford Intelligent Systems Laboratory, Stanford University, Stanford, CA, 94305, USA; Stanford Intelligent Systems Laboratory, Stanford University, Stanford, CA, 94305, USA; Osaro Inc., 1182nd Street, Suite 200, San Francisco, CA, 94105, USA; Stanford Intelligent Systems Laboratory, Stanford University, Stanford, CA, 94305, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1534","1539","Simulation is an appealing option for validating the safety of autonomous vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been shown to learn representative human driver models. These human driver models were learned through training in single-agent environments, but they have difficulty in generalizing to multi-agent driving scenarios. We argue these difficulties arise because observations at training and test time are sampled from different distributions. This difference makes such models unsuitable for the simulation of driving scenes, where multiple agents must interact realistically over long time horizons. We extend GAIL to address these shortcomings through a parameter-sharing approach grounded in curriculum learning. Compared with single-agent GAIL policies, policies generated by our PS-GAIL method prove superior at interacting stably in a multi-agent setting and capturing the emergent behavior of human drivers.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593758","","Vehicles;Training;Trajectory;Optimization;Biological system modeling;Testing;Markov processes","intelligent transportation systems;learning (artificial intelligence);multi-agent systems","multiagent Imitation Learning;human drivers;multiagent setting;PS-GAIL method;single-agent GAIL policies;curriculum learning;multiple agents;test time;multiagent driving scenarios;single-agent environments;representative human driver models;Generative Adversarial Imitation Learning;autonomous vehicles;appealing option","","","29","","","","","IEEE","IEEE Conferences"
"Impedance Control of a High Performance Twisted-Coiled Polymer Actuator","T. Luong; K. Kim; S. Seo; J. H. Park; Y. Kim; S. Y. Yang; K. H. Cho; J. C. Koo; H. R. Choi; H. Moon","Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea; Sungkyunkwan University, Faculty of Mechanical Engineering, Suwon, 2066, Seobu-ro, Jangan-gu, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8701","8706","This paper presents a 1-link robotic arm that is antagonistically driven by one pair of a high performance super-coiled polymer actuators with an embedded controller. The actuator which is made from Spandex and nylon fibers is low-cost, easy to fabricate and light-weight. Moreover, it can generate large displacement and provide Joule heating capability. The main contribution of the paper is the model-based impedance controller, which enables position control of the antagonistic joint with variable stiffness and damping. The impedance control is a torque-based law, which in turn depends on a proposed backstepping control law to control the force of each actuator. The control system is proved to be stable using dissipativity stability theory and verified through experiments. Experimental results show that our system can track the angular position reference with the worst position error of 0.43deg and root-mean squared error of 0.16deg at steady state for sinusoidal waveform tracking (with the frequency of 0.1Hz), and the worst position error of 0.2deg for set-point regulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593937","","Actuators;Impedance;Mathematical model;Force;Damping;Strain;Water heating","actuators;closed loop systems;control nonlinearities;control system synthesis;damping;digital control;force control;manipulators;motion control;position control;stability","worst position error;impedance control;angular position reference;control system;backstepping control law;torque-based law;variable stiffness;position control;model-based impedance controller;Joule heating capability;nylon fibers;embedded controller;high performance super-coiled polymer actuators;1-link robotic arm;high performance twisted-coiled polymer actuator","","","21","","","","","IEEE","IEEE Conferences"
"Computing a Collision-Free Path Using the Monogenic Scale Space","K. Holmquist; O. Şenel; M. Felsberg","Computer Vision Laboratory, Linköping University, Department of Electrical Engineering, Sweden; Computer Vision Laboratory, Linköping University, The Department of Electrical Engineering, Sweden; Computer Vision Laboratory, Linköping University, Department of Electrical Engineering, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8097","8102","Mobile robots have been used for various purposes with different functionalities which require them to freely move in environments containing both static and dynamic obstacles to accomplish given tasks. One of the most relevant capabilities in terms of navigating a mobile robot in such an environment is to find a safe path to a goal position. This paper shows that there exists an accurate solution to the Laplace equation which allows finding a collision-free path and that it can be efficiently calculated for a rectangular bounded domain such as a map which is represented as an image. This is accomplished by the use of the monogenic scale space resulting in a vector field which describes the attracting and repelling forces from the obstacles and the goal. The method is shown to work in reasonably convex domains and by the use of tessellation of the environment map for non-convex environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593583","","Kernel;Laplace equations;Mathematical model;Mobile robots;Magnetic domains;Magnetic resonance imaging","collision avoidance;Laplace equations;mobile robots;multi-robot systems;position control","static obstacles;dynamic obstacles;mobile robot;safe path;goal position;Laplace equation;collision-free path;rectangular bounded domain;monogenic scale space;environment map;nonconvex environments;functionalities","","","21","","","","","IEEE","IEEE Conferences"
"Human-in-the-loop Augmented Mapping","A. Sidaoui; I. H. Elhajj; D. Asmar","Maroun Semaan Faculty of Engineering and Architecture, Electrical and Computer Engineering Department, American University of Beirut, Riad El Solh, Beirut, 11072020, Lebanon; Maroun Semaan Faculty of Engineering and Architecture, Electrical and Computer Engineering Department, American University of Beirut, Riad El Solh, Beirut, 11072020, Lebanon; Maroun Semaan Faculty of Engineering and Architecture, Electrical and Computer Engineering Department, American University of Beirut, Riad El Solh, Beirut, 11072020, Lebanon","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3190","3195","In this paper we develop a real-time human augmented mapping system. This approach replaces the traditional offline post processing of maps by a user-friendly system allowing for online editing capabilities. A wide number of applications that acquire accurate mapping of the environment could benefit from such a solution. The proposed framework consists of two main parts: 2D map building using LIDAR, encoders, and IMU; and a user interface for human map augmentation. The first part is built over Gmapping ROS package, while the second is developed in Unity software. Realworld experiments validated the ability of our system to correct for sensor noise and various mapping errors, thus increasing the accuracy of the obtained maps without additional computational costs.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594494","","Two dimensional displays;Laser radar;Simultaneous localization and mapping;Three-dimensional displays;Corporate acquisitions","inertial systems;mobile robots;operating systems (computers);optical radar;path planning;robot programming;user interfaces","2D map building;user interface;human map augmentation;LIDAR;Gmapping ROS package;Unity software;online editing capabilities;user-friendly system;traditional offline post processing;real-time human augmented mapping system;human-in-the-loop;mapping errors","","","25","","","","","IEEE","IEEE Conferences"
"Online Learning of Body Orientation Control on a Humanoid Robot Using Finite Element Goal Babbling","P. Loviken; N. Hemion; A. Laflaquière; M. Spranger; A. Cangelosi","Softbank Robotics Europe, AI Lab, Paris, France; Softbank Robotics Europe, AI Lab, Paris, France; Softbank Robotics Europe, AI Lab, Paris, France; Sony Computer Science Laboratories Inc., Tokyo, Japan; University of Plymouth, Plymouth, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4091","4098","How can high dimensional robots learn general sets of skills from experience in the real world? Many previous approaches focus on maximizing a single utility function and require large datasets of experience to do this, something that is not possible to collect outside of simulation as every data point is expensive both in time and in a potential wear down of the robot. This paper addresses this question using a newly developed framework called Finite Element Goal Babbling (FEGB). FEGB is an online learning method that aims at providing general control over some measurable feature, in contrast to optimizing it to some given utility function. It generalizes standard goal babbling by breaking down the full learning problem into local sub-problems, and combining it with a planner that learns how to navigate between these subproblems. We test FEGB using a real humanoid robot Nao, and find that it could quickly learn to robustly control its body orientation. After only 20-30 minutes of training, the robot could freely move into any body orientation between lying on either side and on its back. Rapid learning of body orientation control in high dimensional real robots is largely an unexplored field of robotics, and although many challenges remain, FEGB shows a feasible approach to the problem.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593762","","Task analysis;Aerospace electronics;Finite element analysis;Space exploration;Humanoid robots;Robot sensing systems","control engineering computing;finite element analysis;humanoid robots;learning (artificial intelligence);optimisation;position control;robust control","finite element goal babbling;utility function maximization;Nao humanoid robot;robust control;online learning method;FEGB;body orientation control;time 20.0 min to 30.0 min","","","24","","","","","IEEE","IEEE Conferences"
"A Tutorial on Quantitative Trajectory Evaluation for Visual(-Inertial) Odometry","Z. Zhang; D. Scaramuzza","Dep. of Informatics, University of Zürich, Dep. of Neuroinformatics, University of Zürich, ETH Zürich, Robotics and Perception Group, Switzerland; Dep. of Informatics, University of Zürich, Dep. of Neuroinformatics, University of Zürich, ETH Zürich, Robotics and Perception Group, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7244","7251","In this tutorial, we provide principled methods to quantitatively evaluate the quality of an estimated trajectory from visual(-inertial) odometry (VO/VIO), which is the foundation of benchmarking the accuracy of different algorithms. First, we show how to determine the transformation type to use in trajectory alignment based on the specific sensing modality (i.e., monocular, stereo and visual-inertial). Second, we describe commonly used error metrics (i.e., the absolute trajectory error and the relative error) and their strengths and weaknesses. To make the methodology presented for VO/VIO applicable to other setups, we also generalize our formulation to any given sensing modality. To facilitate the reproducibility of related research, we publicly release our implementation of the methods described in this tutorial.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593941","","Trajectory;Cameras;Noise measurement;Tutorials;Sensors;Visualization","distance measurement;mobile robots;path planning;pose estimation;robot vision","quantitative trajectory evaluation;trajectory alignment;specific sensing modality;error metrics;absolute trajectory error;relative error;visual odometry","","1","16","","","","","IEEE","IEEE Conferences"
"Robust Fruit Counting: Combining Deep Learning, Tracking, and Structure from Motion","X. Liu; S. W. Chen; S. Aditya; N. Sivakumar; S. Dcunha; C. Qu; C. J. Taylor; J. Das; V. Kumar","GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, 19104, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1045","1052","We present a novel fruit counting pipeline that combines deep segmentation, frame to frame tracking, and 3D localization to accurately count visible fruits across a sequence of images. Our pipeline works on image streams from a monocular camera, both in natural light, as well as with controlled illumination at night. We first train a Fully Convolutional Network (FCN) and segment video frame images into fruit and non-fruit pixels. We then track fruits across frames using the Hungarian Algorithm where the objective cost is determined from a Kalman Filter corrected Kanade-Lucas-Tomasi (KLT) Tracker. In order to correct the estimated count from tracking process, we combine tracking results with a Structure from Motion (SfM) algorithm to calculate relative 3D locations and size estimates to reject outliers and double counted fruit tracks. We evaluate our algorithm by comparing with ground-truth human-annotated visual counts. Our results demonstrate that our pipeline is able to accurately and reliably count fruits across image sequences, and the correction step can significantly improve the counting accuracy and robustness. Although discussed in the context of fruit counting, our work can extend to detection, tracking, and counting of a variety of other stationary features of interest such as leaf-spots, wilt, and blossom.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594239","","Image segmentation;Tracking;Three-dimensional displays;Pipelines;Image sequences;Deep learning;Cameras","cameras;computer vision;feature extraction;image classification;image colour analysis;image motion analysis;image segmentation;image sequences;Kalman filters;object detection;object tracking;pose estimation;video signal processing","Motion algorithm;double counted fruit tracks;ground-truth human-annotated visual counts;fruit counting pipeline;fruit counting pipeline;tracking process;Kanade-Lucas-Tomasi Tracker;Hungarian Algorithm;nonfruit pixels;segment video frame images;image streams;pipeline works;visible fruits;frame tracking;deep segmentation;deep learning;robust fruit counting;counting accuracy;image sequences","","1","22","","","","","IEEE","IEEE Conferences"
"Optimal Feedback Control Based on Analytical Linear Models Extracted from Neural Networks Trained for Nonlinear Systems","Y. Duan; S. Ikemoto; K. Hosoda","Graduate School of Engineering Science, Osaka University, Department of System Innovation, Toyonaka, Osaka, 1-3 Machikaneyama, Japan; Graduate School of Engineering Science, Osaka University, Department of System Innovation, Toyonaka, Osaka, 1-3 Machikaneyama, Japan; Graduate School of Engineering Science, Osaka University, Department of System Innovation, Toyonaka, Osaka, 1-3 Machikaneyama, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8689","8694","A number of researches have been focusing on the development and control of robots with soft structures such as flexible musculoskeletal systems. Thus far, it has been reported that these robots can achieve high adaptability to environments despite their extremely simple controllers. However, because these robots are difficult to model mathematically, there is still no systematic design policy, in which control theory has been playing a role in conventional robotics, for constituting simple controllers. To tackle this problem, we propose a new approach using a neural network to obtain mathematical models. In particular, with this method, the control theory is applied to linear system models extracted from a network trained to express the forward dynamics of a robot. Through simulations, the validity and advantage of the proposed method was successfully confirmed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593507","","Mathematical model;Neural networks;Computational modeling;Manipulators;Control theory;Aerospace electronics","control system synthesis;feedback;linear systems;neurocontrollers;nonlinear control systems;optimal control;robots","neural network;mathematical models;control theory;optimal feedback control;analytical linear models;nonlinear systems;robots;soft structures;flexible musculoskeletal systems;systematic design policy;conventional robotics;linear system models","","","22","","","","","IEEE","IEEE Conferences"
"Improving Offline Value-Function Approximations for POMDPs by Reducing Discount Factors","Y. Chen; M. J. Kochenderfer; M. T. J. Spaan","PhD student at UCLA Anderson School of Management, USA; Assistant Professor of Aeronautics and Astronautics and by courtesy, of Computer Science at Stanford University, USA; Associate Professor at Delft University of Technology, Delft, The Netherlands","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3531","3536","A common solution criterion for partially observable Markov decision processes (POMDPs) is to maximize the expected sum of exponentially discounted rewards, for which a variety of approximate methods have been proposed. Those that plan in the belief space typically provide tighter performance guarantees, but those that plan over the state space (e.g., QMDP and FIB) often require much less memory and computation. This paper presents an encouraging result that shows that reducing the discount factor while planning in the state space can actually improve performance significantly when evaluated on the original problem. This phenomenon is confirmed by both a theoretical analysis as well as a series of empirical studies on benchmark problems. As predicted by the theory and confirmed empirically, the phenomenon is most prominent when the observation model is noisy or rewards are sparse.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594418","","Planning;Observability;Approximation error;Markov processes;Memory management;Benchmark testing","decision theory;function approximation;Markov processes","exponentially discounted rewards;state space;observation model;offline value-function approximations;partially observable Markov decision processes;POMDP;discount factor reduction","","","16","","","","","IEEE","IEEE Conferences"
"Efficient Pose Estimation from Single RGB-D Image via Hough Forest with Auto-Context","H. Dong; Dilip K. Prasad; Q. Yuan; J. Zhou; E. Asadi; I. Chen","Nanyang Technological University, 639798, Singapore; Nanyang Technological University, 639798, Singapore; Nanyang Technological University, 639798, Singapore; Nanyang Technological University, 639798, Singapore; Nanyang Technological University, 639798, Singapore; Nanyang Technological University, 639798, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7201","7206","We propose a high efficient learning approach to estimating 6D (Degree of Freedom) pose of the textured or texture-less objects for grasping purposes in a cluttered environment where the objects might be partially occluded. The method comprises three main steps. Given a single RGB-D image, we first deploy appropriate features and the random forest to deduce the object class probability and cast votes for the 6D pose in Hough space by joint regression and classification framework, adopting reservoir sampling and summarizing the pose distribution by clustering. Next, we integrate the auto-context into cascaded Hough forests to improve the efficiency of learning. Extensive experiments on various public datasets and robotic grasps indicate that our method presents some improvements over the state-of-art and reveals the capability for estimating poses in practical applications efficiently.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594064","","Training;Forestry;Vegetation;Three-dimensional displays;Reservoirs;Pose estimation;Covariance matrices","feature extraction;image classification;image colour analysis;learning (artificial intelligence);object detection;pose estimation;probability;regression analysis","6D pose;public datasets;high efficient learning approach;robotic grasps;cascaded Hough forests;pose distribution;classification framework;joint regression;Hough space;object class probability;random forest;cluttered environment;textured texture-less;auto-context;single RGB-D image;efficient pose estimation","","","26","","","","","IEEE","IEEE Conferences"
"CReaM: Condensed Real-time Models for Depth Prediction using Convolutional Neural Networks","A. Spek; T. Dharmasiri; T. Drummond","Faculty of Electrical and Computer Systems Engineering, Monash University, Australia; Faculty of Electrical and Computer Systems Engineering, Monash University, Australia; Faculty of Electrical and Computer Systems Engineering, Monash University, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","540","547","Since the resurgence of CNNs the robotic vision community has developed a range of algorithms that perform classification, semantic segmentation and structure prediction (depths, normals, surface curvature) using neural networks. While some of these models achieve state-of-the art results and super human level performance, deploying these models in a time critical robotic environment remains an ongoing challenge. Real-time frameworks are of paramount importance to build a robotic society where humans and robots integrate seamlessly. To this end, we present a novel real-time structure prediction framework that predicts depth at 30 frames per second on an NVIDIA-TX2. At the time of writing, this is the first piece of work to showcase such a capability on a mobile platform. We also demonstrate with extensive experiments that neural networks with very large model capacities can be leveraged in order to train accurate condensed model architectures in a “from teacher to student” style knowledge transfer.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594243","","Real-time systems;Predictive models;Robots;Training;Modeling;Task analysis;Semantics","convolutional neural nets;image classification;image segmentation;mobile robots;neurocontrollers;robot vision","CNNs;robotic vision community;semantic segmentation;surface curvature;robotic society;real-time structure prediction framework;NVIDIA-TX2;CReaM;real-time models;depth prediction;convolutional neural networks;classification;mobile platform;condensed model architectures","","","36","","","","","IEEE","IEEE Conferences"
"Decentralized Connectivity-Preserving Deployment of Large-Scale Robot Swarms","N. Majcherczyk; A. Jayabalan; G. Beltrame; C. Pinciroli","Robotics Engineering, Worcester Polytechnic Institute, 85 Prescott St., Worcester, MA, 10609, USA; Robotics Engineering, Worcester Polytechnic Institute, 85 Prescott St., Worcester, MA, 10609, USA; Department of Computer and Software Engineering, École Polytechnique Montréal, 2900 Edouard Montpetit Blvd, Montréal, QC, H3T 1J4, Canada; Robotics Engineering, Worcester Polytechnic Institute, 85 Prescott St., Worcester, MA, 10609, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4295","4302","We present a decentralized and scalable approach for deployment of a robot swarm. Our approach tackles scenarios in which the swarm must reach multiple spatially distributed targets, and enforce the constraint that the robot network cannot be split. The basic idea behind our work is to construct a logical tree topology over the physical network formed by the robots. The logical tree acts as a backbone used by robots to enforce connectivity constraints. We study and compare two algorithms to form the logical tree: outwards and inwards. These algorithms differ in the order in which the robots join the tree: the outwards algorithm starts at the tree root and grows towards the targets, while the inwards algorithm proceeds in the opposite manner. Both algorithms perform periodic reconfiguration, to prevent suboptimal topologies from halting the growth of the tree. Our contributions are (i) The formulation of the two algorithms; (ii) A comparison of the algorithms in extensive physics-based simulations; (iii) A validation of our findings through real-robot experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594422","","Robot kinematics;Topology;Heuristic algorithms;Network topology;Switches;Task analysis","collision avoidance;decentralised control;mobile robots;multi-robot systems;robots;trees (mathematics)","physics-based simulations;logical tree;robot network;spatially distributed targets;robot swarm;large-scale robot;decentralized connectivity-preserving deployment;real-robot experiments;tree root;connectivity constraints;physical network;logical tree topology","","","22","","","","","IEEE","IEEE Conferences"
"Move Base Flex","S. Pütz; J. Santos Simón; J. Hertzberg","Osnabrück University, Knowledge Based Systems Group, Institute of Computer Science, Wachsbleiche 27, Osnabrück, 49090, Germany; Magazino GmbH, Landsberger Str. 234, München, 80687, Germany; Osnabrück University, Knowledge Based Systems Group, Institute of Computer Science, Wachsbleiche 27, Osnabrück, 49090, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3416","3421","We present Move Base Flex (MBF), a highly flexible, modular, map-independent, open-source navigation framework for use in ROS. MBF provides modular actions for executing plugins for path planning, motion control, and recovery. These actions define interfaces for external executives to allow highly flexible navigation strategies, which can be intertwined with other robot tasks. MBF has been successfully deployed in a professional setting at customer facilities to control robots in highly dynamic environments. We compare MBF with the well-known move_base and present the architecture as well as different deployment approaches, including how MBF can be used with different executives to perform complex navigation tasks interleaved with other robot operations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593829","","Navigation;Robots;Computer architecture;Task analysis;Flexible printed circuits;Servers;Planning","mobile robots;motion control;navigation;path planning","MBF;path planning;motion control;robot tasks;complex navigation tasks;Move Base Flex;highly flexible navigation framework;modular navigation;map-independent navigation;open-source navigation","","","15","","","","","IEEE","IEEE Conferences"
"Variational Autoencoder for End-to-End Control of Autonomous Driving with Novelty Detection and Training De-biasing","A. Amini; W. Schwarting; G. Rosman; B. Araki; S. Karaman; D. Rus","Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Toyota Research Institute (TRI); Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","568","575","This paper introduces a new method for end-to-end training of deep neural networks (DNNs) and evaluates it in the context of autonomous driving. DNN training has been shown to result in high accuracy for perception to action learning given sufficient training data. However, the trained models may fail without warning in situations with insufficient or biased training data. In this paper, we propose and evaluate a novel architecture for self-supervised learning of latent variables to detect the insufficiently trained situations. Our method also addresses training data imbalance, by learning a set of underlying latent variables that characterize the training data and evaluate potential biases. We show how these latent distributions can be leveraged to adapt and accelerate the training pipeline by training on only a fraction of the total dataset. We evaluate our approach on a challenging dataset for driving. The data is collected from a full-scale autonomous vehicle. Our method provides qualitative explanation for the latent variables learned in the model. Finally, we show how our model can be additionally trained as an end-to-end controller, directly outputting a steering control command for an autonomous vehicle.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594386","","Training;Autonomous vehicles;Aerospace electronics;Image reconstruction;Training data;Data models;Robots","learning (artificial intelligence);neural nets;traffic engineering computing","variational autoencoder;end-to-end control;autonomous driving;novelty detection;end-to-end training;deep neural networks;DNN training;sufficient training data;trained models;insufficient training data;biased training data;self-supervised learning;latent variables;insufficiently trained situations;training data imbalance;latent distributions;training pipeline;full-scale autonomous vehicle;end-to-end controller","","","32","","","","","IEEE","IEEE Conferences"
"Learning to Pour using Deep Deterministic Policy Gradients","C. Do; C. Gordillo; W. Burgard","Department of Computer Science, University of Freiburg, Georges-Köhler-Allee 80, Freiburg, 79110, Germany; Department of Computer Science, University of Freiburg, Georges-Köhler-Allee 80, Freiburg, 79110, Germany; Department of Computer Science, University of Freiburg, Georges-Köhler-Allee 80, Freiburg, 79110, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3074","3079","Pouring is a fundamental skill for robots in both domestic and industrial environments. Ideally, a robot should be able to pour with high accuracy to specific, pre-defined heights and without spilling. However, due to the complex dynamics of liquids, it is difficult to learn how to pour to achieve these goals. In this paper we present an approach to learn a policy for pouring using Deep Deterministic Policy Gradients (DDPG). We remove the need for collecting training experiences on a real robot, by using a state-of-the-art liquid simulator, which allows for learning the liquid dynamics. We show through our experiments, performed with a PR2 robot, that it is possible to successfully transfer the learned policy to a real robot and even apply it to different liquids.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593654","","Liquids;Training;Task analysis;Reinforcement learning;Service robots;Trajectory","learning (artificial intelligence);robots","domestic environments;industrial environments;pre-defined heights;liquid dynamics;PR2 robot;learned policy;fundamental skill;deep deterministic policy gradients;liquid simulator","","","30","","","","","IEEE","IEEE Conferences"
"Learning Forward and Inverse Kinematics Maps Efficiently","D. Kubus; R. Rayyes; J. J. Steil","Technische Universität Braunschweig Institut für Robotik und Prozessinformatik, Braunschweig, 38106, Germany; Technische Universität Braunschweig Institut für Robotik und Prozessinformatik, Braunschweig, 38106, Germany; Technische Universität Braunschweig Institut für Robotik und Prozessinformatik, Braunschweig, 38106, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5133","5140","When learning forward and inverse kinematics maps of manipulators, usually little attention is paid to data-efficiency, i.e., the accuracy gained per action-outcome sample. This paper examines properties of popular (online) learning techniques and demonstrates that - regardless of the employed exploration strategy - the structure of kinematics mappings does not allow for a practically viable trade-off between the number of samples and the resulting approximation error for manipulators with more than a few DoFs - unless tailored parametric models are employed. We discuss suitable choices for these parametric models for both rigid and elastic discretely-actuated robots and compare their data -efficiency to that of popular exploratory learning approaches relying on non-parametric models. Our theoretical considerations are confirmed by various experimental results for inverse kinematics mappings of rigid and omnielastic manipulators.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593833","","Manipulators;Kinematics;Solid modeling;Elasticity;Analytical models;Strain","actuators;control engineering computing;elasticity;learning (artificial intelligence);manipulator kinematics;nonparametric statistics","learning forward kinematics maps;exploratory learning approaches;action-outcome sampling;omnielastic manipulators;rigid manipulators;inverse kinematics mappings;nonparametric models;elastic discretely-actuated robots;rigid discretely-actuated robots;tailored parametric models;data-efficiency","","","43","","","","","IEEE","IEEE Conferences"
"A Biomimetic Soft Robot for Inspecting Pipeline with Significant Diameter Variation","X. Zhang; T. Pan; H. L. Heung; P. W. Y. Chiu; Z. Li","the Chinese University of Hong Kong, Department of Surgery; the Chinese University of Hong Kong, Department of Biomedical Engineering Programme; Department of Electronic Engineering, the Chinese University of Hong Kong, The Biomedical Engineering Programme, Hong Kong; The Chinese University of Hong Kong, Department of Surgery and Chow Yuk Ho Technology Centre for innovative Medicine, Hong Kong; The Chinese University of Hong Kong, Department of Surgery and Chow Yuk Ho Technology Centre for innovative Medicine, Hong Kong","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7486","7491","Navigation through tubular environment is fundamental in tasks such as pipeline inspection, gastrointestinal tract inspection, etc. Conventional pipeline inspection robots are mostly made by rigid materials and could not well adapt to the large size variation of the environment. Soft robots provide an additional solution for inspection of pipelines, especially with significant size variation. In this work, we present a soft robot for pipeline inspection, which consists of an earthworm-like soft robot and a Central Pattern Generator (CPG)-based control system. An analytical model is developed to predict the maximum pipe diameter that the robot could adapt to. For the current prototype, the robot could adapt to size change of three times. Experimental results show that this robot could navigate through pipelines with sharp turnings and with large diameter change.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594390","","Pipelines;Inspection;Actuators;Soft robotics;Mobile robots;Valves","biomimetics;diseases;industrial robots;inspection;pipelines","central pattern generator-based control system;pipeline inspection robots;earthworm-like soft robot;CPG-based control system;pipeline navigation;gastrointestinal tract inspection;tubular environment;biomimetic soft robot","","","19","","","","","IEEE","IEEE Conferences"
"Pneumatic Microneedle-Based High-Density sEMG Sleeve for Stable and Comfortable Skin Contact During Dynamic Motion","M. Kim; G. Gu; W. K. Chung","Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5477","5482","Skin impedance should be minimized to obtain reliable and precise surface electromyography (sEMG) signals. High skin impedance decreases sensitivity to muscular activation and makes sEMG signals vulnerable to external noise. Microneedle-based electrodes have been proposed to achieve low skin impedance and high spatial resolution. However, unstable skin contact can occur during dynamic motion due to the electrodes small contact area, and the signal is easily influenced by motion artifacts. In this study, a pneumatic microneedle-based high-density sEMG sleeve is proposed that guarantees stable sEMG signal measurement by pressing the electrodes to the skin. Pneumatic air control, sEMG signal processing, and wireless signal transmission are processed in a single processor. The proposed interface automatically controls the air volume according to sEMG signal quality and is comfortable for users. The usability of the proposed interface was compared to conventional Velcro armbands by examining acquired sEMG signals. The results indicated that the proposed pneumatic sleeve guarantees reliable sEMG signal measurement during dynamic motion. Additionally, optimal pneumatic pressure and needle length were investigated.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594135","","Electrodes;Skin;Impedance;Needles;Solenoids;Valves;Motion artifacts","biomechanics;biomedical electrodes;biomedical measurement;electromyography;medical signal processing;needles;skin","microneedle-based electrodes;pneumatic microneedle-based high-density sEMG sleeve;pneumatic air control;sEMG signal processing;wireless signal transmission;sEMG signal quality;stable skin contact;comfortable skin contact;skin impedance;sEMG signal measurement;surface electromyography signals;motion artifacts;Velcro armbands;pneumatic pressure;needle length","","","22","","","","","IEEE","IEEE Conferences"
"Neural-Network-Controlled Spring Mass Template for Humanoid Running","S. Xin; B. Delhaisse; Y. You; C. Zhou; M. Shahbazi; N. Tsagarakis","Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego 30,16163, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego 30,16163, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego 30,16163, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego 30,16163, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego 30,16163, Genova, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, via Morego 30,16163, Genova, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1725","1731","To generate dynamic motions such as hopping and running on legged robots, model-based approaches are usually used to embed the well studied spring-loaded inverted pendulum (SLIP) model into the whole-body robot. In producing controlled SLIP-like behaviors, existing methods either suffer from online incompatibility or resort to classical interpolations based on lookup tables. Alternatively, this paper presents the application of a data-driven approach which obviates the need for solving the inverse of the running return map online. Specifically, a deep neural network is trained offline with a large amount of simulation data based on the SLIP model to learn its dynamics. The trained network is applied online to generate reference foot placements for the humanoid robot. The references are then mapped to the whole-body model through a QP-based inverse dynamics controller. Simulation experiments on the WALK-MAN robot are conducted to evaluate the effectiveness of the proposed approach in generating bio-inspired and robust running motions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593403","","Legged locomotion;Neural networks;Data models;Training;Biological system modeling;Robot kinematics","humanoid robots;interpolation;legged locomotion;neurocontrollers;pendulums;robot dynamics;springs (mechanical);table lookup","lookup tables;data-driven approach;deep neural network;simulation data;SLIP model;humanoid robot;whole-body model;QP-based inverse dynamics controller;WALK-MAN robot;robust running motions;neural-network-controlled spring mass template;humanoid running;legged robots;model-based approaches;whole-body robot;controlled SLIP-like behaviors;online incompatibility;interpolations;spring-loaded inverted pendulum model","","","28","","","","","IEEE","IEEE Conferences"
"Online Shape Estimation based on Tactile Sensing and Deformation Modeling for Robot Manipulation","J. Sanchez; C. M. Mateo; J. A. Corrales; B. Bouzgarrou; Y. Mezouar","SIGMA Clermont, Institut Pascal, Université Clermont Auvergne, BP 10448, Clermont-Ferrand, F-63000, France; SIGMA Clermont, Institut Pascal, Université Clermont Auvergne, BP 10448, Clermont-Ferrand, F-63000, France; SIGMA Clermont, Institut Pascal, Université Clermont Auvergne, BP 10448, Clermont-Ferrand, F-63000, France; SIGMA Clermont, Institut Pascal, Université Clermont Auvergne, BP 10448, Clermont-Ferrand, F-63000, France; SIGMA Clermont, Institut Pascal, Université Clermont Auvergne, BP 10448, Clermont-Ferrand, F-63000, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","504","511","Precise robot manipulation of deformable objects requires an accurate and fast estimation of their shape as they deform. So far, visual sensing has been mostly used to solve this issue, but vision sensors are sensitive to occlusions, which might be inevitable when manipulating an object with robot. To address this issue, we present a modular pipeline to track the shape of a soft object in an online manner by coupling tactile sensing with a deformation model. Using a model of a tactile sensor, we compute the magnitude and location of a contact force and apply it as an external force to the deformation model. The deformation model then updates the nodal positions of a mesh that describes the shape of the deformable object. The proposed sensor model and pipeline, are evaluated using a Shadow Dexterous Hand equipped with BioTac sensors on its fingertips and an RGB-D sensor.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594314","","Strain;Robot sensing systems;Deformable models;Force;Shape;Computational modeling","dexterous manipulators;force control;image sensors;tactile sensors","deformation model;tactile sensor;deformable object;sensor model;online shape estimation;tactile sensing;deformation modeling;visual sensing;soft object;robot manipulation;shadow dexterous hand;BioTac sensors;RGB-D sensor","","","25","","","","","IEEE","IEEE Conferences"
"System Identification and Closed-Loop Control of a Hydraulically Amplified Self-Healing Electrostatic (HASEL) Actuator","C. Schunk; L. Pearson; E. Acome; T. G. Morrissey; N. Correll; C. Keplinger; M. E. Rentschler; J. S. Humbert","University of Colorado, Boulder; University of Colorado, Boulder; University of Colorado, Boulder; University of Colorado, Boulder; University of Colorado, Boulder; University of Colorado, Boulder; University of Colorado, Boulder; University of Colorado, Boulder","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6417","6423","This paper describes a system identification method and the development of a closed-loop controller for a Hydraulically Amplified Self-healing Electrostatic (HASEL) actuator. Our efforts focus on developing a reliable and consistent way to identify system models for these soft robotic actuators using high-speed videography based motion tracking. Utilizing a mass-spring-damper model we are able to accurately capture the behavior of a HASEL actuator. We use the resulting plant model to design a Proportional-Integral controller that demonstrates improved closed-loop tracking and steady-state error performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593797","","Actuators;Strain;Sensors;Data acquisition;Capacitance;Electrodes;Dielectric liquids","closed loop systems;hydraulic actuators;PI control;robots;shock absorbers;springs (mechanical);vibration control","HASEL actuator;Proportional-Integral controller;closed-loop control;Hydraulically Amplified Self-healing Electrostatic actuator;system identification method;closed-loop controller;soft robotic actuators;high-speed videography based motion tracking;mass-spring-damper model","","","21","","","","","IEEE","IEEE Conferences"
"Learning Coordinated Vehicle Maneuver Motion Primitives from Human Demonstration","K. C. Mbanisi; H. Kimpara; T. Meier; M. Gennert; Z. Li","Worcester Polytechnic Institute, Robotics Engineering, Worcester, MA, 01609, USA; Worcester Polytechnic Institute, Robotics Engineering, Worcester, MA, 01609, USA; Worcester Polytechnic Institute, Robotics Engineering, Worcester, MA, 01609, USA; Worcester Polytechnic Institute, Robotics Engineering, Worcester, MA, 01609, USA; Worcester Polytechnic Institute, Robotics Engineering, Worcester, MA, 01609, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6560","6565","High-fidelity computational human models provide a safe and cost-efficient method for studying driver experience in vehicle maneuvers and for validation of vehicle design. Compared to passive human models, active human models capable of reproducing the decision-making, as well as vehicle maneuver motion planning and control, will be able to support realistic simulation of human-vehicle interaction. In this paper, we propose an integrated human-vehicle interaction simulation framework which learns vehicle maneuver motion primitives from human drivers, and uses them to compose natural and contextual driving motions. Specifically, we recruited six experienced drivers and recorded their vehicle maneuver motions on a fixed-base driving simulation testbed. We further segmented and classified the collected data based on their similarity in joint coordination. Using a combination of imitation learning methods, we extracted the regularity and variability of vehicle maneuver motions across subjects, and learned the dynamic motion primitives to be used for motion reproduction in simulation. We present an implementation of the framework on lower-extremity joint coordination in pedal activation for longitudinal vehicle control. Our research efforts lead to a motion primitive library which enables planning natural driver motions, and will be integrated with the driving decision-making, motion control, and vehicle dynamics in the proposed framework for simulating human-vehicle interaction.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593976","","Vehicles;Computational modeling;Task analysis;Motion segmentation;Vehicle dynamics;Hidden Markov models;Dynamics","control engineering computing;decision making;learning (artificial intelligence);mobile robots;motion control;path planning;road vehicles;vehicle dynamics","human-vehicle interaction simulation framework;driving motions;vehicle maneuver motion primitives;driving decision-making;vehicle design;human demonstration;vehicle dynamics;motion control;motion primitive library;longitudinal vehicle control;motion reproduction;dynamic motion primitives;imitation learning methods;fixed-base driving simulation;vehicle maneuver motion planning","","","29","","","","","IEEE","IEEE Conferences"
"Online Path Planning and Compliance Control of Space Robot for Capturing Tumbling Large Object","D. Hirano; H. Kato; T. Saito","Research Unit II, Research and Development Directorate, Japan Aerospace Exploration Agency (JAXA), 2-1-1 Sengen, Tsukuba, Ibaraki, 305-8505, JAPAN; Research Unit II, Research and Development Directorate, Japan Aerospace Exploration Agency (JAXA), 2-1-1 Sengen, Tsukuba, Ibaraki, 305-8505, JAPAN; Research Unit II, Research and Development Directorate, Japan Aerospace Exploration Agency (JAXA), 2-1-1 Sengen, Tsukuba, Ibaraki, 305-8505, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2909","2916","This paper presents the path planning and coordinated control of a space robot with a manipulator for capturing a rotating large object. As the grasping point on a rotating large object is translationally moving fast, an appropriate strategy and coordinated motion control of the spacecraft base and robotic arm must be employed for approaching and tracking such a grasping point. In this paper, we propose a robust control scheme including the online path planning and compliance control for grasping such a target. The path planning is derived in a simple form that allows the desired end-effector trajectory to be easily modified in real-time using the newly updated states without complex numerical calculation. In addition, the compliance control allows the end-effector to track the planned trajectory or the moving grasping point, while using contact force feedback to reduce the end-effector position error from the grasping point when capturing the target. This end-effector motion is implemented by coordinated control on the spacecraft base and robotic arm, which can suitably alter their distribution of motion according to scenes using a weighted pseudoinverse matrix. Experiments are conducted to demonstrate the validity of the proposed path planning and compliance control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594099","","Grasping;End effectors;Robot kinematics;Trajectory","aerospace control;aerospace robotics;compliance control;end effectors;force feedback;image capture;manipulator dynamics;mobile robots;motion control;object recognition;path planning;position control;robot vision;robust control","compliance control;planned trajectory;moving grasping point;end-effector position error;end-effector motion;coordinated control;spacecraft base;robotic arm;online path planning;space robot;coordinated motion control;robust control scheme;end-effector trajectory;tumbling large object capturing","","","15","","","","","IEEE","IEEE Conferences"
"The Power of a Hand-shake in Human-Robot Interactions","J. Avelino; F. Correia; J. Catarino; P. Ribeiro; P. Moreno; A. Bernardino; A. Paiva","ISR-Lisboa, Instituto Superior Tecnico, Univ. Lisboa; INESC-ID & Instituto Superior Técnico, Universidade de Lisboa; Instituto Superior Técnico, Universidade de Lisboa; Instituto Superior Técnico, Universidade de Lisboa; ISR-Lisboa, Instituto Superior Tecnico, Univ. Lisboa; ISR-Lisboa, Instituto Superior Tecnico, Univ. Lisboa; INESC-ID & Instituto Superior Técnico, Universidade de Lisboa","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1864","1869","In this paper, we study the influence of a handshake in the human emotional bond to a robot. In particular, we evaluate the human willingness to help a robot whether the robot first introduces itself to the human with or without a handshake. In the tested paradigm the robot and the human have to perform a joint task, but at a certain stage, the robot needs help to navigate through an obstacle. Without requesting explicit help from the human, the robot performs some attempts to navigate through the obstacle, suggesting to the human that it requires help. In a study with 45 participants, we measure the human's perceptions of the social robot Vizzy, comparing the handshake vs non-handshake conditions. In addition, we evaluate the influence of a handshake in the pro-social behaviour of helping it and the willingness to help it in the future. The results show that a handshake increases the perception of Warmth, Animacy, Likeability, and the tendency to help the robot more, by removing the obstacle.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593980","","Task analysis;Navigation;Haptic interfaces;Human-robot interaction;Tactile sensors","control engineering computing;human-robot interaction","nonhandshake conditions;human-robot interactions;human emotional bond;human willingness;social robot Vizzy;handshake conditions","","","32","","","","","IEEE","IEEE Conferences"
"Pose Estimation for Mobile Robots to Maximise Data Quality of Fixed-Focus Laser Diagnostics in Hazardous Environments","A. West; S. Watson; B. Lennox","The University of Manchester, School of Electrical and Electronic Engineering, Manchester, M13 9PL, UK; The University of Manchester, School of Electrical and Electronic Engineering, Manchester, M13 9PL, UK; The University of Manchester, School of Electrical and Electronic Engineering, Manchester, M13 9PL, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3599","3604","Characterisation of nuclear environments is critical for long term operation and decommissioning. Laser Induced Breakdown Spectroscopy (LIBS) is an example of a scientific instrument that could be deployed to aid in characterisation of unknown environments. LIBS consists of a high intensity pulsed laser being focussed down onto a target to create a plasma, and optical emission from the plasma is then used to determine elemental composition of unknown materials. For robots deployed with these instruments in extreme environments, mission time can be limited by hazards present such as radiation. Once deployed a robot must be able to collect the best data possible whilst maximising operational runtime. We present a data quality based probabilistic approach to robot pose estimation to maximise data quality, by considering optimum sensor placement whilst avoiding harmful environmental features such as radiation for a fixed-focus laser diagnostic such as LIBS. This approach is able to determine optimum robot poses for arbitrary targets in 3D for arbitrary diagnostic mounting with respect to the robot. The approach is able to avoid obstacles and avoid occlusion of the target by said obstacles. This can be used as part of autonomous investigation and characterisation performed by mobile robots in hazardous environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593367","","Robot kinematics;Robot sensing systems;Data integrity;Lasers;Instruments;Plasmas","collision avoidance;laser beam effects;mobile robots;pose estimation;sensor placement;service robots;spectroscopy","pose estimation;mobile robots;data quality;fixed-focus laser diagnostic;hazardous environments;nuclear environments;decommissioning;LIBS;scientific instrument;optical emission;arbitrary diagnostic mounting;obstacle avoidance;diagnostic mounting;sensor placement;high intensity pulsed laser;laser induced breakdown spectroscopy","","","19","","","","","IEEE","IEEE Conferences"
"Accurate Mix-Norm-Based Scan Matching","D. Wang; J. Xue; Z. Tao; Y. Zhong; D. Cui; S. Du; N. Zheng","Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China; Visual Cognitive Computing and Intelligent Vehicle (VCC&IV) Lab, Xi'an Jiaotong University, Xi'an, P.R. China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1665","1671","Highly accurate mapping and localization is of prime importance for mobile robotics, and its core lies in efficient scan matching. Previous research are focusing on designing a robust objective function and the residual error distribution is often ignored or simply assumed as unitary or mixture of simple distributions. In this paper, a mixture of exponential power (MoEP) distributions is proposed to approximate the residual error distribution. The objective function induced by MoEP-based residual error modelling ensembles a mix-norm-based scan matching (MiNoM), which enhances the matching accuracy and convergence characteristic. Both the parameters of transformation (rotation and translation) and residual error distribution are estimated efficiently via an EM-like algorithm. The optimization of MiNoM is iteratively achieved via two phases: An on-line parameter learning (OPL) phase to learn residual error distribution for better representation according to the likelihood field model (LFM), and an iteratively reweighted least squares (IRLS) phase to attain transformation for accuracy and efficiency. Extensive experimental results validate that the proposed MiNoM out-performs several state-of-the-art scan matching algorithms in both convergence characteristic and matching accuracy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594278","","Iterative closest point algorithm;Linear programming;Gaussian distribution;Standards;Convergence;Optimization;Heuristic algorithms","expectation-maximisation algorithm;image matching;learning (artificial intelligence);least squares approximations;mobile robots;optimisation;pose estimation","exponential power distributions;convergence characteristic;mix-norm-based scan matching;robust objective function design;MoEP-based residual error model;EM-like algorithm;likelihood field model;iteratively reweighted least squares phase;LFM;IRLS;on-line parameter learning;MiNoM optimization;mobile robotics","","","21","","","","","IEEE","IEEE Conferences"
"Soft LEGO: Bottom-Up Design Platform for Soft Robotics","J. Lee; J. Eom; W. Choi; K. Cho","Department of Mechanical & Aerospace Engineering, BioRobotics Laboratory, Seoul National University, Seoul, 08826, Korea; Department of Mechanical & Aerospace Engineering, BioRobotics Laboratory, Seoul National University, Seoul, 08826, Korea; Department of Mechanical & Aerospace Engineering, BioRobotics Laboratory, Seoul National University, Seoul, 08826, Korea; Department of Mechanical & Aerospace Engineering, BioRobotics Laboratory, Seoul National University, Seoul, 08826, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7513","7520","This paper introduces soft LEGO for bottom-up design platform of soft robotics that can be used for various purposes, ranging from research and fast prototyping of soft robots to toys and entertainment. We integrated the interlocking mechanism of LEGO into a modular soft robot. With this design, soft robots could be built by a simple and play-like assembling process. Three kinds of components were proposed to make soft robotics compatible with LEGO: pneumatically inflatable soft brick, flexible bending brick, and channel brick. The soft brick has an air chamber and can generate motions when inflated. The bending brick has flexure and is bendable for generating motion when the assembled soft bricks are pneumatically actuated. The air channel brick has an air channel inside and works as an interface between air hoses and soft LEGO bricks. Detailed design parameters of the soft brick were optimized based on the Taguchi method with finite-element analysis to improve robustness. Design of the bending brick was selected based on experimental results to enhance the robustness of the flexure. Thanks to the multi-material 3-dimensional printer, the soft LEGO bricks could be fabricated with a single printing process. To see the feasibility of soft LEGO as a bottom-up design platform, a simple toy robot for children and a gripper that had a hybrid mechanism of hard and soft materials were built and tested. We hope this soft LEGO could lower the hurdle of soft robotics for children, researchers from other fields, and the public interest in robotics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593546","","Soft robotics;Hoses;Actuators;Pins;Toy manufacturing industry;Joining processes","assembling;bending;design engineering;finite element analysis;grippers;mobile robots;pneumatic actuators;rapid prototyping (industrial);Taguchi methods;three-dimensional printing","soft LEGO bricks;soft robotics;pneumatically inflatable soft brick;assembled soft bricks;bottom-up design platform;flexible bending brick;air channel brick;Taguchi method;finite-element analysis;multimaterial 3-dimensional printer","","","30","","","","","IEEE","IEEE Conferences"
"Assisted Telemanipulation: A Stack-Of-Tasks Approach to Remote Manipulator Control","T. Stoyanov; R. Krug; A. Kiselev; D. Sun; A. Loutfi","örebro University, Center for Applied Autonomous Sensor Systems (AASS), Fakultetsgatan 1, örebro, 701 82, Sweden; KTH Royal Institute of Technology, Robotics, Learning and Perception lab, Teknikringen 14, Stockholm, 100 44, Sweden; örebro University, Center for Applied Autonomous Sensor Systems (AASS), Fakultetsgatan 1, örebro, 701 82, Sweden; örebro University, Center for Applied Autonomous Sensor Systems (AASS), Fakultetsgatan 1, örebro, 701 82, Sweden; örebro University, Center for Applied Autonomous Sensor Systems (AASS), Fakultetsgatan 1, örebro, 701 82, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This article presents an approach for assisted teleoperation of a robot arm, formulated within a real-time stack-of-tasks (SoT)whole-body motion control framework. The approach leverages the hierarchical nature of the SoT framework to integrate operator commands with assistive tasks, such as joint limit and obstacle avoidance or automatic gripper alignment. Thereby some aspects of the teleoperation problem are delegated to the controller and carried out autonomously. The key contributions of this work are two-fold: the first is a method for unobtrusive integration of autonomy in a telemanip-ulation system; and the second is a user study evaluation of the proposed system in the context of teleoperated pick-and-place tasks. The proposed approach of assistive control was found to result in higher grasp success rates and shorter trajectories than achieved through manual control, without incurring additional cognitive load to the operator.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594457","","Task analysis;Grippers;Robot kinematics;Manipulators;Acceleration;Collision avoidance","collision avoidance;dexterous manipulators;force control;grippers;haptic interfaces;humanoid robots;human-robot interaction;mobile robots;motion control;telerobotics","assisted telemanipulation;stack-of-tasks approach;remote manipulator control;assisted teleoperation;robot arm;hierarchical nature;SoT framework;operator commands;assistive tasks;joint limit;obstacle avoidance;automatic gripper alignment;teleoperation problem;assistive control;manual control;real-time stack-of-tasks whole-body motion control framework;teleoperated pick-and-place tasks;telemanipulation system","","","15","","","","","IEEE","IEEE Conferences"
"Game-Theoretic Cooperative Lane Changing Using Data-Driven Models","G. Ding; S. Aghli; C. Heckman; L. Chen","Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3640","3647","Self-driving vehicles are being increasingly deployed in the wild. One of the most important next hurdles for autonomous driving is how such vehicles will optimally interact with one another and with their surroundings. In this paper, we consider the lane changing problem that is fundamental to road-bound multi-vehicle systems, and approach it through a combination of deep reinforcement learning (DRL) and game theory. We introduce a proactive-passive lane changing framework and formulate the lane changing problem as a Markov game between the proactive and passive vehicles. Based on different approaches to carry out DRL to solve the Markov game, we propose an asynchronous lane changing scheme as in a single-agent RL setting and a synchronous cooperative lane changing scheme that takes into consideration the adaptive behavior of the other vehicle in a vehicle's decision. Experimental results show that the synchronous scheme can effectively create and find proper merging moment after sufficient training. The framework and solution developed here demonstrate the potential of using reinforcement learning to solve multi-agent autonomous vehicle tasks such as the lane changing as they are formulated as Markov games.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593725","","Games;Markov processes;Merging;Reinforcement learning;Autonomous vehicles;Neural networks;Space vehicles","game theory;learning (artificial intelligence);Markov processes;multi-agent systems;road traffic","data-driven models;self-driving vehicles;autonomous driving;road-bound multivehicle systems;DRL;game theory;proactive-passive lane changing framework;Markov game;multiagent autonomous vehicle tasks;deep reinforcement learning;single-agent RL setting","","","40","","","","","IEEE","IEEE Conferences"
"Verification of a Robotic Ankle Exoskeleton Control Scheme for Gait Assistance in Individuals with Cerebral Palsy","G. M. Gasparri; M. O. Bair; R. P. Libby; Z. F. Lerner","Northern Arizona University, Biomechatronics Laboratory, Flagstaff, AZ, 86011, USA; Northern Arizona University, Biomechatronics Laboratory, Flagstaff, AZ, 86011, USA; Northern Arizona University, Biomechatronics Laboratory, Flagstaff, AZ, 86011, USA; Northern Arizona University, Biomechatronics Laboratory, Flagstaff, AZ, 86011, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4673","4678","Walking ability is critically important for pediatric health, well-being, and independence. Children with cerebral palsy (CP), the most prevalent cause of pediatric physical disability, often present pathological gait patterns that negatively impact walking capacity. Reduced function of the muscles surrounding the ankle joint in those with CP also greatly increases the energy cost of transport leading to reduce mobility. Ankle-foot-orthoses show limited effectiveness for clinically relevant improvement in gait mechanics, while orthopedic surgery, muscle injections and physical therapy are unable to completely restore gait function. While wearable exoskeletons hold promise for gait rehabilitation, appropriately controlling the timing and magnitude of powered assistance across individuals and conditions remains a considerable challenge. This work seeks to address this challenge through the design and initial clinical verification of a simple ankle exoskeleton control scheme designed to reduce the metabolic cost of transport during walking in an individual with CP. Preliminary experimental results from instrumented gait analysis following 5 training visits demonstrated a 45% increase in positive ankle power and a 16% reduction in net metabolic rate during walking with the exoskeleton providing powered plantar-flexion assistance compared to walking without the exoskeleton. Future work will expand this investigation to a larger cohort of individuals with CP and across additional modes of locomotion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593904","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593904","","Exoskeletons;Legged locomotion;Torque;DC motors;Atmospheric measurements;Particle measurements;Muscles","gait analysis;handicapped aids;medical robotics;muscle;orthopaedics;orthotics;paediatrics;patient rehabilitation;wearable robots","robotic ankle exoskeleton control scheme;gait assistance;cerebral palsy;walking ability;pediatric health;pediatric physical disability;pathological gait patterns;CP;ankle-foot-orthoses;clinically relevant improvement;gait mechanics;orthopedic surgery;muscle injections;physical therapy;wearable exoskeletons;gait rehabilitation;initial clinical verification;instrumented gait analysis;positive ankle power;powered plantar-flexion assistance;reduced muscle function;powered assistance magnitude;powered assistance timing;net metabolic rate;locomotion","","","28","","","","","IEEE","IEEE Conferences"
"Closed-Loop Robot Task Planning Based on Referring Expressions","D. Kuhner; J. Aldinger; F. Burget; M. Göbelbecker; W. Burgard; B. Nebel","Albert-Ludwigs-Universität, Institut für Informatik, Freiburg, 79110, Germany; Albert-Ludwigs-Universität, Institut für Informatik, Freiburg, 79110, Germany; Albert-Ludwigs-Universität, Institut für Informatik, Freiburg, 79110, Germany; Albert-Ludwigs-Universität, Institut für Informatik, Freiburg, 79110, Germany; Albert-Ludwigs-Universität, Institut für Informatik, Freiburg, 79110, Germany; Albert-Ludwigs-Universität, Institut für Informatik, Freiburg, 79110, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","876","881","Increasing the accessibility of autonomous robots also for inexperienced users requires user-friendly and high-level control opportunities of robotic systems. While automated planning is able to decompose a complex task into a sequence of steps which reaches an intended goal, it is difficult to formulate such a goal without knowing the internals of the planning system and the exact capabilities of the robot. This becomes even more important in dynamic environments in which manipulable objects are subject to change. In this paper, we present an adaptive control interface which allows users to specify goals based on an internal world model by incrementally building referring expressions to the objects in the world. We consider fetch-and-carry tasks and automatically deduce potential high-level goals from the world model to make them available to the user. Based on its perceptions our system can react to changes in the environment by adapting the goal formulation within the domain-independent planning system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593371","","Task analysis;Planning;Robots;Natural languages;Graphical user interfaces;Glass","adaptive control;closed loop systems;mobile robots;path planning;planning (artificial intelligence);user interfaces","fetch-and-carry tasks;autonomous robots accessibility;user friendly;closed-loop robot task planning;complex task;automated planning;robotic systems;domain-independent planning system;goal formulation;referring expressions;adaptive control interface;manipulable objects;dynamic environments","","","24","","","","","IEEE","IEEE Conferences"
"Pose Estimation for Objects with Rotational Symmetry","E. Corona; K. Kundu; S. Fidler","University of Toronto, Vector Institute, Department of Computer Science; University of Toronto, Vector Institute, Department of Computer Science; NVIDIA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7215","7222","Pose estimation is a widely explored problem, enabling many robotic tasks such as grasping and manipulation. In this paper, we tackle the problem of pose estimation for objects that exhibit rotational symmetry, which are common in man-made and industrial environments. In particular, our aim is to infer poses for objects not seen at training time, but for which their 3D CAD models are available at test time. Previous work has tackled this problem by learning to compare captured views of real objects with the rendered views of their 3D CAD models, by embedding them in a joint latent space using neural networks. We show that sidestepping the issue of symmetry in this scenario during training leads to poor performance at test time. We propose a model that reasons about rotational symmetry during training by having access to only a small set of symmetry-labeled objects, whereby exploiting a large collection of unlabeled CAD models. We demonstrate that our approach significantly outperforms a naively trained neural network on a new pose dataset containing images of tools and hardware.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594282","","Solid modeling;Three-dimensional displays;Pose estimation;Training;Shape;Neural networks;Computational modeling","CAD;inference mechanisms;learning (artificial intelligence);neural nets;pose estimation;solid modelling","neural network;test time;symmetry-labeled objects;unlabeled CAD models;pose estimation;widely explored problem;poses;training time;3D CAD models;rotational symmetry","","","42","","","","","IEEE","IEEE Conferences"
"An Automatic Tracked Robot Chain System for Gas Pipeline Inspection and Maintenance Based on Wireless Relay Communication","W. Zhao; M. Kamezaki; K. Yoshida; M. Konno; A. Onuki; S. Sugano","Mechanical Engineering, Waseda Univ., 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Waseda Univ., Research Institute for Science and Engineering (RISE), 7 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Mechanical Engineering, Waseda Univ., 17 Kikui-cho, Shinjuku-ku, Tokyo, 162-0044, Japan; Strategy Planning Department, Pipeline Technology Center, Tokyo Gas Co., Ltd., 1-7-7, Suehiro-cho, Tsurumi-ku, Yokohama-city, Kanagawa, 230-0045, Japan; Strategy Planning Department, Pipeline Technology Center, Tokyo Gas Co., Ltd., 1-7-7, Suehiro-cho, Tsurumi-ku, Yokohama-city, Kanagawa, 230-0045, Japan; Department of Modern Mechanical Engineering, Waseda Univ., 3-4-1 Okubo, Shinjuku-ku, Tokyo, 169-8555, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3978","3983","Gas pipeline requires to be inspected regularly for leakages caused by natural disaster. Robots are widely used for pipeline inspection since they are more convenient than manual inspection. Several problems, however, exist due to the restriction by complex pipe networks. The most significant one is limited inspection range caused by restriction of cable length or wireless signal attenuation. In this paper, we proposed a concept of wireless relay communication to assist robot to extend the inspection range, and we newly developed a tracked robot chain system. In this system, each robot serves as a relay communication node. Leakage information of pipes are transmitted via these relay nodes. To ensure the stability of relay communication between adjacent robots, we adopted RSSI (received signal strength indication)-based evaluation method for cooperative and coordinated movement of robot chain system. Moreover, wireless application layer communication protocol (WALCP) was used to increase the stable performance of wireless relay communication. Each robot can self-navigate based on distance measurement module, which enables robots to pass through an elbow junction. Multiple experiments to evaluate relay transmission efficiency, RSSI-based cooperative movement, and comprehensive performance were conducted. Results revealed that our proposed system could realize relatively accurate relay transmission and RSSI-based coordinated movement.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593550","","Robot sensing systems;Robot kinematics;Pipelines;Relays;Wireless communication;Wireless sensor networks","cooperative communication;inspection;mobile robots;protocols","automatic tracked robot chain system;gas pipeline inspection;wireless relay communication;wireless signal attenuation;relay communication node;wireless application layer communication protocol;relay transmission efficiency;RSSI-based coordinated movement","","","13","","","","","IEEE","IEEE Conferences"
"Motion Planning for a UAV with a Straight or Kinked Tether","X. Xiao; J. Dufek; M. Suhail; R. Murphy","Texas A&M University, Department of Computer Science and Engineering, College Station, TX, 77843; Texas A&M University, Department of Computer Science and Engineering, College Station, TX, 77843; Texas A&M University, Department of Visualization, College Station, Texas, 77843; Texas A&M University, Department of Computer Science and Engineering, College Station, TX, 77843","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8486","8492","This paper develops and compares two motion planning algorithms for a tethered UAV with and without the possibility of the tether contacting the confined and cluttered environment. Tethered aerial vehicles have been studied due to their advantages such as power duration, stability, and safety. However, the disadvantages brought in by the extra tether have not been well investigated by the robotic locomotion community, especially when the tethered agent is locomoting in a non-free space occupied with obstacles. In this work, we propose two motion planning frameworks that (1) reduce the reachable configuration space by taking into account the tether and (2) deliberately plan (and relax) the contact point(s) of the tether with the environment and enable an equivalent reachable configuration space as the non-tethered counterpart would have. Both methods are tested on a physical robot, Fotokite Pro. With our approaches, tethered aerial vehicles could find their applications in confined and cluttered environments with obstacles as opposed to ideal free space, while still maintaining the advantages from the usage of a tether. The motion planning strategies are particularly suitable for marsupial heterogeneous robotic teams, such as visual servoing/assisting for another mobile, tele-operated primary robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594461","","Planning;Visualization;Casting;Cameras;Robot sensing systems;Unmanned aerial vehicles","aircraft control;autonomous aerial vehicles;collision avoidance;mobile robots;motion control;multi-robot systems;robot vision","confined environment;cluttered environment;tethered aerial vehicles;tethered agent;nonfree space;motion planning frameworks;motion planning strategies;motion planning algorithms;UAV;robotic locomotion;reachable configuration space;marsupial heterogeneous robotic teams;Fotokite Pro","","","22","","","","","IEEE","IEEE Conferences"
"Unit Quaternion-Based Parameterization for Point Features in Visual Navigation","J. Maley; G. Huang","U.S. Army Research Lab, Aberdeen Proving Ground, MD, 21005, USA; University of Delaware, Department of Mechanical Engineering, Newark, DE, 19716, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6880","6886","In this paper, we propose to use unit quaternions to represent point features in visual navigation. Contrary to the Cartesian 3D representation, the unit quaternion can well represent features at both large and small distances from the camera without suffering from convergence problems. Contrary to inverse-depth, homogeneous points, or anchored homogeneous points, the unit quaternion has error state of minimum dimension of three. In contrast to prior representations, the proposed method does not need to approximate an initial infinite depth uncertainty. In fact, the unit-quaternion error covariance can be initialized from the initial feature observations without prior information, and the initial error-states are not only bounded, but the bound is identical for all scene geometries. To the best of our knowledge, this is the first time bearing-only recursive estimation (in covariance form) of point features has been possible without using measurements to initialize error covariance. The proposed unit quaternion-based representation is validated on numerical examples.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594206","","Quaternions;Cameras;Simultaneous localization and mapping;Visualization;Navigation;Convergence;Three-dimensional displays","covariance matrices;geometry;image representation;recursive estimation;SLAM (robots)","point features;visual navigation;Cartesian 3D representation;homogeneous points;error state;unit-quaternion error covariance;initial feature observations;initial error-states;unit quaternion-based representation;unit quaternion-based parameterization;initial infinite depth uncertainty","","","25","","","","","IEEE","IEEE Conferences"
"GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation","N. Hirose; A. Sadeghian; M. Vázquez; P. Goebel; S. Savarese","Computer Science Department, Stanford University, Stanford AI Lab, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, Stanford AI Lab, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, Stanford AI Lab, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, Stanford AI Lab, 353 Serra Mall, Stanford, CA, USA; Computer Science Department, Stanford University, Stanford AI Lab, 353 Serra Mall, Stanford, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3044","3051","We present semi-supervised deep learning approaches for traversability estimation from fisheye images. Our method, GONet, and the proposed extensions leverage Generative Adversarial Networks (GANs) to effectively predict whether the area seen in the input image(s) is safe for a robot to traverse. These methods are trained with many positive images of traversable places, but just a small set of negative images depicting blocked and unsafe areas. This makes the proposed methods practical. Positive examples can be collected easily by simply operating a robot through traversable spaces, while obtaining negative examples is time consuming, costly, and potentially dangerous. Through extensive experiments and several demonstrations, we show that the proposed traversability estimation approaches are robust and can generalize to unseen scenarios. Further, we demonstrate that our methods are memory efficient and fast, allowing for real-time operation on a mobile robot with single or stereo fisheye cameras. As part of our contributions, we open-source two new datasets for traversability estimation. These datasets are composed of approximately 24h of videos from more than 25 indoor environments. Our methods outperform baseline approaches for traversability estimation on these new datasets.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594031","","Cameras;Estimation;Robot vision systems;Generators;Training;Gallium nitride","learning (artificial intelligence);mobile robots;neural nets;stereo image processing","traversable places;traversable spaces;traversability estimation approaches;GONet;semisupervised deep learning approach;fisheye images;generative adversarial networks;GANs;stereo fisheye cameras;time 24.0 hour","","2","44","","","","","IEEE","IEEE Conferences"
"Bio-Inspired Design of a Gliding-Walking Multi-Modal Robot","W. D. Shin; J. Park; H. Park","University of Illinois at Urbana-Champaign, Department of Mechanical Science and Engineering, Urbana, IL; University of Illinois at Urbana-Champaign, Department of Mechanical Science and Engineering, Urbana, IL; University of Illinois at Urbana-Champaign, Department of Mechanical Science and Engineering, Urbana, IL","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8158","8164","Versatile multi-modal robots are advantageous for their wider operational environments. By taking design principles from observation of Pteromyini, commonly known as the flying squirrel, which shows balanced performances in both aerial and terrestrial locomotion, a novel robotic platform with the ability of gliding and walking is designed. The flexible membrane and gliding method of Pteromyini have been applied to the robot design. The legs of the robot were optimized to perform with regulated motor torques in both walking and gliding. The robot glided with an average gliding ratio of 1.88 and controlled its angle-of-attack for slowing down to land safely. The robot was able to walk utilizing different gait patterns. These results demonstrated our robot's balanced multi-modal locomotion of gliding and walking.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594210","","Legged locomotion;Aerodynamics;Muscles;Drag;Stability analysis;Thermal stability","aerospace robotics;design engineering;legged locomotion","Pteromyini;multimodal robot gliding;multimodal robot walking;multimodal locomotion robot;regulated motor torques;robot design;flexible membrane;terrestrial locomotion;aerial locomotion;flying squirrel;bio-inspired design","","","31","","","","","IEEE","IEEE Conferences"
"Towards to a Robotic Assisted System for Percutaneous Nephrolithotomy","H. Li; I. Paranawithana; Z. H. Chau; L. Yang; T. S. K. Lim; S. Foong; F. C. Ng; U. Tan","Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Zhejiang University, University of Illinois at Urbana-Champaign Institute, China; Department of Urology, Changi General Hospital, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Department of Urology, Changi General Hospital, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","791","797","Percutaneous Nephrolithotomy is a recommended treatment method for large kidney stone removal. However, the first and most important step, i.e., getting the percutaneous access to create the tract between the targeted calyx and the flank skin, is challenging as the surgeon is often occupied by several tasks at a given time. Therefore, in this paper, we propose a robotic assisted system that collaborates with the surgeon and provides assistance in order for the surgeons to focus on more critical jobs resulting in better surgical performance. A procedure for this robot including three working stages is described. This procedure allows the surgeon to choose a suitable percutaneous target using an ultrasound probe based on his or her experience and the robot will track the respiratory motion of the target kidney stone and insert the needle automatically after the surgeon releases the probe. Experiments are conducted to demonstrate the procedure with the proposed assisted robot for PCNL.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593689","","Surgery;Needles;Probes;Robot sensing systems;Force;Robot kinematics","biomedical ultrasonics;kidney;medical robotics;needles;skin;surgery;ultrasonic therapy","target kidney stone;surgeon;robotic assisted system;percutaneous nephrolithotomy;recommended treatment method;kidney stone removal;percutaneous access;targeted calyx;flank skin;surgical performance;ultrasound probe;respiratory motion;percutaneous target","","","32","","","","","IEEE","IEEE Conferences"
"Design and Implementation of a Novel Aerial Manipulator with Tandem Ducted Fans","Y. Zhang; C. Xiang; B. Xu; Y. Wang; X. Wang","Beijing Institute of Technology, School of Mechanical Engineering, Beijing, 100081, China; Beijing Institute of Technology, Vehicle Research Center, Beijing, 100081, China; Beijing Institute of Technology, Vehicle Research Center, Beijing, 100081, China; China North Vehicle Research Institute, Beijing, 10072, China; Beijing Institute of Technology, School of Mechanical Engineering, Beijing, 100081, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4210","4217","This paper proposes a novel aerial manipulator with tandem ducted fans, which takes both trafficability and effective loading into account. The aerial manipulator is particularly suitable for grasping in complex and narrow environment, in which traditional multi-rotor and helicopter would be inaccessible. The comprehensive integrated dynamic model is established by taking the aerial vehicle dynamics and manipulator dynamics as a whole. On this basis, a multilayer composite controller with feedforward compensation is designed, considering the mutual reactive influence between the aerial vehicle and the manipulator to improve the stability of the system under the motion of the manipulator. The simulation and actual flight tests verify the effectiveness of the design and show good stability and tracking performance of the system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593868","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593868","","Manipulator dynamics;Fans;Payloads;Helicopters;Ducts","aerospace testing;aircraft control;autonomous aerial vehicles;compensation;control system synthesis;fans;feedforward;helicopters;manipulator dynamics;stability;vehicle dynamics","aerial vehicle dynamics;manipulator dynamics;tandem ducted fans;trafficability;comprehensive integrated dynamic model;aerial manipulator;loading;multirotor;multilayer composite controller;feedforward compensation;flight tests","","","19","","","","","IEEE","IEEE Conferences"
"CalibNet: Geometrically Supervised Extrinsic Calibration using 3D Spatial Transformer Networks","G. Iyer; R. K. Ram; J. K. Murthy; K. M. Krishna","Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Mila, Université de Montréal, Quebec, Canada; Robotics Research Center, International Institute of Information Technology, Hyderabad, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1110","1117","3D LiDARs and 2D cameras are increasingly being used alongside each other in sensor rigs for perception tasks. Before these sensors can be used to gather meaningful data, however, their extrinsics (and intrinsics) need to be accurately calibrated, as the performance of the sensor rig is extremely sensitive to these calibration parameters. A vast majority of existing calibration techniques require significant amounts of data and/or calibration targets and human effort, severely impacting their applicability in large-scale production systems. We address this gap with CalibNet: a geometrically supervised deep network capable of automatically estimating the 6-DoF rigid body transformation between a 3D LiDAR and a 2D camera in real-time. CalibNet alleviates the need for calibration targets, thereby resulting in significant savings in calibration efforts. During training, the network only takes as input a LiDAR point cloud, the corresponding monocular image, and the camera calibration matrix K. At train time, we do not impose direct supervision (i.e., we do not directly regress to the calibration parameters, for example). Instead, we train the network to predict calibration parameters that maximize the geometric and photometric consistency of the input images and point clouds. CalibNet learns to iteratively solve the underlying geometric problem and accurately predicts extrinsic calibration parameters for a wide range of mis-calibrations, without requiring retraining or domain adaptation. The project page is hosted at https://epiception.github.io/CalibNet.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593693","","Calibration;Three-dimensional displays;Cameras;Laser radar;Robot sensing systems;Training;Two dimensional displays","calibration;cameras;image processing;image sensors;learning (artificial intelligence);optical radar","extrinsic calibration parameters;underlying geometric problem;photometric consistency;geometric consistency;camera calibration matrix K;LiDAR point cloud;calibration efforts;rigid body transformation;geometrically supervised deep network capable;calibration targets;calibration techniques;meaningful data;sensor rig;3D LiDAR;3D spatial transformer networks;geometrically supervised extrinsic calibration","","","24","","","","","IEEE","IEEE Conferences"
"A Differential Elastic Joint for Multi-linked Pipeline Inspection Robots","A. Kakogawa; S. Ma","Department of Robotics, Faculty of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, JAPAN; Department of Robotics, Faculty of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","949","954","This study presents a differential elastic joint for use in multi-linked pipeline inspection robots. Active joints to stretch against the pipe wall are essential for adapting robots to use in vertical pipes and slippery inner surfaces where a large traction force is required. Series elastic actuators with a high reduction system have typically been used to sense force/torque in such applications. However, compactness, power, and bi-directional series elasticity are required to conduct in-pipe inspections. In this study, we propose an active joint using a differential elastic actuator with a rubber spring for decreasing the size and increasing the stiffness of the joint. After describing the configuration of the differential elastic actuator that is suitable for our robot and the design theory of the rubber spring cross-section, we conducted experiments to verify its torque property.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593872","","Springs;Gears;Torque;Robots;Wheels;Inspection;Actuators","actuators;elasticity;inspection;mobile robots;pipelines;pipes;rubber;service robots;springs (mechanical)","bi-directional series elasticity;series elastic actuators;slippery inner surfaces;vertical pipes;pipe wall;multilinked pipeline inspection robots;differential elastic joint;differential elastic actuator;active joint;in-pipe inspections","","","24","","","","","IEEE","IEEE Conferences"
"Learning How Pedestrians Navigate: A Deep Inverse Reinforcement Learning Approach","M. Fahad; Z. Chen; Y. Guo","Department of Electrical & Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, 07030, USA; Department of Electrical & Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, 07030, USA; Department of Electrical & Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, 07030, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","819","826","Humans and mobile robots will be increasingly cohabiting in the same environments, which has lead to an increase in studies on human robot interaction (HRI). One important topic in these studies is the development of robot navigation algorithms that are socially compliant to humans navigating in the same space. In this paper, we present a method to learn human navigation behaviors using maximum entropy deep inverse reinforcement learning (MEDIRL). We use a large open dataset of pedestrian trajectories collected in an uncontrolled environment as the expert demonstrations. Human navigation behaviors are captured by a nonlinear reward function through deep neural network (DNN) approximation. The developed MEDIRL algorithm takes feature inputs including social affinity map (SAM) that are extracted from human motion trajectories. We perform simulation experiments using the learned reward function, and the performance is evaluated comparing it with the real measured pedestrian trajectories in the dataset. The evaluation results show that the proposed method has acceptable prediction accuracy compared to other state-of-the-art methods, and it can generate pedestrian trajectories similar to real human trajectories with natural social navigation behaviors such as collision avoidance, leader-follower, and split-and-rejoin.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593438","","Navigation;Robots;Trajectory;Reinforcement learning;Collision avoidance;Neural networks;Entropy","collision avoidance;feature extraction;human-robot interaction;learning (artificial intelligence);mobile robots;navigation;neural nets;trajectory control","mobile robots;human robot interaction;robot navigation algorithms;human navigation behaviors;maximum entropy deep inverse reinforcement learning;nonlinear reward function;deep neural network approximation;social affinity map;human motion trajectories;learned reward function;natural social navigation behaviors;deep inverse reinforcement learning approach;pedestrian trajectories;MEDIRL algorithm;feature extraction;collision avoidance;pedestrians navigation","","","28","","","","","IEEE","IEEE Conferences"
"A Multi-Rate State Observer for Visual Tracking of Magnetic Micro-Agents Using 2D Slow Medical Imaging Modalities","M. Kaya; A. Denasi; S. Scheggi; E. Agbahca; C. Yoon; D. H. Gracias; S. Misra","Department of Biomechanical Engineering, University of Twente, Surgical Robotics Laboratory, Netherlands; Department of Biomechanical Engineering, University of Twente, Surgical Robotics Laboratory, Netherlands; Department of Biomechanical Engineering, University of Twente, Surgical Robotics Laboratory, Netherlands; Department of Computer Engineering, Faculty of Technology, Selcuk University, Turkey; Department of Materials Science and Engineering, The Johns Hopkins University, USA; Department of Materials Science and Engineering, The Johns Hopkins University, USA; Department of Biomechanical Engineering, University of Twente, Surgical Robotics Laboratory, Netherlands","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","Minimally invasive surgery can benefit greatly from utilizing micro-agents. These miniaturized agents need to be clearly visualized and precisely controlled to ensure the success of the surgery. Since medical imaging modalities suffer from low acquisition rate, multi-rate sampling methods can be used to estimate the intersample states of micro-agents. Hence, the sampling rate of the controller can be virtually increased even if the position data is acquired using a slow medical imaging modality. This study presents multi-rate Luenberger and Kalman state estimators for visual tracking of micro-agents. The micro-agents are tracked using sum of squared differences and normalized cross correlation based visual tracking. Further, the outputs of the two methods are merged to minimize the tracking error and prevent tracking failures. During the experiments, the micro-agents with different geometrical shapes and sizes are imaged using a 2D ultrasound machine and a microscope, and manipulated using electromagnetic coils. The multi-rate state estimation accuracy is measured using a high speed camera. The precision of the tracking and multi-rate state estimation are verified experimentally under challenging conditions. For this purpose, an elliptical shaped magnetic micro-agent with a length of 48 pixels is used. Maximum absolute error in x and y axes are 2.273 and 2.432 pixels for an 8-fold increase of the sample rate (25 frames per second), respectively. During the experiments, it was observed that the micro-agents could be tracked more reliably using normalized cross correlation based visual tracking and inters ample states could be estimated more accurately using Kalman state estimator. Experimental results show that the proposed method could be used to track micro-agents in medical imaging modalities and estimate system states at intermediate time instants in real-time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594349","","Visualization;Tracking;Biomedical imaging;Jacobian matrices;Two dimensional displays;State estimation;Magnetic resonance imaging","biological tissues;biomedical optical imaging;biomedical ultrasonics;cameras;Kalman filters;medical image processing;object tracking;observers;sampling methods;surgery","multirate state observer;visual tracking;magnetic microagents;Luenberger state estimators;minimally invasive surgery;tracking error;ultrasound microscope;ultrasound machine;electromagnetic coils;Kalman state estimator;multirate state estimation;medical imaging modality;multirate sampling methods","","","23","","","","","IEEE","IEEE Conferences"
"Predicting Part Affordances of Objects Using Two-Stream Fully Convolutional Network with Multimodal Inputs","K. Chaudhary; K. Okada; M. Inaba; X. Chen","Graduate School of Information Science and Technology, The University of Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Japan; Key Laboratory of Machine Perception, Peking University, Beijing, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3096","3101","For a robot to manipulate an object, it has to understand the functions and the actions that can be subjected to the object. This set of information is known as affordance of the object. Affordances are generally defined by the geometrical structures and physical properties of the objects. In this paper, we present an affordance detection network (ADNet) for detecting object affordances using multimodal input i.e., RGB-D data. The method is based on the state-of-the-art fully convolutional network with two encoding streams and one decoding stream. In the presented formulation, the network learns powerful discriminative features independently from the RGB and depth images, which enables it to abstract rich photometrical and geometrical properties of the objects. The multimodal encoding is combined at multiple stages of the network using the late-fusion strategy and used is for predicting the potential affordances of the objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593617","Affordance detection network (ADNet);fully convolutional network (FCN)","Feature extraction;Encoding;Task analysis;Robots;Streaming media;Decoding;Fuses","convolutional neural nets;image fusion;learning (artificial intelligence)","convolutional network;part affordances;object affordances;affordance detection network;physical properties;geometrical structures;two-stream fully convolutional network;potential affordances;multimodal encoding;geometrical properties;abstract rich photometrical properties;depth images;powerful discriminative features;decoding stream;encoding streams;RGB-D data","","","18","","","","","IEEE","IEEE Conferences"
"Robot Identification and Localization with Pointing Gestures","B. Gromov; L. M. Gambardella; A. Giusti","IDSIA USI-SUPSI, Dalle Molle Institute for Artificial Intelligence, Lugano, Switzerland; IDSIA USI-SUPSI, Dalle Molle Institute for Artificial Intelligence, Lugano, Switzerland; IDSIA USI-SUPSI, Dalle Molle Institute for Artificial Intelligence, Lugano, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3921","3928","We propose a novel approach to establish the relative pose of a mobile robot with respect to an operator that wants to interact with it; we focus on scenarios in which the robot is in the same environment as the operator, and is visible to them. The approach is based on comparing the trajectory of the robot, which is known in the robot's odometry frame, to the motion of the arm of the operator, who, for a short time, keeps pointing at the robot they want to interact with. In multi-robot scenarios, the same approach can be used to simultaneously identify which robot the operator wants to interact with. The main advantage over alternatives is that our system only relies on the robot's odometry, on a wearable inertial measurement unit (IMU), and, crucially, on the operator's own perception. We experimentally show the feasibility of our approach using real-world robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594174","","Robot sensing systems;Robot kinematics;Solid modeling;Manipulators;Drones;Three-dimensional displays","distance measurement;gesture recognition;mobile robots;multi-robot systems;pose estimation;robot vision;SLAM (robots)","mobile robot;multirobot scenarios;robot identification and localization;gesture pointing;robot odometry frame;inertial measurement unit;IMU","","2","33","","","","","IEEE","IEEE Conferences"
"Motion Control of Piezo-Driven Stage via a Chattering-Free Sliding Mode Controller with Hysteresis Compensation","Y. Fan; Y. He; D. Zhang; U. Tan","Singapore University of Technology and Design, Pillar of Engineering Product Development, 8 Somapah Road, Singapore, 487372, Singapore; Singapore University of Technology and Design, Pillar of Engineering Product Development, 8 Somapah Road, Singapore, 487372, Singapore; School of Mechanical Engineering, Shanghai Jiao Tong University, State Key Laboratory of Mechanical System and Vibration, Shanghai, 200240, China; Singapore University of Technology and Design, Pillar of Engineering Product Development, 8 Somapah Road, Singapore, 487372, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6424","6430","This paper presents a novel sliding mode controller for trajectory tracking of the piezo-driven stage. The tracking performance of piezoelectric actuator is mainly affected by the hysteresis nonlinearity. Sliding mode control is a possible solution to achieve better tracking performance. However, conventional sliding mode control generates discontinuous control signal which results in chattering. Hence, the hysteresis nonlinearity is first compensated with a hysteresis model, and an uncertainty and disturbance estimator is designed and included to devise a smooth control action. The stability of the proposed method is demonstrated via Lyapunov analysis. Both simulation and experiment are also conducted to verify the effectiveness of the proposed approach. The results are compared with a conventional sliding mode controller and a proportional-integral control with notch filter (PIC-NF).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593442","","Hysteresis;Uncertainty;Sliding mode control;Stability analysis;Feedforward systems;Integrated circuit modeling","compensation;control nonlinearities;hysteresis;Lyapunov methods;motion control;nonlinear control systems;piezoelectric actuators;stability;trajectory control;uncertain systems;variable structure systems","hysteresis compensation;trajectory tracking;piezo-driven stage;hysteresis nonlinearity;hysteresis model;motion control;chattering-free sliding mode controller;disturbance estimator;Lyapunov analysis","","","24","","","","","IEEE","IEEE Conferences"
"Deep Reinforcement Learning for Robotic Assembly of Mixed Deformable and Rigid Objects","J. Luo; E. Solowjow; C. Wen; J. A. Ojea; A. M. Agogino","Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Siemens Corporate Technology, Berkeley, CA, 94704, USA; Siemens Corporate Technology, Berkeley, CA, 94704, USA; Siemens Corporate Technology, Berkeley, CA, 94704, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2062","2069","Reinforcement learning for assembly tasks can yield powerful robot control algorithms for applications that are challenging or even impossible for “conventional” feedback control methods. Insertion of a rigid peg into a deformable hole of smaller diameter is such a task. In this contribution we solve this task with Deep Reinforcement Learning. Force-torque measurements from a robot arm wrist sensor are thereby incorporated two-fold; they are integrated into the policy learning process and they are exploited in an admittance controller that is coupled to the neural network. This enables robot learning of contact-rich assembly tasks without explicit joint torque control or passive mechanical compliance. We demonstrate our approach in experiments with an industrial robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594353","","Robot sensing systems;Task analysis;Reinforcement learning;Neural networks;Service robots;Robotic assembly","control engineering computing;feedback;industrial robots;learning (artificial intelligence);neural nets;position control;robot programming;robotic assembly;torque control;torque measurement","neural network;force torque measurements;passive mechanical compliance;deep reinforcement learning;torque control;robot control algorithms;assembly tasks;feedback control methods;robotic assembly;industrial robot;robot learning;admittance controller;policy learning process;robot arm wrist sensor;deformable hole;rigid peg","","","28","","","","","IEEE","IEEE Conferences"
"SOS: Stereo Matching in O(1) with Slanted Support Windows","V. Tankovich; M. Schoenberg; S. R. Fanello; A. Kowdle; C. Rhemann; M. Dzitsiuk; M. Schmidt; J. Valentin; S. Izadi","Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google; Augmented Perception group at Google","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6782","6789","Depth cameras have accelerated research in many areas of computer vision. Most triangulation-based depth cameras, whether structured light systems like the Kinect or active (assisted) stereo systems, are based on the principle of stereo matching. Depth from stereo is an active research topic dating back 30 years. Despite recent advances, algorithms usually trade-off accuracy for speed. In particular, efficient methods rely on fronto-parallel assumptions to reduce the search space and keep computation low. We present SOS (Slanted O(1) Stereo), the first algorithm capable of leveraging slanted support windows without sacrificing speed or accuracy. We use an active stereo configuration, where an illuminator textures the scene. Under this setting, local methods - such as PatchMatch Stereo - obtain state of the art results by jointly estimating disparities and slant, but at a large computational cost. We observe that these methods typically exploit local smoothness to simplify their initialization strategies. Our key insight is that local smoothness can in fact be used to amortize the computation not only within initialization, but across the entire stereo pipeline. Building on these insights, we propose a novel hierarchical initialization that is able to efficiently perform search over disparity and slants. We then show how this structure can be leveraged to provide high quality depth maps. Extensive quantitative evaluations demonstrate that the proposed technique yields significantly more precise results than current state of the art, but at a fraction of the computational cost. Our prototype implementation runs at 4000 fps on modern GPU architectures.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593800","","Microsoft Windows;Cameras;Image reconstruction;Three-dimensional displays;Correlation;Image resolution;Optimization","cameras;computer vision;image matching;image reconstruction;image texture;stereo image processing","stereo matching;slanted support windows;computer vision;triangulation-based depth cameras;structured light systems;active research topic;trade-off accuracy;fronto-parallel assumptions;search space;active stereo configuration;local methods;PatchMatch Stereo;computational cost;local smoothness;entire stereo pipeline;high quality depth maps","","","48","","","","","IEEE","IEEE Conferences"
"3D-printed flexure-based finger joints for anthropomorphic hands","L. Garcia; M. Naves; D. M. Brouwer","Precision Engineering, Faculty of Engineering Technology, University of Twente, Enschede, AE, 7500, The Netherlands; Precision Engineering, Faculty of Engineering Technology, University of Twente, Enschede, AE, 7500, The Netherlands; Precision Engineering, Faculty of Engineering Technology, University of Twente, Enschede, AE, 7500, The Netherlands","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1437","1442","Flexure-based finger joints for prosthetic hands have been studied, but until now they lack stiffness and load bearing capacity. In this paper we present a design which combines large range of motion, stiffness and load bearing capacity, with an overload protection mechanism. Several planar and non-planar hinge topologies are studied to determine load capacity over the range of motion. Optimized topologies are compared, in 30 degrees deflected state, in terms of stresses by deflection and grasping forces. Additionally, support stiffnesses were computed for all hinges in the whole range of motion (45 degrees). The Hole Cross Hinge presented the best performance over the range of motion with a grasping force up to 15 N while deflected 30 degrees. A new concept, the Angle Three-Flexure Cross Hinge, provides outstanding performance for deflections from 17.5 up to 30 degrees with a 20 N maximum grasping force when fully deflected. Experimental verification of the support stiffness over the range of motion shows some additional compliances, but the stiffness trend of the printed hinge is in line with the model. The presented joints power grasping capability outperform current state flexure-base hands and are comparable to commercial non-flexure-based prosthetic hands. In the event of excessive loads, an overload protection mechanism is in place to protect the flexure- hinges.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594102","Compliant joints;flexures;robotic hand;prosthetic hand;anthropomorphic;additive manufacturing","Fasteners;Force;Topology;Grasping;Stress;Optimization;Load modeling","dexterous manipulators;grippers;hinges;production engineering computing;prosthetics;springs (mechanical);three-dimensional printing","3D printed flexure-based finger joints;grasping force;load bearing capacity;anthropomorphic hands;nonflexure-based prosthetic hands;presented joints power grasping capability outperform current state flexure-base hands;Angle Three-Flexure Cross Hinge","","","19","","","","","IEEE","IEEE Conferences"
"Development of Tendon Driven Under-Actuated Mechanism Applied in an EMG Prosthetic Hand with Three Major Grasps for Daily Life","X. Jing; X. Yong; L. Tian; S. Togo; Y. Jiang; H. Yokoi; G. Li","CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences (CAS), Shenzhen, Guangdong, 518055, China; Guangdong Provincial Key Lab of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China; CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences (CAS), Shenzhen, Guangdong, 518055, China; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, 182-8585, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, 182-8585, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu, Tokyo, 182-8585, Japan; CAS Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences (CAS), Shenzhen, Guangdong, 518055, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2774","2779","This paper presents a lightweight (<;250 g) and low-cost (<;350 USD) biomimetic prosthetic hand with two actuators embedded in the palm. One of them is employed for flexion/extension of the five digits, and the other one is used for the adduction/abduction of thumb. Thus, the hand can achieve major grasping tasks that account for about 85% of activities in daily life. The unique transmission provides various advantages such as a compact structure, weight saving, and short driven distance. Furthermore, by using 3D printing technology, most parts of the prosthetic hand were made to be much lighter and have a humanlike appearance, compared with conventionally manufactured artificial hand. Finally, the performance and practical applicability of the proposed design was verified experimentally through both of a motion verification and an intuitive control test by a healthy subject and a transradial amputee.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593939","","Thumb;Tendons;Indexes;Grasping;Prosthetic hand;Actuators","actuators;biomechanics;biomimetics;electromyography;medical control systems;prosthetics;three-dimensional printing","EMG prosthetic hand;grasps;daily life;actuators;grasping tasks;weight saving;short driven distance;3D printing technology;flexion-extension;artificial hand;tendon driven under-actuated mechanism;biomimetic prosthetic hand;thumb adduction-abduction;compact structure;motion verification;transradial amputee","","","16","","","","","IEEE","IEEE Conferences"
"Adversarial Transfer Networks for Visual Tracking","L. Liu; J. Lu; J. Zhou","Department of Automation, Tsinghua University, State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, 100084, China; Department of Automation, Tsinghua University, State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, 100084, China; Department of Automation, Tsinghua University, State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, 100084, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","75","81","Visual tracking plays an important role in unmanned systems. In many cases, the system needs to keep track of targets it has never seen before, and the only training sample available is the specified object in the initial frame. In this paper, we propose a deep architecture called adversarial transfer networks (ATNet), which aims to make well use of offline video training data and solve the problem of lacking training samples in visual tracking. Different from most existing trackers which neglect significant differences between videos and gulp the training data all together, our method utilizes the special nature of tracking problem and concentrates on transferring domain-specific information across similar tracking tasks. We first propose an efficient way to select a training video that is most similar to online tracking task and regard it as source domain. With the labeled data in the selected source domain, we apply adversarial transfer learning to make the feature distribution of source-domain samples and target-domain samples as similar as possible. Therefore, the transferred source-domain samples can provide various possible appearance of tracked target for training and boost the tracking performance. Experimental results on three OTB tracking benchmarks show that our method outperforms the state-of-the-art trackers in both accuracy and robustness.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593585","","Target tracking;Videos;Training;Visualization;Task analysis;Feature extraction;Learning systems","learning (artificial intelligence);object tracking;video signal processing","visual tracking;domain-specific information;target-domain samples;adversarial transfer networks;unmanned systems;offline video training data;ATNet;source-domain samples;adversarial transfer learning","","","30","","","","","IEEE","IEEE Conferences"
"Sensory-motor augmentation of the robot with shared human perception","R. Ishida; L. Meli; Y. Tanaka; K. Minamizawa; D. Prattichizzo","Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Gokiso-cho, Nagoya, 466-8555, Japan; Dept. of Information Engineering and Mathematics, University of Siena, Italy; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Gokiso-cho, Nagoya, 466-8555, Japan; Graduate School of Media Design, Keio University, Yokohama, Kanagawa, 223-8526, Japan; Dept. of Information Engineering and Mathematics, University of Siena, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2596","2603","Robots have replaced people in many manufacturing production lines but the information they gather from sensors might not be sufficient to autonomously accomplish dexterous manipulation operations. Symbiotic human-robot cooperation appears to be a more realistic near future in industrial scenarios. In this paper we present a configuration of human-robot collaboration in which the robot is sensory-augmented by means of a set of tactile signals coming from the human operator. The incorporation of low-level robot “intelligence” permits the cooperative manipulation of an object while enabling the human operator to stay focused on task itself and carry it out in the most natural way. The effectiveness of this approach is demonstrated in a use case in which a robot helps a human operator to successfully accomplish a writing task. System performance has been evaluated, considering several positions of the tiny vibration sensor in charge of gathering the human perception, by testing it on both the human hand and the co-manipulated object. Results suggest that the sensor provides valuable information for recognizing operator actions when it is placed either on the human hand or on the co-manipulated object. However, the sensor on the finger directly represents the operator's perception, while the output of the sensor attached to the object changes according to the distance between the interaction point and the sensor itself. In addition, in wearing the sensor, neither the object nor the robot need to be instrumented: the operator is free to interact with a large set of objects and collaborate with any existing robot without requiring supplemental equipment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594496","","Robot sensing systems;Task analysis;Vibrations;Force;Mechanical sensors","control engineering computing;dexterous manipulators;haptic interfaces;human-robot interaction;manipulators;man-machine systems;mobile robots;robot vision;robots;tactile sensors","operator actions;co-manipulated object;human hand;tiny vibration sensor;low-level robot intelligence;human operator;human-robot collaboration;human-robot cooperation;dexterous manipulation operations;manufacturing production lines;shared human perception;sensory-motor augmentation","","","20","","","","","IEEE","IEEE Conferences"
"Fuzzy-Based Feedback Control of a Tip-Mounted Module for Robot-Assisted Endoscopy*This material based on work supported by Defense Advanced Research Projects Agency (DARPA), A2P (Grant No. FA8650-15-C-7548). This work was also partially funded by the Wyss Institute for Biologically Inspired Engineering and the John A. Paulson School of Engineering and Applied Sciences at Harvard University. In addition, the prototypes were enabled by equipment supported by the ARO DURIP program (Award No. W911NF-13-1-0311)","J. Gafford; H. Aihara; C. Thompson; C. Walsh; R. Wood","Harvard University, John A. Paulson School of Engineering and Applied Sciences, Cambridge, MA, 02138, USA; Hiroyuki Aihara and Christopher Thompson are with Brigham and Women's Hospital, Boston, MA, 02115, USA; Hiroyuki Aihara and Christopher Thompson are with Brigham and Women's Hospital, Boston, MA, 02115, USA; Hiroyuki Aihara and Christopher Thompson are with Brigham and Women's Hospital, Boston, MA, 02115, USA; Paulson School of Engineering and Applied Sciences and the Wyss Institute for Biologically-Inspired Engineering, Cambridge, MA, 02138, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Nascent endoscopic therapeutic procedures, such as endoscopic submucosal dissection, enable unparalleled access to and removal of mid-size cancerous neoplasia from within the gastrointestinal tract. However, the remote locations of these lesions often incur substantial distal dexterity which imparts appreciable cognitive loading on the clinician and opens up the possibility of adverse events such as intestinal perforation due to limited dexterity and a lack of sensory feedback. In this work, we introduce a mm-scale, tip-mounted robotic system, EndoMODRA (Endoscopic Module for On-Demand Robotic Assistance), which interfaces with commercially-available endoscopic tools and provides additional dexterity and feedback sensing using on-board actuators and sensors, decoupling tool motion from endoscope motion. Leveraging alternative high-energy-density actuation strategies and monolithic, printed-circuit-inspired manufacturing processes, all actuation and sensing is fully contained within the distally-mounted module, obviating the need for a continuous mechanical transmission to a proximal motor package. We develop a fuzzy-tuned PID/PWM controller for closing the loop distally to enable closed-loop position-controlled trajectory execution using onboard actuation and sensing, realizing fully -distal loop closure in an endoscope-mounted robotic module with no proximal actuation or sensing component. Controller performance is validated on a fully-integrated module with on-board sensing, demonstrating the ability to execute pre-determined trajectories as well as real-time rate-based teleoperation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593764","","Robot sensing systems;Actuators;Tools;Endoscopes;Cooling","actuators;biomedical optical imaging;cancer;closed loop systems;dexterous manipulators;endoscopes;feedback;medical robotics;position control;surgery;telerobotics;three-term control","intestinal perforation;sensory feedback;tip-mounted robotic system;commercially-available endoscopic tools;feedback sensing;on-board actuators;tool motion;endoscope motion;alternative high-energy-density actuation strategies;monolithic circuit-inspired manufacturing processes;printed-circuit-inspired manufacturing processes;distally-mounted module;proximal motor package;fuzzy-tuned PID/PWM controller;closed-loop position-controlled trajectory execution;distal loop closure;endoscope-mounted robotic module;proximal actuation;controller performance;feedback control;robot-assisted endoscopy;nascent endoscopic therapeutic procedures;endoscopic submucosal dissection;mid-size cancerous neoplasia;gastrointestinal tract;distal dexterity;cognitive loading;tip-mounted module;realtime rate-based teleoperation;endoscopic module for on-demand robotic assistance","","","20","","","","","IEEE","IEEE Conferences"
"PiDrone: An Autonomous Educational Drone Using Raspberry Pi and Python","I. Brand; J. Roy; A. Ray; J. Oberlin; S. Oberlix","Brown University; Brown University; Brown University; Brown University; Brown University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","A compelling robotics course begins with a compelling robot. We introduce a new low-cost aerial educational platform, the PiDrone, along with an associated college-level introductory robotics course. In a series of projects, students incrementally build, program, and test their own drones to create an autonomous aircraft capable of using a downward facing RGB camera and infrared distance sensor to visually localize and maintain position. The PiDrone runs Python and the Robotics Operating System (ROS) framework on an onboard Raspberry Pi, providing an accessible and inexpensive platform for introducing students to robotics. Students can use any web and SSH capable computer as a base station and programming platform. The projects and supplementary homeworks introduce PID control, state estimation, and high-level planning, giving students the opportunity to exercise their new skills in an exciting long-term project.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593943","","Drones;Educational robots;Robot sensing systems;Python;Service robots;Hardware","aerospace robotics;cameras;computer aided instruction;control engineering education;educational courses;mobile robots;Python;remotely operated vehicles;robot programming;robot vision;state estimation;three-term control","high-level planning;PiDrone;autonomous educational drone;Python;compelling robotics course;low-cost aerial educational platform;associated college-level introductory robotics course;autonomous aircraft;downward facing RGB camera;distance sensor;onboard Raspberry Pi;accessible platform;inexpensive platform;SSH capable computer;base station;programming platform;robotics operating system framework;ROS framework;PID control;state estimation","","","18","","","","","IEEE","IEEE Conferences"
"AIBO Robot Mortuary Rites in the Japanese Cultural Context*","E. Knox; K. Watanabe","Faculty of Science and Engineering, Waseda University, Japan; Department of Intermedia Art and Science, Waseda University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2020","2025","In 1999 Sony released the AlBO Entertainment Robot, selling more than 150,000 units worldwide until 2006. By 2014, Sony had stopped offering upgrades and maintenance for the product, and owners were faced with the fact their pet-like robots would “die”. Some shrines and temples in Japan hold ningyo kuyo̅ or mass funerals for dolls and other toys. At the suggestion of a small Japanese tech-repair company called A-Fun, one temple began offering a Buddhist funeral ceremony for AIBOs. Approximately 700 AIBOs have so far received a funeral service. This paper surveys A-Fun`s maintenance services for old AIBOs, the AIBO funerals, and Sony's new 2018 AIBO release, in the cross-disciplinary context of human-machine relations in Japan and elsewhere. Drawing on the author's interviews with key actors, it articulates links between philosophy and neuroscience to explain tendencies toward zoomorphism in robot design. Perceiving presence (sonzai kan) and sensibility (kansei) in objects is a culturally contingent phenomenon. Whereas ways of conceiving the partly animate are largely absent from Western philosophy, in the case of AIBO ownership in Japan there is a reverential mindfulness of the technology's inherent contradictions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594066","","Companies;Maintenance engineering;Animals;Robot sensing systems;Medical treatment;Toy manufacturing industry","biomimetics;robots","AIBO Robot mortuary rites;Japanese cultural context;AlBO Entertainment Robot;Japanese tech-repair company;Buddhist funeral ceremony;A-Fun's maintenance services;AIBO funerals;human-machine relations;robot design;pet-like robots;zoomorphism","","","29","","","","","IEEE","IEEE Conferences"
"Robust Plant Phenotyping via Model-Based Optimization","P. Sodhi; H. Sun; B. Póczos; D. Wettergreen","carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Computer Science Department, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Machine Learning Department, Pittsburgh, PA, 15213, USA; carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7689","7696","Plant phenotyping is the measurement of observable plant traits. Current methods for phenotyping in the field are labour intensive and error prone. High throughput plant phenotyping in an automated and noninvasive manner is crucial to accelerating plant breeding methods. Occlusions and non-ideal sensing conditions is a major problem for high throughput plant phenotyping with most state-of-the-art 3D phenotyping algorithms relying heavily on heuristics or hand-tuned parameters. To address this problem, we present a novel model-based optimization approach for estimating plant physical traits from plant units called phytomers. The proposed approach involves sampling parameterized 3D plant models from an underlying probability distribution. It then optimizes, making the mass of this probability distribution approach true parameters of the model. Reformulating the phenotyping objective as a search in the space of plant models lets us reason about the plant structure in a holistic manner without having to rely on hand-tuned parameters. This makes our approach robust to noise and occlusions as frequently encountered in real world environments. We evaluate our approach for plant units taken across simulated, greenhouse and field environments. This work furthers field-based robotic phenotyping capabilities paving the way for plant biologists to study the coupled effect of genetics and environment on improving crop yields.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594245","","Three-dimensional displays;Imaging;Optimization;Robot sensing systems;Green products;Image reconstruction;Solid modeling","agriculture;biology computing;botany;crops;genetic algorithms;genetics;industrial plants;probability;solid modelling","robust plant phenotyping;observable plant traits;labour intensive error prone;automated manner;noninvasive manner;plant breeding methods;nonideal sensing conditions;high throughput plant phenotyping;state-of-the-art 3D phenotyping algorithms;hand-tuned parameters;novel model-based optimization approach;estimating plant physical traits;plant units;plant models;probability distribution approach;phenotyping objective;plant structure;work furthers field-based robotic phenotyping capabilities;plant biologists;crop yields","","","21","","","","","IEEE","IEEE Conferences"
"ROS Reality: A Virtual Reality Framework Using Consumer-Grade Hardware for ROS-Enabled Robots","D. Whitney; E. Rosen; D. Ullman; E. Phillips; S. Tellex","Brown University; Brown University; Brown University; Brown University; Brown University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Virtual reality (VR)systems let users intuitively interact with 3D environments and have been used extensively for robotic teleoperation tasks. While more immersive than their 2D counterparts, early VR systems were expensive and required specialized hardware. Fortunately, there has been a recent proliferation of consumer-grade VR systems at affordable price points. These systems are inexpensive, relatively portable, and can be integrated into existing robotic frameworks. Our group has designed a VR teleoperation package for the Robot Operating System (ROS), ROS Reality, that can be easily integrated into such frameworks. ROS Reality is an open-source, over-the-Internet teleoperation interface between any ROS-enabled robot and any Unity-compatible VR headset. We completed a pilot study to test the efficacy of our system, with expert human users controlling a Baxter robot via ROS Reality to complete 24 dexterous manipulation tasks, compared to the same users controlling the robot via direct kinesthetic handling. This study provides insight into the feasibility of robotic teleoperation tasks in VR with current consumer-grade resources and exposes issues that need to be addressed in these VR systems. In addition, this paper presents a description of ROS Reality, its components, and architecture. We hope this system will be adopted by other research groups to allow for easy integration of VR teleoperated robots into future experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593513","","Robots;Task analysis;Solid modeling;Virtual reality;Hardware;Two dimensional displays;Engines","control engineering computing;dexterous manipulators;Internet;operating systems (computers);telerobotics;virtual reality","direct kinesthetic handling;robot operating system;ROS reality;virtual reality systems;virtual reality framework;VR teleoperation package;robotic frameworks;consumer-grade VR systems;consumer-grade hardware;robotic teleoperation tasks;Baxter robot;Unity-compatible VR headset;ROS-enabled robot","","","20","","","","","IEEE","IEEE Conferences"
"SwarmTouch: Tactile Interaction of Human with Impedance Controlled Swarm of Nano-Quadrotors","E. Tsykunov; L. Labazanova; A. Tleugazy; D. Tsetserukou","Skolkovo Institute of Science and Technology, Intelligent Space Robotics Laboratory, Moscow, Russian Federation; Skolkovo Institute of Science and Technology, Intelligent Space Robotics Laboratory, Moscow, Russian Federation; Skolkovo Institute of Science and Technology, Intelligent Space Robotics Laboratory, Moscow, Russian Federation; Skolkovo Institute of Science and Technology, Intelligent Space Robotics Laboratory, Moscow, Russian Federation","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4204","4209","We propose a novel interaction strategy for a human-swarm communication when a human operator guides a formation of quadrotors with impedance control and receives vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a life-like swarm behavior. Experimental results with Crazyflie 2.0 quadrotor platform validate the proposed control algorithm. The tactile patterns representing dynamics of the swarm (extension or contraction) are proposed. The user feels the state of the swarm at his fingertips and receives valuable information to improve the controllability of the complex life-like formation. The user study revealed the patterns with high recognition rates. Subjects stated that tactile sensation improves the ability to guide the drone formation and makes the human-swarm communication much more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and immersion into the swarm navigation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594424","","Impedance;Drones;Robots;Mathematical model;Shape;Force;Safety","aircraft control;autonomous aerial vehicles;human-robot interaction;microrobots;multi-robot systems;path planning;tactile sensors;trajectory control","impedance controlled swarm;nanoquadrotors;novel interaction strategy;human-swarm communication;human operator guides;quadrotors;impedance control;human hand velocity;formation shape;Crazyflie 2.0 quadrotor platform;control algorithm;tactile patterns;controllability;complex life-like formation;tactile sensation;drone formation;human-swarm interaction;swarm navigation","","","18","","","","","IEEE","IEEE Conferences"
"HARK-Bird-Box: A Portable Real-time Bird Song Scene Analysis System","R. Kojima; O. Sugiyama; K. Hoshiba; R. Suzuki; K. Nakadai","Department of Biomedical Data Intelligence, Graduate School of Medicine, Kyoto University, Kyoto, Japan; Preemptive Medicine & Lifestyle-Related Disease Research Center, Kyoto University Hospital, Kyoto, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Graduate School of Information Science, Nagoya University, Aichi, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Tokyo, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2497","2502","This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594070","bird song scene analysis;robot audition;scene understanding;real-time system","Birds;Real-time systems;Microphone arrays;Source separation;Feature extraction;Image analysis","acoustic signal processing;feature extraction;learning (artificial intelligence);microphone arrays;neural nets;public domain software;robots;zoology","wild birds;portable device;sound sources;real-time requirement;sound source detection;bird song analysis;open source software;bird song classifier;portability;computational time;bird song dataset;classification accuracy;HARK-bird-box;real-time bird song scene analysis system","","","18","","","","","IEEE","IEEE Conferences"
"Deep Multi-Sensor Lane Detection","M. Bai; G. Mattyus; N. Homayounfar; S. Wang; S. K. Lakshmikanth; R. Urtasun","Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group; Uber Advanced Technologies Group","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3102","3109","Reliable and accurate lane detection has been a long-standing problem in the field of autonomous driving. In recent years, many approaches have been developed that use images (or videos) as input and reason in image space. In this paper we argue that accurate image estimates do not translate to precise 3D lane boundaries, which are the input required by modern motion planning algorithms. To address this issue, we propose a novel deep neural network that takes advantage of both LiDAR and camera sensors and produces very accurate estimates directly in 3D space. We demonstrate the performance of our approach on both highways and in cities, and show very accurate estimates in complex scenarios such as heavy traffic (which produces occlusion), fork, merges and intersections.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594388","","Cameras;Three-dimensional displays;Laser radar;Sensors;Roads;Task analysis;Reliability","driver information systems;image sensors;neural nets;object detection;optical radar;road traffic","multisensor lane detection;reliable lane detection;accurate lane detection;long-standing problem;autonomous driving;image space;accurate image estimates;precise 3D lane boundaries;modern motion planning algorithms;deep neural network;camera sensors;accurate estimates;LiDAR","","","25","","","","","IEEE","IEEE Conferences"
"Diversity in Pedestrian Safety for Industrial Environments Using 3D Lidar Sensors and Neural Networks*Research supported by the New Zealand Ministry for Business Innovation and Employment (MBIE) on contract UOAX1414.","J. Bell; B. A. MacDonald; H. SeokAhn","University of Auckland, Department of Electrical and Computer Engineering, New Zealand; University of Auckland, Department of Electrical and Computer Engineering, New Zealand; University of Auckland, Department of Electrical and Computer Engineering, New Zealand","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7743","7749","The motivation of the work presented here is to create a component of a safety system based on 3D lidar sensors, specifically for industrial environments where some rules can be set for people who will be in close proximity to working robots. Specifically, the operating procedure that is put in place in the workplace is that all people must wear the provided high visibility clothing, which has retro-reflective strips attached. It is shown here that the retro-reflective strips provide a strong cue for pedestrian detection in the intensity data from a lidar sensor within a range of 4 metres. We present and compare multiple methods of exploiting this cue and provide a recommendation for how a safety system should be architected in order to best exploit the lidar intensity data in combination with more common approaches for detection of objects from the lidar range data. Amongst these detection methods is the use of neural networks, which present challenges for key components of standardized safety system development-in particular, for programming methodology control, interpretability of testing and diagnostic coverage. We propose methods for how to start to address these challenges and how to integrate neural networks into safety systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593835","","Laser radar;Safety;Sensors;Neural networks;Three-dimensional displays;Clothing;Strips","neural nets;object detection;optical radar;pedestrians;road safety","high visibility clothing;neural networksresearch;detection methods;lidar range data;lidar intensity data;lidar sensor;pedestrian detection;strong cue;retro-reflective strips;contract UOAX1414;business innovation;new zealand ministry;3D lidar sensors;industrial environments;pedestrian safety","","","26","","","","","IEEE","IEEE Conferences"
"Robust Continuous System Integration for Critical Deep-Sea Robot Operations Using Knowledge-Enabled Simulation in the Loop","C. A. Mueller; T. Doernbach; A. G. Chavez; D. Köhntopp; A. Birk","Computer Science & Electrical Engineering, Jacobs University Bremen, Robotics Group, Germany; Computer Science & Electrical Engineering, Jacobs University Bremen, Robotics Group, Germany; Computer Science & Electrical Engineering, Jacobs University Bremen, Robotics Group, Germany; Computer Science & Electrical Engineering, Jacobs University Bremen, Robotics Group, Germany; Computer Science & Electrical Engineering, Jacobs University Bremen, Robotics Group, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1892","1899","Deep-sea robot operations demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. We present an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This simulation in the loop (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this work provides a platform to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. The conducted evaluation shows the benefit of the proposed work in tasks related to perception and self-localization under changing spatial and environmental conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594392","","Task analysis;Robot sensing systems;Data models;Benchmark testing;Continuous time systems","autonomous underwater vehicles;data acquisition;marine safety;mobile robots","perception;robust continuous system integration;critical deep-sea robot operations;knowledge-enabled simulation;reliability;self-localization;system components;safety;simulation in the loop methodology;SIL methodology","","","26","","","","","IEEE","IEEE Conferences"
"Automatic Extrinsic Calibration of a Camera and a 3D LiDAR Using Line and Plane Correspondences","L. Zhou; Z. Li; M. Kaess","Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5562","5569","In this paper, we address the problem of extrinsic calibration of a camera and a 3D Light Detection and Ranging (LiDAR) sensor using a checkerboard. Unlike previous works which require at least three checkerboard poses, our algorithm reduces the minimal number of poses to one by combining 3D line and plane correspondences. Besides, we prove that parallel planar targets with parallel boundaries provide the same constraints in our algorithm. This allows us to place the checkerboard close to the LiDAR so that the laser points better approximate the target boundary without loss of generality. Moreover, we present an algorithm to estimate the similarity transformation between the LiDAR and the camera for the applications where only the correspondences between laser points and pixels are concerned. Using a similarity transformation can simplify the calibration process since the physical size of the checkerboard is not needed. Meanwhile, estimating the scale can yield a more accurate result due to the inevitable measurement errors of the checkerboard size and the LiDAR intrinsic scale factor that transforms the LiDAR measurement to the metric measurement. Our algorithm is validated through simulations and experiments. Compared to the plane-only algorithms, our algorithm can obtain more accurate result by fewer number of poses. This is beneficial to the large-scale commercial application.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593660","","Cameras;Laser radar;Calibration;Three-dimensional displays;Lasers;Robot vision systems;Approximation algorithms","calibration;cameras;measurement errors;optical radar;optical sensors","checkerboard;3D light detection and ranging sensor;3D line correspondences;3D plane correspondences;measurement errors;plane-only algorithms;LiDAR measurement;LiDAR intrinsic scale factor;calibration process;laser points;parallel planar targets;automatic extrinsic calibration","","","39","","","","","IEEE","IEEE Conferences"
"Natural Dynamics Exploitation of Dynamic Soaring: Towards Bio-Inspired and Energy Efficient Flying Locomotion","M. Nekoui; J. Khaghani; R. Nasiri; M. N. Ahmadabadi","Control and Intelligent Processing Center of Excellence (CIPCE), School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran; Control and Intelligent Processing Center of Excellence (CIPCE), School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran; Control and Intelligent Processing Center of Excellence (CIPCE), School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran; Control and Intelligent Processing Center of Excellence (CIPCE), School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Cognitive Systems Laboratory, Iran","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8171","8176","Albatross has an energy efficient flying pattern (dynamic soaring) among seabirds. This interesting point encourages us to exploit its flying natural dynamics so as to control the flying robots on energy efficient and robust gaits. In doing so, we study the albatross dynamic soaring from analytical and biological perspectives and realize that to generate the dynamic soaring instead of trajectory control, the mechanical energy should be regulated. Accordingly, the control objective is set to mechanical energy regulation, and the bank angle and lift coefficient are computed to satisfy this objective. The presented method is simulated on a standard albatross model and generates two different types of dynamic soaring; O-shaped and a-shaped patterns. In addition, by means of simulations, it is investigated that the presented method is robust in face of variations in initial conditions and unexpected disturbances in the environment's model; i.e., they cannot disturb the stability and cyclic behavior of the system. Moreover, the simulation results are compared with pieces of natural evidence from albatross and interesting similarities are observed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594137","Bio-inspired locomotion;Energy efficiency;Natural dynamics exploitation;Dynamic soaring;Cyclic tasks","Mechanical energy;Aerodynamics;Trajectory;Mathematical model;Birds;Robots","biomimetics;energy conservation;gait analysis;legged locomotion;motion control;robot dynamics;robust control;trajectory control","energy efficient flying locomotion;flying robots;robust gaits;albatross dynamic soaring;biological perspectives;trajectory control;mechanical energy regulation;bio-inspired locomotion;seabirds;stability","","","24","","","","","IEEE","IEEE Conferences"
"Drone Detection Using Depth Maps","A. Carrio; S. Vemprala; A. Ripoll; S. Saripalli; P. Campoy","Computer Vision & Aerial Robotics Group, Universidad Politecnica de Madrid (UPM-CSIC), Madrid, 28003, Spain; Department of Mechanical Engineering, Texas A&M University, College Station, TX, 77843, USA; Computer Vision & Aerial Robotics Group, Universidad Politecnica de Madrid (UPM-CSIC), Madrid, 28003, Spain; Department of Mechanical Engineering, Texas A&M University, College Station, TX, 77843, USA; Computer Vision & Aerial Robotics Group, Universidad Politecnica de Madrid (UPM-CSIC), Madrid, 28003, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1034","1037","Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV) navigation. While solutions have been proposed for static obstacle avoidance, systems enabling avoidance of dynamic objects, such as drones, are hard to implement due to the detection range and field-of-view (FOV) requirements, as well as the constraints for integrating such systems on-board small UAVs. In this work, a dataset of 6k synthetic depth maps of drones has been generated and used to train a state-of-the-art deep learning-based drone detection model. While many sensing technologies can only provide relative altitude and azimuth of an obstacle, our depth map-based approach enables full 3D localization of the obstacle. This is extremely useful for collision avoidance, as 3D localization of detected drones is key to perform efficient collision-free path planning. The proposed detection technique has been validated in several real depth map sequences, with multiple types of drones flying at up to 2 m/s, achieving an average precision of 98.7 %, an average recall of 74.7 % and a record detection range of 9.5 meters.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593405","","Drones;Cameras;Three-dimensional displays;Atmospheric modeling;Sensors;Neural networks;Two dimensional displays","autonomous aerial vehicles;collision avoidance;image sensors;learning (artificial intelligence);mobile robots;object detection","static obstacle avoidance;dynamic objects;field-of-view requirements;on-board small UAVs;relative altitude;azimuth;depth map-based approach;collision avoidance;depth map sequences;unmanned aerial vehicle navigation;collision-free path planning;FOV;deep learning-based drone detection model;sensing technologies;3D localization","","","20","","","","","IEEE","IEEE Conferences"
"Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints","S. Makino; K. Kawaharazuka; A. Fujii; M. Kawamura; T. Makabe; M. Onitsuka; Y. Asano; K. Okada; K. Kawasaki; M. Inaba","Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4562","4567","Human hands can not only grasp objects of various shape and size and manipulate them in hands but also exert such a large gripping force that they can support the body in the situations such as dangling a bar and climbing a ladder. On the other hand, it is difficult for most robot hands to manage both. Therefore in this paper we developed the hand which can grasp various objects and exert large gripping force. To develop such hand, we focused on the thumb CM joint with wide range of motion and the MP joints of four fingers with the DOF of abduction and adduction. Based on the hand with large gripping force and flexibility using machined spring, we applied above mentioned joint mechanism to the hand. The thumb CM joint has wide range of motion because of the combination of three machined springs and MP joints of four fingers have variable rigidity mechanism instead of driving each joint independently in order to move joint in limited space and by limited actuators. Using the developed hand, we achieved the grasping of various objects, supporting a large load and several motions with an arm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594316","","Springs;Joints;Thumb;Muscles;Actuators;Force;Wires","actuators;biomechanics;dexterous manipulators;shear modulus;springs (mechanical)","grasping;fingered hand;machined spring;variable stiffness;human hands;gripping force;robot hands;thumb CM joint;MP joints;fingers;variable rigidity mechanism;joint mechanism","","","13","","","","","IEEE","IEEE Conferences"
"Social Coordination for Looking-Together Situations","S. Akita; S. Satake; M. Shiomi; M. Imai; T. Kanda","ATR, Kyoto, Japan; ATR, Kyoto, Japan; ATR, Kyoto, Japan; ATR, Kyoto, Japan; ATR, Kyoto, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","834","841","People engage in social coordination without explicitly communicating when they are conflicting over spatial resources, e.g., a shop clerk who yields to customers the best place to view products. In this study, we proposed a method that achieves such social coordination with a robot. Our idea is that the social coordination between two agents can be represented as utility-maximizing behavior for joint utility rather than just by a single agent utility. That is, given that each agent's reasonable behavior can be represented as utility-maximizing behavior for single agent utility, we model each agent's plans for himself as well as for the partner agent. Moreover, superiority relationships exist in this joint-utility computation. Since each agent knows such superiority relationships, social coordination can be modeled as utility-yielding behavior based on informed superiority. We specifically focus on looking-together situations for which we developed a utility model. With simulations, we investigate whether the above joint-utility-based modeling successfully reproduces social coordination in looking-together situations. We conducted an experiment in a situation where a tele-operated robot and a customer together look at products in a shop environment. Our experimental results show that our proposed method enables the robot to socially coordinate spatial resources, yielding significantly more thoughtful, less-self-centered, and appropriate impressions than the alternate robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594141","","Robot kinematics;Wheelchairs;Legged locomotion;Computational modeling;Human-robot interaction","telerobotics","social coordination;looking-together situations;utility-maximizing behavior;joint utility;joint-utility computation;utility-yielding behavior;utility model;teleoperated robot","","","31","","","","","IEEE","IEEE Conferences"
"Dual-Arm Relative Tasks Performance Using Sparse Kinematic Control","S. Tarbouriech; B. Navarro; P. Fraisse; A. Crosnier; A. Cherubini; D. Sallé","CNRS, LIRMM, Université de Montpellier, Montpellier, France; CNRS, LIRMM, Université de Montpellier, Montpellier, France; CNRS, LIRMM, Université de Montpellier, Montpellier, France; CNRS, LIRMM, Université de Montpellier, Montpellier, France; CNRS, LIRMM, Université de Montpellier, Montpellier, France; Industry and Transport Division, Tecnalia Research and Innovation","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6003","6009","To make production lines more flexible, dual-arm robots are good candidates to be deployed in autonomous assembly units. In this paper, we propose a sparse kinematic control strategy, that minimizes the number of joints actuated for a coordinated task between two arms. The control strategy is based on a hierarchical sparse QP architecture. We present experimental results that highlight the capability of this architecture to produce sparser motions (for an assembly task) than those obtained with standard controllers.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594320","","Task analysis;Kinematics;Robot kinematics;Jacobian matrices;Manipulators;Aerospace electronics","manipulator kinematics;mobile robots;robotic assembly","dual-arm relative tasks performance;standard controllers;hierarchical sparse QP architecture;coordinated task;sparse kinematic control strategy;autonomous assembly units;dual-arm robots;production lines","","","28","","","","","IEEE","IEEE Conferences"
"Utility Model Re-description within a Motivational System for Cognitive Robotics","A. Romero; F. Bellas; A. Prieto; R. J. Duro","EPS, University of A Coruna, Integrated Group for Engineering Research, Campus de Esteiro, 15043, Spain; EPS, University of A Coruna, Integrated Group for Engineering Research, Campus de Esteiro, 15043, Spain; EPS, University of A Coruna, Integrated Group for Engineering Research, Campus de Esteiro, 15043, Spain; EPS, University of A Coruna, Integrated Group for Engineering Research, Campus de Esteiro, 15043, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2324","2329","This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593799","","Robot sensing systems;Cognitive systems;Robot kinematics;Space exploration;Instruments;Drives","cognition;intelligent robots;learning (artificial intelligence)","motivational system;cognitive architecture;interaction traces;robotic setup;cognitive robotics;value functions;redescriptive approach;utility model redescription;precise utility models;MotivEn model;robot coordination","","","17","","","","","IEEE","IEEE Conferences"
"Close Coordination of Mobile Robots Using Radio Beacons: A New Concept Aimed at Smart Spraying in Agriculture","T. Tourrette; M. Deremetz; O. Naud; R. Lenain; J. Laneurit; V. De Rudnicki","TSCF Unit, Irstea, Aubiere, 9 avenue Blaise Pascal CS 20085, 63172, France; TSCF Unit, Irstea, Aubiere, 9 avenue Blaise Pascal CS 20085, 63172, France; ITAP, Montpellier SupAgro, Univ Montpellier, Irstea, France; TSCF Unit, Irstea, Aubiere, 9 avenue Blaise Pascal CS 20085, 63172, France; TSCF Unit, Irstea, Aubiere, 9 avenue Blaise Pascal CS 20085, 63172, France; ITAP, Montpellier SupAgro, Univ Montpellier, Irstea, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7727","7734","Many agricultural tasks are known to be dangerous for human operators, the environment, and human health in general. The increasing pressure both on safety and on production levels motivates the development of new methodologies and technologies. The rising of off-road mobile robots for agricultural application appears to be a promising contribution to required innovations. It both permits to limit the exposure of people to hazardous products and to achieve difficult and repetitive tasks. Nevertheless, to be fully efficient, autonomous robots have to ensure a high level of accuracy, while carrying potentially heavy tools, possibly in harsh conditions. It is especially the case of spraying, for which accuracy is a key challenge for reducing environmental impacts. The use of huge robots for spraying might seem to be a straightforward solution, by simply automating existing machines. Nevertheless, a simple automation does not reduce directly the environmental impact of human activities (soil compaction, energy, reduction of the use of chemical products). Moreover, huge machines are not necessarily an advantage when considering safety aspects (rollover risk and maneuverability). As a result, a solution based on the cooperation of at least two mobile robots, moving from either side of a vine row, is investigated in this paper thanks to Ultra Wide Band (UWB) technology.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593978","","Mobile robots;Robot kinematics;Robot sensing systems;Spraying;Agriculture","agricultural safety;agriculture;environmental factors;hazardous materials;mobile robots;off-road vehicles;soil;spraying;ultra wideband technology","UWB;Ultra Wide Band technology;soil compaction;safety aspects;chemical products;human activities;environmental impact;autonomous robots;hazardous products;agricultural application;off-road mobile robots;production levels;human health;human operators;smart spraying;radio beacons","","","17","","","","","IEEE","IEEE Conferences"
"Vision-Based State Estimation and Trajectory Tracking Control of Car-Like Mobile Robots with Wheel Skidding and Slipping","S. Zhou; Z. Miao; Z. Liu; H. Zhao; H. Wang; H. Chen; Y. Liu","Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR; Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR; Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR; Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR; Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR; Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR; Dept. of Mechanical and Automation Engg., The Chinese University of Hong Kong, HKSAR","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4270","4275","Most existing trajectory tracking controllers are based on non-skidding and non-slipping assumptions, also assume that full states are accessible, which is unrealistic for real-world applications due to tire-road interaction. This paper presents a novel vision-based approach to achieve high performance tracking control of a Car-Like Mobile Robot (CLMR) with wheel skidding and slippage. A visual estimation algorithm is proposed to provide reliable position, velocity, skidding and slipping information to close the control loop. The stability of the proposed system can be guaranteed by Lyapunov method since the position tracking error and the estimation error converge to zero simultaneously. Simulation is made to validate the effectiveness of the developed controller in the presence of skidding and slipping with online visual estimator.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593982","","Mobile robots;Wheels;Perturbation methods;Visualization;Estimation;Trajectory tracking","automobiles;control system synthesis;estimation theory;Lyapunov methods;mobile robots;motion control;robot vision;stability;state estimation;trajectory control;wheels","car-like mobile robots;wheel slipping;Lyapunov method;system stability;visual estimation algorithm;vision-based approach;wheel skidding;trajectory tracking control;vision-based state estimation","","","14","","","","","IEEE","IEEE Conferences"
"Trait-based Culture and its Organization: Developing a Culture Enabler for Artificial Agents","S. Borgol; E. Blanzieri","Stefano Borgo is with Laboratory for Applied Ontology (LOA), Institute of Cognitive Sciences and Technologies CNR, Trento, Italy; Department of Information Engineering and Computer Science, University of Trento, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","333","338","Artificial agents might not understand human interests and actions if these agents cannot anticipate how a person understands a situation and, based on this, what could be his/her expectations. In many cases, understanding, expectations and behaviors are constrained, if not driven, by culture. Can we provide human culture to an artificial agent? Can we provide formal representations of different cultures? In this paper we discuss the (elusive) notion of culture and propose an approach based on the notion of trait which, we argue, allows building formal modules suitable to represent culture (broadly understood). We distinguish the trait types (knowledge, rule, behavior, interpretation) that such modules should contain and briefly discuss how they could be organized. Finally, we exemplify the role of a trait module in the flow of information internal to an agent highlighting surprising potentialities.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593369","","Cultural differences;Global communication;Organizations;Knowledge based systems;Standards organizations;Intelligent robots;Buildings","artificial intelligence;multi-agent systems;social sciences computing;software agents","trait-based culture;culture enabler;artificial agent;human interests;human culture;trait types;trait module","","","32","","","","","IEEE","IEEE Conferences"
"Iterative Learning of Energy-Efficient Dynamic Walking Gaits","F. H. Kong; I. R. Manchester","The Australian Centre for Field Robotics at the University of Sydney, Sydney, NSW 2006, Australia; The Australian Centre for Field Robotics at the University of Sydney, Sydney, NSW 2006, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3815","3820","Dynamic walking robots have the potential for efficient and lifelike locomotion, but computing efficient gaits and tracking them is difficult in the presence of under-modeling. Iterative Learning Control (ILC) is a method to learn the control signal to track a periodic reference over several attempts, augmenting a model with online data. Terminal ILC (TILC), a variant of ILC, allows other performance objectives to be addressed at the cost of ignoring parts of the reference. However, dynamic walking robot gaits are not necessarily periodic in time. In this paper, we adapt TILC to jointly optimize final foot placement and energy efficiency on dynamic walking robots by indexing by a phase variable instead of time, yielding “phase-indexed TILC” (θ - TILC). When implemented on a five-link walker in simulation, θ- TILC learns a more energy-efficient walking motion compared to traditional time-indexed TILC.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593548","","Legged locomotion;Computational modeling;Data models;Foot;Planning;Convergence","iterative methods;learning systems;legged locomotion;motion control;robot dynamics","energy-efficient dynamic walking gaits;dynamic walking robots;lifelike locomotion;efficient gaits;Iterative Learning Control;control signal;periodic reference;terminal ILC;dynamic walking robot gaits;final foot placement;energy efficiency;phase-indexed TILC;energy-efficient walking motion;time-indexed TILC","","","36","","","","","IEEE","IEEE Conferences"
"Robust Sensor Fusion with Self-Tuning Mixture Models","T. Pfeifer; P. Protzel","Dept. of Electrical Engineering and Information Technology, TU Chemnitz, Germany; Dept. of Electrical Engineering and Information Technology, TU Chemnitz, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3678","3685","A fundamental problem of non-linear state estimation in robotics is the violation of assumptions about the sensors' error distribution. State of the art approaches reduce the impact of these violations with robust cost functions or predefined non-Gaussian error models. Both require extensive parameter tuning and fail if the sensors' error characteristic changes over time, due to environmental changes, ageing or sensor malfunctions. We demonstrate how the error distribution itself can be part of the state estimation process. Based on an efficient approximation of a Gaussian mixture, we optimize the sensor model simultaneously during the standard state estimation. Due to an implicit expectation-maximization approach, we achieve a fast convergence without prior knowledge of the true distribution parameters. We implement this self-tuning algorithm in a least-squares optimization framework and demonstrate its real time capability on a real world dataset for satellite localization of a driving vehicle. The resulting estimation quality is superior to previous robust algorithms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594459","","Estimation;Robot sensing systems;Optimization;Tuning;Biological system modeling;Heuristic algorithms;Standards","adaptive control;control system synthesis;expectation-maximisation algorithm;Gaussian processes;least squares approximations;mixture models;nonlinear control systems;optimisation;robots;robust control;self-adjusting systems;sensor fusion;state estimation","robust sensor fusion;self-tuning mixture models;nonlinear state estimation;robotics;robust cost functions;nonGaussian error models;environmental changes;ageing;error distribution;state estimation process;Gaussian mixture;sensor model;standard state estimation;implicit expectation-maximization approach;distribution parameters;self-tuning algorithm;least-squares optimization framework;parameter tuning","","","20","","","","","IEEE","IEEE Conferences"
"A Natural Adaptive Control Law for Robot Manipulators","T. Lee; J. Kwon; F. C. Park","Seoul National University, Department of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea; Seoul National University, Department of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea; Seoul National University, Department of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Existing adaptive robot control laws typically require an engineering choice of a constant adaptation gain matrix, which often involves repeated and time-consuming trial and error. Moreover, physical consistency of the estimated inertial parameters or the uniform positive definiteness of the estimated robot mass matrix cannot in general be guaranteed without nonsmooth corrections, e.g., projection to the boundary of the feasible parameter set. In this paper we present a natural adaptive control law that mitigates many of these difficulties, by exploiting the coordinate-invariant differential geometric structure of the space of physically consistent inertial parameters. Our approach provides a more generalizable and physically consistent adaptation law for the robot parameters without significant additional computations compared to existing methods. Simulation results showing markedly improved tracking error convergence over existing adaptive control laws are provided as validation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593727","","Adaptive control;Symmetric matrices;Robot kinematics;Lead;Manipulators;Measurement","adaptive control;control system synthesis;geometry;manipulators","natural adaptive control law;robot manipulators;robot parameters;coordinate-invariant differential geometric structure","","","24","","","","","IEEE","IEEE Conferences"
"Inspection System for Automatic Measurement of Level Differences in Belt Conveyors Using Inertial Measurement Unit","A. Y. Yasutomi; H. Enoki; S. Yamaguchi; K. Tamura","Mechanical Engineering, Research & Development Group, Hitachi. Ltd., Center for Technology Innovation; Mechanical Engineering, Research & Development Group, Hitachi. Ltd., Center for Technology Innovation; Science & Medical Systems Business Group, Hitachi High-Technologies Co., Medical Systems Product Div.; Science & Medical Systems Business Group, Hitachi High-Technologies Co., Medical Systems Product Div.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6155","6161","Belt conveyors are transport systems composed by a plurality of belt lines. When those systems are used to transport fragile materials or liquid containers, it is necessary to minimize the oscillations of the transported objects in order to avoid damage, spillage and particle degradation. Those oscillations are regularly caused by steps (i.e. differences in level) at the joints of the belt lines, and for that reason, it is necessary to inspect those steps during installation and maintenance. Regular inspections involve the visual verification of the steps, which stops production, takes significant time, occasionally requires system disassembly and is subjected to human errors. In this paper, a novel belt conveyor inspection system which is able to detect and measure the steps at the joints of the belt lines is presented. This system consists in the acquirement of data of the belt conveyor with an inertial measurement unit (IMU), and the processing of this data with original algorithms for zero offset filtering, sensor progressing direction detection, step event detection and step height calculation. The presented system had successfully detected and measured the steps of a complex belt conveyor with an accuracy of ±0.3 mm. It is demonstrated that this cost-effective and ready to use system enables an automatic and prompt inspection of the whole belt conveyor system at once, thus reducing the workload, time and errors of the belt conveyor inspection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593906","","Belts;Inspection;Angular velocity;Batteries;Containers;Fixtures;Event detection","belts;conveyors;inspection;maintenance engineering;sensors;transportation","belt conveyor inspection system;liquid container;conveyor maintenance;sensor progressing;cost-effective;human errors;automatic inspection;system disassembly;spillage;belt lines;transport systems;inertial measurement unit;automatic measurement","","","14","","","","","IEEE","IEEE Conferences"
"Constrained Path Planning Using Quadratic Programming","F. Fusco; O. Kermorgant; P. Martinet","Laboratoire des Sciences du Numerique de Nantes LS2N, Centrale Nantes, France; Laboratoire des Sciences du Numerique de Nantes LS2N, Centrale Nantes, France; Laboratoire des Sciences du Numerique de Nantes LS2N, Centrale Nantes, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8134","8139","Sampling-based planning algorithms have been extensively exploited to solve a wide variety of problems. In recent years, many efforts have been dedicated to extend these tools to solve problems involving constraints, such as geometric loop-closure, which lead the valid Configuration Space (CS) to collapse to a lower-dimensional manifold. One proposed solution considers an approximation of the constrained Configuration Space that is obtained by relaxing constraints up to a desired tolerance. The resulting set has then non-zero measure, allowing to exploit classical planning algorithms to search for a path connecting two given states. When constraints involve kinematic loops in the system, relaxation generally bears to undesired contact forces, which need to be compensated during execution by a proper control action. We propose a new tool that exploits relaxation to plan in presence of constraints. Local motions inside the approximated manifold are found as the result of an iterative scheme that uses Quadratic Optimization to proceed towards a new sample without falling outside the relaxed region. By properly guiding the exploration, paths are found with smaller relaxation factors and the need of a dedicated controller to compensate errors is reduced. We complete the analysis by showing the feasibility of the approach with experiments on a real platform.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593373","","Manifolds;Jacobian matrices;Optimization;Planning;End effectors;Interpolation","iterative methods;manipulator kinematics;path planning;quadratic programming","kinematic loops;local motions;iterative scheme;geometric loop-closure;CS;lower-dimensional manifold;contact forces;quadratic optimization;quadratic programming;constrained configuration space;constrained path planning;sampling-based planning algorithms","","","13","","","","","IEEE","IEEE Conferences"
"A Comparative Analysis of Contact Models in Trajectory Optimization for Manipulation*","A. O. Onol; P. Long; T. Padlr","RIVeR Lab, Northeastern University, Boston, MA, USA; RIVeR Lab, Northeastern University, Boston, MA, USA; RIVeR Lab, Northeastern University, Boston, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, we analyze the effects of contact models on contact-implicit trajectory optimization for manipulation. We consider three different approaches: (1)a contact model that is based on complementarity constraints, (2)a smooth contact model, and our proposed method (3) a variable smooth contact model. We compare these models in simulation in terms of physical accuracy, quality of motions, and computation time. In each case, the optimization process is initialized by setting all torque variables to zero, namely, without a meaningful initial guess. For simulations, we consider a pushing task with varying complexity for a 7 degrees-of-freedom robot arm. Our results demonstrate that the optimization based on the proposed variable smooth contact model provides a good trade-off between the physical fidelity and quality of motions at the cost of increased computation time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594284","","Task analysis;Robots;Force;Trajectory optimization;Computational modeling;Dynamics","manipulators;optimisation","manipulation;contact-implicit trajectory optimization;variable smooth contact model;optimization process","","","24","","","","","IEEE","IEEE Conferences"
"Active Learning based on Data Uncertainty and Model Sensitivity","N. Chen; A. Klushyn; A. Paraschos; D. Benbouzid; P. Van der Smagt","AI Research, Data: Lab, Volkswagen Group, Munich, Germany; AI Research, Data: Lab, Volkswagen Group, Munich, Germany; AI Research, Data: Lab, Volkswagen Group, Munich, Germany; AI Research, Data: Lab, Volkswagen Group, Munich, Germany; AI Research, Data: Lab, Volkswagen Group, Munich, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1547","1554","Robots can rapidly acquire new skills from demonstrations. However, during generalisation of skills or transitioning across fundamentally different skills, it is unclear whether the robot has the necessary knowledge to perform the task. Failing to detect missing information often leads to abrupt movements or to collisions with the environment. Active learning can quantify the uncertainty of performing the task and, in general, locate regions of missing information. We introduce a novel algorithm for active learning and demonstrate its utility for generating smooth trajectories. Our approach is based on deep generative models and metric learning in latent spaces. It relies on the Jacobian of the likelihood to detect non-smooth transitions in the latent space, i.e., transitions that lead to abrupt changes in the movement of the robot. When non-smooth transitions are detected, our algorithm asks for an additional demonstration from that specific region. The newly acquired knowledge modifies the data manifold and allows for learning a latent representation for generating smooth movements. We demonstrate the efficacy of our approach on generalising elementary skills, transitioning across different skills, and implicitly avoiding collisions with the environment. For our experiments, we use a simulated pendulum where we observe its motion from images and a 7-DoF anthropomorphic arm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593552","","Uncertainty;Jacobian matrices;Manifolds;Data models;Measurement;Robot sensing systems","humanoid robots;learning (artificial intelligence);pendulums","elementary skills;smooth movements;newly acquired knowledge;additional demonstration;nonsmooth transitions;latent space;metric learning;deep generative models;smooth trajectories;abrupt movements;missing information;necessary knowledge;fundamentally different skills;model sensitivity;data uncertainty;active learning","","","33","","","","","IEEE","IEEE Conferences"
"LIPS: LiDAR-Inertial 3D Plane SLAM","P. Geneva; K. Eckenhoff; Y. Yang; G. Huang","Dept. of Computer and Information Sciences, University of Delaware, Newark, DE, 19716, USA; Dept. of Mechanical Engineering, University of Delaware, Newark, DE, 19716, USA; Dept. of Mechanical Engineering, University of Delaware, Newark, DE, 19716, USA; Dept. of Mechanical Engineering, University of Delaware, Newark, DE, 19716, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","123","130","This paper presents the formalization of the closest point plane representation and an analysis of its incorporation in 3D indoor simultaneous localization and mapping (SLAM). We present a singularity free plane factor leveraging the closest point plane representation, and demonstrate its fusion with inertial preintegratation measurements in a graph-based optimization framework. The resulting LiDAR-inertial 3D plane SLAM (LIPS) system is validated both on a custom made LiDAR simulator and on a real-world experiment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594463","","Simultaneous localization and mapping;Three-dimensional displays;Laser radar;Optimization;Lips","graph theory;image representation;mobile robots;optical radar;optimisation;robot vision;SLAM (robots)","inertial preintegratation measurement;LiDAR-inertial 3D plane SLAM;simultaneous localization and mapping;singularity free plane factor;closest point plane representation","","1","38","","","","","IEEE","IEEE Conferences"
"Resistive Pulse Study of Liposome Stability: Towards Precision and Efficient Drug Delivery","Y. Lin; X. Liu; T. Arai","Beijing Institute of Technology, Advance Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Institute of Technology, Advance Innovation Center for Intelligent Robots and Systems, Beijing, China; Beijing Institute of Technology, Advance Innovation Center for Intelligent Robots and Systems, Beijing, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4914","4919","In this work, the authors report the investigation of liposomes' stability as a drug delivery vehicle, using the method of resistive pulse method. The main objects of interest are the 50nm diameter liposomes, while the 100nm diameter liposomes are widely used for its stability. However, certain drug delivery scenarios arise, like tighter cancerous tissue arrangement and different circulation time requirement, which dictates the necessity of sub-100nm diameter vesicles. The size measurements upon freshly fabricated liposomes are performed frequently on increasing time interval. The results exhibit a trend of size increasing, suggesting the existence of liposome fusion. The possible models of fusion are proposed and discussed. This work demonstrates the localized organic nanoparticle measurement with fine dual 3D manipulator positioning, which paves the way for the possible cellular in-vivo measurement within an environmental SEM chamber.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593731","drug delivery vehicle;liposome;3D manipulator;resistive pulse method;size measurement;sub 100nm Nano pores","Lipidomics;Drug delivery;Manipulators;Stability analysis;Size measurement;Three-dimensional displays;Glass","biological tissues;biomedical materials;biomembranes;cancer;cellular biophysics;drug delivery systems;lipid bilayers;molecular biophysics;nanofabrication;nanomedicine;nanoparticles;scanning electron microscopy","resistive pulse study;liposome stability;drug delivery vehicle;resistive pulse method;liposome fusion;cancerous tissue arrangement;organic nanoparticle measurement;3D manipulator positioning;cellular in-vivo measurement;environmental SEM chamber;size 50.0 nm;size 100.0 nm","","","30","","","","","IEEE","IEEE Conferences"
"Sequence Pattern Extraction by Segmenting Time Series Data Using GP-HSMM with Hierarchical Dirichlet Process","M. Nagano; T. Nakamura; T. Nagai; D. Mochihashi; I. Kobayashi; M. Kaneko","Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Mathematical Analysis and Statistical Inference, Institute of Statistical Mathematics, Tachikawa, Japan; Department of Information Sciences, Faculty of Sciences, Ochanomizu University, Bunkyo-ku, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4067","4074","Humans recognize perceived continuous information by dividing it into significant segments such as words and unit motions. We believe that such unsupervised segmentation is also an important ability that robots need to learn topics such as language and motions. Hence, in this paper, we propose a method for dividing continuous time-series data into segments in an unsupervised manner. To this end, we proposed a method based on a hidden semi-Markov model with Gaussian process (GP-HSMM). If Gaussian processes, which are nonparametric models, are used, unit motion patterns can be extracted from complicated continuous motion. However, this approach requires the number of classes of segments in the time-series data in advance. To overcome this problem, in this paper, we extend GP-HSMM to a nonparametric Bayesian model by introducing a hierarchical Dirichlet process (HDP) and propose the hierarchical Dirichlet processes-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). In the nonparametric Bayesian model, an infinite number of classes is assumed and it becomes difficult to estimate the parameters naively. Instead, the parameters of the proposed HDP-GP-HSMM are estimated by applying slice sampling. In the experiments, we use various synthetic and motion-capture data to show that our proposed model can estimate a more correct number of classes and achieve more accurate segmentation than baseline methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594029","","Hidden Markov models;Motion segmentation;Gaussian processes;Bayes methods;Data models;Trajectory;Kernel","Bayes methods;feature extraction;Gaussian processes;hidden Markov models;image motion analysis;image sampling;image segmentation;learning (artificial intelligence);nonparametric statistics;time series","continuous time-series data;semiMarkov model;Gaussian processes;nonparametric models;unit motion patterns;complicated continuous motion;nonparametric Bayesian model;hierarchical Dirichlet process;hierarchical Dirichlet processes-Gaussian process;HDP-GP-HSMM;motion-capture data;sequence pattern extraction;time series data;continuous information;unit motions;unsupervised segmentation","","","21","","","","","IEEE","IEEE Conferences"
"Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding","S. M. Ahmed; Y. Z. Tan; C. M. Chew; A. A. Mamun; F. S. Wong","National University of Singapore, Department of Mechanical Engineering; National University of Singapore, Department of Electrical Engineering; National University of Singapore, Department of Mechanical Engineering; National University of Singapore, Department of Electrical Engineering; Keppel Technology and Innovation, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7350","7355","In this paper, we propose novel edge and corner detection algorithms for unorganized point clouds. Our edge detection method evaluates symmetry in a local neighborhood and uses an adaptive density based threshold to differentiate 3D edge points. We extend this algorithm to propose a novel corner detector that clusters curvature vectors and uses their geometrical statistics to classify a point as corner. We perform rigorous evaluation of the algorithms on RGB-D semantic segmentation and 3D washer models from the ShapeNet dataset and report higher precision and recall scores. Finally, we also demonstrate how our edge and corner detectors can be used as a novel approach towards automatic weld seam detection for robotic welding. We propose to generate weld seams directly from a point cloud as opposed to using 3D models for offline planning of welding paths. For this application, we show a comparison between Harris 3D and our proposed approach on a panel workpiece.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593910","","Three-dimensional displays;Image edge detection;Welding;Feature extraction;Corner detection;Clustering algorithms;Detectors","computer vision;edge detection;feature extraction;image recognition;image representation;image segmentation;stereo image processing","robotic welding;weld seams;point cloud;welding paths;Harris 3D;unorganized point clouds;edge detection method;local neighborhood;adaptive density;corner detector;clusters curvature vectors;RGB-D semantic segmentation;3D washer models;recall scores;automatic weld seam detection","","","20","","","","","IEEE","IEEE Conferences"
"Stopper Angle Design for a Multi-link Articulated Wheeled In-pipe Robot with Underactuated Twisting Joints","Y. Oka; A. Kakogawa; S. Ma","Department of Robotics, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, JAPAN; Department of Robotics, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, JAPAN; Department of Robotics, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","973","978","In this paper, we present a multi-link articulated wheeled in-pipe robot that can drive the wheel and roll joint by using only a single actuator installed in each link. The proposed mechanism enables the robot to move forward or backward and helically in pipes owing to rotation of the drive wheel and twisting of the body. These two movements are generated by a miter-geared differential mechanism installed in each joint, and the magnitudes of these movements depend on the load applied to the wheels and roll joints. However, controlling of two outputs independently and aligning the rotation of the roll joints as desired are extremely challenging. Therefore, in this study, we switch those two movements by driving the rear wheels and the front wheels of the robot alternately. In addition, a stopper is used to constrain the roll joint movement. By calculating the angle of elevation of the robot's helical movement in the pipe by using a kinematic model, we can design a stopper to precisely adjust the roll angle. We verified that the robot can twist using the differential mechanism, and we validated experimentally the effectiveness of the stopper.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594208","","Mobile robots;Wheels;Robot kinematics;Kinematics;Pipelines;Actuators","actuators;design engineering;drives;gears;mobile robots;motion control;pipes;robot kinematics;wheels","roll joint;single actuator;drive wheel;miter-geared differential mechanism;rear wheels;joint movement;helical movement;kinematic model;multilink articulated wheeled in-pipe robot;underactuated twisting joints;stopper angle design;roll angle","","","12","","","","","IEEE","IEEE Conferences"
"Modelling an Actuated Large Deformation Soft Continuum Robot Surface Undergoing External Forces Using a Lumped-Mass Approacb* Research supported by UK Engineering and Physical Sciences Research Council (EPSRC).","H. Habibi; C. Yang; R. Kang; I. D. Walker; I. S. Godage; X. Dong; D. T. Branson","University of Nottingham, Faculty of Engineering, Nottingham, United Kingdom; Equipment Design of Ministry of Education, School of Mechanical Engineering, Tianjin University, Key Laboratory of Mechanism Theory, Tianjin, China; Equipment Design of Ministry of Education, School of Mechanical Engineering, Tianjin University, Key Laboratory of Mechanism Theory, Tianjin, China; Clemson University, Department of Electrical & Computer Engineering, Clemson, SC, 29634-0915, US; DePaul University, School of Computing, Chicago, IL, 60604; University of Nottingham, Faculty of Engineering, Nottingham, United Kingdom; University of Nottingham, Faculty of Engineering, Nottingham, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5958","5963","Precise actuation of continuum surfaces in combination with continuum robotic arms that undergo large deformation is of high interest in soft robotics but of limited model-based study to date. This work develops this area towards enabling the robust design and control of large deformation continuum surfaces (LDCS) across multiple industrial applications in the healthcare, aerospace, manufacturing, and automotive domains. It introduces an actuation based dynamic model of LDCSs to accurately determine their deflection due to application of concentrated external forces while maintaining many physical characteristics and constraints on actuation elements and surface structure such as gravity, inertia, damping, elasticity, and interactive forces between actuators and LDCS. Using the lumped-mass methodology, a 3D integrated surface-arm model is developed, simulated and then validated experimentally where a pair of parallel arms are attached to the surface to actuate and deform it. The surface is then simultaneously subjected to a concentrated constant external force at its top center between the two arms. Comparing measured displacements between the experimental and modelling results over actuation time yielded the maximum error is less than 1% of the length of the surface's side at its final deflected profile despite the limited number of nodes (masses) used in the LDCS model while it is exposed to a significant external force.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594033","","Mathematical model;Robots;Load modeling;Deformable models;Strain;Actuators;Springs","compliant mechanisms;continuum mechanics;finite element analysis;manipulator dynamics;shear modulus","large deformation continuum surfaces;soft continuum robotic arms;3D integrated surface-arm model;lumped-mass methodology;soft robotics","","","23","","","","","IEEE","IEEE Conferences"
"Auxetic Sleeves for Soft Actuators with Kinematically Varied Surfaces","A. Sedal; M. Fisher; J. Bishop-Moser; A. Wineman; S. Kota","Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, 48109, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, 48109, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, 48109, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, 48109, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, 48109, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","464","471","Soft actuators with auxetic, or negative Poisson's ratio (NPR), behavior offer a way to create soft robots with novel kinematic behavior. This paper presents an original framework for reinforcement of a soft actuator using a generalized NPR element, called a Representative Auxetic Element (RAE), and an experimental validation of the kinematic behavior that it enables. We build a generalized kinematic model that enables the design of RAE-patterned actuators and reveal the distinct auxetic behavior of RAE actuators with comparable model accuracy to the legacy McKibben actuators. A simple, reproducible way of designing and fabricating RAE actuators is described and varied prototypes are shown. This RAE-based design scheme can be used to create actuators with specified kinematics like bending, extension, and radial expansion, which can also vary across the actuator's surface both circumferentially and axially in a tractable, scalable manner.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594212","","Actuators;Auxetic materials;Kinematics;Finite element analysis;Shape;Strain;Stress","actuators;auxetics;bending;Poisson ratio;prototypes;robot kinematics","radial expansion;bending;prototypes;auxetic sleeves;representative auxetic element;kinematic model;Poisson's ratio;RAE-based design scheme;RAE-patterned actuators;soft robots;soft actuator","","","26","","","","","IEEE","IEEE Conferences"
"A Synergetic Voluntary Control for Exoskeleton based on Spinal Cord Mapping of Peripheral Bioelectric Activity","S. Ishikawa; H. Kadone; K. Suzuki","Graduate School of Systems and Information Engineering, University of Tsukuba, Ibaraki, Japan; Center for Cybernics Research, University of Tsukuba, Ibaraki, Japan; Center for Cybernics Research, University of Tsukuba, Ibaraki, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2274","2279","Walking rehabilitation must be performed based on voluntary motion intention, and for this purpose, the development of a control method for an exoskeleton robot based on voluntary intention is investigated. This study proposes a method of exoskeleton robot control to estimate the voluntary lower limb muscle activities lost after a spinal cord injury (SCI). This method is based on the spinal cord mapping of the remaining muscle activities and its matching to the one obtained from healthy participants considering the muscle synergy of the whole body during the walking motion. By implementing the matching procedure at the spinal cord map level and incorporating information of reliable and unreliable spinal cord levels based on a diagnosis, the method has the potential to provide a maximally voluntary locomotion for people with SCI. We report an analysis of the synergy of the whole-body muscle activity during walking and its spinal cord mapping using non-negative matrix factorization and the computation of the transformation matrix to estimate the intended lower limb muscle activity from the remaining spinal cord activity. The implementation of the proposed method using the right leg of the hybrid assistive limb and walking experiments with a healthy participant are also reported.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593695","","Muscles;Legged locomotion;Spinal cord;Exoskeletons;Robot kinematics;Estimation","bioelectric phenomena;electromyography;gait analysis;injuries;matrix decomposition;medical robotics;neurophysiology;patient rehabilitation","synergetic voluntary control;spinal cord mapping;peripheral bioelectric activity;voluntary motion intention;control method;exoskeleton robot control;voluntary lower limb muscle activities;spinal cord injury;muscle synergy;walking motion;spinal cord map level;reliable cord levels;unreliable spinal cord levels;maximally voluntary locomotion;whole-body muscle activity;intended lower limb muscle activity;spinal cord activity;walking rehabilitation;nonnegative matrix factorization;transformation matrix;hybrid assistive limb;walking experiments","","","20","","","","","IEEE","IEEE Conferences"
"Force/Velocity Manipulability Analysis for 3D Continuum Robots","M. Khadem; L. Da Cruz; C. Bergeles","School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK; UCL Wellcome/EPSRC Centre for Interventional and Surgical Engineering Sciences, UCL Institute of Ophthalmology, and Moorfields Eye Hospital, London, UK; School of Biomedical Engineering and Imaging Sciences, King's College London, London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4920","4926","The enhanced dexterity and manipulability offered by continuum manipulators makes them the robots of choice for complex procedures inside the human body. However, without tailored analytical tools to evaluate their manipulability, many capabilities of continuum robots such as safe and effective manipulation will remain largely inaccessible. This paper presents a quantifiable measure for analysing force/velocity manipulability of continuum robots. We expand classical measures of manipulability for rigid robots to introduce three types of manipulability indices to continuum robots, namely, velocity, compliance, and unified force-velocity manipulability. We provide a specific case study using the proposed method to analyse the force/velocity manipulability for a concentric-tube robot. We investigate the application of the manipulability measures to compare performance of continuum robots in terms of compliance and force-velocity manipulability. The proposed manipulability measures enable future research on design and optimal path planning for continuum robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593874","","Robot kinematics;Indexes;Force;Manipulators;Jacobian matrices;Ellipsoids","dexterous manipulators;mobile robots;path planning","continuum robots;continuum manipulators;effective manipulation;rigid robots;manipulability indices;unified force-velocity manipulability;concentric-tube robot;manipulability measurement;force-velocity manipulability analysis","","","25","","","","","IEEE","IEEE Conferences"
"Deep Q-Learning for Dry Stacking Irregular Objects","Y. Liu; S. M. Shamsi; L. Fang; C. Chen; N. Napp","Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, 14260, USA; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, 14260, USA; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, 14260, USA; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, 14260, USA; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, 14260, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1569","1576","We propose a reinforcement learning approach for automatically building dry stacked (i.e. no mortar) structures with irregular objects. Stacking irregular objects is a challenging problem since each assembly action can be drawn from a continuous space of poses for an object, and several local geometric and physical considerations strongly affect the stability. To tackle this challenge, we concentrate on a simplified 2D version of the problem. We present a reinforcement learning algorithm based on deep Q-learning, where the learned Q-function, which maps state-action pairs into expected long-term rewards, is represented by a deep neural network. As the action space is continuous the Q-network is trained by sampling a finite number of actions that consider both geometric and physical constraints to approximate the target Q-values, Experiments show that the proposed method outperforms previous heuristics-based planning, leading to super construction with objects containing a significant amount of variations. We validate the generated stacking plans by executing them using a robot arm and manufactured, irregular objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593619","","Stacking;Buildings;Robots;Planning;Shape;Stability analysis;Reinforcement learning","learning (artificial intelligence);manipulators;motion control;neurocontrollers","state-action pairs;Q-network;robot arm;generated stacking plans;physical constraints;geometric constraints;action space;deep neural network;learned Q-function;reinforcement learning algorithm;local geometric considerations;reinforcement learning approach;dry stacking irregular objects;deep Q-learning","","","25","","","","","IEEE","IEEE Conferences"
"Image Based Visual Servoing for Tumbling Objects","P. Mithun; H. Pandya; A. Gaud; S. V. Shah; K. M. Krishna","International Institute of Information Technology, Hyderabad, India; International Institute of Information Technology, Hyderabad, India; International Institute of Information Technology, Hyderabad, India; Department of Mechanical Engineering, Indian Institute of Technology, Jodhpur, India; International Institute of Information Technology, Hyderabad, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2901","2908","Objects in space often exhibit a tumbling motion around the major inertial axis. In this paper, we address the image based visual servoing of a robotic system towards an uncooperative tumbling object. In contrast to previous approaches that require explicit reconstruction of the object and an estimation of its velocity, we propose a novel controller that is able to minimize the feature error directly in image space. This is achieved by observing that the feature points on the tumbling object follow a circular path around the axis of rotation and their projection creates an elliptical track in the image plane. Our controller minimizes the error between this elliptical track and the desired features, such that at the desired pose the features lie on the circumference of the ellipse. The effectiveness of our framework is exhibited by implementing the algorithm in simulation as well on a mobile robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594176","","Visual servoing;Cameras;Feature extraction;Estimation;Solid modeling;Satellites","feature extraction;image reconstruction;mobile robots;pose estimation;robot vision;visual servoing","image based visual servoing;image plane;elliptical track;feature points;image space;feature error;explicit reconstruction;uncooperative tumbling object;robotic system;inertial axis;tumbling motion","","","29","","","","","IEEE","IEEE Conferences"
"A Sliding Mode Control Architecture for Human-Manipulator Cooperative Surface Treatment Tasks","L. Gracia; J. E. Solanes; P. Muñoz-Benavent; J. V. Miro; C. Perez-Vidal; J. Tornero","Instituto de Diseño y Fabricación, Universitat Politécnica de València, Camino de vera s/n, Valencia, 46022, Spain; Instituto de Diseño y Fabricación, Universitat Politécnica de València, Camino de vera s/n, Valencia, 46022, Spain; Instituto de Diseño y Fabricación, Universitat Politécnica de València, Camino de vera s/n, Valencia, 46022, Spain; Centre for Autonomous Systems, University of Technology Sydney, Sydney, NSW, 2007, Australia; Departamento de Ingeinería de Sistemas y Automática, Universidad Miguel Hernández, Avda de la Universidad s/n, Elche, 03202, Spain; Instituto de Diseño y Fabricación, Universitat Politécnica de València, Camino de vera s/n, Valencia, 46022, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1318","1325","This paper presents a control architecture readily suitable for surface treatment tasks such as polishing, grinding, finishing or deburring as carried out by a human operator, with the added benefit of accuracy, recurrence and physical strength as administered by a robotic manipulator partner. The shared strategy effectively couples the human operator propioceptive abilities and fine skills through his interactions with the autonomous physical agent. The novel proposed control scheme is based on task prioritization and a non-conventional sliding mode control, which is considered to benefit from its inherent robustness and low computational cost. The system relies on two force sensors, one located between the last link of the robot and the surface treatment tool, and the other located in some place of the robot end-effector: the former is used to suitably accomplish the conditioning task, while the latter is used by the operator to manually guide the robotic tool. When the operator chooses to cease guiding the tool, the robot motion safely switches back to an automatic reference tracking. The paper presents the theories for the novel collaborative controller, whilst its effectiveness for robotic surface treatment is substantiated by experimental results using a redundant 7R manipulator and a mock-up conditioning tool.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593444","","Robot sensing systems;Surface treatment;Task analysis;Tools;Surface morphology;Manipulators","control engineering computing;deburring;end effectors;force sensors;industrial manipulators;industrial robots;mobile robots;motion control;multi-robot systems;position control;variable structure systems","redundant 7R manipulator;robotic surface treatment;novel collaborative controller;robot motion;robotic tool;conditioning task;robot end-effector;surface treatment tool;nonconventional sliding mode control;task prioritization;control scheme;autonomous physical agent;human operator propioceptive abilities;shared strategy effectively couples;robotic manipulator partner;physical strength;surface treatment tasks;human-manipulator;sliding mode control architecture","","","14","","","","","IEEE","IEEE Conferences"
"Leg Design to Enable Dynamic Running and Climbing on BOBCAT","M. P. Austin; J. M. Brown; C. A. Young; J. E. Clark","FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3799","3806","The design process for leg morphology has taken much of its inspiration from the manipulator community, including the concept of maximizing the workspace of a design. In this paper, we define the concept of Effective Dynamic Workspace, which examines the subset of the overall workspace capable of achieving the desired template dynamics. With this new design tool, the leg configuration of a new multi-modal platform BOBCAT is examined and refined. With the refined design, BOBCAT is able to achieve speeds of 2m/s while running and 0.17m/s while climbing a vertical wall.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594355","","Legged locomotion;Dynamics;Couplings;Force;Kinematics;Foot","legged locomotion;manipulator dynamics;robot kinematics","design tool;leg configuration;multimodal platform BOBCAT;leg design;design process;leg morphology;manipulator community;dynamic workspace;template dynamics;dynamic climbing;dynamic running","","","26","","","","","IEEE","IEEE Conferences"
"Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots","M. Turan; E. P. Ornek; N. Ibrahimli; C. Giracoglu; Y. Almalioglu; M. F. Yanik; M. Sitti","Mehmet Turan is with Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Germany; Informatics Faculty, Technical University of Muenich, Germany; Informatics Faculty, Technical University of Muenich, Germany; Informatics Faculty, Technical University of Muenich, Germany; Computer Science Department, University of Oxford, Oxford, UK; Department -of Information Technology and Electrical Engineering, Zurich, Switzerland; Metin Sitti is with Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1801","1807","In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, realtime odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593623","","Cameras;Robots;Endoscopes;Reliability;Sensors;Pose estimation","biomedical optical imaging;diseases;endoscopes;image sequences;medical image processing;medical robotics;motion estimation;unsupervised learning","single-view depth estimation network;passive capsule endoscopes;minimally invasive diagnostic technology;realtime odometry;monocular endoscopic capsule robots;multiview pose estimation;endoscopic capsule robots;disease detection;drug delivery;gastrointestinal tract;reprojection minimization;unsupervised odometry;depth learning;biopsy-like operations;ex-vivo porcine stomach datasets;motion estimation","","","31","","","","","IEEE","IEEE Conferences"
"Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks","C. Brooks; M. Atreya; D. Szafir","University of Colorado Boulder, Department of Computer Science; University of Colorado Boulder, Department of Mechanical Engineering; University of Colorado Boulder, Department of Computer Science and ATLAS Institute","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8567","8573","Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594180","","Task analysis;Robot kinematics;Fasteners;Feature extraction;Activity recognition;Recurrent neural networks","control engineering computing;human-robot interaction;recurrent neural nets","proactive robot assistants;freeform collaborative tasks;multimodal recognition;generic subtasks;successful human-robot collaboration;shared understanding;current goals;nonlinear tasks;freeform tasks;explicit task model;robot partners;meaningful task knowledge;multimodal recurrent neural networks;short-term memory units;real-time subtask recognition;context-aware assistance;generic assembly tasks;specific subtasks;individual modalities;high-level representations;nonlinear connection layer;multimodal subtask recognition system;predictive assistance;human partner;human-robot team;assembly task;similar subtasks;freeform assembly scenario;RNN","","","30","","","","","IEEE","IEEE Conferences"
"Development of Camber-Flat Wing Structure Convert Mechanism for Asymmetric Flapping Micro Air Vehicle","J. Jang; G. Yang","Department of Robotics and Virtual Engineering, University of Science and Technology, Daejeon, 34113, Korea; Department of Robotics and Virtual Engineering, University of Science and Technology, Daejeon, 34113, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1395","1400","This study presents principle of the camber-flat wing structure conversion mechanism, which is inspired by a dragonfly, and its applicability to MAV. The camber-flat wing structure convert mechanism makes MAV flight using asymmetric flapping pattern through control of angle of attack without complicate structure. This mechanism was inspired from the dragonfly's feature that the camber structure of the wing increases the rigidity of wing structure and makes dragonfly has asymmetric flapping pattern. Experimental results show that MAV has asymmetric flapping pattern that can more stable flight performance when hovering flight with a camber structure and superior performance when the forward flight with a flat structure. The average lift force in the camber wing structure was 0.02N, the average thrust force was 0.02N and the average lift force was 0.011N in the flat wing structure at 20 Hz flapping frequency.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594104","","Force;Muscles;Robots;Drag;Force measurement;Insects;Actuators","aerodynamics;aerospace components;autonomous aerial vehicles;design engineering;vehicle dynamics","r asymmetric flapping micro air vehicle;rigidity;camber-flat wing structure convert mechanism","","","15","","","","","IEEE","IEEE Conferences"
"XBotCloud: A Scalable Cloud Computing Infrastructure for XBot Powered Robots","L. Muratore; B. Lennox; N. G. Tsagarakis","The University of Manchester, School of Electrical and Electronic Engineering, M13 9PL, UK; The University of Manchester, School of Electrical and Electronic Engineering, M13 9PL, UK; Istituto Italiano di Tecnologia, Advanced Robotics Department (ADVR), Genova, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Limitations with the on-board computational resources installed on untethered robots such as humanoids and mobile robots in general affects significantly the performance and capabilities of these machines. An approach to address this issue is to make use of the cloud robotics concept and take advantage of the extensive computational resources of the cloud. XBotCloud is a recently developed component of the XBot framework. It tackles the above challenges by introducing the tools and mechanisms to enable users and robots to exploit the computational resources of the cloud allowing the execution of services with low, soft or hard Real-Time execution/communication performance. The latter is ensured thanks to the functionality provided by the XBotCore Real-Time cross-robot software component of the XBot framework. XBotCloud addresses also one of the main challenges related with cloud robotics: security. To avoid remote attacks it takes advantage of the Amazon Web Services (AWS)Cloud Security and it uses an internal VPN Network to handle the connectivity between the robot and the cloud server. The full implementation of the framework is presented and its functionality is demonstrated in realistic tasks involving pipelines that mix the execution of cloud services with moderate execution time constraints and Real-Time modules running on the robot local control unit. XBotCloud performances and cross-robot flexibility are experimentally validated on two different robotic platforms, the WALK-MAN humanoid and the CENTAURO upper body/full-body.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593587","","Cloud computing;Robot sensing systems;Software as a service;Task analysis;Servers","cloud computing;control engineering computing;software agents;Web services","computational resources;robotic platforms;Amazon Web Services Cloud Security;XBotCloud;cross-robot flexibility;XBotCloud performances;robot local control unit;Real-Time modules;moderate execution time constraints;cloud services;cloud server;XBotCore Real-Time cross-robot software component;hard Real-Time execution/communication performance;soft Time execution/communication performance;XBot framework;cloud robotics concept;mobile robots;untethered robots;on-board computational resources;scalable cloud computing infrastructure","","","24","","","","","IEEE","IEEE Conferences"
"Design, Control and Preliminary Test of Robotic Ankle Prosthesis","X. Sun; F. Sugai; K. Okada; M. Inaba","Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan; Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2787","2793","Currently, most of commercially available ankle foot prosthesis are passive, which don't exhibit appropriate biomechanics during walking and could not adapt to dynamic property of able-bodied walking. In this paper, we present a novel robotic ankle foot prosthesis with variable transmission series elastic actuator (SEA). Slider crank mechanism is applied to transform linear motion of series elastic actuator to rotary motion of ankle foot joint. And this could contribute to variable transmission ratio while ankle angle varies. Because of variable transmission ratio, ankle joint torque is increasing while ankle angle is flexed from plantar flexion to dorsiflexion, whose feature has similar increase trend with human's ankle joint torque-angle relationship, and exhibits an appropriate characteristic for developing robotic ankle foot prosthesis. Larger torque could be obtained in powered plantar flexion, and this indicates that variable transmission mechanism would help reduce required motor torque compared with traditional mechanism. Energy stored in springs of series elastic actuator contribute a torque to powered plantar flexion. Preliminary experiments with a transtibial amputee and a transferomal amputee have been performed to test the prototype.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594498","","Prosthetics;Foot;Legged locomotion;Torque;Springs","actuators;artificial limbs;biomechanics;elasticity;gait analysis;medical control systems;medical robotics;prosthetics;springs (mechanical);torque;torque control","variable transmission series elastic actuator;commercially available ankle foot prosthesis;robotic ankle prosthesis;preliminary test;variable transmission mechanism;powered plantar flexion;robotic ankle foot prosthesis;ankle joint torque-angle;ankle angle varies;variable transmission ratio;ankle foot joint","","","20","","","","","IEEE","IEEE Conferences"
"Recursive Bayesian Human Intent Recognition in Shared-Control Robotics","S. Jain; B. Argall","Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, 60208, USA; Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, 60208, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3905","3912","Effective human-robot collaboration in shared control requires reasoning about the intentions of the human user. In this work, we present a mathematical formulation for human intent recognition during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user. In addition to contextual observations, we model and incorporate the human agent's behavior as goal-directed actions with adjustable rationality to inform the underlying intent. We examine human inference on robot motion and furthermore validate our approach with a human subjects study that evaluates autonomy intent inference performance under a variety of goal scenarios and tasks, by novice subjects. Results show that our approach outperforms existing solutions and demonstrates that the probabilistic fusion of multiple observations improves intent inference and performance for shared-control operation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593766","","Robots;Bayes methods;Task analysis;Hidden Markov models;Uncertainty;Mathematical model;Probabilistic logic","Bayes methods;control engineering computing;human-robot interaction;inference mechanisms;mobile robots;telerobotics","recursive Bayesian human intent recognition;shared-control robotics;human-robot collaboration;mathematical formulation;assistive teleoperation;recursive Bayesian filtering approach models;nonverbal observations;contextual observations;goal-directed actions;human inference;robot motion;autonomy intent inference performance;shared-control operation;probabilistic reasoning;human intent recognition;human agents behavior;probabilistic fusion","","","22","","","","","IEEE","IEEE Conferences"
"Modeling and Control of an Articulated Tail for Maneuvering a Reduced Degree of Freedom Legged Robot","W. Saab; J. Yang; P. Ben-Tzvi","Virginia Tech, Robotics and Mechatronics Lab, Blacksburg, VA, 24060, USA; Virginia Tech, Robotics and Mechatronics Lab, Blacksburg, VA, 24060, USA; Virginia Tech, Robotics and Mechatronics Lab, Blacksburg, VA, 24060, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2695","2700","This paper presents dynamic modeling and control of an articulated robotic tail to maneuver and stabilize a reduced degree-of-freedom (DOF) quadruped robot. Conventional legged robotic systems consist of leg mechanisms that provide simultaneous propulsion, maneuvering and stabilization. However, in nature animals have been observed to utilize their tails to assist the legs in multiple tasks. Similarly, by incorporating an articulated tail onboard a quadruped robot, dynamic tail motions can be used to aid maneuvering. Therefore, tail implementation can potentially lead to simplifications in design and control of the legged robot since the legs will be responsible for only propulsion tasks. In this paper, a robotic system design consisting of an articulated tail and quadruped robot system is presented. Dynamic models are derived to analyze an optimal tail mass and length ratio to enhance inertial adjustment applications and develop an outer loop controller to plan tail trajectories for desired maneuvering applications. Results of analytical optimization are corroborated with measured data from biological animals. To decouple the dynamics of the articulated tail mechanism an inner loop controller using feedback linearization maps the desired behavior to the actuator inputs. This approach is validated using hardware-in-the-loop experiments with tail prototype in conjunction with simulated quadruped platform. Results demonstrate the capabilities of the articulated tail in enabling precise left and right turning (maneuvering).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593945","","Legged locomotion;Robot kinematics;Foot;Dynamics;Task analysis;Manipulators","actuators;feedback;hardware-in-the loop simulation;legged locomotion;linearisation techniques;motion control;robot dynamics","leg mechanisms;quadruped robot;dynamic tail motions;robotic system design;outer loop controller;articulated tail mechanism;inner loop controller;tail prototype;dynamic modeling control;articulated robotic tail;maneuvering;legged robotic systems;reduced degree of freedom legged robot;hardware-in-the-loop experiments;quadruped platform simulation;feedback linearization maps","","","32","","","","","IEEE","IEEE Conferences"
"Cloud services for robotic nurses? Assessing legal and ethical issues in the use of cloud services for healthcare robots","E. Fosch-Villaronga; H. Felzmann; M. Ramos-Montero; T. Mahler","Microsoft Cloud Computing Research Center, Queen Mary University of London, United Kingdom; NUI Galway, Galway, Ireland; Ortelio Ltd., Coventry, United Kingdom; Norwegian Research Center for Computers and Law, University of Oslo, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","290","296","This paper explores ethical and legal implications arising from the intertwinement of cloud services, healthcare and robotics. It closes an existing gap in the literature by highlighting the distinctive ethical and legal concerns associated with the inter-dependence of the cyber- and the physical aspects of healthcare cloud robotics. The identified core concerns include uncertainties with regard to data protection requirements; distributed responsibilities for unintended harm; achievement of transparency and consent for cloud robot services especially for vulnerable robot users; secondary uses of cloud data derived from robot activities; data security; and wider social issues. The paper aims to raise awareness and stimulate reflection of the legal and ethical impacts on different stakeholders arising from the use of cloud services in healthcare robotics. We show that due to the complexity of these concerns the design and implementation of such robots in healthcare requires an interdisciplinary development and impact assessment process. In light of legal requirements and ethical responsibilities towards end-users and other stakeholders, we draw practical considerations for engineers developing cloud services for robots in healthcare.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593591","","Cloud computing;Medical services;Robot kinematics;Robot sensing systems;Law","cloud computing;ethical aspects;health care;legislation;medical robotics;mobile robots;security of data","cyber- aspects;data protection requirements;data security;healthcare cloud robotics;ethical issues;legal issues;robotic nurses","","","41","","","","","IEEE","IEEE Conferences"
"Hydrodynamics Parameter Identification of Submerged Bodies: Numerical Methods Comparison and Friction Model Analysis","N. Gartner; M. Richier; V. Hugel","Université de Toulon, Laboratoire COSMER; Université de Toulon, Laboratoire COSMER; Université de Toulon, Laboratoire COSMER","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5628","5633","This paper focuses on numerical methods that can be used to identify hydrodynamic parameters of submerged bodies, namely added mass, linear and quadratic friction coefficients. The mechanical setup is a free decay pendulum that is equipped with an encoder. The first contribution of this paper deals with the comparison of two estimation methods: one method that fits the acceleration of the dynamical model with the acceleration obtained from derivatives of the measured angular position, and another method that fits this position with the angle obtained by numerical integration. The second contribution consists of investigating to what extent estimated added mass and friction coefficient parameters of the dynamical model match the empirical or theoretical values in the case of a spherical object. The results obtained show that the numerical integration method allows to determine the added mass with a good accuracy and a single friction coefficient could be used for the dynamic model without loosing validity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593770","","Hydrodynamics;Friction;Numerical models;Damping;Acceleration;Cutoff frequency;Estimation","friction;hydrodynamics;integration;numerical analysis;parameter estimation;pendulums","hydrodynamics parameter;numerical methods;friction model analysis;free decay pendulum;single friction coefficient;numerical integration method;dynamical model;estimation methods;quadratic friction coefficients;submerged bodies","","","15","","","","","IEEE","IEEE Conferences"
"Invariant smoothing on Lie Groups","P. Chauchat; A. Barrau; S. Bonnabel","Paul Chauchat and Silvere Bonnabel are with MINES ParisTech, PSL Reasearch University, Centre for Robotics, 60bd Saint-Michel, Paris, 75006, France; SAFRAN TECH Groupe Safran, Rue des Je-unes Bois - Chateaufort, Magny Les Hameaux CEDEX, 78772, France; Paul Chauchat and Silvere Bonnabel are with MINES ParisTech, PSL Reasearch University, Centre for Robotics, 60bd Saint-Michel, Paris, 75006, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1703","1710","In this paper we propose a (non-linear) smoothing algorithm for group-affine observation systems, a recently introduced class of estimation problems on Lie groups that bear a particular structure. As most non-linear smoothing methods, the proposed algorithm is based on a maximum a posteriori estimator, determined by optimization. But owing to the specific properties of the considered class of problems, the involved linearizations are proved to have a form of independence with respect to the current estimates, leveraged to avoid (partially or sometimes totally) the need to relinearize. The method is validated on a robot localization example, both in simulations and on real experimental data.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594068","","Smoothing methods;Manifolds;Simultaneous localization and mapping;Kalman filters;Random variables;Estimation;Robot localization","estimation theory;Kalman filters;Lie groups;linearisation techniques;optimisation;robot vision;SLAM (robots);smoothing methods","linearizations;invariant Kalman filtering;robot localization;posteriori estimator;nonlinear smoothing methods;group-affine observation systems;Lie groups;invariant smoothing","","","37","","","","","IEEE","IEEE Conferences"
"A Soft Robot to Navigate the Lumens of the Body Using Undulatory Locomotion Generated by a Rotating Magnetic Dipole Field","L. N. Pham; J. J. Abbott","Department of Mechanical Engineering and the Robotics Center, University of Utah, USA; Department of Mechanical Engineering and the Robotics Center, University of Utah, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1783","1788","In this paper, we describe a soft-robotic actuation concept to enable a mesoscale medical robot to navigate the natural lumens of the body, such as blood vessels and intestines. The concept comprises a simple soft robot with two embedded permanent magnets with alternating magnetic polarity, and a rotating (nonuniform) dipole magnetic field that is swept over the robot, resulting in a traveling-wave undulatory motion that propels the robot forward and backward. This soft-actuation technology can be fabricated in a wide range of sizes due to its simplicity, and has the potential to be applied in a variety of diagnostic and therapeutic contexts. We conduct experiments and numerical simulations to verify the movement of the soft robot. Then, we confirm the benefits of using nonuniform dipole fields over using uniform fields, as well as the benefits of alternating the polarity of the magnets embedded in the device.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594247","","Coils;Magnetic resonance imaging;Magnetic separation;Soft robotics;Permanent magnets;Magnetic moments","blood vessels;magnetic actuators;magnetic fields;magnetic sensors;medical robotics;microrobots;mobile robots;motion control;numerical analysis;path planning;permanent magnets","rotating magnetic dipole field;soft-robotic actuation concept;mesoscale medical robot;natural lumens;blood vessels;embedded permanent magnets;magnetic polarity;rotating dipole magnetic field;traveling-wave undulatory motion;soft-actuation technology;nonuniform dipole fields;undulatory locomotion;uniform dipole fields;diagnostic context;therapeutic context;numerical simulation","","","21","","","","","IEEE","IEEE Conferences"
"Intuitive Gaze-Control of a Robotized Flexible Endoscope","T. J. C. O. Vrielink; J. G. Puyal; A. Kogkas; A. Darzi; G. Mylonas","Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, HARMS lab; Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, HARMS lab; Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, HARMS lab; Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, HARMS lab; Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, HARMS lab","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1776","1782","Flexible endoscopy is a routinely performed procedure that has predominantly remained unchanged for decades despite its many challenges. This paper introduces a novel, more intuitive and ergonomic platform that can be used with any flexible endoscope, allowing easier navigation and manipulation. A standard endoscope is robotized and a gaze control system based on eye-tracking is developed and implemented, allowing hands-free manipulation. The system characteristics and step response has been evaluated using visual servoing. Further, the robotized system has been compared with a manually controlled endoscope during a user study. The users (n=11) showed a preference for the gaze controlled endoscope and a lower task load when the task was performed with the gaze control. In addition, gaze control was related to a higher success rate and a lower time to perform the task. The results presented validate the system's technical performance and demonstrate the intuitiveness of hands-free gaze control in flexible endoscopy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594426","","Endoscopes;Robots;Optical imaging;Task analysis;Gears;Control systems;Cameras","endoscopes;manipulators;medical robotics;visual servoing","intuitive gaze-control;robotized flexible endoscope;flexible endoscopy;intuitive platform;ergonomic platform;standard endoscope;gaze control system;eye-tracking;hands-free manipulation;system characteristics;robotized system;manually controlled endoscope;gaze controlled endoscope;lower task load;hands-free gaze control;visual servoing","","","20","","","","","IEEE","IEEE Conferences"
"Discrete Configuration Space Methods for Determining Modular Connector Area of Acceptance in Higher Dimensions","N. Eckenstein; M. Yim","Dept. of Mechanical Engineering and Applied Mechanics, Univ. of Pennsylvania, GRASP Lab., Philadelphia, PA, USA; Dept. of Mechanical Engineering and Applied Mechanics, Univ. of Pennsylvania, GRASP Lab., Philadelphia, PA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","430","435","Physical connectors with self-aligning geometry aid in the docking process for many robotic and automatic control systems such as robotic self-reconfiguration and air-to-air refueling. This self-aligning geometry provides a wider range of acceptable error tolerance in relative pose between the two rigid objects, increasing successful docking chances. We present a new method for computing the error range (or area of acceptance) for a pair of rigid connector objects with self-aligning geometry capable of higher dimensional analysis which was previously limited to three. The method is based on the configuration space obstacle model, which gives us a representation of the space of contact states between the two objects. Using an approach direction as analogous to gravity, and assuming the target docked configuration is stable, the set of misaligned points that lead to docking is the target configuration's watershed for an arbitrarily dimensioned configuration space obstacle. It is well known that the watershed of a height map on a discrete grid can be found using any number of algorithms from image segmentation. We present an implementation based on Meyer's flooding algorithm to determine this watershed and measure the AA for simple connectors in 2D and 3D. Results are presented for systems including unconstrained motion in SE(2) and motion constrained to four dimensions (ie. x,y,z,pitch) in SE(3).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594072","","Connectors;Geometry;Robots;Contacts;Three-dimensional displays;Two dimensional displays;Image segmentation","collision avoidance;discrete systems;mobile robots","discrete configuration space methods;physical connectors;docking process;robotic control systems;automatic control systems;robotic self-reconfiguration;air-to-air refueling;configuration space obstacle model;modular connector area of acceptance;self-aligning geometry;Meyer's flooding algorithm","","","21","","","","","IEEE","IEEE Conferences"
"An Integrated Localization-Navigation Scheme for Distance-Based Docking of UAVs","T. Nguyen; Z. Qiu; M. Cao; T. H. Nguyen; L. Xie","Nanyang Technological University, School of Electrical and Electronic Engineering, 50 Nanyang Ave, 639798, Singapore; Nanyang Technological University, School of Electrical and Electronic Engineering, 50 Nanyang Ave, 639798, Singapore; Nanyang Technological University, School of Electrical and Electronic Engineering, 50 Nanyang Ave, 639798, Singapore; Nanyang Technological University, School of Electrical and Electronic Engineering, 50 Nanyang Ave, 639798, Singapore; Nanyang Technological University, School of Electrical and Electronic Engineering, 50 Nanyang Ave, 639798, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5245","5250","In this paper we study the distance-based docking problem of unmanned aerial vehicles (UAVs) by using a single landmark placed at an arbitrarily unknown position. To solve the problem, we propose an integrated estimation-control scheme to simultaneously achieve the relative localization and navigation tasks for discrete-time integrators under bounded velocity: a nonlinear adaptive estimation scheme to estimate the relative position to the landmark, and a delicate control scheme to ensure both the convergence of the estimation and the asymptotic docking at the given landmark. A rigorous proof of convergence is provided by invoking the discrete-time LaSalle's invariance principle, and we also validate our theoretical findings on quadcopters equipped with ultra-wideband ranging sensors and optical flow sensors in a GPS-less environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594251","","Navigation;Convergence;Distance measurement;Adaptive estimation;Estimation;Task analysis;Optical sensors","adaptive estimation;autonomous aerial vehicles;convergence;image sequences;invariance;mobile robots;navigation;path planning;position control","single landmark;unmanned aerial vehicles;GPS-less environment;optical flow sensors;ultra-wideband ranging sensors;discrete-time LaSalle invariance principle;UAV;distance-based docking problem;integrated localization-navigation scheme;asymptotic docking;delicate control scheme;relative position;nonlinear adaptive estimation scheme;bounded velocity;discrete-time integrators;navigation tasks;relative localization;integrated estimation-control scheme;arbitrarily unknown position","","","20","","","","","IEEE","IEEE Conferences"
"Robotic Grasping Using Proximity Sensors for Detecting both Target Object and Support Surface","K. Sasaki; K. Koyama; A. Ming; M. Shimojo; R. Plateaux; J. Choley","Department of Mechanical Engineering and Intelligent Systems, The University of Electro Communications, Tokyo, Japan; Department of Creative Informatics, The University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro Communications, Tokyo, Japan; Department of Creative Informatics, The University of Tokyo, Tokyo, Japan; Department of Quartz laboratory, EA7393, SUPMECA, Saint-Ouen, France; Department of Quartz laboratory, EA7393, SUPMECA, Saint-Ouen, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2925","2932","The robustness of the positioning and posturing of robot hands relative to target object and support surface is an important issue for autonomous grasping. For example, to perform a grasping action such as picking up thin objects from a table top, the position and posture of the hand must be controlled to keep adequate relative posture and distance to the support surface besides those between the hand and the target object. Because slight errors in the posture and position are enough to cause grasping failure, the positioning and posturing of the hand must be precise enough, specially when the hand is close to the target object and support surface. To improve the robustness of robotic grasping, in this paper we present a method by grasping control based on the relative posture and position between hand and support surface besides those between hand and target object, using proximity sensors. Proximity sensors are newly installed on fingernails besides on the fingertips. As the fingernail sensor, an integration of Time-of-Flight (TOF) sensor and photo-reflector is designed to realize long range detection, as well as with precise and high-speed detection regardless of the reflectance of support surfaces when approaching the support surface. By the sensors, the hand can approach the object and support surface coarsely first, and then can be controlled fast and precisely to realize adequate grasping motion along the support surface but without contact with the support face. The method has been implemented to a manipulator system, and successful grasping experiments have demonstrated the effectiveness of the proposed method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594430","","Grasping;Robot sensing systems;Robot kinematics;Visualization;Optical sensors","biomechanics;dexterous manipulators;force control;grippers;manipulators;position control;robot vision;tactile sensors","support surface;target object;positioning;posturing;robotic grasping;proximity sensors;adequate relative posture","","","25","","","","","IEEE","IEEE Conferences"
"Progress and Prospects of EAST Remote Maintenance System","H. Pan; S. Shi; Y. Cheng; W. Zhao","Shenzhen University, Advanccd Energy Research Center, Shenzhen, 518060, People's Republic of China; Chinese Academy of Sciences, Institute of Plasma Physics, Hefei, 330031, People's Republic of China; Chinese Academy of Sciences, Institute of Plasma Physics, Hefei, 330031, People's Republic of China; Shenzhen University, Advanccd Energy Research Center, Shenzhen, 518060, People's Republic of China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3593","3598","Fast inspection and light maintenance capability is already a clear demand to control the tokamak condition and improve the efficiency of the experimental campaigns. EAST remote maintenance system has been developed to implement inspection and grasping tasks during plasma. The paper presents design description of EAMA (EAST articulated maintenance arm) robot, the gripper and the CASK. The field commissioning was performed both in mockup and EAST tokamak to demonstrate the availability and functionalities of EAMA system. To be able to realize fully routine operation on EAST, improvement of EAMA control system was proposed with integration developed algorithm, such as the robot flexible model modeling, vision servo, motion planning, etc. Finally, thoughts for CFETR In-Vessel Inspection System (CIVIS) are given.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594000","","Maintenance engineering;Inspection;Solid modeling;Manipulators;Robot sensing systems","automatic optical inspection;edge detection;fusion reactor instrumentation;grippers;inspection;maintenance engineering;nuclear power stations;object detection;plasma toroidal confinement;power system control;robot vision;service robots;Tokamak devices","light maintenance capability;tokamak condition;EAST remote maintenance system;grasping tasks;EAMA robot;EAST articulated maintenance arm;EAMA control system;EAST tokamak;CIVIS;CFETR in-vessel inspection system","","","15","","","","","IEEE","IEEE Conferences"
"A Variable Degree-of-Freedom and Self-Sensing Soft Bending Actuator Based on Conductive Liquid Metal and Thermoplastic Polymer Composites","Y. Hao; Z. Liu; Z. Xie; X. Fang; T. Wang; L. Wen","Beijing Advanced Innovation Center for Biomedical Engineering, School of Mechanical Engineering and Automation; Beijing Advanced Innovation Center for Biomedical Engineering, School of Mechanical Engineering and Automation; Beijing Advanced Innovation Center for Biomedical Engineering, School of Mechanical Engineering and Automation; Beijing Advanced Innovation Center for Biomedical Engineering, School of Mechanical Engineering and Automation; Beijing Advanced Innovation Center for Biomedical Engineering, School of Mechanical Engineering and Automation; Beijing Advanced Innovation Center for Biomedical Engineering, School of Mechanical Engineering and Automation","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents a soft actuator embedded with conductive liquid metal and shape memory epoxy (SME) which function together to enable self-sensing, tunable mechanical degrees of freedom (DoF), and variable stiffness. We embedded thermoplastic shape memory epoxy in the bottom portion of the actuator. Different sections of the SME could be selectively softened by an implanted conductive silver yarn located at different positions. When an electric current passes through the conductive silver yarn, it induces a phase transition that changes the epoxy from stiff state to compliant state. Each section of SME could be softened within 5 s by applying a current of 200 mA to the silver yarn. To acquire the strain curvature, eGaIn was infused into a microchannel surrounding the chambers of the soft actuator. A spiral-shaped eGaIn sensor was also attached to the tip of the actuator to perceive the contact with reliable dynamic force response. Systematic experiments were performed to characterize the stiffness, tunable DoF, and sensing property. We show the ability of the soft composite actuator to support a weight of 200g at the tip (as a cantilever) while maintaining the shape and the ability to recover its original shape after large bending deformation. In particular, seven different motion patterns could be achieved under the same pneumatic pressure of the actuator due to selectively heating the SME sections. A gripper which was fabricated by assembling two actuators to a base was able to grasp the weight up to 56 times of a single actuator through an appropriate motion pattern. For demonstration purposes, the gripper was used to grasp various objects by adjusting the DoF and stiffness with real-time feedback of the bending strain and the contact force.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593658","","Actuators;Robot sensing systems;Force;Resistance;Force sensors;Shape;Yarn","grippers;liquid metals;plastic deformation;pneumatic actuators;polymers;shape memory effects","self-sensing soft bending actuator;conductive liquid metal;thermoplastic polymer composites;thermoplastic shape memory epoxy;bending strain;pneumatic actuators;contact force","","","30","","","","","IEEE","IEEE Conferences"
"A 3D Convolutional Neural Network Towards Real-Time Amodal 3D Object Detection","H. Sun; Z. Meng; X. Du; M. H. Ang","National University of Singapore, Department of Mechanical Engineering, Singapore; National University of Singapore, Department of Mechanical Engineering, Singapore; Alliance for Research and Technology, Singapore-MIT; National University of Singapore, Department of Mechanical Engineering, Singapore","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8331","8338","We focus on the task of amodal 3D object detection, which is to predict object locations, dimensions, poses and categories in the real world. We introduce a 3D Convolutional Neural Network that takes a volumetric representation of an indoor scene as input and predicts 3D object bounding boxes, object categories, and orientations. Unlike prior state-of-the-arts, our approach does not depend on region proposal techniques to hypothesize object locations. We treat detection and recognition as one regression problem in a single network. Our elegant model is extremely fast and all predictions are reasoned from the global context of a point cloud in a continuous pipeline. We evaluate our approach on two standard datasets: the NYUv2 RGBD dataset and the SUN RGBD dataset. Experiments show that our approach is faster than start-of-the-art 3D detectors by several orders of magnitude towards real-time amodal 3D object detection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593837","","Three-dimensional displays;Two dimensional displays;Object detection;Proposals;Solid modeling;Detectors;Shape","convolutional neural nets;image colour analysis;object detection;object recognition;regression analysis","3D Convolutional Neural Network;3D detectors;object categories;object locations;real-time amodal 3D object detection","","","33","","","","","IEEE","IEEE Conferences"
"LIMO: Lidar-Monocular Visual Odometry","J. Graeter; A. Wilczynski; M. Lauer","Karlsruhe Institute of Technology, Institute of Measurement and Control, Germany; Karlsruhe Institute of Technology, Institute of Measurement and Control, Germany; Karlsruhe Institute of Technology, Institute of Measurement and Control, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7872","7879","Higher level functionality in autonomous driving depends strongly on a precise motion estimate of the vehicle. Powerful algorithms have been developed. However, their great majority focuses on either binocular imagery or pure LIDAR measurements. The promising combination of camera and LIDAR for visual localization has mostly been unattended. In this work we fill this gap, by proposing a depth extraction algorithm from LIDAR measurements for camera feature tracks and estimating motion by robustified keyframe based Bundle Adjustment. Semantic labeling is used for outlier rejection and weighting of vegetation landmarks. The capability of this sensor combination is demonstrated on the competitive KITTI dataset, achieving a placement among the top 15. The code is released to the community.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594394","","Feature extraction;Laser radar;Cameras;Estimation;Three-dimensional displays;Calibration;Visual odometry","cameras;distance measurement;feature extraction;mobile robots;motion estimation;object tracking;optical radar;pose estimation;robot vision;stereo image processing","visual localization;depth extraction algorithm;camera feature tracks;outlier rejection;sensor combination;LIMO;lidar-monocular visual odometry;higher level functionality;autonomous driving;precise motion estimate;powerful algorithms;great majority;binocular imagery;bundle adjustment;LIDAR measurements","","1","25","","","","","IEEE","IEEE Conferences"
"Real-Time Object Pose Estimation with Pose Interpreter Networks","J. Wu; B. Zhou; R. Russell; V. Kee; S. Wagner; M. Hebert; A. Torralba; D. M. S. Johnson","MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Charles Stark Draper Laboratory, Cambridge, MA, USA; Charles Stark Draper Laboratory, Cambridge, MA, USA; Dexai Robotics, Boston, MA, USA; Charles Stark Draper Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Dexai Robotics, Boston, MA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6798","6805","In this work, we introduce pose interpreter networks for 6-DoF object pose estimation. In contrast to other CNN-based approaches to pose estimation that require expensively annotated object pose data, our pose interpreter network is trained entirely on synthetic pose data. We use object masks as an intermediate representation to bridge real and synthetic. We show that when combined with a segmentation model trained on RGB images, our synthetically trained pose interpreter network is able to generalize to real data. Our end-to-end system for object pose estimation runs in real-time (20 Hz) on live RGB data, without using depth information or ICP refinement.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593662","","Pose estimation;Image segmentation;Three-dimensional displays;Quaternions;Real-time systems;Training;Task analysis","convolutional neural nets;image colour analysis;image representation;image segmentation;object recognition;pose estimation","object pose estimation;CNN-based approaches;synthetic pose data;object masks;RGB images;6-DoF object;pose interpreter network","","","51","","","","","IEEE","IEEE Conferences"
"Lightweight Collision Avoidance for Resource-Constrained Robots","M. Shahriari; I. Švogor; D. St-Onge; G. Beltrame","NA; Department of Computer and Software Engineering, Ecole Polytechnique de Montréal, 2900 Boul Édouard-Montpetit Québec, CA; Department of Computer and Software Engineering, Ecole Polytechnique de Montréal, 2900 Boul Édouard-Montpetit Québec, CA; Department of Computer and Software Engineering, Ecole Polytechnique de Montréal, 2900 Boul Édouard-Montpetit Québec, CA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","One of the safest and most reliable strategies for vehicle's collision avoidance is embedded control at low level to guarantee safe motion in all situations using on-board sensors. In this paper, we propose a novel lightweight collision avoidance strategy that can be implemented as a low level motion control to achieve safe motion while simultaneously tracking the robot's reference control input. This strategy is designed to be general so that it can be easily integrated with most control designs, with the primary target of resource-constrained robot swarms that act in real-time, dynamic environments. The main advantages of our approach are a very simple structure and low computational requirements. We verified the effectiveness of the proposed collision avoidance strategy through two simulated scenarios and with physical robots. We believe our design can be directly used in many areas, such as autonomous driving, intelligent transportation and planetary exploration.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593841","","Collision avoidance;Robot sensing systems;Navigation;Vehicle dynamics","collision avoidance;control system synthesis;mobile robots;motion control","resource-constrained robot;controller design;lightweight collision avoidance strategy;embedded control;reference control input;dynamic environment;low level motion control;on-board sensors;vehicle;physical robots;low computational requirements","","","19","","","","","IEEE","IEEE Conferences"
"FPGA-Based Velocity Estimation for Control of Robots with Low-Resolution Encoders","J. Y. Wu; Z. Chen; A. Deguet; P. Kazanzides","Johns Hopkins University, Dept. of Computer Science, Baltimore, MD, 21218, USA; Johns Hopkins University, Dept. of Computer Science, Baltimore, MD, 21218, USA; Johns Hopkins University, Dept. of Computer Science, Baltimore, MD, 21218, USA; Johns Hopkins University, Dept. of Computer Science, Baltimore, MD, 21218, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6384","6389","Robot control algorithms often rely on measurements of robot joint velocities, which can be estimated by measuring the time between encoder edges. When encoder edges occur infrequently, such as at low velocities and/or with low resolution encoders, this measurement delay may affect the stability of closed-loop control. This is evident in both the joint position control and Cartesian impedance control of the da Vinci Research Kit (dVRK), which contains several low-resolution encoders. We present a hardware-based method that gives more frequent velocity updates and is not affected by common encoder imperfections such as non-uniform duty cycles and quadrature phase error. The proposed method measures the time between consecutive edges of the same type but, unlike prior methods, is implemented for the rising and falling edges of both channels. Additionally, it estimates acceleration to enable software compensation of the measurement delay. The method is shown to improve Cartesian impedance control of the dVRK.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594139","","Velocity measurement;Estimation;Delays;Silicon;Acceleration;Robots","closed loop systems;field programmable gate arrays;position control;robot dynamics;velocity control","Cartesian impedance control;FPGA-based velocity estimation;low-resolution encoders;robot control algorithms;robot joint velocities;encoder edges;low velocities;low resolution encoders;measurement delay;closed-loop control;joint position control;frequent velocity updates;common encoder imperfections","","","12","","","","","IEEE","IEEE Conferences"
"Safe Motion Planning for Steerable Needles Using Cost Maps Automatically Extracted from Pulmonary Images","M. Fu; A. Kuntz; R. J. Webster; R. Alterovitz","Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27599, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27599, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, 37235, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27599, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4942","4949","Lung cancer is the deadliest form of cancer, and early diagnosis is critical to favorable survival rates. Definitive diagnosis of lung cancer typically requires needle biopsy. Common lung nodule biopsy approaches either carry significant risk or are incapable of accessing large regions of the lung, such as in the periphery. Deploying a steerable needle from a bronchoscope and steering through the lung allows for safe biopsy while improving the accessibility of lung nodules in the lung periphery. In this work, we present a method for extracting a cost map automatically from pulmonary CT images, and utilizing the cost map to efficiently plan safe motions for a steerable needle through the lung. The cost map encodes obstacles that should be avoided, such as the lung pleura, bronchial tubes, and large blood vessels, and additionally formulates a cost for the rest of the lung which corresponds to an approximate likelihood that a blood vessel exists at each location in the anatomy. We then present a motion planning approach that utilizes the cost map to generate paths that minimize accumulated cost while safely reaching a goal location in the lung.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593407","","Needles;Lung;Biomedical imaging;Planning;Biopsy;Computed tomography;Blood vessels","blood vessels;cancer;computerised tomography;feature extraction;lung;medical image processing;needles","lung nodule biopsy;steerable needles;bronchoscope;bronchial tubes;blood vessels;safe motion planning;motion planning approach;lung pleura;pulmonary CT images;cost map;lung periphery;lung nodules;needle biopsy;lung cancer","","","43","","","","","IEEE","IEEE Conferences"
"Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality","M. P. Das; Z. Dong; S. Scherer","Indian Institute of Technology, Kharagpur, WB, 721302, India; Wuhan University, State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan, 430079, China; Carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6357","6363","This paper introduces a method of structure inspection using mixed-reality headsets to reduce the human effort in reporting accurate inspection information such as fault locations in 3D coordinates. Prior to every inspection, the headset needs to be localized. While external pose estimation and fiducial marker based localization would require setup, maintenance, and manual calibration; marker-free self-localization can be achieved using the onboard depth sensor and camera. However, due to limited depth sensor range of portable mixed-reality headsets like Microsoft HoloLens, localization based on simple point cloud registration (sPCR) would require extensive mapping of the environment. Also, localization based on camera image would face same issues as stereo ambiguities and hence depends on viewpoint. We thus introduce a novel approach to Joint Point Cloud and Image-based Localization (JPIL) for mixed-reality headsets that uses visual cues and headset orientation to register small, partially overlapped point clouds and save significant manual labor and time in environment mapping. Our empirical results compared to sPCR show average 10 fold reduction of required overlap surface area that could potentially save on average 20 minutes per inspection. JPIL is not only restricted to inspection tasks but also can be essential in enabling intuitive human-robot interaction for spatial mapping and scene understanding in conjunction with other agents like autonomous robotic systems that are increasingly being deployed in outdoor environments for applications like structural inspection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594318","","Three-dimensional displays;Headphones;Inspection;Cameras;Virtual reality;Solid modeling;Robot sensing systems","augmented reality;calibration;cameras;human-robot interaction;image registration;image sensors;inspection;mobile robots;robot vision;SLAM (robots);stereo image processing","mixed-reality headsets;headset orientation;structure inspection;marker-free self-localization;onboard depth sensor;simple point cloud registration;camera image;inspection information;joint point cloud and image-based localization;JPIL;human-robot interaction;time 20.0 min","","","18","","","","","IEEE","IEEE Conferences"
"Characterization of Active/Passive Pneumatic Actuators for Assistive Devices","D. Kaneishi; M. Tomizuka; R. P. Matthew","Department of Mechanical Engineering, University of California, Berkeley, CA, 94702, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94702, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, 94702, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2747","2754","Assistive devices have been developed for power augmentation and task-oriented assistance such as loaded walking. The effective joint dynamics of the user can be altered using a wearable system, providing assistance when a task is performed. The authors have investigated an Active/Passive Pneumatic Actuator (AP2A) for an assistive device, which has a simple structure and responds as a passive nonlinear spring with controllable stiffness. This paper introduces a novel controller for the AP2 A and validates the performance through experiments. The developed controller is found to stabilize at the desired stiffness response within 1 second, confirming the ability of the AP2 A to act as an adjustable passive nonlinear spring.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594143","","Force;Valves;Springs;Task analysis;Assistive devices;Pneumatic actuators","handicapped aids;nonlinear control systems;pneumatic actuators;springs (mechanical);stability","passive nonlinear spring;stability;assistive device;active/passive pneumatic actuators;adjustable passive nonlinear spring","","","24","","","","","IEEE","IEEE Conferences"
"The Socially Invisible Robot Navigation in the Social World Using Robot Entitativity","A. Bera; T. Randhavane; E. Kubin; A. Wang; K. Gray; D. Manocha","Department of Computer Science, University of North Carolina, Chapel Hill, USA; Department of Computer Science, University of North Carolina, Chapel Hill, USA; Department of Psychology and Neuroscience, University of North Carolina, Chapel Hill, USA; Department of Computer Science, University of North Carolina, Chapel Hill, USA; Department of Psychology and Neuroscience, University of North Carolina, Chapel Hill, USA; Department of Computer Science, University of Maryland, College Park, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4468","4475","We present a real-time, data-driven algorithm to enhance the social-invisibility of robots within crowds. Our approach is based on prior psychological research, which reveals that people notice and-importantly-react negatively to groups of social actors when they have high entitativity, moving in a tight group with similar appearances and trajectories. In order to evaluate that behavior, we performed a user study to develop navigational algorithms that minimize entitativity. This study establishes mapping between emotional reactions and multi-robot trajectories and appearances, and further generalizes the finding across various environmental conditions. We demonstrate the applicability of our entitativity modeling for trajectory computation for active surveillance and dynamic intervention in simulated robot-human interaction scenarios. Our approach empirically shows that various levels of entitative robots can be used to both avoid and influence pedestrians while not eliciting strong emotional reactions, giving multi-robot systems socially-invisibility.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593411","","Trajectory;Navigation;Psychology;Computational modeling;Surveillance;Robot kinematics","human-robot interaction;multi-robot systems;navigation;path planning","simulated robot-human interaction scenarios;entitative robots;strong emotional reactions;socially invisible robot navigation;robot entitativity;data-driven algorithm;navigational algorithms;trajectory computation;multirobot systems","","","42","","","","","IEEE","IEEE Conferences"
"Energy-Efficient Design and Control of a Vibro-Driven Robot","P. Liu; G. Neumann; Q. Fu; S. Pearson; H. Yu","Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Lincoln Institute for Agri-Food Technology (LIAT), University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Faculty of Science and Technology, Bournemouth University, Poole, BH12 5BB, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1464","1469","Vibro-driven robotic (VDR) systems use stick-slip motions for locomotion. Due to the underactuated nature of the system, efficient design and control are still open problems. We present a new energy preserving design based on a spring-augmented pendulum. We indirectly control the friction-induced stick-slip motions by exploiting the passive dynamics in order to achieve an improvement in overall travelling distance and energy efficiency. Both collocated and non-collocated constraint conditions are elaborately analysed and considered to obtain a desired trajectory generation profile. For tracking control, we develop a partial feedback controller for the driving pendulum which counteracts the dynamic contributions from the platform. Comparative simulation studies show the effectiveness and intriguing performance of the proposed approach, while its feasibility is experimentally verified through a physical robot. Our robot is to the best of our knowledge the first nonlinear-motion prototype in literature towards the VDR systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594322","","Robots;Trajectory;Force;Dynamics;Friction;Energy efficiency;Acceleration","control system synthesis;feedback;friction;mobile robots;motion control;nonlinear control systems;pendulums;position control;robot dynamics;springs (mechanical);stick-slip","trajectory generation profile;VDR systems;nonlinear-motion prototype;physical robot;dynamic contributions;driving pendulum;partial feedback controller;tracking control;noncollocated constraint conditions;travelling distance;passive dynamics;friction-induced stick-slip motions;spring-augmented pendulum;open problems;underactuated nature;locomotion;vibro-driven robotic systems;energy-efficient design","","","18","","","","","IEEE","IEEE Conferences"
"Online prediction of threading task failure using Convolutional Neural Networks","G. R. Moreira; G. J. G. Lahr; T. Boaventura; J. O. Savazzi; G. A. P. Caurin","Mechanical Engineering Department at São Carlos, School of Engineering, University of São Paulo, São Carlos, Brazil; Mechanical Engineering Department at São Carlos, School of Engineering, University of São Paulo, São Carlos, Brazil; Mechanical Engineering Department at São Carlos, School of Engineering, University of São Paulo, São Carlos, Brazil; GPX-Embraer, Gavião Peixoto, SP, Brazil; Aeronautics Engineering Department, São Carlos School of Engineering, University of São Paulo, São Carlos, Brazil","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2056","2061","Fasteners assembly automation in different industries require flexible systems capable of dealing with faulty situations. Fault detection and isolation (FDI) techniques are used to detect failure and deal with them, avoiding losses on parts, tools or robots. However, FDI usually deals with the faults after or at the moment they occur. Thus, we propose a method that predicts potential failures online, based on the forces and torques signatures captured during the task. We demonstrate the approach experimentally using an industrial robot, equipped with a force-torque sensor and a pneumatic gripper, used to align and thread nuts into bolts. All effort information is fed into a supervised machine learning algorithm, based on a Convolutional Neural Network (CNN) classifier. The network was able to predict and classify the threading task outcomes in 3 groups: mounted, not mounted or jammed. Our approach was able to reduce in 10.9% the threading task execution time when compared to a reference without FDI, but had problem to predict jammed cases. The same experiment was also performed with other two additional learning algorithms, and the results were systematically compared.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594501","","Fasteners;Task analysis;Robot sensing systems;Instruction sets;Force;Service robots","assembling;convolutional neural nets;fasteners;fault diagnosis;flexible manufacturing systems;force sensors;grippers;industrial robots;pattern classification;production engineering computing;supervised learning","online prediction;fasteners assembly automation;flexible systems;industrial robot;force-torque sensor;pneumatic gripper;supervised machine learning algorithm;threading task execution time;task failure;FDI techniques;convolutional neural network classifier;fault detection and isolation;CNN","","","23","","","","","IEEE","IEEE Conferences"
"A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots","F. Morbidi; E. Bretagne","Université de Picardie Jules Verne, MIS laboratory, 33 rue Saint-Leu, Amiens, France, 80039; Université de Picardie Jules Verne, MIS laboratory, 33 rue Saint-Leu, Amiens, France, 80039","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4833","4839","In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593984","","Mobile robots;Wheels;Robot kinematics;Kinematics;Vehicle dynamics;Axles","mobile robots;multi-agent systems;multi-robot systems;position control;trajectory control","multiagent systems;classification task;conventional centered wheel;distance-bearing formations;unicycle robots;distance-bearing constraints;macro-robot;regular convex polygon;trajectory-tracking control problem","","","25","","","","","IEEE","IEEE Conferences"
"An Actuator Design Criterion to Maximize Physical Balance Recovery","J. J. M. Driessen; R. Featherstone; A. E. Gkikakis","Dept. Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Dept. Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy; Dept. Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2829","2836","This paper first presents a formula to predict the largest balance disturbance from which a legged robot can recover without taking a step. It then presents an actuator design criterion derived from this formula that maximizes the robot's ability to recover. In this study, it is assumed that the robot is using a single major joint (e.g, a hip joint) to perform its balance recovery movement, and that the actuator consists of an electric motor and reduction gear. It is also assumed that the robot's support polygon is sufficiently small that it can be approximated as a point, and that the balance recovery motion is essentially planar, so that a 2-D analysis remains valid in 3-D. Finally, it is assumed that, for the purpose of studying balance recovery motion, the robot can be approximated by a reaction wheel pendulum. The theory has been tested experimentally on a robot designed to be good at balancing, and was found to agree closely with experimental results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593729","","Actuators;Torque;Robot kinematics;Friction;Electrical resistance measurement;Legged locomotion","actuators;control system synthesis;gears;legged locomotion;mechanical stability;motion control;optimisation;pendulums;robot dynamics;wheels","legged robot;hip joint;balance recovery motion;actuator design;physical balance recovery;electric motor;gear reduction;wheel pendulum;robot design","","","23","","","","","IEEE","IEEE Conferences"
"Implementing Full-body Torque Control in Humanoid Robot with High Gear Ratio Using Pulse Width Modulation Voltage","K. Lee; O. Sim; H. Jeong; J. Oh; H. Bae; S. Hong; J. Oh","Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Humanoid Research Center, School of Mechanical, Aerospace & Systems Engineering, 291 Daehak-ro, Yuseong-gu, Daejeon, 305-338, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","726","732","Most state-of-the-art torque control-based legged robots show excellent performance, exceeding that of conventional position control-based robots. Many conventional position control-based legged robots have high gear ratios, but do not have joint torque sensors. In addition, some robots cannot generate current for controlling the motor torque. To apply torque control-based walking algorithms to a position control-based humanoid robot, we proposed current control using a motor thermal model and realized joint torque control by compensating for the joint dynamics and robot dynamics. We conducted experiments to verify the performance of the Hubo2 platform developed in 2008 by applying a full-body dynamics control framework. The results confirmed the possibility of using torque control algorithms with existing position-based robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593908","","Torque;Robots;Resistance;Aerodynamics;Temperature sensors;Modeling;Torque control","electric current control;gears;humanoid robots;legged locomotion;mobile robots;motion control;position control;robot dynamics;torque control;voltage control","full-body torque control;high gear ratio;pulse width modulation voltage;motor torque;current control;joint torque control;robot dynamics;humanoid robot;position control;legged robots","","","21","","","","","IEEE","IEEE Conferences"
"Adversarial Learning-Based On-Line Anomaly Monitoring for Assured Autonomy","N. Patel; A. Nandini Saridena; A. Choromanska; P. Krishnamurthy; F. Khorrami","Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, 5 MetroTech Center, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, 5 MetroTech Center, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, 5 MetroTech Center, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, 5 MetroTech Center, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, 5 MetroTech Center, Brooklyn, NY, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6149","6154","The paper proposes an on-line monitoring framework for continuous real-time safety/security in learning-based control systems (specifically application to a unmanned ground vehicle). We monitor validity of mappings from sensor inputs to actuator commands, controller-focused anomaly detection (CFAM), and from actuator commands to sensor inputs, system-focused anomaly detection (SFAM). CFAM is an image conditioned energy based generative adversarial network (EBGAN) in which the energy based discriminator distinguishes between proper and anomalous actuator commands. SFAM is based on an action condition video prediction framework to detect anomalies between predicted and observed temporal evolution of sensor data. We demonstrate the effectiveness of the approach on our autonomous ground vehicle for indoor environments and on Udacity dataset for outdoor environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593375","","Generators;Convolution;Actuators;Monitoring;Anomaly detection;Robot sensing systems;Computer architecture","learning (artificial intelligence);object detection;remotely operated vehicles","indoor environments;Udacity dataset;image conditioned energy based generative adversarial network;on-line monitoring framework;assured autonomy;Adversarial Learning-Based On-Line Anomaly Monitoring;autonomous ground vehicle;sensor data;action condition video prediction framework;anomalous actuator commands;proper actuator commands;generative adversarial network;SFAM;system-focused anomaly detection;CFAM;controller-focused anomaly detection;sensor inputs;unmanned ground vehicle;learning-based control systems","","","26","","","","","IEEE","IEEE Conferences"
"Quotient-Space Motion Planning","A. Orthey; A. Escande; E. Yoshida","UMI3218/RL, CNRS-AIST Joint Robotics Laboratory, Tsukuba-shi, 305-8560, Japan; UMI3218/RL, CNRS-AIST Joint Robotics Laboratory, Tsukuba-shi, 305-8560, Japan; UMI3218/RL, CNRS-AIST Joint Robotics Laboratory, Tsukuba-shi, 305-8560, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8089","8096","A motion planning algorithm computes the motion of a robot by computing a path through its configuration space. To improve the runtime of motion planning algorithms, we propose to nest robots in each other, creating a nested quotient-space decomposition of the configuration space. Based on this decomposition we define a new roadmap-based motion planning algorithm called the Quotient-space roadMap Planner (QMP). The algorithm starts growing a graph on the lowest dimensional quotient space, switches to the next quotient space once a valid path has been found, and keeps updating the graphs on each quotient space simultaneously until a valid path in the configuration space has been found. We show that this algorithm is probabilistically complete and outperforms a set of state-of-the-art algorithms implemented in the open motion planning library (OMPL).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593554","","Planning;Manipulators;Runtime;Visualization;Probabilistic logic;Manifolds","mobile robots;motion control;path planning","quotient-space motion planning;OMPL;robot;Quotient-space roadMap Planner;roadmap-based motion planning algorithm;nested quotient-space decomposition;open motion planning library","","1","27","","","","","IEEE","IEEE Conferences"
"Distributed Direction of Arrival Estimation-Aided Cyberattack Detection in Networked Multi-Robot Systems","S. Lee; B. Min","Department of Computer and Information Technology, SMART Lab Purdue University, West Lafayette, IN, 47907, USA; Department of Computer and Information Technology, SMART Lab Purdue University, West Lafayette, IN, 47907, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This study proposes a Direction of Arrival (DoA)-aided attack detection scheme to identify cyberattacks on networked multi-robot systems. For each agent, a local estimator is designed to generate robust residuals, and a parametric statistical tool corresponding to the residuals is elaborated to build sensitive decision rules. These locally stored residuals and thresholds are shared between robots via a wireless network, allowing a multi-robot system to complete its mission in the presence of one or more compromised agents. The proposed DoA-aided attack detection scheme is tested on a multi-robot testbed with a team of 10 robots. Experimental results demonstrate that the proposed detection scheme enables each robot to identify malicious activities without shearing the global coordination.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594465","","Direction-of-arrival estimation;Robot sensing systems;Multi-robot systems;Antenna measurements;Robot kinematics","control engineering computing;direction-of-arrival estimation;multi-robot systems;networked control systems;security of data;statistical analysis","networked multirobot systems;parametric statistical tool;wireless network;DoA-aided attack detection scheme;multirobot testbed;distributed direction of arrival estimation-aided cyberattack detection","","","18","","","","","IEEE","IEEE Conferences"
"A 3D Laparoscopic Imaging System Based on Stereo-Photogrammetry with Random Patterns","C. Sui; Z. Wang; Y. Liu","Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, T Stone Robotics Institute, HKSAR, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, T Stone Robotics Institute, HKSAR, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, T Stone Robotics Institute, HKSAR, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1276","1282","In this paper, we propose a novel 3D laparoscopic imaging system based on stereo-photogrammetry which is assisted by projecting patterns on the tissue surface. The proposed laparoscopic imaging system has three optic channels, two of which are responsible for stereo vision feedback and the other one is used for coded structured patterns projection. The projected patterns provide the robustness to homogeneous tissue surface since they add more features that can be relied on in the stereo matching. Image fiber bundles (100k pixels) and Gradient-index (GRIN) lenses are utilized to facilitate the remote image acquisition and miniaturization of the laparoscopic probe. Moreover, we adopt a digital micromirror device (DMD) and high-speed cameras to achieve fast pattern switching (up to 4 kHz) and high frame rate image acquisition. The system configuration allows for implementation of the time multiplexing pattern codification strategy in the 3D laparoscopic imaging system to enhance the reliability and resolution of the 3D surface reconstruction. A prototype is established, and various experiments are conducted. Comparative experimental results prove the advantages of our system design. The static and dynamic 3D reconstruction results validate the performance of the proposed 3D laparoscopic imaging system quantitatively and qualitatively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593733","","Three-dimensional displays;Laparoscopes;Lenses;Imaging;Probes;Image resolution;Surface reconstruction","image reconstruction;image sensors;lenses;medical image processing;photogrammetry;stereo image processing;surgery","high frame rate image acquisition;stereo-photogrammetry;coded structured patterns projection;stereo matching;3D surface reconstruction;stereo vision feedback;novel 3D laparoscopic imaging system;frequency 4.0 kHz","","","27","","","","","IEEE","IEEE Conferences"
"Development of a Musculoskeletal Humanoid Robot as a Platform for Biomechanical Research on the Underwater Dolphin Kick","Y. Ishii; S. Nishikawa; R. Niiyama; Y. Kuniyoshi","Faculty of Engineering, The University of Tokyo, Japan; The University of Tokyo, Graduate School of Information Science and Technology, Japan; The University of Tokyo, Graduate School of Information Science and Technology, Japan; The University of Tokyo, Graduate School of Information Science and Technology, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3285","3291","The dolphin kick is a swimming style characterized by undulation of the body. As a platform for swimming research, we have developed a musculoskeletal humanoid robot called Triton. Triton has a flexible spine with erector spinae muscles and a stiffness adjustment system for lumbar joints. The musculoskeletal body includes biarticular and polyarticular muscles, providing multi-joint coordination. The robot is actuated by pneumatic muscles, yielding lightweight and inherently waterproof properties. The compliance of the joints allows interactions between body and fluid similar to those of human swimming. This study presents the design concept of Triton and experimental results from a water tank test. We compare the results with simulation and human movements reported in literature. The results show that the musculoskeletal swimming robot has similar cycle trends in joint angle and thrust force.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593912","","Muscles;Dolphins;Force;Legged locomotion;Sports","biomechanics;bone;humanoid robots;kinematics;mobile robots;motion control;muscle","swimming style;musculoskeletal humanoid robot;Triton;flexible spine;erector spinae muscles;stiffness adjustment system;lumbar joints;musculoskeletal body;multijoint coordination;pneumatic muscles;lightweight properties;inherently waterproof properties;human swimming;musculoskeletal swimming robot;joint angle;thrust force;biomechanical research;underwater dolphin kick","","","25","","","","","IEEE","IEEE Conferences"
"A Confidence-Based Shared Control Strategy for the Smart Tissue Autonomous Robot (STAR)","H. Saeidi; J. D. Opfermann; M. Kam; S. Raghunathan; S. Leonard; A. Krieger","Mechanical Engineering Department, University of Maryland, College Park, MD, 20742, USA; Childrens National Health System, Sheikh Zayed Institute for Pediatric Surgical Innovation, 111 Michigan Ave. N.W., Washington, DC, 20010; Mechanical Engineering Department, University of Maryland, College Park, MD, 20742, USA; Mechanical Engineering Department, University of Maryland, College Park, MD, 20742, USA; Electrical and Computer Science Engineering Department, Johns Hopkins University, Baltimore, MD, 21211; Mechanical Engineering Department, University of Maryland, College Park, MD, 20742, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1268","1275","Autonomous robotic assisted surgery (RAS) systems aim to reduce human errors and improve patient outcomes leveraging robotic accuracy and repeatability during surgical procedures. However, full automation of RAS in complex surgical environments is still not feasible and collaboration with the surgeon is required for safe and effective use. In this work, we utilize our Smart Tissue Autonomous Robot (STAR) to develop and evaluate a shared control strategy for the collaboration of the robot with a human operator in surgical scenarios. We consider 2D pattern cutting tasks with partial blood occlusion of the cutting pattern using a robotic electrocautery tool. For this surgical task and RAS system, we i) develop a confidence-based shared control strategy, ii) assess the pattern tracking performances of manual and autonomous controls and identify the confidence models for human and robot as well as a confidence-based control allocation function, and iii) experimentally evaluate the accuracy of our proposed shared control strategy. In our experiments on porcine fat samples, by combining the best elements of autonomous robot controller with complementary skills of a human operator, our proposed control strategy improved the cutting accuracy by 6.4%, while reducing the operator work time to 44% compared to a pure manual control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594290","","Robots;Trajectory;Task analysis;Surgery;Human factors;Cameras;Blood","biological tissues;blood;medical robotics;mobile robots;surgery","confidence-based shared control strategy;STAR;surgery systems;robotic accuracy;surgical procedures;complex surgical environments;surgical scenarios;cutting pattern;robotic electrocautery tool;surgical task;confidence models;confidence-based control allocation function;autonomous robot controller;smart tissue autonomous robot;autonomous robotic assisted surgery;2D pattern cutting","","","27","","","","","IEEE","IEEE Conferences"
"Do I act familiar? Investigating the Similarity-Attraction Principle on Culture-specific Communicative behaviour for Social Robots","B. Lugrin; A. Bartl; H. Striepe; J. Lax; T. Toriizuka","Human Computer Interaction, University of Wuerzburg, Germany; Human Computer Interaction, University of Wuerzburg, Germany; Human Computer Interaction, University of Wuerzburg, Germany; Human Computer Interaction, University of Wuerzburg, Germany; Nihon University, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2033","2039","Culture, amongst other individual and social factors, plays a crucial role in human-human interactions. If robots should become a part of our society, they should be able to act in culture-specific manners as well. In this paper, we showcase the implementation of a cultural dichotomy, namely individualism vs. collectivism, in a social robots' conversation. Presenting these conversations to human observers from Germany and Japan, we investigate whether the implemented differences are recognized as such, and whether stereotypical culture-specific behaviours that correspond to the observers' cultural background is preferred. Results suggest that the manipulations in behaviour had the intended effect, but are not reflected in personal preferences.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594035","","Cultural differences;Observers;Computational modeling;Global communication;Service robots;Senior citizens","behavioural sciences computing;cultural aspects;human-robot interaction;mobile robots","social robots conversation;cultural dichotomy;human-human interactions;culture-specific communicative behaviour;similarity-attraction principle","","","28","","","","","IEEE","IEEE Conferences"
"A Universal Gripper Using Optical Sensing to Acquire Tactile Information and Membrane Deformation","T. Sakuma; F. Von Drigalski; M. Ding; J. Takamatsu; T. Ogasawara","Ikoma, Graduate School of Information Science Nara Institute of Science and Technology, 8916–5 Takayama, Nara 630-0192, Japan; Ikoma, Graduate School of Information Science Nara Institute of Science and Technology, 8916–5 Takayama, Nara 630-0192, Japan; Ikoma, Graduate School of Information Science Nara Institute of Science and Technology, 8916–5 Takayama, Nara 630-0192, Japan; Ikoma, Graduate School of Information Science Nara Institute of Science and Technology, 8916–5 Takayama, Nara 630-0192, Japan; Ikoma, Graduate School of Information Science Nara Institute of Science and Technology, 8916–5 Takayama, Nara 630-0192, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","The universal gripper has attracted attention due to its simple structure and advanced grasping ability for irregularly shaped objects. In this research, we propose a novel design for a granular-jamming-based gripper which uses a transparent filling and a semi-transparent membrane to allow optical sensing to detect both deformation of the membrane and the object being grasped. By adjusting the refractive index of an oil mixture to the refractive index of the granular bodies, we produced a fully transparent filling that allows the use of a camera inside the universal gripper. In this paper, we present the materials and development of our prototype, and describe the experimental confirmation of the prototype's performance. We showed that our prototype was able to grasp cylindrical and rectangular objects between 10 to 70 mm length while also tracking the deformation of the gripper.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593697","","Grippers;Cameras;Strain;Grasping;Prototypes;Optical sensors","deformation;grippers;jamming;membranes;refractive index;tactile sensors","granular-jamming-based gripper;semitransparent membrane;irregularly shaped objects;membrane deformation;acquire tactile information;optical sensing;rectangular objects;cylindrical objects;universal gripper;fully transparent filling;granular bodies;refractive index","","","13","","","","","IEEE","IEEE Conferences"
"Trajectory Planning for Heterogeneous Robot Teams","M. Debord; W. Hönig; N. Ayanian","Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7924","7931","We describe a trajectory planning method for heterogeneous mobile robot teams in known environments. We consider two core problems that arise with heterogeneous robot teams: asymmetric inter-robot collision constraints and varying dynamic limits. Asymmetric collision constraints are important for close-proximity flight of rotorcraft due to the downwash effect, which complicates spatial coordination. Varying dynamic limits complicate temporal coordination between robots and must be taken into account during planning. Our method builds upon a hybrid planner that combines graph-planning techniques with trajectory optimization and scales well to large homogeneous robot teams. We extend the hybrid planning approach to include the additional spatial and temporal coordination to support heterogeneous teams. Our method scales well with the number of robots and robot types and we demonstrate our approach on a team of 15 physical robots of 4 different types, including quadrotors and differential drive robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593876","","Collision avoidance;Trajectory;Robot kinematics;Mobile robots;Schedules","collision avoidance;graph theory;helicopters;mobile robots;trajectory optimisation (aerospace)","trajectory planning method;heterogeneous mobile robot teams;graph-planning techniques;trajectory optimization;differential drive robots;inter-robot collision constraints;close-proximity flight;rotorcraft;quadrotors","","","19","","","","","IEEE","IEEE Conferences"
"Robust Model-Predictive Deformation Control of a Soft Object by Using a Flexible Continuum Robot","B. Ouyang; H. Mo; H. Chen; Y. Liu; D. Sun","Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Harbin Institute of Technology Shenzhen, Shenzhen, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","613","618","Flexible continuum robots have exhibited unique advantages in working in an unstructured environment. Many applications require robots to actively control the deformation of soft objects, such as soft tissues in surgery. Thus, this study presents a robust model-predictive deformation control of a soft object using a flexible continuum robot. A linear approximation model for mapping from actuation space of a continuum robot to deformation space of a soft object is established. Jacobian matrix is estimated online by using a robust Geman-McClure estimator. Then, the deformation of the soft object is regulated by using a prediction horizon-based controller with exponential weighting for model uncertainty. The proposed control approach is effective in manipulating a soft object with a flexible continuum robot that is in contact with obstacles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593880","","Strain;Jacobian matrices;Force;Deformable models;Uncertainty;End effectors","deformation;Jacobian matrices;manipulators;mobile robots;nonlinear control systems;predictive control;robust control;surgery","robust model-predictive deformation control;soft object;flexible continuum robot;soft tissues;prediction horizon-based controller","","","36","","","","","IEEE","IEEE Conferences"
"Towards Automatic 3D Shape Instantiation for Deployed Stent Grafts: 2D Multiple-class and Class-imbalance Marker Segmentation with Equally-weighted Focal U-Net","X. Zhou; C. Riga; S. Lee; G. Yang","Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Regional Vascular Unit, St Mary's Hospital, London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1261","1267","Robot-assisted Fenestrated Endovascular Aortic Repair (FEVAR) is currently navigated by 2D fluoroscopy which is insufficiently informative. Previously, a semi-automatic 3D shape instantiation method was developed to instantiate the 3D shape of a main, deployed, and fenestrated stent graft from a single fluoroscopy projection in real-time, which could help 3D FEVAR navigation and robotic path planning. This proposed semi-automatic method was based on the Robust Perspective-S-Point (RP5P) method, graft gap interpolation and semiautomatic multiple-class marker center determination. In this paper, an automatic 3D shape instantiation could be achieved by automatic multiple-class marker segmentation and hence automatic multiple-class marker center determination. Firstly, the markers were designed into five different shapes. Then, Equally-weighted Focal U-Net was proposed to segment the fluoroscopy projections of customized markers into five classes and hence to determine the marker centers. The proposed Equally-weighted Focal U-Net utilized U-Net as the network architecture, equally-weighted loss function for initial marker segmentation, and then equally-weighted focal loss function for improving the initial marker segmentation. This proposed network outperformed traditional Weighted U-Net on the class-imbalance segmentation in this paper with reducing one hyperparameter - the weight. An overall mean Intersection over Union (mIoU) of 0.6943 was achieved on 78 testing images, where 81.01 % markers were segmented with a center position error <; 1.6mm. Comparable accuracy of 3D shape instantiation was also achieved and stated. The data, trained models and TensorFlow codes are available on-line.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594178","","Image segmentation;Shape;Three-dimensional displays;Aneurysm;Training;Two dimensional displays;Testing","blood vessels;cardiovascular system;image registration;image segmentation;medical image processing;mobile robots;path planning;stents","focal loss function;fluoroscopy projection;robot-assisted fenestrated endovascular aortic repair;automatic 3D shape instantiation;focal u-net;multiple class marker segmentation;multiple class marker center determination;robust perspective-S-point method;tensorflow codes;mean intersection over union;weighted u-net;network architecture;graft gap interpolation;stent graft;semiautomatic 3D shape instantiation method;FEVAR;class-imbalance marker segmentation;initial marker segmentation;fluoroscopy projections","","1","20","","","","","IEEE","IEEE Conferences"
"Optimal Constrained Trajectory Generation for Quadrotors Through Smoothing Splines","S. Lai; M. Lan; B. M. Chen","Department of Electrical and Computer Engineering, National University of Singapore (NUS); NUS, Graduate School for Integrative Science & Engineering; Department of Electrical and Computer Engineering, National University of Singapore (NUS)","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4743","4750","In this paper, we present a trajectory generation method for quadrotors based on the optimal smoothing B-spline. Compared to existing methods which rely on polynomial splines or time optimal control techniques, our method systematically addresses the issue of axes-coupled and interval-wise constraints. These constraints can be used to construct safe flying zones and satisfy vehicle's physical limits. The proposed approach has also been extended to generate trajectories from the nominal plan which consists of not only points but also lines and planes, opening a door for new improvements and applications. Moreover, a closed-form solution can be obtained for cases without inequality constraints. Such a solution is numerically stable for the large-scale fitting problem, which allows us to directly fit the human sketching input from the touch device and capture all subtle details. Our approach is verified by various real flight experiments..","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594357","","Trajectory;Splines (mathematics);Optimization;Smoothing methods;Closed-form solutions;Space vehicles;Safety","autonomous aerial vehicles;helicopters;optimisation;path planning;splines (mathematics);time optimal control;trajectory control","vehicles physical limits;large-scale fitting problem;human sketching;optimal constrained trajectory generation;inequality constraints;closed-form solution;safe flying zones;interval-wise constraints;axes-coupled;time optimal control techniques;polynomial splines;optimal smoothing B-spline;quadrotors","","","18","","","","","IEEE","IEEE Conferences"
"Active Range and Bearing-based Radiation Source Localization","M. S. Lee; D. Shy; W. R. Whittaker; N. Michael","Robotics Institute at Carnegie Mellon University; Department of Nuclear Engineering and Radiological Sciences, University of Michigan; Robotics Institute at Carnegie Mellon University; Robotics Institute at Carnegie Mellon University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1389","1394","3D radiation source localization is a common task across applications such as decommissioning, disaster response, and security, but traditional count-based sensors struggle to efficiently disambiguate between symmetries in sensor, source, and environment configurations. Recent works have demonstrated successful passive source localization using a bearing sensor called the Compton gamma camera that can image radiation. This paper first presents an approach to mapping the spatial distribution of radiation with a gamma camera to estimate source locations. An active source localization framework is then developed that greedily selects new waypoints that maximize the Fisher Information provided by the camera's range and bearing observations for source localization. Finally the common assumption of a static step size in between waypoints is relaxed to allow step sizes to adapt online to the observed information. The proposed radiation mapping approach is evaluated in 5×4 m<sup>2</sup> and 14×6 m<sup>2</sup> laboratory environments, where multiple point sources were localized to within an average of 0.26 m or 0.6% of the environment dimensions. The active source localization approach is evaluated in simulation and an adaptive step size yields a 27% decrease in the localization time and a 16% decrease in the distance traveled to localize a source in a 15×15×15 m<sup>3</sup> environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593625","","Sensors;Cameras;Photonics;Three-dimensional displays;Image sensors;Position measurement;Two dimensional displays","cameras;image sensors;radioactive sources","static step size;radiation mapping approach;active source localization approach;adaptive step size;localization time;3D radiation source localization;bearing sensor;Compton gamma camera;image radiation;source locations;active source localization framework;Fisher Information;bearing-based radiation source localization;passive source localization;size 0.26 m","","","25","","","","","IEEE","IEEE Conferences"
"Learning Hardware Dynamics Model from Experiments for Locomotion Optimization","K. Chen; S. Ha; K. Yamane","Mechanical and Aerospace Engineering Department, Rutgers University; Disney Research, Pittsburgh, PA, 15206, USA; Disney Research, Pittsburgh, PA, 15206, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3807","3814","The hardware compatibility of legged locomotion is often illustrated by Zero Moment Point (ZMP) that has been extensively studied for decades. One of the most popular models for computing the ZMP is the linear inverted pendulum (LIP) model that expresses ZMP as a linear function of the center of mass(COM) and its acceleration. In the real world, however, it may not accurately predict the true ZMP of hardware due to various reasons such as unmodeled dynamics and differences between simulation model and hardware. In this paper, we aim to improve the theoretical ZMP model by learning the real hardware dynamics from experimental data. We first optimize the motion plan using the theoretical ZMP model and collect COP data by executing the motion on a force plate. We then train a new ZMP model that maps the motion plan variable to the actual ZMP and use the learned model for finding a new hardware-compatible motion plan. Through various locomotion tasks of a quadruped, we demonstrate that motions planned for the learned ZMP model are compatible on hardware when those for the theoretical ZMP model are not. Furthermore, experiments using ZMP models with different complexities reveal that overly complex models may suffer from over-fitting even though they can potentially represent more complex, unmodeled dynamics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593804","","Hardware;Optimization;Dynamics;Legged locomotion;Data models;Solid modeling","control engineering computing;learning (artificial intelligence);legged locomotion;motion control;optimisation;pendulums;robot dynamics","locomotion optimization;hardware compatibility;hardware-compatible motion plan;linear inverted pendulum;ZMP;hardware dynamics model learning;zero moment point;LIP;center of mass;quadruped","","","20","","","","","IEEE","IEEE Conferences"
"Design and Fabrication of a Bipedal Robot Using Serial-Parallel Hybrid Leg Mechanism","K. G. Gim; J. Kim; K. Yamane","Disney Research Los Angeles, Glendale, CA, 91201, USA; Disney Research Los Angeles, Glendale, CA, 91201, USA; Honda Research Institute USA, Disney Research, Pittsburgh, PA, 15213, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5095","5100","In this paper, we present the design and performance evaluation of a bipedal robot that utilizes the Hybrid Leg mechanism. It is a leg mechanism that achieves 6 DOF with a combined structure of serial and parallel mechanism. It is designed to have a light structural inertia and large workspace for agile bipedal locomotion. A new version of Hybrid Leg is fabricated with carbon fiber tubes and bearings to improve its structural rigidity and accuracy while supporting its weight. A pair of Hybrid Legs is assembled together for bipedal locomotion. In the assembly, we adopt a pelvis structure with an yaw angle offset to enlarge the feet workspace, inspired by the toe-out angle of the human feet. The workspace and range of velocity are presented in simulation and verified with hardware experiments. We also demonstrate a simple forward walking motion with the developed robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594182","","Legged locomotion;Foot;Hip;Servomotors;Humanoid robots;Knee","design engineering;legged locomotion;machine bearings;motion control;robot dynamics;velocity control","serial-parallel hybrid leg mechanism;forward walking motion;developed robot;feet workspace;pelvis structure;structural rigidity;bearings;carbon fiber tubes;agile bipedal locomotion;light structural inertia;parallel mechanism;serial mechanism;bipedal robot;performance evaluation","","","19","","","","","IEEE","IEEE Conferences"
"Associative Skill Memory Models","H. Girgin; E. Ugur","Department of Computer Engineering, Bogazici University, Istanbul, Turkey; Department of Computer Engineering, Bogazici University, Istanbul, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6043","6048","Associative Skill Memories (ASMs) were formulated to encode stereotypical movements along with their stereotypical sensory events to increase the robustness of underlying dynamic movement primitives (DMPs) against noisy perception and perturbations. In ASMs, the stored sensory trajectories, such as the haptic and tactile measurements, are used to compute how much a perturbed movement deviates from the desired one, and to correct the movement if possible. In our work, we extend ASMs: rather than using stored single sensory trajectory instances, our system generates sensory event models and exploits those models to correct the perturbed movements during executions with the aim of generalizing to novel configurations. In particular, measured force and the torque trajectories are modelled using Parametric Hidden Markov Models, and then reproduced by Gaussian Mixture Regression. With Baxter robot, we demonstrate that our proposed force feedback model can be used to correct a trajectory while pushing an object with a mass never experienced before, and which otherwise slips away from the gripper because of noise. In the end, we discuss how far this skill can be generalized using the force model and possible future improvements.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593450","","Hidden Markov models;Robot sensing systems;Trajectory;Task analysis;Force feedback;Force","force feedback;Gaussian processes;grippers;haptic interfaces;hidden Markov models;humanoid robots;mobile robots;neurophysiology;regression analysis","perturbed movements;torque trajectories;Parametric Hidden Markov Models;force feedback model;associative skill memory models;ASMs;stereotypical movements;stereotypical sensory events;dynamic movement primitives;noisy perception;stored sensory trajectories;haptic measurements;tactile measurements;perturbed movement deviates;stored single sensory trajectory instances;sensory event models","","","22","","","","","IEEE","IEEE Conferences"
"Embedding Ethics in the Design of Culturally Competent Socially Assistive Robots","L. Battistuzzi; A. Sgorbissa; C. Papadopoulos; I. Papadopoulos; C. Koulouglioti","University of Genoa, Via all'Opera Pia 13, Genova, 16145, Italy; University of Genoa, Via all'Opera Pia 13, Genova, 16145, Italy; University of Bedfordshire, Park Square, Luton, LU1 3JU, United Kingdom; Middlesex University Higher Education Corporation, The Burroughs, Hendon, London, NW4 4BT, United Kingdom; Middlesex University Higher Education Corporation, The Burroughs, Hendon, London, NW4 4BT, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1996","2001","Research focusing on the development of socially assistive robots (SARs) for the care of older adults has grown in recent years, prompting a great deal of ethical analysis and reflection on the future of SARs in caring roles. Much of this ethical thinking, however, has taken place far from the settings where technological innovation is practiced. Different frameworks have been proposed to bridge this gap and enable researchers to handle the ethical dimension of technology from within the design and development process, including Value Sensitive Design (VSD). VSD has been defined as a “theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process”. Inspired in part by VSD, we have developed a process geared towards embedding ethics at the core of CARESSES, an international multidisciplinary project that aims to design the first culturally competent SAR for the care of older adults. Here we describe that process, which included extracting key ethical concepts from relevant ethical guidelines and applying those concepts to scenarios that describe how the CARESSES robot will interact with individuals belonging to different cultures. This approach highlights the ethical implications of the robot's behavior early in the design process, thus enabling researchers to identify and engage with ethical problems proactively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594361","","Robots;Task analysis;Ethics;Guidelines;Cultural differences;Assistive technology;Medical services","ethical aspects;geriatrics;medical robotics","CARESSES robot;ethical thinking;VSD;international multidisciplinary project;culturally competent SAR;ethical concepts;value sensitive design;culturally competent socially assistive robots","","","15","","","","","IEEE","IEEE Conferences"
"Autonomous Localization, Navigation and Haustral Fold Detection for Robotic Endoscopy","J. M. Prendergast; G. A. Formosa; C. R. Heckman; M. E. Rentschler","Department of Mechanical Engineering, University of Colorado, Boulder, CO, 80309, USA; Department of Mechanical Engineering, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Mechanical Engineering, University of Colorado, Boulder, CO, 80309, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","783","790","Capsule endoscopes have gained popularity over the last decade as minimally invasive devices for diagnosing gastrointestinal abnormalities such as colorectal cancer. While this technology offers a less invasive and more convenient alternative to traditional scopes, these capsules are only able to provide observational capabilities due to their passive nature. With the addition of a reliable mobility system and a real-time navigation system, capsule endoscopes could transform from observational devices into active surgical tools, offering biopsy and therapeutic capabilities and even autonomous navigation in a single minimally invasive device. In this work, a vision system is developed to allow for autonomous lumen center tracking and haustral fold identification and tracking during colonoscopy. This system is tested for its ability to accurately identify and track multiple haustral folds across many frames in both simulated and in vivo video, and the lumen center tracking is tested onboard a robotic endoscope platform (REP) within an active simulator to demonstrate autonomous navigation. In addition, real-time localization is demonstrated using open source ORB-SLAM2. The vision system successfully identified 95.6% of Haustral folds in simulator frames and 70.6% in in vivo frames and false positives occurred in less than 1% of frames. The center tracking algorithm showed in vivo center estimates within a mean error of 6.6% of physician estimates and allowed for the REP to traverse 2 m of the active simulator in 6 minutes without intervention.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594106","","Endoscopes;Robot sensing systems;Colon;Navigation;Wheels;In vivo","biological organs;biomedical optical imaging;cancer;endoscopes;medical image processing;medical robotics;surgery","autonomous localization;Haustral fold detection;robotic endoscopy;capsule endoscopes;minimally invasive devices;gastrointestinal abnormalities;colorectal cancer;real-time navigation system;observational devices;autonomous navigation;single minimally invasive device;vision system;autonomous lumen center tracking;haustral fold identification;multiple haustral folds;robotic endoscope platform;active simulator;real-time localization;center tracking algorithm;colonoscopy;in vivo video;surgical tools;mobility system","","","37","","","","","IEEE","IEEE Conferences"
"Human Motion Classification Based on Multi-Modal Sensor Data for Lower Limb Exoskeletons","J. Beil; I. Ehrenberger; C. Scherer; C. Mandery; T. Asfour","Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Germany; Karlsruhe Institute of Technology, Institute for Anthropomatics and Robotics, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5431","5436","Intuitive exoskeleton control is fundamental since it contributes to improved user acceptance and wearability comfort. This requires the detection of user's motion intention and its incorporation into the exoskeleton control system. In this work, we propose a classification system based on Hidden Markov Models (HMMs), which facilitates the online classification of multi-modal sensor data acquired from a lower-limb exoskeleton based on previously defined motion patterns. For classification of these motion patterns at each time step, we consider the most recent sensor measurements by using a sliding window approach. We collected a training data set from a total number of 10 subjects performing 13 different motions with a passive exoskeleton equipped with 7 3D-force sensors and 3 inertial measurement units (IMUs). Our evaluation includes an analysis of the time needed for correct classification (latency), a validation for a training set containing all subjects and a leave-one-out validation to assess the generalization performance of the approach. The results indicate that our approach can classify motions of subjects included in the training set with an average accuracy of 92.80% and is able to achieve a generalization performance of 84.46%. With the selected parameters an average latency of 368.97 ms is achieved.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594110","","Exoskeletons;Hidden Markov models;Robot sensing systems;Legged locomotion;Force;Force sensors;Thigh","biomechanics;force sensors;gait analysis;hidden Markov models;image motion analysis;learning (artificial intelligence);medical robotics;patient rehabilitation;pattern classification;wearable computers","human motion classification;multimodal sensor data;lower limb exoskeletons;intuitive exoskeleton control;improved user acceptance;wearability comfort;exoskeleton control system;online classification;lower-limb exoskeleton;defined motion patterns;recent sensor measurements;sliding window approach;training data;passive exoskeleton;3D-force sensors;3 inertial measurement units;correct classification;generalization performance;hidden Markov models","","","24","","","","","IEEE","IEEE Conferences"
"Acoustic Tag State Estimation with Unsynchronized Hydrophones on AUVs","J. Shi; T. Ma; C. Lee; E. Shimelis; C. Van Eijk; C. M. Clark; C. G. Lowe","Dept. of Engineering, Harvey Mudd College, Claremont, CA, 91711; Dept. of Engineering, Harvey Mudd College, Claremont, CA, 91711; Dept. of Engineering, Harvey Mudd College, Claremont, CA, 91711; Dept. of Engineering, Harvey Mudd College, Claremont, CA, 91711; Dept. of Engineering, Harvey Mudd College, Claremont, CA, 91711; Dept. of Engineering, Harvey Mudd College, Claremont, CA, 91711; Department of Biological Sciences, CSU Long Beach, Long Beach, CA, 90840","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1919","1926","This paper presents an underwater robotic sensor system for localizing acoustic transmitters when the robot's hydrophones cannot be time-synchronized. The development of the system is motivated by applications where tracking of marine animals that are tagged with an underwater acoustic transmitter is required. The system uses two novel real-time calibration algorithms that improve the accuracy of time of flight (TOF) and time difference of arrival (TDOA) measurements. The first algorithm corrects non-linear clock skews in TOF measurements based on temperature variation. The second algorithm compensates the localized relative clock skew between clocks using a mixed integer linear program. To validate the system's performance, an Autonomous Underwater Vehicle (AUV) was deployed to track a moving tag where GPS data was used as ground truth. Compared to traditional TOF and TDOA filtering methods, the results show that the proposed system can achieve reduction of mean localization errors by 59%, and a reduction of the standard deviation of measurements by 44%.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593589","","Clocks;Sonar equipment;Acoustics;Temperature measurement;Acoustic measurements;Estimation","autonomous underwater vehicles;calibration;clocks;Global Positioning System;hydrophones;integer programming;linear programming;mobile robots;sensors;synchronisation;time-of-arrival estimation;underwater sound","underwater acoustic transmitter;real-time calibration algorithms;TOF measurements;temperature variation;mixed integer linear program;AUV;TDOA filtering methods;mean localization errors;acoustic tag state estimation;unsynchronized hydrophones;underwater robotic sensor system;marine animals;time difference of arrival;autonomous underwater vehicle;nonlinear clock skews;time of flight;GPS data;TOF filtering methods;standard deviation","","","19","","","","","IEEE","IEEE Conferences"
"A Combined RGB and Depth Descriptor for SLAM with Humanoids","R. Sheikh; S. OBwald; M. Bennewitz","Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1718","1724","In this paper, we present a visual simultaneous localization and mapping (SLAM) system for humanoid robots. We introduce a new binary descriptor called DLab that exploits the combined information of color, depth, and intensity to achieve robustness with respect to uniqueness, reproducibility, and stability. We use DLab within ORB-SLAM, where we replaced the place recognition module with a modification of FAB-MAP that works with newly built codebooks using our binary descriptor. In experiments carried out in simulation and with a real Nao humanoid equipped with an RGB-D camera, we show that DLab has a superior performance in comparison to other descriptors. The application to feature tracking and place recognition reveal that the new descriptor is able to reliably track features even in sequences with seriously blurred images and that it has a higher percentage of correctly identified similar images. As a result, our new visual SLAM system has a lower absolute trajectory error in comparison to ORB-SLAM and is able to accurately track the robot's trajectory.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593768","","Simultaneous localization and mapping;Image color analysis;Cameras;Three-dimensional displays;Humanoid robots;Visualization","cameras;feature extraction;humanoid robots;image colour analysis;mobile robots;pose estimation;robot vision;SLAM (robots)","feature tracking;codebooks;reproducibility;humanoid robots;visual simultaneous localization;depth descriptor;ORB-SLAM;visual SLAM system;track features;DLab;RGB-D camera;Nao humanoid;binary descriptor;FAB-MAP;place recognition module","","","24","","","","","IEEE","IEEE Conferences"
"Deep Sequential Models for Sampling-Based Planning","Y. Kuo; A. Barbu; B. Katz","Computer Science and AI Laboratory, MIT; Computer Science and AI Laboratory, MIT; Computer Science and AI Laboratory, MIT","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6490","6497","We demonstrate how a sequence model and a sampling-based planner can influence each other to produce efficient plans and how such a model can automatically learn to take advantage of observations of the environment. Sampling-based planners such as RRT generally know nothing of their environments even if they have traversed similar spaces many times. A sequence model, such as an HMM or LSTM, guides the search for good paths. The resulting model, called DeRRT*, observes the state of the planner and the local environment to bias the next move and next planner state. The neural-network-based models avoid manual feature engineering by co-training a convolutional network which processes map features and observations from sensors. We incorporate this sequence model in a manner that combines its likelihood with the existing bias for searching large unexplored Voronoi regions. This leads to more efficient trajectories with fewer rejected samples even in difficult domains such as when escaping bug traps. This model can also be used for dimensionality reduction in multi-agent environments with dynamic obstacles. Instead of planning in a high-dimensional space that includes the configurations of the other agents, we plan in a low-dimensional subspace relying on the sequence model to bias samples using the observed behavior of the other agents. The techniques presented here are general, include both graphical models and deep learning approaches, and can be adapted to a range of planners.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593947","","Hidden Markov models;Computational modeling;Planning;Adaptation models;Space exploration;Uncertainty;Sensors","collision avoidance;computational geometry;learning (artificial intelligence);mobile robots;multi-agent systems;path planning;sampling methods","deep sequential models;sequence model;sampling-based planner;efficient plans;planner state;neural-network-based models;fewer rejected samples;multiagent environments;graphical models","","","34","","","","","IEEE","IEEE Conferences"
"Reliable fusion of black-box estimates of underwater localization","H. F. Chame; M. M. dos Santos; S. S. da Costa Botelho","Universidade Federal do Rio Grande (FURG), Centro de Ciências Computacionais C3, Rio Grande, BRAZIL; Universidade Federal do Rio Grande (FURG), Centro de Ciências Computacionais C3, Rio Grande, BRAZIL; Universidade Federal do Rio Grande (FURG), Centro de Ciências Computacionais C3, Rio Grande, BRAZIL","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1900","1905","The research on robot tracking has focused on the problem of information fusion from redundant parametric estimations, though the aspect of choosing an adaptive fusion policy, that is computationally efficient, and is able to reduce the impact of un-modeled noise, are still open issues. The objective of this work is to study the problem of underwater robot localization. For this, we have considered a task relying on inertial and geophysical sensory. We propose an heuristic model that performs adaptable fusion of information based on the principle of contextually anticipating the localization signal within an ordered neighborhood, such that a set of nodes properties is related to the task context, and the confidence on individual estimates is evaluated before fusing information. The results obtained show that our model outperforms the Kalman filter and the Augmented Monte Carlo Localization algorithms in the task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593593","","Estimation;Task analysis;Reliability;Robot sensing systems;Global Positioning System;Computational modeling","estimation theory;Kalman filters;mobile robots;Monte Carlo methods;sensor fusion;underwater vehicles","inertial sensory;Kalman filter;augmented Monte Carlo localization algorithms;geophysical sensory;task context;localization signal;heuristic model;underwater robot localization;un-modeled noise;adaptive fusion policy;redundant parametric estimations;information fusion;robot tracking;black-box estimates;reliable fusion","","","15","","","","","IEEE","IEEE Conferences"
"Deeply Informed Neural Sampling for Robot Motion Planning","A. H. Qureshi; M. C. Yip","University of California San Diego, Department of Electrical and Computer Engineering, La Jolla, CA, 92093, USA; University of California San Diego, Department of Electrical and Computer Engineering, La Jolla, CA, 92093, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6582","6588","Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593772","","Planning;Robots;Encoding;Three-dimensional displays;Convergence;Switched mode power supplies;Transforms","collision avoidance;computational complexity;feedforward neural nets;geometry;learning (artificial intelligence);mobile robots;sampling methods","obstacle geometry;computational complexity;configuration space;optimal path solution;hand-crafted heuristics;high-dimensional spaces;neural network-based adaptive sampler;raw point cloud data;workspace encoding;collision-free optimal paths;point-mass robot;6-link robotic manipulator;dropout-based stochastic deep feedforward neural network;DeepSMPs neural architecture;deep sampling-based motion planner;robot motion planning;deeply informed neural sampling;contractive autoencoder;rigid-body","","","18","","","","","IEEE","IEEE Conferences"
"Learning Actionable Representations from Visual Observations","D. Dwibedi; J. Tompson; C. Lynch; P. Sermanet","Google Brain; Google Brain; Google Brain; Google Brain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1577","1584","In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN) that learn from visual observations by embedding multiple frames jointly in the embedding space as opposed to a single frame. We show that by doing so, we are now able to encode both position and velocity attributes significantly more accurately. We test the usefulness of this self-supervised approach in a reinforcement learning setting. We show that the representations learned by agents observing themselves take random actions, or other agents perform tasks successfully, can enable the learning of continuous control policies using algorithms like Proximal Policy Optimization (PPO) using only the learned embeddings as input. We also demonstrate significant improvements on the real-world Pouring dataset with a relative error reduction of 39.4% for motion attributes and 11.1% for static attributes compared to the single-frame baseline. Video results are available at https://sites.google.com/view/actionablerepresentations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593951","","Task analysis;Robots;Visualization;Reinforcement learning;Aerospace electronics;Solid modeling;Semantics","learning (artificial intelligence);video coding","learning task-agnostic representations;continuous control tasks;multiple frames;single frame;self-supervised approach;reinforcement learning setting;random actions;continuous control policies;Proximal Policy Optimization;learned embeddings;real-world Pouring dataset;single-frame baseline;learning actionable representations;time-contrastive networks","","","40","","","","","IEEE","IEEE Conferences"
"Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning","C. Sampedro; A. Rodriguez-Ramos; I. Gil; L. Mejias; P. Campoy","Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, QLD, 4000, Australia; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","979","986","In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594249","","Visual servoing;Reinforcement learning;Unmanned aerial vehicles;Task analysis;Detectors;Cameras","aerospace computing;aerospace robotics;aircraft control;control engineering computing;gradient methods;helicopters;learning (artificial intelligence);mobile robots;robot vision;visual servoing","deep reinforcement learning algorithm;deep deterministic policy gradients;image-based visual servoing controller;IBVS policy;linear velocity commands;multirotor aerial robots;simulated flight scenarios;Gazebo-based simulation scenario;RL-IBVS controller","","","34","","","","","IEEE","IEEE Conferences"
"Rolling-Joint Design Optimization for Tendon Driven Snake-Like Surgical Robots","P. Berthet-Rayne; K. Leibrandt; K. Kim; C. A. Seneci; J. Shang; G. Yang","The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4964","4971","The use of snake-like robots for surgery is a popular choice for intra-luminal procedures. In practice, the requirements for strength, flexibility and accuracy are difficult to be satisfied simultaneously. This paper presents a computational approach for optimizing the design of a snake-like robot using serial rolling-joints and tendons as the base architecture. The method optimizes the design in terms of joint angle range and tendon placement to prevent the tendons and joints from colliding during bending motion. The resulting optimized joints were manufactured using 3D printing. The robot was characterized in terms of workspace, dexterity, precision and manipulation forces. The results show a repeatability as low as 0.9mm and manipulation forces of up to 5.6N.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593517","","Tendons;Tools;Navigation;Robot sensing systems;Mathematical model;Three-dimensional displays","manipulators;medical robotics;surgery","tendon driven snake-like surgical robots;intra-luminal procedures;flexibility;serial rolling-joints;base architecture;joint angle range;tendons;rolling-joint design optimization;optimized joints","","","30","","","","","IEEE","IEEE Conferences"
"Comparison of 3D Surgical Tool Segmentation Procedures with Robot Kinematics Prior","Y. Su; I. Huang; K. Huang; B. Hannaford","Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA; Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA; Dept. of Engineering, Trinity College, 300 Summit St, Hartford, CT, 06106, USA; Dept. of Electrical Engineering, University of Washington, 185 Stevens Way, Paul Allen Center - Room AE100R, Campus Box 352500, Seattle, WA, 98195-2500, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4411","4418","3D reconstruction and surgical tool segmentation are necessary for several advanced tasks in robot-assisted laparoscopic surgery. These tasks include vision-based force estimation, surgical guidance, and medical image registration where pre-operative data (CT or MRI scan image slices) are overlaid on patient anatomy in real-time during surgery [1] to name a few. In this work, two main strategies were considered: (1) initialize with surgical tool segmentation from 2D images, then proceed to local 3D reconstruction near the tool-tissue interaction region by projecting the segmented result into 3D space, and (2) initialize with 3D reconstruction of the entire surgical task space, followed by surgical tool segmentation from within the 3D reconstructed model. Both methods were implemented on the Raven II surgical robot system, and accuracy and time complexity for both methods were comparatively analyzed while considering various task parameters. Finally, based on the results of this work, guidelines for selecting reconstruction and segmentation strategies and procedure for particular situations are outlined in Section V.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594428","","Tools;Three-dimensional displays;Cameras;Image segmentation;Robot vision systems;Force;Image reconstruction","biological tissues;biomedical MRI;computerised tomography;image reconstruction;image registration;image segmentation;medical image processing;medical robotics;robot kinematics;surgery","robot-assisted laparoscopic surgery;surgical guidance;local 3D reconstruction;tool-tissue interaction region;3D reconstructed model;Raven II surgical robot system;3D surgical tool segmentation procedure;robot kinematics;vision-based force estimation;medical image registration;preoperative data;patient anatomy;surgical task space","","","29","","","","","IEEE","IEEE Conferences"
"Maneuverability in Dynamic Vertical Climbing","J. M. Brown; M. P. Austin; B. Kanwar; T. E. Jonas; J. E. Clark","FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310; FAMU/FSU College of Engineering, Tallahassee, FL, 32310","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4340","4347","In this paper, we examine the reduced order pendular dynamic climbing model with the addition of attachment windows based on prescribed body roll. With this model and on the new dynamic climbing platform, TAILS, we demonstrate dynamic downward climbing as well as identify distinct dynamic gaits within downward climbing. This, combined with the application of an asymmetric configuration of the rear legs enables strafing motions and thus dynamic maneuverability on walls in the vertical domain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594074","","Legged locomotion;Dynamics;Foot;Mathematical model;Force;Trajectory","legged locomotion;robot dynamics","distinct dynamic gait identification;dynamic climbing platform;prescribed body roll;reduced order pendular dynamic climbing model;dynamic vertical climbing;dynamic maneuverability;dynamic downward climbing","","","17","","","","","IEEE","IEEE Conferences"
"Automated Map Reading: Image Based Localisation in 2-D Maps Using Binary Semantic Descriptors","P. Panphattarasap; A. Calway","Department of Computer Science, University of Bristol, UK; Department of Computer Science, University of Bristol, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6341","6348","We describe a novel approach to image based localisation in urban environments which uses semantic matching between images and a 2-D cartographic map. This contrasts with the majority of existing approaches which use image to image database matching. We use highly compact binary descriptors to represent locations, indicating the presence or not of semantic features, which significantly increases scalability and has the potential for greater invariance to variable imaging conditions. The approach is also more akin to human map reading, making it better suited to human-system interaction. In this initial study we use semantic features relating to buildings and road junctions in discrete viewing directions. CNN classifiers are used to detect the features in images and we match descriptor estimates with location tagged descriptors derived from the 2-D map to give localisation. The descriptors are not sufficiently discriminative on their own, but when concatenated sequentially along a route, their combination becomes highly distinctive and allows localisation even when using non-perfect classifiers. Performance is further improved by taking into account left or right turns over a route. Experimental results obtained using Google StreetView and OpenStreetMap data show that the approach has considerable potential, achieving localisation accuracy of around 85% using routes corresponding to approximately 200 meters.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594253","","Semantics;Buildings;Junctions;Roads;Databases;Feature extraction;Meters","cartography;image classification;image matching;image representation;visual databases","compact binary descriptors;localisation accuracy;2-D map;location tagged descriptors;descriptor estimates;human-system interaction;human map reading;variable imaging conditions;semantic features;image database matching;2-D cartographic map;semantic matching;binary semantic descriptors;image based localisation;automated map reading","","","26","","","","","IEEE","IEEE Conferences"
"Humanoid Teleoperation Using Task-Relevant Haptic Feedback","F. Abi-Farrajl; B. Henze; A. Werner; M. Panzirsch; C. Ott; M. A. Roa","CNRS at Irisa and Inria Rennes Bretagne Atlantique Campus de Beaulieu, Rennes Cedex, 35042, France; German Aerospace Center (DLR) Institute of Robotics and Mechatronics, Wessling, 82234, Germany; German Aerospace Center (DLR) Institute of Robotics and Mechatronics, Wessling, 82234, Germany; German Aerospace Center (DLR) Institute of Robotics and Mechatronics, Wessling, 82234, Germany; German Aerospace Center (DLR) Institute of Robotics and Mechatronics, Wessling, 82234, Germany; German Aerospace Center (DLR) Institute of Robotics and Mechatronics, Wessling, 82234, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5010","5017","Robotic teleoperation is a key technology for a wide variety of fields. Teleoperating a humanoid in particular is essential as it allows the user to act remotely on an interface designed especially for humans, e.g., in a space station, or operating tools and machinery in disaster scenarios. This paper presents a `task-relevant' haptic interface for humanoid teleoperation, which bridges the gap between the task at hand and the balance of the robot. The operator is given command over the humanoid's hands and is informed through haptic cues about the impact of her/his potential actions on the robot' stability. Moreover, a null-space autonomous controller acts in the operator's null-space to provide her/him with a wider workspace and help in the successful execution of the task. The architecture is designed to top an existing compliance controller for a torque-controlled humanoid robot. Experiments on the humanoid robot TORO are reported to demonstrate the feasibility and effectiveness of the approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593521","","Humanoid robots;Task analysis;End effectors;Haptic interfaces;Robot sensing systems;Aerospace electronics","compliance control;feedback;haptic interfaces;humanoid robots;stability;telerobotics;torque control","operating tools;space station;key technology;robotic teleoperation;task-relevant haptic feedback;humanoid robot TORO;torque-controlled humanoid robot;null-space autonomous controller;robot stability;haptic cues;humanoid teleoperation;task-relevant haptic interface;disaster scenarios","","","27","","","","","IEEE","IEEE Conferences"
"Planning Hand-Arm Grasping Motions with Human-Like Appearance","N. García; R. Suárez; J. Rosell","Universitat Politècnica de Catalunya (UPC), Institute of Industrial and Control Engineering (IOC), Barcelona, Spain; Universitat Politècnica de Catalunya (UPC), Institute of Industrial and Control Engineering (IOC), Barcelona, Spain; Universitat Politècnica de Catalunya (UPC), Institute of Industrial and Control Engineering (IOC), Barcelona, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3517","3522","This paper addresses the problem of obtaining human-like motions on hand-arm robotic systems performing grasping actions. The focus is set on the coordinated movements of the robotic arm and the anthropomorphic mechanical hand, with which the arm is equipped. For this, human movements performing different grasps are captured and mapped to the robot in order to compute the human hand synergies. These synergies are used to both obtain human-like movements and to reduce the complexity of the planning phase by reducing the dimension of the search space. In addition, the paper proposes a sampling-based planner, which guides the motion planning following the synergies and considering different types of grasps. The introduced approach is tested in an application example and thoroughly compared with a state-of-the-art planning algorithm, obtaining better results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594432","","Planning;Grasping;Robot kinematics;Trajectory;Complexity theory;Manipulators","humanoid robots;manipulator kinematics;motion control;path planning","planning hand-arm grasping motions;hand-arm robotic systems;grasping actions;coordinated movements;robotic arm;anthropomorphic mechanical hand;human movements;human hand synergies;planning phase;motion planning;state-of-the-art planning algorithm;human-like appearance;search space;sampling-based planner","","","30","","","","","IEEE","IEEE Conferences"
"Robot Programming Through Augmented Trajectories in Augmented Reality","C. P. Quintero; S. Li; M. K. Pan; W. P. Chan; H. F. Machiel Van der Loos; E. Croft","Collaborative Advanced Robotics and Intelligent Systems (CARIS) Laboratory, University of British Columbia; Department of Aeronautics and Astronautics, University of Washington; Collaborative Advanced Robotics and Intelligent Systems (CARIS) Laboratory, University of British Columbia; Collaborative Advanced Robotics and Intelligent Systems (CARIS) Laboratory, University of British Columbia; Collaborative Advanced Robotics and Intelligent Systems (CARIS) Laboratory, University of British Columbia; Monash University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1838","1844","This paper presents a future-focused approach for robot programming based on augmented trajectories. Using a mixed reality head-mounted display (Microsoft Hololens) and a 7-DOF robot arm, we designed an augmented reality (AR) robotic interface with four interactive functions to ease the robot programming task: 1) Trajectory specification. 2) Virtual previews of robot motion. 3) Visualization of robot parameters. 4) Online reprogramming during simulation and execution. We validate our AR-robot teaching interface by comparing it with a kinesthetic teaching interface in two different scenarios as part of a pilot study: creation of contact surface path and free space path. Furthermore, we present an industrial case study that illustrates our AR manufacturing paradigm by interacting with a 7-DOF robot arm to reduce wrinkles during the pleating step of the carbon-fiber-reinforcement-polymer vacuum bagging process in a simulated scenario.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593700","","Task analysis;Trajectory;Service robots;Visualization;End effectors","augmented reality;helmet mounted displays;human-robot interaction;industrial robots;motion control;robot programming;teaching","augmented trajectories;augmented reality;mixed reality head-mounted display;robotic interface;robot programming task;robot motion;AR-robot teaching interface;kinesthetic teaching interface;7-DOF robot arm;Microsoft Hololens;carbon-fiber-reinforcement-polymer vacuum bagging process;AR manufacturing paradigm","","","17","","","","","IEEE","IEEE Conferences"
"Head-Mounted Augmented Reality for Explainable Robotic Wheelchair Assistance","M. Zolotas; J. Elsdon; Y. Demiris","Department of Electrical and Electronic Engineering, Imperial College London, Personal Robotics Lab, Exhibition Road, London, SW7 2BT, UK; Department of Electrical and Electronic Engineering, Imperial College London, Personal Robotics Lab, Exhibition Road, London, SW7 2BT, UK; Department of Electrical and Electronic Engineering, Imperial College London, Personal Robotics Lab, Exhibition Road, London, SW7 2BT, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1823","1829","Robotic wheelchairs with built-in assistive features, such as shared control, are an emerging means of providing independent mobility to severely disabled individuals. However, patients often struggle to build a mental model of their wheelchair's behaviour under different environmental conditions. Motivated by the desire to help users bridge this gap in perception, we propose a novel augmented reality system using a Microsoft Hololens as a head-mounted aid for wheelchair navigation. The system displays visual feedback to the wearer as a way of explaining the underlying dynamics of the wheelchair's shared controller and its predicted future states. To investigate the influence of different interface design options, a pilot study was also conducted. We evaluated the acceptance rate and learning curve of an immersive wheelchair training regime, revealing preliminary insights into the potential beneficial and adverse nature of different augmented reality cues for assistive navigation. In particular, we demonstrate that care should be taken in the presentation of information, with effort-reducing cues for augmented information acquisition (for example, a rear-view display) being the most appreciated.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594002","","Wheelchairs;Mobile robots;Navigation;Visualization;Collision avoidance;Trajectory","augmented reality;handicapped aids;human-robot interaction;medical robotics;mobile robots;wheelchairs","robotic wheelchair assistance;visual feedback;wheelchair navigation;head-mounted aid;Microsoft Hololens;mental model;severely disabled individuals;robotic wheelchairs;head-mounted augmented reality;augmented information acquisition;assistive navigation;immersive wheelchair training regime;learning curve","","","28","","","","","IEEE","IEEE Conferences"
"Dynamic Scaling Factors of Covariances for Accurate 3D Normal Distributions Transform Registration","H. Hong; B. H. Lee","Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, 08826, Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, 08826, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1190","1196","Distribution-to-distribution normal distributions transform (NDT-D2D) is one of the fast point set registrations. Since the normal distributions transform (NDT) is a set of normal distributions generated by discrete and regular cells, local minima of the objective function is an issue of NDT-D2D. Also, we found that the objective function based on L<sub>2</sub> distance between distributions has a negative correlation with rotational alignment. To overcome the problems, we present a method using dynamic scaling factors of covariances to improve the accuracy of NDT-D2D. Two scaling factors are defined for the preceding and current NDTs respectively, and they are dynamically varied in each iteration of NDT-D2D. We implemented the proposed method based on conventional NDT-D2D and probabilistic NDT-D2D and compared to the NDT-D2D with fixed scaling factors using KITTI benchmark data set. Also, we experimented estimating odometry with an initial guess as an application of distribution-to-distribution probabilistic NDT (PNDT-D2D) with the proposed method. As a result, the proposed method improves both translational and rotational accuracy of the NDT-D2D and PNDT-D2D.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593839","","Linear programming;Gaussian distribution;Correlation;Probabilistic logic;Three-dimensional displays;Transforms;Robots","covariance analysis;image registration;iterative methods;normal distribution;stereo image processing;transforms","NDT-D2D;3D normal distributions transform registration;distribution-to-distribution normal distributions transform;PNDT-D2D;distribution-to-distribution probabilistic NDT;objective function;fast point set registrations;dynamic scaling factors","","1","19","","","","","IEEE","IEEE Conferences"
"Acoustic Sensing for Soft Pneumatic Actuators","G. Zöller; V. Wall; O. Brock","Technische Universtität, Robotics and Biology Laboratory, Berlin, Germany; Technische Universtität, Robotics and Biology Laboratory, Berlin, Germany; Technische Universtität, Robotics and Biology Laboratory, Berlin, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6986","6991","We propose a novel sensing method for soft pneumatic actuators. The method uses a single microphone, embedded into the actuator's air chamber. Contact with the environment induces sound (vibration) in the actuator. The materials and the shape of the actuator reflect, refract, and attenuate the sound as it propagates inside the actuator. This produces a unique sound signature for different types of events, enabling the sensing of contact locations, contact force, and the type of contacted material. Sensing is insensitive to the inflation state of the actuator and to background noise. We demonstrate the robustness and versatility of the microphone-based sensor solution in experiments with a PneuFlex actuator. The proposed sensorization avoids the fundamental challenges of sensorizing soft pneumatic actuators, because the placement of a microphone does not negatively affect the compliance of the actuator and because a single microphone suffices for sensorization of the entire actuator, eliminating the need for an application-specific sensor layout.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594396","","Robot sensing systems;Microphones;Pneumatic actuators;Force","microphones;pneumatic actuators;sensors","microphone-based sensor solution;PneuFlex actuator;soft pneumatic actuators;acoustic sensing;contacted material;sensing method;sound signature;contact locations;contact force","","","28","","","","","IEEE","IEEE Conferences"
"Distributed Pressure Sensing for Enabling Self-Aware Autonomous Aerial Vehicles","D. Cellucci; N. Cramer; S. S. -. Swei","Cornell University, Department of Mechanical and Aerospace Engineering, Ithaca, NY, 14850, USA; Stinger Ghaffarian Technologies (SGT) Inc., Moffett Field, CA, 94035, USA; NASA Ames Research Center, Moffett Field, CA, 94035, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6769","6775","Autonomous aerial transportation will be a fixture of future robotic societies, simultaneously requiring more stringent safety requirements and fewer resources for characterization than current commercial air transportation. More robust, adaptable, self-state estimation will be necessary to create such autonomous systems. We present a modular, scalable, distributed pressure sensing skin for aerodynamic state estimation of a large, flexible aerostructure. This skin used a network of 22 nodes that performed in situ computation and communication of data collected from 74 pressure sensors, which were embedded into the skin panels of an ultra-lightweight 14-foot wingspan made from commutable, lattice-based subcomponents, and tested at NASA Langley Research Center's 14X22 wind tunnel. The density of the pressure sensors allowed for the use of a novel distributed algorithm to generate estimates of the wing lift contribution that were more accurate than the direct integration of the pressure distribution over the wing surface.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593664","","Robot sensing systems;Pressure sensors;Skin;Aerodynamics;NASA","aerodynamics;aerospace components;autonomous aerial vehicles;pressure control;pressure sensors;state estimation;wind tunnels","pressure sensors;NASA Langley Research Center;distributed algorithm;wind tunnel;commercial air transportation;self-aware autonomous aerial vehicles;lattice-based subcomponents;14-foot wingspan;skin panels;flexible aerostructure;aerodynamic state estimation;modular distributed pressure sensing skin;autonomous systems;adaptable self-state estimation;robust self-state estimation;autonomous aerial transportation;pressure distribution","","","33","","","","","IEEE","IEEE Conferences"
"Vision-based Target Tracking for a Skid-steer Vehicle using Guided Policy Search with Field-of-view Constraint","T. Kim; C. Lee; H. Seo; S. Choi; W. Kim; H. J. Kim","Department of Mechanical and Aerospace Engineering and ASRI, Seoul National University, Seoul, 08826, Korea, Republic; Department of Mechanical and Aerospace Engineering and ASRI, Seoul National University, Seoul, 08826, Korea, Republic; Department of Mechanical and Aerospace Engineering and ASRI, Seoul National University, Seoul, 08826, Korea, Republic; Department of Mechanical and Aerospace Engineering and ASRI, Seoul National University, Seoul, 08826, Korea, Republic; Department of Mechanical and Aerospace Engineering and ASRI, Seoul National University, Seoul, 08826, Korea, Republic; Department of Mechanical and Aerospace Engineering and ASRI, Seoul National University, Seoul, 08826, Korea, Republic","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2418","2425","This paper describes a vision-based target tracking method for a skid-steer vehicle. With the development of deep reinforcement learning, many researchers have tried to generate an end-to-end policy to control the mobile robot from a raw pixel image data. However, the action in most research only concerns high-level decisions such as go straight, turn left and right. High-level decisions alone are not sufficient to precisely control platforms such as a skid-steer vehicle due to the lack of steering mechanism. Thus, unlike existing work, we aim to control the motor command for the wheels directly. To this end, we employ guided policy search (GPS) based on the general kinematic slip model for the skid-type robot. Furthermore, to prohibit the target from getting out of the camera field of view (FOV) in the training phase, we update local policy optimization with a FOV constraint and perform a pre-training to make the initial policy more efficient. Our method allows the skid-type robot to automatically acquire the vision-based tracking policy while local policies satisfy the FOV constraint during the training phase. We evaluate our method through both simulation and experiment with a skid-steer mobile robot. Finally, we test the performance of learned policy with a moving target in a new environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593843","","Mobile robots;Training;Kinematics;Cameras;Target tracking;Wheels","learning (artificial intelligence);mobile robots;optimisation;remotely operated vehicles;robot dynamics;robot kinematics;robot vision;search problems;steering systems;target tracking","skid-steer vehicle;guided policy search;skid-type robot;local policy optimization;FOV constraint;vision-based tracking policy;skid-steer mobile robot;field-of-view constraint;vision-based target tracking method;end-to-end policy;pixel image data;deep reinforcement learning;kinematic slip model","","","24","","","","","IEEE","IEEE Conferences"
"Should We Compete or Should We Cooperate? Applying Game Theory to Task Allocation in Drone Swarms","J. Jesús Roldán; J. Del Cerro; A. Barrientos","Technical University of Madrid, Centre for Automation and Robotics (UPM-CSIC), José Gutiérrez Abascal, 2, Madrid, 28006, Spain; Technical University of Madrid, Centre for Automation and Robotics (UPM-CSIC), José Gutiérrez Abascal, 2, Madrid, 28006, Spain; Technical University of Madrid, Centre for Automation and Robotics (UPM-CSIC), José Gutiérrez Abascal, 2, Madrid, 28006, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5366","5371","Let's imagine a swarm of drones that has to visit some locations and build a map in a disaster area. Let's assume the drones only can communicate to their neighbors and manage partial information of the mission. A relevant question in this scenario is “Should the robots compete or should they cooperate?”. This work analyzes the described scenario to answer this question. Two game theoretical algorithms have been developed: one competitive and another cooperative. The competitive algorithm poses games among each drone and its neighbors and searches the Nash Equilibrium. The cooperative one defines electoral systems that allow the drones to vote their preferred task allocations for their neighbors. Both algorithms are extensively tested in multiple scenarios with different features. After the experiments the question can be answered “The robots should cooperate!”.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594145","","Task analysis;Robots;Resource management;Games;Drones;Nash equilibrium;Genetic algorithms","game theory","preferred task allocations;competitive algorithm;game theoretical algorithms;described scenario;relevant question;partial information;disaster area;drone swarms;task allocation;game theory","","","19","","","","","IEEE","IEEE Conferences"
"Quadruped Locomotion Control Based on Two Bipeds Jointly Carrying Model","G. Zhang; S. Ma; F. Liang; Y. Li","Ritsumeikan Global Innovation Research Organization, Ritsumeikan University, Shiga, Japan; Department of Robotics, Ritsumeikan University, Shiga, Japan; University of Washington, Seattle, United States; School of Control Science and Engineering, Shandong University, Jinan, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1732","1738","A novel gait planning and control framework was developed for quadruped locomotion of a robot. It modeled the quadruped robot as two bipeds carrying the body from the front and rear ends. We first mapped the relationship between the joint torques of support legs and the torso forces of the bipedal sub-robots. Then the equations describing the relationship between the quadruped body forces and the bipedal torso forces under various operating modes of the robot were deduced and solved. Virtual forces were generated on the quadruped body to manipulate its velocity and orientation. Then these virtual forces were distributed to the front and hind sub-robots to generate support leg torques. The state machines and gait generators for the two bipedal sub-robots were designed individually, resulting in the decoupling of the gait parameters in the front legs and hind legs. The effectiveness of the controller was validated through dynamic simulations.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593413","","Legged locomotion;Robot kinematics;Torso;Radio frequency;Hip;Mathematical model","gait analysis;legged locomotion;motion control;robot dynamics","quadruped locomotion control;novel gait planning;control framework;quadruped robot;rear ends;joint torques;support legs;bipedal sub-robots;quadruped body forces;bipedal torso forces;operating modes;virtual forces;support leg torques;gait generators;gait parameters;hind legs","","","14","","","","","IEEE","IEEE Conferences"
"Band of Brothers and Bolts: Caring About Your Robot Teammate","J. Wen; A. Stewart; M. Billinghurst; C. Tossell","Department of Behavior Sciences and Leadership, United States Air Force Academy, USAFA, Colorado, USA; Department of Behavior Sciences and Leadership, United States Air Force Academy, USAFA, Colorado, USA; Department of Computer Science, University of South Australia, Ad elaide, Australia; Department of Behavior Sciences and Leadership, United States Air Force Academy, USAFA, Colorado, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1853","1858","It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594324","","Robots;Atmospheric measurements;Particle measurements;Computer bugs;Time measurement;Bonding","computer games;human-robot interaction","consequential behavioral pattern;empathic response;robot teammate;robot companion","","","11","","","","","IEEE","IEEE Conferences"
"Aerial Radio-Based Telemetry for Tracking Wildlife","H. Bayram; N. Stefas; V. Isler","Department of Electrical & Electronics Engineering, Istanbul Medeniyet University, Istanbul, Turkey; Department of Computer Science & Engineering, University of Minnesota, Minneapolis, USA; Department of Computer Science & Engineering, University of Minnesota, Minneapolis, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4723","4728","This paper considers the problem of choosing measurement locations of an aerial robot in an online manner in order to localize an animal with a radio collar. The aerial robot has a commercial, low-cost directional antenna and USB receiver to capture the signal. It uses its own movement to obtain a bearing measurement. The uncertainty in these measurements is assumed to be bounded and represented as wedges. The measurements are then merged by intersecting the wedges. The localization uncertainty is quantified by the area of the resulting intersection. The goal is to reduce the localization uncertainty to a value below a given threshold in minimum time. We present an online strategy to choose measurement locations during execution based on previous readings and analyze its performance with competitive analysis. The time required to localize a target is upper-bounded by the function of measurement noise, desired localization uncertainty and minimum step length. We also validate the strategy in extensive simulations and show its applicability through field experiments over a 5 hectare area using an autonomous aerial robot equipped with a directional antenna.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594503","","Antenna measurements;Animals;Measurement uncertainty;Uncertainty;Time measurement;Sensors;Robots","autonomous aerial vehicles;directive antennas;mobile radio;mobile robots;radio tracking;telemetry","aerial radio-based telemetry;measurement locations;radio collar;low-cost directional antenna;USB receiver;wedges;online strategy;measurement noise;autonomous aerial robot;wildlife tracking;localization uncertainty","","","22","","","","","IEEE","IEEE Conferences"
"Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning","A. Zeng; S. Song; S. Welker; J. Lee; A. Rodriguez; T. Funkhouser","Princeton University; Princeton University; Google; Google; Massachusetts Institute of Technology; Princeton University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4238","4245","Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end-effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors even amid challenging cases of tightly packed clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu/","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593986","","Grasping;Training;Three-dimensional displays;Reinforcement learning;Planning;Manipulators","convolutional neural nets;end effectors;learning (artificial intelligence);motion control;neurocontrollers","learning synergies;self-supervised deep reinforcement learning;cluttered objects;pushing movements;model-free deep reinforcement learning;fully convolutional networks;end-effector orientations;Q-learning framework;pushing motions;grasping success rates;picking efficiencies;skilled robotic manipulation;grasping;prehensile action;pixel-wise sampling","","","39","","","","","IEEE","IEEE Conferences"
"Speeding-Up Object Detection Training for Robotics with FALKON","E. Maiettini; G. Pasquale; L. Rosasco; L. Natale","Istituto Italiano di Tecnologia, iCub Facility, Genoa, Italy; Istituto Italiano di Tecnologia, iCub Facility, Genoa, Italy; Istituto Italiano di Tecnologia and Massachusetts Institute of Technology, Laboratory for Computational and Statistical Learning, Cambridge, MA; Istituto Italiano di Tecnologia, iCub Facility, Genoa, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5770","5776","Latest deep learning methods for object detection provide remarkable performance, but have limits when used in robotic applications. One of the most relevant issues is the long training time, which is due to the large size and imbalance of the associated training sets, characterized by few positive and a large number of negative examples (i.e. background). Proposed approaches are based on end-to-end learning by back-propagation [22] or kernel methods trained with Hard Negatives Mining on top of deep features [8]. These solutions are effective, but prohibitively slow for on-line applications. In this paper we propose a novel pipeline for object detection that overcomes this problem and provides comparable performance, with a 60x training speedup. Our pipeline combines (i) the Region Proposal Network and the deep feature extractor from [22] to efficiently select candidate RoIs and encode them into powerful representations, with (ii) the FALKON [23] algorithm, a novel kernel-based method that allows fast training on large scale problems (millions of points). We address the size and imbalance of training data by exploiting the stochastic subsampling intrinsic into the method and a novel, fast, bootstrapping approach. We assess the effectiveness of the approach on a standard Computer Vision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a real robotic scenario with the iCubWorld Transformations [18] dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593990","","Training;Feature extraction;Pipelines;Object detection;Robots;Task analysis;Proposals","computer vision;data mining;feature extraction;learning (artificial intelligence);object detection;robots;sampling methods;stochastic processes","end-to-end learning;deep feature extractor;bootstrapping approach;object detection training;deep learning methods;robotic applications;back-propagation;region proposal network;hard negatives mining;FALKON algorithm;kernel-based method;stochastic subsampling;computer vision dataset","","","33","","","","","IEEE","IEEE Conferences"
"Slip Avoidance in Dual-Arm Manipulation","D. S. Carabis; J. T. Wen","Mechanical, Aerospace, and Nuclear Eng. Department, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA; Electrical, Computer, and Systems Eng. Department, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2872","2879","In multi-finger or multi-arm grasping with friction contacts, maintaining force closure during motion is critical. Violation of this condition would cause contact slippage and possibly loss of grasp. This issue is of particular importance in space robotics, where the loss of grasp could lead to catastrophic consequences. There has been ample literature on stable grasp and force closure under static conditions. This paper investigates multi-arm grasping during motion, where the inertial force from the load could adversely affect grasp stability. Our approach dynamically adjusts the squeeze force and commanded robot/load motion to maintain a safe force closure condition. For a specified motion trajectory, the squeeze force is updated to prevent slippage based on the estimated inertial force. When the required squeeze force is beyond what the manipulators can safely apply, the trajectory will be scaled to reduce the inertial force component. In addition to motion-induced disturbance force, contact between the load and other objects in the environment can also cause slippage. The slip prevention strategy is extended to this case as well. The application scenario is based on the dual-arm transportation and berthing of a load in a micro-gravity environment. For laboratory testing, we use a fixed-base dual-arm robot to grasp, transport, and berth an object on a planar air bearing table. We also extend the transportation tests to a more general spatial setting, and use the dynamic squeeze adjustment to grasp, lift, and transport an object. Experimental results show the proposed method is effective at avoiding contact slippage during motion and when the object is in contact with the environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593377","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593377","","Force;Manipulators;Satellites;Grasping;Collision avoidance;Friction","aerospace robotics;force control;friction;manipulator dynamics;manipulators;mobile robots;motion control;position control;stability","slip avoidance;dual-arm manipulation;multifinger;multiarm grasping;friction contacts;contact slippage;space robotics;stable grasp;static conditions;grasp stability;safe force closure condition;specified motion trajectory;estimated inertial force;required squeeze force;inertial force component;motion-induced disturbance force;slip prevention strategy;dual-arm transportation;dual-arm robot;dynamic squeeze adjustment;robot-load motion","","","16","","","","","IEEE","IEEE Conferences"
"Hybrid Bio-Inspired Architecture for Walking Robots Through Central Pattern Generators Using Open Source FPGAs","J. C. Linares; A. Barrientos; E. M. Márquez","Universidad Politécnica de Madrid; Universidad Politécnica de Madrid; everis - NTT DATA, NextGen Robotics","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7071","7076","In this paper we present a new robotic control approach inspired in the animal nervous system control. The system implements the binomial Brain-Peripheral Nervous System (CNS-PNS) combining the use of microprocessors as the high level control, or brain, and FPGAs as the low level control, or nervous system. Thanks to the new open source tools for FPGAs, we are able to apply them in the field of robotics in new ways that were impossible before. In this paper, we will demonstrate that our approach is not only able to control the movements of robots using digital circuits built inside an FPGA, but is also capable of generating, synthesizing and uploading them inside the FPGA in real time and on demand.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594288","","Field programmable gate arrays;Level control;Legged locomotion;Microprocessors;Robot sensing systems","control engineering computing;data acquisition;field programmable gate arrays;gait analysis;legged locomotion;microprocessor chips;public domain software","hybrid bio-inspired architecture;central pattern generators;robotic control approach;animal nervous system control;CNS-PNS;high level control;low level control;open source tools;binomial brain-peripheral nervous system;open source FPGA;digital circuits;microprocessors","","","17","","","","","IEEE","IEEE Conferences"
"A Comparative Study on Sigma-Point Kalman Filters for Trajectory Estimation of Hybrid Aerial-Aquatic Vehicles","R. T. S. da Rosa; P. J. D. O. Evald; P. L. J. Drews; A. A. Neto; A. C. Horn; R. Z. Azzolin; S. S. C. Botelho","Centro de Ciências Computacionais, C3, Univ. Federal do Rio Grande, FURG, NAUTEC, Rio Grande, Brazil; Centro de Ciências Computacionais, C3, Univ. Federal do Rio Grande, FURG, NAUTEC, Rio Grande, Brazil; Centro de Ciências Computacionais, C3, Univ. Federal do Rio Grande, FURG, NAUTEC, Rio Grande, Brazil; Univ. Federal de Minas Gerais, UFMG, Dep. de Engenharia Eletrônica, Belo Horizonte, Brazil; Centro de Ciências Computacionais, C3, Univ. Federal do Rio Grande, FURG, NAUTEC, Rio Grande, Brazil; Centro de Ciências Computacionais, C3, Univ. Federal do Rio Grande, FURG, NAUTEC, Rio Grande, Brazil; Centro de Ciências Computacionais, C3, Univ. Federal do Rio Grande, FURG, NAUTEC, Rio Grande, Brazil","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7460","7465","In this paper, a study on nonlinear state estimation methods for Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) is presented. Based on a detailed dynamic model simulation, we analyse and elect the best nonlinear algorithm among those presented in the state-of-the-art literature addressing local derivative-free nonlinear Kalman Filters (KFs): the Unscented Kalman Filter (UKF), the Cubature Kalman Filter (CKF) and the Transformed Unscented Kalman Filter (TUKF). Here, these three nonlinear probabilistic estimators were compared in terms of the Root Mean Square Error (RMSE) and the average execution time over Monte Carlo simulations. We simulated real-world conditions for our in-production HUAUV prototype using Inertial Measurement Unit (IMU) data and state augmentation for sensor data filtering and trajectory estimation. We have concluded that the CKF proved to be the most interesting KF to low-cost on-board applications for high dimensional state spaces.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593556","","Kalman filters;Trajectory tracking;State estimation;Vehicle dynamics;Robot sensing systems","autonomous aerial vehicles;autonomous underwater vehicles;Kalman filters;Monte Carlo methods;nonlinear filters;robot dynamics;state estimation","detailed dynamic model simulation;nonlinear algorithm;derivative-free nonlinear Kalman Filters;Cubature Kalman Filter;CKF;nonlinear probabilistic estimators;average execution time;Monte Carlo simulations;in-production HUAUV prototype;state augmentation;sensor data filtering;trajectory estimation;high dimensional state spaces;comparative study;sigma-point Kalman;aerial-aquatic vehicles;nonlinear state estimation methods;transformed unscented Kalman filter;root-mean square error;hybrid unmanned aerial underwater vehicles;HUAUV","","","26","","","","","IEEE","IEEE Conferences"
"RoboTracker: Collaborative robotic assistant device with electromechanical patient tracking for spinal surgery","A. Amarillo; J. Oñativia; E. Sanchez","Materials and manufacturing division of CEIT, University of Navarra, Donostia-San Sebastián, E20018, Spain; EGILE Innovative Solutions, Mendaro, E-20850, Spain; Materials and manufacturing division of CEIT, University of Navarra, Donostia-San Sebastián, E20018, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1312","1317","Due to the risks of muscle, bone and neural damage in spinal surgical procedures that require pedicle screw fixation, technological improvements have appeared to help surgeons perform the procedures with higher accuracy. Systems based on optical tracking navigation impose a stringent limitation in the workflow of surgeons since a clear line of sight has to be kept between the cameras and the tracked elements. Other solutions are based on mounting a miniature robot on the spine of the patient, which is very invasive and entails some risks. For these reasons, a novel robotic assisted surgery system capable to guide surgical instruments with minimal deviations compensating patient motion is being developed. This paper presents the system and the electromechanical tracking device used to sense patient motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594467","","Fasteners;Tracking;Surgery;Robot kinematics;Kinematics;Mathematical model","biomechanics;bone;medical robotics;neurophysiology;orthopaedics;surgery","RoboTracker;electromechanical patient tracking;spinal surgery;neural damage;spinal surgical procedures;pedicle screw fixation;technological improvements;surgeons;optical tracking navigation;stringent limitation;tracked elements;miniature robot;novel robotic assisted surgery system;surgical instruments;patient motion;electromechanical tracking device;collaborative robotic assistant device","","","14","","","","","IEEE","IEEE Conferences"
"Sampling of Pareto-Optimal Trajectories Using Progressive Objective Evaluation in Multi-Objective Motion Planning","J. Lee; D. Yi; S. S. Srinivasa","University of Washington, Computer Science & Engineering; University of Washington, Computer Science & Engineering; University of Washington, Computer Science & Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","In this paper, we introduce a Markov chain Monte Carlo (MCMC)method to solve multi-objective motion-planning problems. We formulate the problem of finding Pareto-optimal trajectories as a problem of sampling trajectories from a Pareto-optimal set. We define an implicit uniform distribution over the Pareto-frontier using a dominance function and then sample in the space of trajectories. The nature of MCMC guarantees the convergence to the Pareto-frontier, while the uniform distribution ensures the diversity of the trajectories. We also propose progressive objective evaluation to increase efficiency in problems with expensive-to-evaluate objective functions. This enables determination of dominance relationship between trajectories before they are entirely evaluated. We finally analyze the effectiveness of the framework and its applications in robotics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593735","","Trajectory;Markov processes;Planning;Monte Carlo methods;Sociology;Optimization","Bayes methods;Markov processes;Monte Carlo methods;Pareto optimisation;path planning","implicit uniform distribution;Pareto-frontier;progressive objective evaluation;objective functions;Pareto-optimal trajectories;multiobjective motion planning;multiobjective motion-planning problems;sampling trajectories;Pareto-optimal set;Markov chain Monte Carlo method","","","30","","","","","IEEE","IEEE Conferences"
"Nonprehensile Pushing Manipulation Strategies for a Multi-Limb Robot*","G. Zhang; S. Ma; Y. Li","The Ritsumeikan Global Innovation Research Organization, Ritsumeikan University, Shiga, Japan; The Department of Robotics, Ritsumeikan University, Shiga, Japan; Shandong University, The School of Control Science and Engineering, Jinan, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper explores the control strategy for a multi-limb robot nonprehensilely pushing an object to slide on the floor. The robot's limb distals perform point contacts with the object and the floor. The contact velocity constraint and force constraint are proposed to prevent separation and restrict the system forces. Then the constraints are combined with the system dynamic models to obtain bounds on the system states. We solve the motion planning problem by selecting a feasible path in the reduced-dimensional space and generating the system trajectory along the selected path. An example is provided to illustrate the application of our technique on the physical platform.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593914","","Robot kinematics;Force;Acceleration;Humanoid robots;Legged locomotion;Friction","legged locomotion;manipulators;mobile robots;motion control;path planning;position control","system states;system trajectory;nonprehensile;manipulation strategies;multilimb robot;control strategy;point contacts;contact velocity constraint;force constraint;system forces;system dynamic models","","","14","","","","","IEEE","IEEE Conferences"
"An Adaptive Robot for Building In-Plane Programmable Structures","M. Pieber; R. Neurauter; J. Gerstmayr","Department of Mechatronics, University of Innsbruck, Innsbruck, 6020, Austria; Department of Mechatronics, University of Innsbruck, Innsbruck, 6020, Austria; Department of Mechatronics, University of Innsbruck, Innsbruck, 6020, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","A new approach for cellular robots is presented. The single elements of the robot are triangular cells, which can change their shape by means of linear actuators at each edge. The novelty concerns the connection of autonomous cells at their edges rather than at the vertices. In this way, unstructured triangular meshes can be formed. The robot can self-reconfigure and thus can reproduce almost arbitrary planar shapes. In a similar way, the system has been realized with tetrahedrons in a simplified way within a previous work. The self-reconfigurable system shall serve as a basis for programmable matter. The present paper includes the mechatronic design, its components and the kinematic model of the cellular robot. In order to reduce positioning errors, a model is developed, which considers compliance and clearance in the links and joints. Based on a simplified mechanical model using elastic trusses, the positioning errors can be predicted. The parameters of these models are identified from simple motion sequences. Furthermore, the nonlinearity of actuators is identified and corrected. In this way, the desired triangular shapes can be prescribed without measuring the position of the cells.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593381","","Actuators;Robots;Couplings;Kinematics;Shape;Latches;Computational modeling","actuators;control system synthesis;elasticity;mechatronics;mesh generation;nonlinear control systems;optimal control;position control;robot kinematics;supports","autonomous cells;unstructured triangular meshes;arbitrary planar shapes;self-reconfigurable system;programmable matter;kinematic model;cellular robot;positioning errors;simplified mechanical model;adaptive robot;single elements;triangular cells;linear actuators;triangular shapes;in-plane programmable structures","","","10","","","","","IEEE","IEEE Conferences"
"Walking on a Steep Slope Using a Rope by a Life-Size Humanoid Robot","M. Bando; M. Murooka; S. Nozawa; K. Okada; M. Inaba","Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Infomatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","705","712","In this paper, we propose methods for walking on a steep slope using a rope by a humanoid robot. There are two difficulties for walking on a steep slope without a rope. First, range of motion of ankle joints get limited. Second, feet of a robot slip on a steep slope. For these problems, using a rope is effective solution because the robot can receive enough friction force from the slope and walk on a steep slope by pulling a rope with proper tension. In addition, the robot pulling a rope on a slope can relax limitations of ankle joints. Therefore, we propose methods to determine tension of a grasped rope by solving a linear least-square problem considering deformability of a rope. With these methods, a life-size humanoid robot HRP-2 could walk on a steep slope which angle is 40 degree.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594292","","Legged locomotion;Friction;Robot kinematics;Humanoid robots;Force;Foot","friction;humanoid robots;least squares approximations;mobile robots;motion control","friction force;linear least-square problem;life-size humanoid robot HRP-2;rope;steep slope","","","11","","","","","IEEE","IEEE Conferences"
"Hand-Impedance Measurement During Laparoscopic Training Coupled with Robotic Manipulators","H. Tugal; B. Gautier; M. Kircicek; M. S. Erden","Sensors, Signals and Systems, School of Engineering and Physical Sciences Heriot-Watt University Edinburgh Centre for Robotics, Edinburgh, EH14 4AL, UK; Sensors, Signals and Systems, School of Engineering and Physical Sciences Heriot-Watt University Edinburgh Centre for Robotics, Edinburgh, EH14 4AL, UK; Sensors, Signals and Systems, School of Engineering and Physical Sciences Heriot-Watt University Edinburgh Centre for Robotics, Edinburgh, EH14 4AL, UK; Sensors, Signals and Systems, School of Engineering and Physical Sciences Heriot-Watt University Edinburgh Centre for Robotics, Edinburgh, EH14 4AL, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4404","4410","This paper presents measurements of human hand-impedance during a laparoscopic training program with physically interactive robotic manipulators. The knowledge of how the hand-impedance changes due to training might be useful to inform better training programs and to introduce co-manipulated robotic assistants for effective trainings. Ten novice subjects participated in a three weeks training program for a suturing activity in laparoscopy. The subjects have been instructed to set the needle, enter the skin, and tie knots by using laparoscopic tools within a Minimally Invasive Surgery training box. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle. Based on the interaction force and end-effector position information, impedances of the left and right hands were computed in four different directions. The computed results were compared with respect to the participants skill progression.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593560","","Robots;Force;Laparoscopes;Training;Admittance;Frequency measurement;Stability analysis","end effectors;force sensors;medical robotics;position control;surgery","end-effector position information;impedance measurement;human hand-impedance;laparoscopic training program;physically interactive robotic manipulators;robotic assistants;needle;variable admittance controlled robots;step vice velocity disturbances;force sensor;minimally invasive surgery training box","","","29","","","","","IEEE","IEEE Conferences"
"Vision-Based Surgical Tool Pose Estimation for the da Vinci® Robotic Surgical System","R. Hao; O. Özgüner; M. C. Çavuşoğlu","Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1298","1305","This paper presents an approach to surgical tool tracking using stereo vision for the da Vinci<sup>®</sup> Surgical Robotic System. The proposed method is based on robot kinematics, computer vision techniques and Bayesian state estimation. The proposed method employs a silhouette rendering algorithm to create virtual images of the surgical tool by generating the silhouette of the defined tool geometry under the da Vinci<sup>®</sup> robot endoscopes. The virtual rendering method provides the tool representation in image form, which makes it possible to measure the distance between the rendered tool and real tool from endoscopic stereo image streams. Particle Filter algorithm employing the virtual rendering method is then used for surgical tool tracking. The tracking performance is evaluated on an actual da Vinci<sup>®</sup> surgical robotic system and a ROS/Gazebo-based simulation of the da Vinci<sup>®</sup> system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594471","","Tools;Solid modeling;Rendering (computer graphics);Robots;Cameras;Bayes methods;Geometry","Bayes methods;computer vision;endoscopes;medical image processing;medical robotics;particle filtering (numerical methods);pose estimation;rendering (computer graphics);robot vision;stereo image processing;surgery;virtual reality","robot endoscopes;defined tool geometry;virtual images;silhouette rendering algorithm;Bayesian state estimation;computer vision techniques;robot kinematics;stereo vision;vision-based Surgical tool pose estimation;surgical robotic system;surgical tool tracking;endoscopic stereo image streams;virtual rendering method","","","28","","","","","IEEE","IEEE Conferences"
"Minimax Iterative Dynamic Game: Application to Nonlinear Robot Control Tasks","O. Ogunmolu; N. Gans; T. Summers","Department of Electrical Engineering; Department of Electrical Engineering; University of Texas at Dallas, Department of Mechanical Engineering, Richardson, TX, 75080, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6919","6925","Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks. However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios. We present how to quantify the sensitivity of such policies in order to inform of their robustness capacity. We also propose a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties. We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task. The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's website: https://goo.gl/JhshTB, while the codes for reproducing our experiments are on github: https://goo.gl/3G2VBy. A self-contained environment for reproducing our results is on docker: https://goo.gl/Bo7MBe.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594037","","Robustness;Heuristic algorithms;Trajectory;Games;Task analysis;Uncertainty;Approximation algorithms","iterative methods;learning (artificial intelligence);minimax techniques;mobile robots;neurocontrollers;nonlinear control systems","model mismatch;model uncertainties;high-risk scenarios;robustness capacity;minimax iterative dynamic game;robust policies;carefully designed deep neural network policy;policy robustness;adversarial disturbances;ocally robust optimal multistage policy;nonlinear robot control tasks;multistage decision policies;high-dimensional state spaces;complex control tasks;meta-learning-deep policies","","","28","","","","","IEEE","IEEE Conferences"
"Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments","R. Senanayake; F. Ramos","The University of Sydney, School of Information Technologies, Centre for Translational Data Science, Australia; The University of Sydney, School of Information Technologies, Centre for Translational Data Science, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3241","3248","Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594041","","Vehicle dynamics;Robot sensing systems;Data models;Uncertainty;Navigation","collision avoidance;human-robot interaction;mobile robots;optical radar;path planning;probability","directional grid maps;occupancy map;mobile robot;robotic arm;static environments;dynamic objects;safer navigation;human-robot interaction;directional statistics;robotic mapping;model circular data;angular motion;probability measure-field;angular variations;indoor environments;outdoor environments;dynamic environments;grid maps;multimodal angular uncertainty","","","43","","","","","IEEE","IEEE Conferences"
"An Uncertainty-Aware Minimal Intervention Control Strategy Learned from Demonstrations","J. Silvério; Y. Huang; L. Rozo; D. G. caldwell","Istituto Italiano di Tecnologia, Department of Advanced Robotics, Genova, 16163, Italy; Istituto Italiano di Tecnologia, Department of Advanced Robotics, Genova, 16163, Italy; Istituto Italiano di Tecnologia, Department of Advanced Robotics, Genova, 16163, Italy; Istituto Italiano di Tecnologia, Department of Advanced Robotics, Genova, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6065","6071","Motivated by the desire to have robots physically present in human environments, in recent years we have witnessed an emergence of different approaches for learning active compliance. Some of the most compelling solutions exploit a minimal intervention control principle, correcting deviations from a goal only when necessary, and among those who follow this concept, several probabilistic techniques have stood out from the rest. However, these approaches are prone to requiring several task demonstrations for proper gain estimation and to generating unpredictable robot motions in the face of uncertainty. Here we present a Programming by Demonstration approach for uncertainty-aware impedance regulation, aimed at making the robot compliant - and safe to interact with - when the uncertainty about its predicted actions is high. Moreover, we propose a data-efficient strategy, based on the energy observed during demonstrations, to achieve minimal intervention control, when the uncertainty is low. The approach is validated in an experimental scenario, where a human collaboratively moves an object with a 7-DoF torque-controlled robot.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594220","","Robots;Uncertainty;Hidden Markov models;Task analysis;Impedance;Probabilistic logic;Covariance matrices","learning (artificial intelligence);motion control;robots","robots;human environments;active compliance;minimal intervention control principle;task demonstrations;proper gain estimation;unpredictable robot motions;robot compliant;data-efficient strategy;torque-controlled robot;uncertainty-aware minimal intervention control strategy","","","17","","","","","IEEE","IEEE Conferences"
"Rendering of Virtual Volumetric Shapes Using an Electromagnetic-Based Haptic Interface","A. Adel; M. M. Micheal; M. A. Self; S. Abdennadher; I. S. M. Khalil","German University in Cairo, New Cairo, Egypt; German University in Cairo, New Cairo, Egypt; German University in Cairo, New Cairo, Egypt; German University in Cairo, New Cairo, Egypt; German University in Cairo, New Cairo, Egypt","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Mid-Air haptic devices have become an active area of research because of their potential impact to augmented/virtual reality. In this work, we develop an electromagnetic-based haptic interface to provide controlled magnetic forces on a wearable orthopedic finger splint with a single magnetic dipole. We model the electromagnetic forces exerted on the finger splint, optimize the design of the electromagnetic coils, and develop an impedance-type haptic rendering algorithm using position feedback. This rendering algorithm capitalizes on minimizing the error between the exerted magnetic force and the desired constraint force of a virtual three-dimensional (3D)object based on the position of the finger splint. In order to investigate the influence of incorporating position feedback, we conduct a comparative study for the same group of participants with (Case I)and without (Case II)position feedback. Our experimental results show that position feedback enables participants to achieve success rate of 66.87 ± 15.0% (n=160) in distinguishing between the geometry of four 3D virtual objects. This rate is decreased to 55.15±15.8% (n=160) in the absence of position feedback. Our analysis shows statistical evidence to conclude that the mean success rate for Case I is greater than that of Case II, at α = 0.1 and 90% confidence level.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593699","","Magnetic moments;Coils;Magnetic forces;Haptic interfaces;Rendering (computer graphics);Force;Three-dimensional displays","electromagnetic forces;haptic interfaces;rendering (computer graphics);statistical analysis;virtual reality","virtual reality;magnetic dipole;rendering algorithm;position feedback;augmented reality;statistical evidence;virtual three dimensional object;3D virtual objects;exerted magnetic force;impedance-type haptic rendering;electromagnetic coils;electromagnetic forces;wearable orthopedic finger splint;controlled magnetic forces;electromagnetic-based haptic interface;virtual volumetric shapes","","","12","","","","","IEEE","IEEE Conferences"
"A Universal Controller for Unmanned Aerial Vehicles","E. Bulka; M. Nahon","Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Department of Mechanical Engineering, McGill University, Montreal, QC, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4171","4176","Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State of the art control strategies for these vehicles are typically limited to a portion of the vehicle's flight envelope, and are tailored to a specific type of platform. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, flying-wing with two thrusters, most tailsitters, and some tilt-rotor/wing platforms. We demonstrate autonomous flight for a quadrotor and agile fixed-wing aircraft in a simulation environment. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and an aggressive turnaround with the fixed-wing aircraft, all using a single controller with a single set of gains.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593878","","Force;Aircraft;Quaternions;Attitude control;Actuators","aerodynamics;aerospace components;aircraft control;attitude control;autonomous aerial vehicles;helicopters;mobile robots","UAVs;agile fixed-wing aircraft;control logic;unmanned aerial vehicles;tilt-rotor;vehicle flight envelope;single physics-based controller;multicopters;autonomous flight;quadrotor","","","16","","","","","IEEE","IEEE Conferences"
"Experience-Based Model Selection to Enable Long-Term, Safe Control for Repetitive Tasks Under Changing Conditions","C. D. McKinnon; A. P. Schoellig","Dynamic Systems Lab (www.dynsyslab.org) at the University of Toronto Institute for Aerospace Studies (UTIAS), Canada; Dynamic Systems Lab (www.dynsyslab.org) at the University of Toronto Institute for Aerospace Studies (UTIAS), Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2977","2984","Learning approaches have enabled significant performance improvements in robotic control allowing robots to execute motions that were previously impossible. The majority of the work to date, however, assumes that the parts to be learned are static or slowly changing, which limits their applicability in realistic scenarios with rapid changes in the conditions. This paper presents a method to extend an existing single-mode safe learning controller based on Gaussian Process Regression to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experiences from a large number of previously visited operating conditions, and to safely adapt when a new and distinct operating condition is encountered. This allows the robot to achieve safety and high performance in a large number of operating conditions that do not have to be specified ahead of time. Our approach runs independently from the controller, imposing no additional computation time on the control loop regardless of the number of previous operating conditions considered. We demonstrate the effectiveness of our approach in experiment on a 900 kg ground robot with both physical and artificial changes to its dynamics. All of our experiments are conducted using vision for localization.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593882","","Robots;Vehicle dynamics;Safety;Heuristic algorithms;Data models;Computational modeling;Task analysis","Gaussian processes;learning (artificial intelligence);learning systems;mobile robots;regression analysis;robot dynamics","learning approaches;significant performance improvements;robotic control;realistic scenarios;rapid changes;existing single-mode safe learning controller;increasing number;nonlinear models;robot dynamics;visited operating conditions;new operating condition;distinct operating condition;control loop;physical changes;artificial changes;experience-based model selection;enable long-term;safe control;repetitive tasks;Gaussian process regression","","1","23","","","","","IEEE","IEEE Conferences"
"Muscle Activation Source Model-based sEMG Signal Decomposition and Recognition of Interface Rotation","M. Kim; W. K. Chung","Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2780","2786","Muscle activation signals are measured from the skin surface as surface electromyography (EMG) signals that contain information on human intentions; therefore, they are widely used in various robotics applications owing to their usability. However, selective muscle activation extraction is difficult because of the complexity of muscle structures. This study investigated muscle activation source model-based sEMG signal decomposition that considers the anatomical factors of muscle structures. The main advantage of the proposed model-based signal decomposition is that sEMG interface rotation can be recognized by comparing source parameters identified before and after rotation. To assess the performance of the proposed model-based decomposition method, hand motion estimation and rotation recognition were conducted. Additionally, two-dimensional simultaneous control was conducted with an inertial measurement unit to verify the usability of the proposed model. The results indicate that the proposed model decomposes an sEMG signal based on motion with good performance and demonstrate feasibility of motion estimation independent of sEMG interface rotation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593448","","Electrodes;Muscles;Mathematical model;Signal resolution;Electromyography;Conductivity;Motion estimation","biomechanics;electromyography;medical signal processing;motion estimation;skin","muscle structures;muscle activation source model-based sEMG signal decomposition;sEMG interface rotation;muscle activation signals;surface electromyography signals;muscle activation extraction;hand motion estimation;rotation recognition;inertial measurement unit","","","18","","","","","IEEE","IEEE Conferences"
"Flexible Fabric Actuator Realizing 3D Movements Like Human Body Surface for Wearable Devices","Y. Funabora","Department of Information and Communication Engineering, Gradate School of Engineering, Nagoya University, Fro-cho, Chikusa-ku, Nagoya, Aichi, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6992","6997","A new flexible fabric actuator realizing three dimensional movements for wearable devices is proposed in this paper. Such actuators must be lightweight and highly flexible, producing movements with high degree of freedom to assist/follow human natural motions. Improving the structure and control system of a fabric actuator from the previous research, the flexible fabric actuator with continuous control is developed. This paper presents new configuration of thin artificial muscles on a flexible rubber swath, a continuous control system to control the fabric actuator smoothly, and control methods to realize six basic movements of human body (forward and backward bends, left and right bends, left and right twists)with less number of muscles. The experiment results indicate the possibility that the proposed fabric actuator woven thin McKibben artificial muscles is a viable technology for use in wearable devices.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594359","","Muscles;Actuators;Fabrics;Rubber;Weaving;Regulators","biomechanics;medical robotics;motion control;muscle;pneumatic actuators;wearable computers","wearable devices;continuous control system;human body surface;rubber swath;fabric actuator;3D movements;motions;McKibben artificial muscles","","","25","","","","","IEEE","IEEE Conferences"
"Unscented Kalman Filter on Lie Groups for Visual Inertial Odometry","M. Brossard; S. Bonnabel; A. Barrau","MINES ParisTech, PSL Research University, Centre for Robotics, 60 Boulevard Saint-Michel, Paris, 75006, France; MINES ParisTech, PSL Research University, Centre for Robotics, 60 Boulevard Saint-Michel, Paris, 75006, France; Safran Tech, Groupe Safran, Rue des Jeunes Bois-Chateaufort, Magny Les Hameaux Cedex, 78772, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","649","655","Fusing visual information with inertial measurements for state estimation has aroused major interests in recent years. However, combining a robust estimation with computational efficiency remains challenging, specifically for low-cost aerial vehicles in which the quality of the sensors and the processor power are constrained by size, weight and cost. In this paper, we present an innovative filter for stereo visual inertial odometry building on: (i) the recently introduced stereo multistate constraint Kalman filter; (ii) the invariant filtering theory; and (iii) the unscented Kalman filter (UKF) on Lie groups. Our solution combines accuracy, robustness and versatility of the UKF. We then compare our approach to state-of-art solutions in terms of accuracy, robustness and computational complexity on the EuRoC dataset and a challenging MAV outdoor dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593627","Lie groups;unscented Kalman filter;visual inertial odometry;aerial vehicle;localization","Cameras;Kalman filters;Visualization;Computational modeling;Uncertainty;Robustness;Noise measurement","distance measurement;Kalman filters;Lie groups;nonlinear filters;SLAM (robots);state estimation;stereo image processing","unscented Kalman filter;Lie groups;visual information;inertial measurements;state estimation;robust estimation;computational efficiency;low-cost aerial vehicles;processor power;innovative filter;stereo visual inertial odometry building;invariant filtering theory;computational complexity;stereo multistate constraint Kalman filter;EuRoC dataset;MAV outdoor dataset","","","27","","","","","IEEE","IEEE Conferences"
"Designing Concentric Tube Manipulators for Stability Using Topology Optimization","K. A. Xin Jue Luo; T. Looi; S. Sabetian; J. Drake","University of Toronto, Toronto, ON, M3B 1W8, Canada; University of Toronto, Toronto, ON, M3B 1W8, Canada; University of Toronto, Toronto, ON, M3B 1W8, Canada; University of Toronto, Toronto, ON, M3B 1W8, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1764","1769","One of the major problems facing the development and road to practical usage of concentric tube continuum robots in surgical environments is that of instability. This issue, also known as the snapping problem, is caused by a tube having a high bending to torsional stiffness ratio (BTSR). Past efforts have shown that by cutting patterns on the tubes, this problem can be avoided. This paper seeks to redesign the topology of the tubes so that BTSR is decreased and the snapping problem is resolved in a particular tube set. The generated designs are then tested through finite element analysis as well as experimental testing to demonstrate the elimination of the snapping problem. Using this novel tube design on a concentric tube robotic system can increase its stable workspace because it allows the usage of greater tube curvatures and/or curve lengths.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593806","","Electron tubes;Optimization;Topology;Stress;Manipulators;Load modeling","bending;finite element analysis;manipulator dynamics;medical robotics;pipes;surgery;torsion","snapping problem;concentric tube robotic system;topology optimization;concentric tube continuum robots;surgical environments;BTSR;tube design;concentric tube manipulators;surgical environment;bending to torsional stiffness ratio;finite element analysis","","","10","","","","","IEEE","IEEE Conferences"
"I Can See Your Aim: Estimating User Attention from Gaze for Handheld Robot Collaboration","J. Stolzenwald; W. W. Mayol-Cuevas","Department of Computer Science, University of Bristol, UK; Department of Computer Science, University of Bristol, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3897","3904","This paper explores the estimation of user attention in the setting of a cooperative handheld robot - a robot designed to behave as a handheld tool but that has levels of task knowledge. We use a tool-mounted gaze tracking system, which, after modelling via a pilot study, we use as a proxy for estimating the attention of the user. This information is then used for cooperation with users in a task of selecting and engaging with objects on a dynamic screen. Via a video game setup, we test various degrees of robot autonomy from fully autonomous, where the robot knows what it has to do and acts, to no autonomy where the user is in full control of the task. Our results measure performance and subjective metrics and show how the attention model benefits the interaction and preference of users.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594184","","Task analysis;Robot kinematics;Tools;Tracking;Gaze tracking;Estimation","gaze tracking;human-robot interaction;mobile robots;robot vision","robot autonomy;attention model;user attention;handheld robot collaboration;handheld tool;task knowledge;tool-mounted gaze tracking system;video game setup;cooperative handheld robot","","","19","","","","","IEEE","IEEE Conferences"
"City-Scale Road Audit System using Deep Learning","S. Yarram; G. Varma; C. V. Jawahar","Centre for Visual Information Technology, Kohli Center for Intelligent System, IIIT, Hyderabad; Centre for Visual Information Technology, Kohli Center for Intelligent System, IIIT, Hyderabad; Centre for Visual Information Technology, Kohli Center for Intelligent System, IIIT, Hyderabad","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","635","640","Road networks in cities are massive and is a critical component of mobility. Fast response to defects, that can occur not only due to regular wear and tear but also because of extreme events like storms, is essential. Hence there is a need for an automated system that is quick, scalable and cost-effective for gathering information about defects. We propose a system for city-scale road audit, using some of the most recent developments in deep learning and semantic segmentation. For building and benchmarking the system, we curated a dataset which has annotations required for road defects. However, many of the labels required for road audit have high ambiguity which we overcome by proposing a label hierarchy. We also propose a multi-step deep learning model that segments the road, subdivide the road further into defects, tags the frame for each defect and finally localizes the defects on a map gathered using GPS. We analyze and evaluate the models on image tagging as well as segmentation at different levels of the label hierarchy.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594363","","Roads;Image segmentation;Semantics;Deep learning;Global Positioning System;Cameras;Real-time systems","Global Positioning System;image segmentation;learning (artificial intelligence);roads;traffic engineering computing","image tagging;GPS;multistep deep learning;road networks;city-scale road audit system;label hierarchy;road defects;semantic segmentation","","","16","","","","","IEEE","IEEE Conferences"
"Mass Manufacturing of Self-Actuating Robots: Integrating Sensors and Actuators Using Flexible Electronics","A. Dementyev; J. Qil; J. Ou; J. Paradiso","Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6099","6104","Currently, the manufacturing of self-actuating and self-sensing robots requires non-standard manufacturing techniques and assembly steps to integrate electrical and mechanical systems. In this work, we developed a novel manufacturing technique, where such robots can be produced at a flexible electronics factory. We developed the technique using standard industrial machines, processes, and materials. Using a lamination process, we were able to integrate air pouches or shape memory alloy (SMA) inside a polyamide-based flexible circuit to produce bending actuators. The bend angle of the actuators is sensed with a chain of inertial measurement units integrated on the actuator. Air-pouch actuators can produce a force of a 2.24N, and a maximum bend angle of 74 degrees. To demonstrate, we manufactured a five-legged robot with the developed actuators and bend sensors, with all the supporting electronics (e.g., microcontrollers, radio) directly integrated into the flexible printed circuit. Such robots are flat and lightweight (15 grams) and thus conveniently compact for transportation and storage. We believe that our technique can allow inexpensive and fast prototyping and deployment of self-actuating and self-sensing robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593631","","Actuators;Robot sensing systems;Manufacturing;Shape memory alloys;Shape","actuators;bending;flexible electronics;microcontrollers;piezoelectric actuators;printed circuits;shape memory effects","air-pouch actuators;maximum bend angle;supporting electronics;flexible printed circuit;self-sensing robots;mass manufacturing;self-actuating robots;integrating sensors;nonstandard manufacturing techniques;electrical systems;mechanical systems;novel manufacturing technique;flexible electronics factory;standard industrial machines;air pouches;shape memory alloy;polyamide-based flexible circuit","","","16","","","","","IEEE","IEEE Conferences"
"Incremental Learning-Based Adaptive Object Recognition for Mobile Robots","M. O. Turkoglu; F. B. Ter Haar; N. van der Stap","University of Twente; TNO Intelligent Imaging; TNO Intelligent Imaging","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6263","6268","3D visual understanding of the surrounding environment is vital for successful mobile robotic tasks such as autonomous navigation or general object interaction. However, current systems have limited perceptual capabilities in the sense that they are not very well adaptable to unknown environments. Human operators, on the other hand, are experts in adapting to previously unknown information. Hence, human-robot teaming in which the human helps the robot to adapt to new environments and the robot assists in automated object recognition to efficiently feed the control environment of the operator is advantageous. In this work, we propose an object recognition and localization system for mobile robots, based on deep learning, and we study the adaptation of the resulting robotic perception to a new environment. We propose two methods to teach the robot a new object category: using prior knowledge and using limited operator input. We conducted several experiments to show the feasibility of proposed methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593810","","Three-dimensional displays;Object recognition;Image segmentation;Mobile robots;Training;Semantics","control engineering computing;human-robot interaction;learning (artificial intelligence);mobile robots;object recognition;robot vision","incremental learning-based adaptive object recognition;autonomous navigation;general object interaction;human-robot teaming;robot assists;localization system;deep learning;robotic perception;mobile robotic tasks","","","18","","","","","IEEE","IEEE Conferences"
"Towards vision-based manipulation of plastic materials","A. Cherubini; J. Leitner; V. Ortenzi; P. Corke","CNRS-UM LIRMM, Interactive Digital Human group, 161 Rue Ada, Montpellier, 34090, France; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4001, Australia; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4001, Australia; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4001, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","485","490","This paper represents a step towards vision-based manipulation of plastic materials. Manipulating deformable objects is made challenging by: 1) the absence of a model for the object deformation, 2) the inherent difficulty of visual tracking of deformable objects, 3) the difficulty in defining a visual error and 4) the difficulty in generating control inputs to minimise the visual error. We propose a novel representation of the task of manipulating deformable objects. In this preliminary case study, the shaping of kinetic sand, we assume a finite set of actions: pushing, tapping and incising. We consider that these action types affect only a subset of the state, i.e., their effect does not affect the entire state of the system (specialized actions). We report the results of a user study to validate these hypotheses and release the recorded dataset. The actions (pushing, tapping and incising) are clearly adopted during the task, although it is clear that 1) participants use also mixed actions and 2) actions' effects can marginally affect the entire state, requesting a relaxation of our specialized actions hypothesis. Moreover, we compute task errors and corresponding control inputs (in the image space) using image processing. Finally, we show how machine learning can be applied to infer the mapping from error to action on the data extracted from the user study.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594108","Manipulation;visual servoing;human studies;learning","Task analysis;Robots;Shape;Plastics;Visualization;Deformable models;Strain","deformation;manipulators;object tracking;plastic products;robot vision","vision-based manipulation;plastic materials;object deformation;visual tracking;visual error;deformable objects;kinetic sand shaping","","","16","","","","","IEEE","IEEE Conferences"
"A Fail-Safe Semi-Centralized Impedance Controller: Validation on a Parallel Kinematics Ankle","F. Ruscelli; A. Laurenzi; E. Mingo Hoffman; N. G. Tsagarakis","Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, 16163; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, 16163; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, 16163; Department of Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Via Morego 30, Genova, 16163","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper proposes the implementation of an impedance controller on the ankle level of COMAN+, a robot with parallel kinematics ankles actuated by a dual four-bar mechanism. The main contribution of the work is a realization of said control scheme that grants a less abrupt and safer robot response in case of system failures, that would cause the local joint torque controllers to lose their torque reference inputs. In particular, we propose a semi-centralized impedance control implementation which eliminates the instability of the pure joint torque control schemes used in the classical fully centralized methods when torque reference interruptions occur. Finally, we present experimental results, proving the effectiveness of our method and demonstrating how it ensures a safer behaviour compared to a fully centralized impedance control implementation when the communication to the ankle joints is interrupted. This paper is a follow-up work of [1], which presented and analyzed the parallel kinematics ankles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594112","","Impedance;Torque;Kinematics;Actuators;Damping;Humanoid robots","humanoid robots;legged locomotion;robot kinematics;torque control","fail-safe semicentralized impedance controller;parallel kinematics ankle;COMAN+;dual four-bar mechanism;fully centralized impedance control implementation;torque reference inputs;local joint torque controllers;safer robot response","","","16","","","","","IEEE","IEEE Conferences"
"Keyframe-Based Photometric Online Calibration and Color Correction","J. Quenzel; J. Horn; S. Houben; S. Behnke","University of Bonn, Autonomous Intelligent Systems Group, Germany; University of Bonn, Autonomous Intelligent Systems Group, Germany; University of Bonn, Autonomous Intelligent Systems Group, Germany; University of Bonn, Autonomous Intelligent Systems Group, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","Finding the parameters of a vignetting function for a camera currently involves the acquisition of several images in a given scene under very controlled lighting conditions, a cumbersome and error-prone task where the end result can only be confirmed visually. Many computer vision algorithms assume photoconsistency, constant intensity between scene points in different images, and tend to perform poorly if this assumption is violated. We present a real-time online vignetting and response calibration with additional exposure estimation for global-shutter color cameras. Our method does not require uniformly illuminated surfaces, known texture or specific geometry. The only assumptions are that the camera is moving, the illumination is static and reflections are Lambertian. Our method estimates the camera view poses by sparse visual SLAM and models the vignetting function by a small number of thin plate splines (TPS) together with a sixth-order polynomial to provide a dense estimation of attenuation from sparsely sampled scene points. The camera response function (CRF) is jointly modeled by a TPS and a Gamma curve. We evaluate our approach on synthetic datasets and in real-world scenarios with reference data from a Structure-from-Motion (SfM) system. We show clear visual improvement on textured meshes without the need for extensive meshing algorithms. A useful calibration is obtained from a few keyframes which makes an on-the-fly deployment conceivable.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593595","","Cameras;Calibration;Splines (mathematics);Image color analysis;Lighting;Estimation;Visualization","calibration;cameras;computer vision;image colour analysis;image motion analysis;image texture;photometry;pose estimation;splines (mathematics)","exposure estimation;thin plate splines;meshing algorithms;camera view poses estimation;sparse visual SLAM;gamma curve;structure-from-motion system;textured meshes;camera response function;sparsely sampled scene points;sixth-order polynomial;TPS;camera view;illumination;uniformly illuminated surfaces;global-shutter color cameras;real-time online vignetting;constant intensity;photoconsistency;computer vision algorithms;vignetting function;color correction;keyframe-based photometric online calibration","","","24","","","","","IEEE","IEEE Conferences"
"Automation in sensing and raw material characterization - a conceptual framework","F. S. Desta; M. W. N. Buxton","Resource Engineering, Delft University of technology, Stevinweg 1, Delft, CN, 2628, The Netherlands; Resource Engineering, Delft University of technology, Stevinweg 1, Delft, CN, 2628, The Netherlands","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1501","1506","The use of sensor technologies for material characterization is rapidly growing and innovative advancement is observed. However, the use of sensor combinations for a raw material characterization in mining is very limited and automation of the material identification process using a combined sensor signal is not defined. Potential sensor technologies for raw material characterization were evaluated based on the applicability and technological maturity. To ensure a rapid implementation of the Real-time mining (RTM) project concept, mature technologies such as Red Green Blue (RGB) imaging, Visible Near Infrared (VNIR) hyperspectral imaging, Short Wave Infrared (SWIR) hyperspectral imaging, Fourier-Transform Infrared Spectroscopy (FTIR), Laser Induced Breakdown Spectroscopy (LIBS) and Raman were selected. Each selected technology was assessed for automation in sensing and applicability (for characterization of the test case materials). Based on the results the sensor data were further considered for data fusion. The proposed sensor combinations approach encompasses three levels of data fusion: low-level, mid-level and high-level. The data of the different sensors are fused together in order to acquire a wide range of mineral properties within each lithotype and an improved classification and predictive models. The preferred level of data fusion and preferred sensor data combinations will be used to develop a multi-variate statistical interpretation rule which relates combination of sensors signals with raw material properties. Thus a tool which integrates the combined sensor signal with materials properties will be developed and used to automate the material characterization process.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593774","sensors data;data fusion;automation;material characterization;polymetallic sulphides","Minerals;Data integration;Automation;Robot sensing systems;Hyperspectral imaging;Raw materials","hyperspectral imaging;image fusion;image sensors;infrared spectra;infrared spectroscopy;statistical analysis","raw material characterization;material identification process;technological maturity;data fusion;sensor combinations approach;sensors signals;sensor technologies;real-time mining project concept;red green blue imaging;short wave infrared hyperspectral imaging;sensing automation;sensor signal;sensor data combinations;RTM;RGB imaging;visible near infrared hyperspectral imaging;VNIR;SWIR;Fourier-transform infrared spectroscopy;FTIR;laser induced breakdown spectroscopy;LIBS;multi-variate statistical interpretation","","","28","","","","","IEEE","IEEE Conferences"
"Scan Context: Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map","G. Kim; A. Kim","Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4802","4809","Compared to diverse feature detectors and descriptors used for visual scenes, describing a place using structural information is relatively less reported. Recent advances in simultaneous localization and mapping (SLAM) provides dense 3D maps of the environment and the localization is proposed by diverse sensors. Toward the global localization based on the structural information, we propose Scan Context, a non-histogram-based global descriptor from 3D Light Detection and Ranging (LiDAR) scans. Unlike previously reported methods, the proposed approach directly records a 3D structure of a visible space from a sensor and does not rely on a histogram or on prior training. In addition, this approach proposes the use of a similarity score to calculate the distance between two scan contexts and also a two-phase search algorithm to efficiently detect a loop. Scan context and its search algorithm make loop-detection invariant to LiDAR viewpoint changes so that loops can be detected in places such as reverse revisit and corner. Scan context performance has been evaluated via various benchmark datasets of 3D LiDAR scans, and the proposed method shows a sufficiently improved performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593953","","Three-dimensional displays;Sensors;Laser radar;Histograms;Shape;Visualization;Encoding","feature extraction;optical radar;robot vision;SLAM (robots);stereo image processing","simultaneous localization and mapping;scan context performance;Light Detection and Ranging scans;visual scenes;two-phase search algorithm;3D LiDAR scans;loop-detection invariant;nonhistogram-based global descriptor;global localization;diverse sensors;dense 3D maps;structural information;diverse feature detectors;3D point cloud map;place recognition","","1","29","","","","","IEEE","IEEE Conferences"
"Collectives of Spinning Mobile Microrobots for Navigation and Object Manipulation at the Air-Water Interface","W. Wang; V. Kishore; L. Koens; E. Lauga; M. Sitti","Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Heisenbergstr. 3, Stuttgart, 70569, Germany; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Heisenbergstr. 3, Stuttgart, 70569, Germany; Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Wilberforce Road. Cambridge CB3 OWA, United Kingdom; Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Wilberforce Road. Cambridge CB3 OWA, United Kingdom; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Heisenbergstr. 3, Stuttgart, 70569, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We use multiple spinning micro-rafts at the air-water interface as mobile microrobot collectives and present here their collective behaviors, including navigating around anchored obstacles, and trapping and transporting floating objects. The 3D-printed micro-rafts are circular disKS of 100 μm in diameter and have parametrically defined undulating edge profile. The study of their local interactions, manifested by the pairwise interactions between micro-rafts, reveals competing magnetic and capillary interactions that keep the collectives in their dynamic state. Using collectives of 7, 19, and 36 micro-rafts and micro-channels between millimeter-sized posts, we demonstrate the effects of the size of the collectives, the size of the obstacles, and maneuver strategies on the collective navigation. Employing methods from information theory, we show that the pairwise mutual information of the collectives increases significantly during the channel-crossing as a result of the additional constraints of the channel walls on the collectives. Finally, we demonstrate the trapping of 1-mm-diameter polystyrene bead and the trapping and transporting of 600~μm-wide pm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593519","","Conferences;Intelligent robots","microrobots;mobile robots","microchannels;pairwise interactions;local interactions;collective behaviors;mobile microrobot collectives;multiple spinning microrafts;air-water interface;object manipulation;spinning mobile microrobots;size 100.0 mum","","","21","","","","","IEEE","IEEE Conferences"
"Online inference of human belief for cooperative robots","M. C. Buehler; T. H. Weisswange","Control Methods & Robotics Lab, TU Darmstadt, Germany; Honda Research Institute Europe GmbH","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","409","415","For human-robot cooperation, inferring a hu-man's cognitive state is very important for an efficient and natural interaction. Similar to human-human cooperation, understanding what the partner plans and knowing, if he is situation aware, is necessary to prevent collisions, offer support at the right time, correct mistakes before they happen or choose the best actions for oneself as early as possible. We propose a model-based belief filter to extract relevant aspects of a human's mental state online during cooperation. It performs inference based on human actions and its own task knowledge, modeling cognitive processes like perception and action selection. In contrast to most prior work, we explicitly estimate the human belief instead of inferring only a single mode or intention. Since this is a double inference process, we focus on representing the human estimates of environmental state and task as well as corresponding uncertainties. We designed a human-robot cooperation experiment that allowed for a variety of cognitive states of both agents and collected data to test and evaluate the proposed belief filter. The results are promising, as our system can be used to provide reasonable predictions of the human action and insights into his situation awareness. At the same time it is inferring interpretable information about the underlying cognitive states - A belief about the human's belief about the environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594076","","Task analysis;Robots;Manufacturing;Collaboration;Probability distribution;Estimation;Mathematical model","belief networks;cognition;cognitive systems;cooperative systems;human-robot interaction;inference mechanisms;interactive systems;mobile robots;multi-robot systems","online inference;natural interaction;human-human cooperation;model-based belief filter;human action;cognitive processes;perception;action selection;double inference process;environmental state;human-robot cooperation experiment;situation awareness;cognitive states","","","15","","","","","IEEE","IEEE Conferences"
"UAV Based Wireless Charging of Sensor Networks Without Prior Knowledge","N. W. Najeeb; C. Detweiler","Dept. of Computer Science and Engineering, University of Nebraska-Lincoln, NIMBUS Lab, Lincoln, NE, 68588, USA; Dept. of Computer Science and Engineering, University of Nebraska-Lincoln, NIMBUS Lab, Lincoln, NE, 68588, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3151","3158","Unmanned Aerial Vehicles (UAVs) can charge Wireless Rechargeable Sensor Networks (WRSNs) in remote or hard to access locations. However, the charging efficiency is heavily affected by the distance between the wireless transmitter and receiver. This efficiency impacts the possible power level increase of each charged node. Most charging algorithms require full knowledge of sensor nodes' power levels to identify the nodes to charge. Collecting this power information adds overhead to the network and limits scalability. We propose and implement Charging with Power Transfer Efficiency Compensation (CPTEC), an algorithm that charges a WRSN without the need for a priori knowledge of the nodes' power levels. We show that CPTEC compensates for efficiency drops, due to landing alignments, making it practical for real-world power transfer scenarios. Our results show that CPTEC is able to perform with a median at ≈ 72% of the optimal performance of a full knowledge algorithm that assumes maximum power transfer efficiency, while other work drops to ≈ 22%. Under constant maximum efficiency CPTEC performs ≈ 90% of the optimal full knowledge case.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594255","","Robot sensing systems;Unmanned aerial vehicles;Wireless sensor networks;Wireless communication;Receivers;Wireless power transfer","autonomous aerial vehicles;wireless sensor networks","Power Transfer Efficiency Compensation;efficiency drops;real-world power transfer scenarios;knowledge algorithm;maximum power transfer efficiency;constant maximum efficiency CPTEC;UAV based Wireless Charging;Unmanned Aerial Vehicles;Wireless Rechargeable Sensor Networks;charging efficiency;wireless transmitter;charged node;sensor nodes;power information;limits scalability;wireless receiver;power level increase;power level increase","","","23","","","","","IEEE","IEEE Conferences"
"Development and validation of MRI compatible pediatric surgical robot with modular tooling for bone biopsy","A. N. Alvara; T. Looi; R. Saab; A. Shorter; A. Goldenberg; J. Drake","University of California, University of California Henry Samueli School of Engineering, Irvine 5200 Engineering Service Rd, Irvine, CA, 92617, USA; University of Toronto, Institute for Biomaterials and Biomedical Engineering, Toronto, ON, M5S 2J7; University of Toronto, Institute for Biomaterials and Biomedical Engineering, Toronto, ON, M5S 2J7; Northwestern University, Department of Biomedical Engineering, Evanston, IL, 60208, USA; Engineering Services Inc (ESI), Toronto, ON, Canada; University of Toronto, Institute for Biomaterials and Biomedical Engineering, Toronto, ON, M5S 2J7","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4935","4941","In clinical practice, magnetic resonance imaging (MRI) is used to locate a lesion/tumor for bone biopsy in children. However, there is a lack of MR-compatible tools that can be used simultaneously during imaging and biopsy while maintaining surgical accuracy and safety. The Pediatric Surgery Robot (PSR) platform is a 5-DOF robot with a modular tool interface. For the case of bone biopsy, a Bone Biopsy Tooling (BBT) is attached. It is designed to fit within a Philips Achieva 3.0T MRI bore and carry a modified titanium bone biopsy needle. A surgical pre-planning and control interface has been developed for joint and Cartesian level control. The PSR-BBT has demonstrated 1.65 +/- 1.77 mm accuracy in Cartesian control in free space. The PSR-BBT can generate 12.46 +/- 0.32 N of axial force while drilling at a speed of 30 rpm, which is sufficient for cortical and cancellous bone phantoms. Under MRI testing (T1-FFE, T1-SE, T2-FFE and T2-TSE scans), the system demonstrated less than 33% signal-to-noise ratio variation while drilling and a 0.46% geometric distortion while powered on without significantly impacting MRI guidance in situ. These results show that the PSR-BBT can allow the user to simultaneously image and perform the biopsy and presents the PSR as a viable platform for MR-guided robotic surgery.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593523","","Biopsy;Bones;Magnetic resonance imaging;Robots;Surgery;Signal to noise ratio;Tools","biomedical MRI;bone;medical robotics;paediatrics;phantoms;surgery;tumours","PSR-BBT;cortical bone phantoms;cancellous bone phantoms;MRI testing;T1-FFE;T2-FFE;MR-guided robotic surgery;modular Tooling;magnetic resonance imaging;MR-compatible tools;surgical accuracy;Pediatric Surgery Robot platform;modular tool interface;Bone Biopsy Tooling;modified titanium bone biopsy needle;joint Cartesian level control;MRI compatible pediatric surgical robot;lesion;tumor;5-DOF robot;Philips Achieva 3.0T MRI bore;surgical preplanning;control interface;Cartesian level control;axial force;signal-to-noise ratio variation;geometric distortion;magnetic flux density 3 T","","","12","","","","","IEEE","IEEE Conferences"
"FSG: A statistical approach to line detection via fast segments grouping","I. Suárez; E. Muñoz; J. M. Buenaposada; L. Baumela","The Graffter, Centro de Empresas, Campus Montegancedo s/n, Pozuelo de Alarcón, 28223, Spain; The Graffter, Centro de Empresas, Campus Montegancedo s/n, Pozuelo de Alarcón, 28223, Spain; ETSII, Universidad Rey Juan Carlos, C/Tulipán, s/n, Móstoles, 28933, Spain; Departamento de Inteligencia Artificial, Universidad Politécnica de Madrid, Campus Montegancedo s/n, Boadilla del Monte, 28660, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","97","102","Line extraction is a preliminary step in various visual robotic tasks performed in low textured scenes such as city and indoor settings. Several efficient line segment detection algorithms such as LSD and EDLines have recently emerged. However, the state of the art segment grouping methods are not robust enough or not amenable for detecting lines in real-time. In this paper we present FSG, a fast and robust line detection algorithm. It is based on two independent components. A proposer that greedily cluster segments suggesting plausible line candidates and a probabilistic model that decides if a group of segments is an actual line. In the experiments we show that our procedure is more robust and faster than the best methods in the literature and achieves state-of-the art performance in a high level robot localization task such as vanishing points detection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594434","","Image segmentation;Probabilistic logic;Estimation;Simultaneous localization and mapping;Task analysis;Detection algorithms","feature extraction;image segmentation;robot vision","fast segments grouping;line segment detection algorithms;segment grouping methods;vanishing points detection;statistical approach;high level robot localization task;plausible line candidates;robust line detection algorithm;FSG;low textured scenes;visual robotic tasks;line extraction","","","30","","","","","IEEE","IEEE Conferences"
"Deep Reinforcement Learning to Acquire Navigation Skills for Wheel-Legged Robots in Complex Environments","X. Chen; A. Ghadirzadeh; J. Folkesson; M. Björkman; P. Jensfelt","NA; NA; NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3110","3116","Mobile robot navigation in complex and dynamic environments is a challenging but important problem. Reinforcement learning approaches fail to solve these tasks efficiently due to reward sparsities, temporal complexities and high-dimensionality of sensorimotor spaces which are inherent in such problems. We present a novel approach to train action policies to acquire navigation skills for wheel-legged robots using deep reinforcement learning. The policy maps height-map image observations to motor commands to navigate to a target position while avoiding obstacles. We propose to acquire the multifaceted navigation skill by learning and exploiting a number of manageable navigation behaviors. We also introduce a domain randomization technique to improve the versatility of the training samples. We demonstrate experimentally a significant improvement in terms of data-efficiency, success rate, robustness against irrelevant sensory data, and also the quality of the maneuver skills.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593702","","Training;Task analysis;Navigation;Mobile robots;Trajectory;Robot sensing systems","learning (artificial intelligence);legged locomotion;path planning;robot vision;wheels","navigation skills;navigation behaviors;action policies training;height-map image observations;motor commands;dynamic environments;mobile robot navigation;complex environments;deep reinforcement learning;wheel-legged robots","","","22","","","","","IEEE","IEEE Conferences"
"Design of a 2 Motor 2 Degrees-of-Freedom Coupled Tendon-driven Joint Module","W. Li; P. Chen; D. Bai; X. Zhu; S. Togo; H. Yokoi; Y. Jiang","Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Tokyo, 182-8585, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Tokyo, 182-8585, Japan; Shenyang University of Technology, Shenyang, 110870, China; Shanghai Jiao Tong University, Shanghai, 200240, China; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Tokyo, 182-8585, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Tokyo, 182-8585, Japan; Brain Science Inspired Life Support Research Center, The University of Electro-Communications, Tokyo, 182-8585, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","943","948","A 2 motor 2 degrees-of-freedom (2M2D) coupled tendon driven joint module is proposed as a basic component for robot arms. Torque reallocation via tendon coupling can enhance the output torque of one single joint. According to the motor position, the joint module is classified into four types: the externally-actuated structure, the internally-coaxially-actuated structure, the internally-separately-actuated structure, and the hybrid-actuated structure. The four structures are analyzed and compared, and their implementation design examples are given. Experiments comparing the proposed joint module with directly-actuated traditional joint suggested that the 2M2D coupled tendon-driven joint module can obtain high control accuracy, and the torque reallocation via tendon coupling is effective to improve output torque. Additionally, an anthropomorphic robot arm with low weight and high payload was developed to show the utility of the proposed joint module.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594080","","Pulleys;Tendons;Torque;Manipulators;Couplings;Routing","actuators;control system synthesis;design engineering;mobile robots;position control","hybrid-actuated structure;internally-separately-actuated structure;internally-coaxially-actuated structure;externally-actuated structure;tendon coupling;torque reallocation;2 motor 2 degrees-of-freedom coupled tendon-driven joint module;anthropomorphic robot arm;2M2D coupled tendon-driven joint module;motor position","","","14","","","","","IEEE","IEEE Conferences"
"Generative Low-Shot Network Expansion","A. Hayat; M. Kliger; S. Fleishman; D. Cohen-Or","Intel; Amazon; Amazon; Tel-Aviv University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6072","6077","Conventional deep learning classifiers are static in the sense that they are trained on a predefined set of classes and learning to classify a novel class typically requires re-training. In this work, we address the problem of Low-Shot network-expansion learning. We introduce a learning framework which enables expanding a pre-trained (base) deep network to classify novel classes when the number of examples for the novel classes is particularly small. We present a simple yet powerful hard distillation method where the base network is augmented with additional weights to classify the novel classes, while keeping the weights of the base network unchanged. We show that since only a small number of weights needs to be trained, the hard distillation excels in low-shot training scenarios. Furthermore, hard distillation avoids detriment to classification performance on the base classes. Finally, we show that low-shot network expansion can be done with a very small memory footprint by using a compact generative model of the base classes training data with only a negligible degradation relative to learning with the full training set.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594004","","Training;Training data;Data models;Memory management;Task analysis;Robots;Feature extraction","learning (artificial intelligence);neural nets;pattern classification","conventional deep learning classifiers;pre-trained deep network;base network;low-shot training scenarios;compact generative model;generative low-shot network expansion;hard distillation method;memory footprint","","","16","","","","","IEEE","IEEE Conferences"
"Incorporating Kinematic Properties into Fused Deposition Toolpath Optimization","S. Lensgraf; R. R. Mettu","Tulane University, Department of Computer Science, New Orleans, LA, 70118; Tulane University, Department of Computer Science, New Orleans, LA, 70118","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8622","8627","The most widely used methods for toolpath planning in fused deposition 3D printing slice the input model into successive 2D layers in order to construct the toolpath. Unfortunately slicing-based methods can incur a substantial amount of wasted motion (i.e., the extruder is moving while not printing), particularly when features of the model are spatially separated. In recent work we have introduced a new paradigm that constructs the toolpath in 3D and prints local features to minimize wasted motion. Our algorithm is based on a local search and we have demonstrated substantial improvements in the efficiency of the resulting toolpaths. Our approach is amenable to incorporating physical constraints of the 3D printing process, and, in this paper we extend our approach to incorporate kinematic properties into toolpath optimization. With an accurate kinematic model of the extruder, our algorithm is able to model the real-world fabrication time of the model with a high degree of accuracy. To our knowledge, this toolpath optimization algorithm is the first to encode real-world fabrication time as the objective function. We demonstrate the real-world improvement in fabrication time that is possible with our algorithm on a benchmark of almost 600 models. We find improvement in nearly every toolpath generated for our benchmark set (with a mean of 3.2%), but substantially larger improvements for some models. To rationalize these results, we introduce a metric for model characterization that we call “oriented compactness” and show that it correlates positively with our observations. We believe this metric can be an important tool in the setup of fabrication (e.g., by guiding an orientation search of the model).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594398","","Printers;Motion segmentation;Kinematics;Fabrication;Acceleration;Optimization;Planning","layered manufacturing;optimisation;production engineering computing;rapid prototyping (industrial);solid modelling;three-dimensional printing","fused deposition toolpath optimization;toolpath planning;fused deposition 3D printing slice;slicing-based methods;wasted motion;extruder;prints local features;local search;3D printing process;accurate kinematic model;real-world fabrication time;toolpath optimization algorithm;real-world improvement;model characterization;2D layers;toolpaths","","","14","","","","","IEEE","IEEE Conferences"
"Soft Biomimetic Prosthetic Hand: Design, Manufacturing and Preliminary Examination","J. Fras; K. Althoefer","Queen Mary University of London, Centre for Advanced Robotics @ Queen Mary (ARQ) Faculty of Science and Engineering; Queen Mary University of London, Centre for Advanced Robotics @ Queen Mary (ARQ) Faculty of Science and Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","The human hand is a complex structure. It is strong but precise. It consists of a very complex mechanical structure that enables the hand to adapt and efficiently handle objects of various shapes, weights and textures. Today's prosthetic devices, struggling to provide similar functions, become overly complex and expensive. They are composed of multiple, precise parts, including miniaturised actuators and sensors as well as complex control, to satisfy the manipulation tasks required. In this paper we propose a soft pneumatic hand that adapts passively to the handled object due to its mechanical compliance. It is pressure driven and enables individual fingers to be controlled independently for dexterity or in groups when a synergistic finger movement is needed. The hand has a truly anatomical shape, is easy to replace and cheap in production. The design can be easily adjusted in terms of shape and size in order to fit each individual user. The paper presents the design, manufacturing technology, current control system and preliminary tests of the hand's capabilities.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593666","","Actuators;Exoskeletons;Manufacturing;Shape;Thumb;Joints;Sensors","artificial limbs;biomechanics;biomimetics;manipulators","human hand;complex mechanical structure;prosthetic devices;handled object;mechanical compliance;synergistic finger movement;current control system;soft biomimetic prosthetic hand","","","19","","","","","IEEE","IEEE Conferences"
"Estimating Achievable Range of Ground Robots Operating on Single Battery Discharge for Operational Efficacy Amelioration","K. Tiwari; X. Xiao; N. Y. Chong","Department of Electrical Engineering & Automation, Aalto University, School of Information Science, Japan Adv. Institute of Sc. & Tech. (JAIST), Espoo, Ishikawa, 02150, Finland; Department of Computer Science and Engineering, Texas A&M University, College Station, Texas, 77843, United States; School of Information Science, Japan Adv. Institute of Sc. & Tech. (JAIST), Ishikawa, 923-1292, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3991","3998","Mobile robots are increasingly being used to assist with active pursuit and law enforcement. One major limitation for such missions is the resource (battery) allocated to the robot. Factors like nature and agility of evader, terrain over which pursuit is being carried out, plausible traversal velocity and the amount of necessary data to be collected all influence how long the robot can last in the field and how far it can travel. In this paper, we develop an analytical model that analyzes the energy utilization for a variety of components mounted on a robot to estimate the maximum operational range achievable by the robot operating on a single battery discharge. We categorize the major consumers of energy as: 1.) ancillary robotic functions such as computation, communication, sensing etc., and 2.) maneuvering which involves propulsion, steering etc. Both these consumers draw power from the common power source but the achievable range is largely affected by the proportion of power available for maneuvering. For this case study, we performed experiments with real robots on planar and graded surfaces and evaluated the estimation error for each case.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593845","","Robot sensing systems;Batteries;Mobile robots;Energy consumption;Discharges (electric)","mobile robots","estimation error;single battery discharge;operational efficacy;mobile robots;active pursuit;law enforcement;plausible traversal velocity;energy utilization;consumers;ancillary robotic functions","","","32","","","","","IEEE","IEEE Conferences"
"Motion Planning for a Small Aerobatic Fixed-Wing Unmanned Aerial Vehicle","J. Levin; A. Paranjape; M. Nahon","McGill University, Department of Mechanical Engineering, Montreal, QC, H3A 0G4, Canada; Imperial College London, Department of Aeronautics, London, SW7 2AZ, United Kingdom; McGill University, Department of Mechanical Engineering, Montreal, QC, H3A 0G4, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8464","8470","A motion planner is developed for guiding a small aerobatic fixed-wing unmanned aerial vehicle to a desired goal region in a highly constrained, three-dimensional, known environment with static obstacles. The planner is based on the Rapidly-Exploring Random Trees (RRT) algorithm, and pieces together feasible trajectories from a library of motion primitives. Among other more conventional motion primitives, the library includes three extreme maneuvers: a cruise-to-hover transition, a hover-to-cruise transition, and an aggressive turn-around. The algorithm is efficient; it can be run in real-time to rapidly generate a plan starting from the aircraft's configuration at run-time. The motion planner is closely coupled to a feedback controller. Simulations using an aircraft dynamics model demonstrate the effectiveness of the system to guide and control the aircraft to a desired goal region. Preliminary flight test results are also presented.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593670","","Aircraft;Trajectory;Libraries;Aerodynamics;Atmospheric modeling;Heuristic algorithms;Planning","aerospace components;aircraft control;autonomous aerial vehicles;collision avoidance;feedback;mobile robots;robot dynamics;trees (mathematics)","cruise-to-hover transition;hover-to-cruise transition;motion planner;motion planning;aerobatic fixed-wing;fixed-wing unmanned aerial vehicle;static obstacles;goal region;rapidly-exploring random trees algorithm","","","17","","","","","IEEE","IEEE Conferences"
"Robot Artist Performs Cartoon Style Facial Portrait Painting","R. C. Luo; Y. J. Liu","Intelligent Robotics and Automation Research (iCeiRA), National Taiwan University, International Center of Excellence, Taipei, Taiwan, No. 1, Sec. 4, Roosevelt Road, 106; Intelligent Robotics and Automation Research (iCeiRA), National Taiwan University, International Center of Excellence, Taipei, Taiwan, No. 1, Sec. 4, Roosevelt Road, 106","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7683","7688","This paper presents a face portrait with cartoon stylization painting and associated algorithms with the visual feedback system to paint like a human cartoonist. The robot cartoonist creates the artwork in two stages-cartoon style transformation and robot artist for colorful painting. In the cartoon style transformation stage, it transfers human portrait photos to cartoon style by face detection and alignment, which can effectively decompose the face into individual components then replace by cartoon facial components. In the second stage, the robot uses an eye-in-hand system to obtain five basic colors (cyan, magenta, yellow, white and black) to automatically mix a variety of colors automatically. For painting strategy, we start with the outline of the face, which we use non-photorealistic rendering (NPR) to generate hand-painted strokes. After that, the robot artist will implement painting the facial features. We also demonstrate the success of this proposed research.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594147","Cartoon face;robot painting","Painting;Image color analysis;Face;Shape;Facial features;Image segmentation","art;face recognition;image colour analysis;painting;rendering (computer graphics)","facial features;hand-painted strokes;painting strategy;basic colors;eye-in-hand system;cartoon facial components;face detection;human portrait photos;cartoon style transformation stage;colorful painting;stages-cartoon style transformation;robot cartoonist;human cartoonist;visual feedback system;cartoon stylization painting;robot artist;cartoon style facial portrait painting;face portrait","","","23","","","","","IEEE","IEEE Conferences"
"Elastic Structure Preserving Impedance (ESπ)Control for Compliantly Actuated Robots","M. Keppler; D. Lakatos; C. Ott; A. Albu-Schaffer","German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Oberpfaffenhofen, 82234, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Oberpfaffenhofen, 82234, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Oberpfaffenhofen, 82234, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Oberpfaffenhofen, 82234, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5861","5868","We present a new approach for Cartesian impedance control of compliantly actuated robots with possibly nonlinear spring characteristics. It reveals a remarkable stiffness and damping range in the experimental evaluation. The most interesting contribution, is the way the desired closed-loop dynamics is designed. Our control concept allows to add a desired stiffness and damping directly on the end-effector, while leaving the system structure intact. The intrinsic inertial and elastic properties of the system are preserved. This is achieved by introducing new motor coordinates that reflect the desired spring and damper terms. Theoretically, by means of additional motor inertia shaping it is possible to make the end-effector interaction behavior with respect to external loads approach, arbitrarily close, the interaction behavior that is achievable by classical Cartesian impedance control on rigid robots. The physically motivated design approach allows for an intuitive understanding of the resulting closed-loop dynamics. We perform a passivity and stability analysis on the basis of al physically motivated storage and Lyapunov function.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593415","","Robot kinematics;Impedance;Springs;Damping;Dynamics;Actuators","closed loop systems;damping;end effectors;Lyapunov methods;manipulator dynamics;stability","compliantly actuated robots;possibly nonlinear spring characteristics;damping range;end-effector interaction behavior;external loads approach;classical Cartesian impedance control;closed-loop dynamics;elastic structure preserving impedance control;stability analysis;Lyapunov function","","","26","","","","","IEEE","IEEE Conferences"
"External Force/Torque Estimation on a Dexterous Parallel Robotic Surgical Instrument Wrist","N. Yilmaz; M. Bazman; U. Tumerdem","Department of Mechanical Engineering, Marmara University, Goztepe, Kadikoy, Istanbul, 34722, Turkey; Department of Mechanical Engineering, Marmara University, Goztepe, Kadikoy, Istanbul, 34722, Turkey; Department of Mechanical Engineering, Marmara University, Goztepe, Kadikoy, Istanbul, 34722, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4396","4403","This paper describes a novel sensorless force estimation algorithm for the rigid link parallel wrist mechanism of a robotic surgical instrument. The method utilizes novel reaction force observers (RFOB) in joint space, which are modified disturbance observers (DOB) combined with Neural Networks (NN) for inverse dynamics calculations, to estimate external forces acting on the motors. External force/torque estimation in Cartesian space is achieved by the use of the robot Jacobian. The proposed algorithm is applicable to any back-drivable rigid-link wrist mechanism without the need for force sensors. In this paper, the method is implemented on a novel 3 degree-of-freedom (DOF) parallel robotic surgical wrist mechanism that is designed for high dexterity (±90 degrees pitch-yaw rotations, thrust motion) and force/torque estimation. The wrist is actuated extracorporally with 3 rigid push-pull rods and 3 linear motors. With a rigid transmission and high back-drivability, external force/torque estimation can be achieved from the motor position readings utilizing the proposed method. Several experiments were performed on the manufactured prototype of the instrument and results validate the efficacy of the wrist and estimation method with RMS force/torque estimation error values of 0.0024 Nm in pitch axis, 0.0043 Nm in yaw axis and 0.1866 N in thrust axis.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594326","","Wrist;Force;Robot sensing systems;Estimation;Jacobian matrices;Kinematics","actuators;dexterous manipulators;force control;force sensors;linear motors;manipulator dynamics;manipulator kinematics;medical robotics;motion control;observers;position control;surgery;torque control","sensorless force estimation algorithm;rigid link parallel wrist mechanism;reaction force observers;back-drivable rigid-link wrist mechanism;force sensors;robotic surgical wrist mechanism;estimation method;dexterous parallel robotic surgical instrument wrist;RMS force-torque estimation error values;external force-torque estimation","","","19","","","","","IEEE","IEEE Conferences"
"Exploiting Friction in Torque Controlled Humanoid Robots","G. Nava; D. Ferigo; D. Pucci","Italian Institute of Technology, Via Morego 30, Genoa, Italy; Italian Institute of Technology, Via Morego 30, Genoa, Italy; Italian Institute of Technology, Via Morego 30, Genoa, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1226","1232","A common architecture for torque controlled humanoid robots consists in two nested loops. The outer loop generates desired joint/motor torques, and the inner loop stabilizes these desired values. In doing so, the inner loop usually compensates for joint friction phenomena, thus removing their inherent stabilizing property that may be also beneficial for high level control objectives. This paper shows how to exploit friction for joint and task space control of humanoid robots. Experiments are carried out on the humanoid robot iCub.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594505","","Friction;Brushless motors;Humanoid robots;Task analysis;Robot sensing systems;Robot kinematics","friction;humanoid robots;motion control;robot dynamics;stability;torque control","torque controlled humanoid robots;common architecture;nested loops;joint/motor torques;joint friction phenomena;high level control objectives;joint task space control;humanoid robot iCub;stabilizing property","","","25","","","","","IEEE","IEEE Conferences"
"Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow","C. Zhao; L. Sun; P. Purkait; T. Duckett; R. Stolkin","University of Birmingham, Extreme Robotics Lab, Birmingham, B15 2TT, UK; University of Lincoln, Lincoln Centre for Autonomous Systems (L-CAS), LN6 7TS, UK; Toshiba Research Europe, Cambridge Research Lab, Cambridge, CB4 0GZ, UK; University of Lincoln, Lincoln Centre for Autonomous Systems (L-CAS), LN6 7TS, UK; University of Birmingham, Extreme Robotics Lab, Birmingham, B15 2TT, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6864","6871","This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 % for average translational error and 0.0143°/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594151","","Three-dimensional displays;Simultaneous localization and mapping;Visual odometry;Two dimensional displays;Deep learning;Cameras;Training","distance measurement;Gaussian processes;image reconstruction;learning (artificial intelligence);mobile robots;motion estimation;neural nets;pose estimation;robot vision;SLAM (robots);stereo image processing","learning monocular visual odometry;monocular SLAM;simultaneous localization;neural network;dual-stream L-VO network;6DOF relative pose;bivariate Gaussian modeling;KITTI odometry;visual SLAM system;dense 2D flow;fully deep learning approach;dense 3D flow;dense 3D mapping","","","31","","","","","IEEE","IEEE Conferences"
"The Deformable Quad-Rotor Enabled and Wasp-Pedal-Carrying Inspired Aerial Gripper","N. Zhao; Y. Luo; H. Deng; Y. Shen; H. Xu","Beijing Institute of Technology, Beijing, 100081, China; University of Nevada, Dept. of Electrical and Biomedical Engineering, Reno, Nevada, 89557, USA; Beijing Institute of Technology, Beijing, 100081, China; University of Nevada, Dept. of Electrical and Biomedical Engineering, Reno, Nevada, 89557, USA; University of Nevada, Dept. of Electrical and Biomedical Engineering, Reno, Nevada, 89557, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","The paper presents the development of a novel deformable quad-rotor enabled aerial gripper. The mechanism of our deformable quad-rotor is based on simultaneous expansion or contraction of the quad-rotor body, which is generated by controlling a rigid elements based morphing structure (REMS). Such deformation results in a highly deformable quad-rotor that can not only perform morphological adaptation in response to environmental changes and obstacles, but also improve the flight performance by contracting to facilitate the agility/maneuverability or by expanding to enhance the stability. Meanwhile, inspired by the wasp grasping behavior, such controllable expansion and contraction from the REMS ingeniously enable a new function of aerial gripper. In this paper, we start to detail the mechanism and design of the REMS based deformable quad-rotor, then present the quad-rotor deformation enabled aerial gripper design, its dynamics modeling, the grasping function and analysis. The simulation was conducted in order to graphically show the elicited aerodynamic flow situation during expansion or contraction of the quad-rotor with and without carrying payload. Experiments were further implemented to validate the grasping function of the gripper and the flight performance of the quad-rotor. Finally, two case studies on the new aerial gripper were performed. All results demonstrate the excellent performance of the deformable quad-rotor enabled aerial gripper, that is, it has the advantages of both flight maneuverability and grasping capability during performing tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594330","","Grippers;Grasping;Strain;Payloads;Rotors;Manipulators;Gravity","aerodynamics;aircraft control;autonomous aerial vehicles;controllability;deformation;grippers;helicopters;mobile robots;stability","aerial gripper design;REMS;quadrotor body;quadrotor deformation;rigid elements based morphing structure;aerodynamic flow;wasp grasping behavior;stability;unmanned aerial vehicles","","","16","","","","","IEEE","IEEE Conferences"
"A minimalist Stair Climbing Robot (SCR) formed as a leg balancing & climbing Mobile Inverted Pendulum (MIP)","D. Yang; T. Bewley","UCSD Coordinated Robotics Lab; UCSD Coordinated Robotics Lab","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2464","2469","This paper presents a (patent-pending) small, quasi-static, minimal-complexity Stair Climbing Robot (SCR). The vehicle design is given simply by adding a third motor to a (Segway-like) Mobile Inverted Pendulum (MIP), enabling it to maneuver up stairs, leveraging feedback control, by planting it's “foot” onto the ground in front of the next step, lifting the chassis/wheel assembly up it's own “leg”, leaning over onto the top of the next step, self uprighting, and repeating for the following step(s). Fore/aft stabilization during leg balancing is given by using the MIP drive wheels as reaction wheels, while left/right stability is given by the width of the foot itself. The design is small and simple enough to potentially be ruggedized as a stair-climbing throwbot, akin to the Recon Scout (but able to climb up stairs) for reconnaissance in military and homeland security applications.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593988","","Wheels;Legged locomotion;Robot kinematics;Gears;Torque","feedback;legged locomotion;motion control;pendulums;robot kinematics;service robots;stability;wheels","SCR;leg balancing;patent-pending;minimal-complexity Stair Climbing Robot;vehicle design;stairs;leveraging feedback control;foot;MIP drive wheels;reaction wheels;stair-climbing throwbot;mobile inverted pendulum;left-right stability;fore-aft stabilization;chassis-wheel assembly;minimalist stair climbing robot","","","13","","","","","IEEE","IEEE Conferences"
"Guess What I Attend: Interface-Free Object Selection Using Brain Signals","H. Kolkhorst; M. Tangermann; W. Burgard","Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7111","7116","Interpreting the brain activity to identify user goals or to ground a robot's hypotheses about them is a promising direction for non-intrusive and intuitive communication. Such a capability can be of particular relevance in the context of human-robot cooperation scenarios. This paper proposes a novel approach to utilize the natural brain responses to highlighted objects in the scene for object selection. By this, it circumvents the need for additional interfaces or user training. Our approach uses methods from information geometry to classify the target/non-target response of these event-related potentials. Online experiments carried out with a real robot demonstrate an accurate detection of target objects solely based on the user's attention.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593992","","Electroencephalography;Covariance matrices;Task analysis;Information geometry;Switches;Mobile robots","human-robot interaction;learning (artificial intelligence);mobile robots;object detection;signal detection","user training;event-related potentials;interface-free object selection;brain signals;brain activity;user goals;intuitive communication;human-robot cooperation scenarios;natural brain responses;target object detection;object selection;information geometry","","","18","","","","","IEEE","IEEE Conferences"
"Unsupervised Trajectory Segmentation and Promoting of Multi-Modal Surgical Demonstrations","Z. Shao; H. Zhao; J. Xie; Y. Qu; Y. Guan; J. Tan","College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, 100048, China; College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, 100048, China; College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, 100048, China; Engineering College, The University of Tennessee, Knoxville, TN, 37996, USA; College of Information Engineering, Beijing Advanced Innovation Center for Imaging Technology, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, 100048, China; Engineering College, The University of Tennessee, Knoxville, TN, 37996, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","777","782","To improve the efficiency of surgical trajectory segmentation for robot learning in robot-assisted minimally invasive surgery, this paper presents a fast unsupervised method using video and kinematic data, followed by a promoting procedure to address the over-segmentation issue. Unsupervised deep learning network, stacking convolutional auto-encoder, is employed to extract more discriminative features from videos in an effective way. To further improve the accuracy of segmentation, on one hand, wavelet transform is used to filter out the noises existed in the features from video and kinematic data. On the other hand, the segmentation result is promoted by identifying the adjacent segments with no state transition based on the predefined similarity measurements. Extensive experiments on a public dataset JIGSAWS show that our method achieves much higher accuracy of segmentation than state-of-the-art methods in the shorter time.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593379","","Kinematics;Feature extraction;Surgery;Trajectory;Convolution;Visualization;Wavelet transforms","feature extraction;image segmentation;medical robotics;robot kinematics;surgery;unsupervised learning;video signal processing;wavelet transforms","multimodal surgical demonstrations;surgical trajectory segmentation;robot learning;robot-assisted minimally invasive surgery;kinematic data;over-segmentation issue;unsupervised deep learning network;convolutional auto-encoder;videos;unsupervised trajectory segmentation method;JIGSAWS dataset;wavelet transform;feature extraction","","","15","","","","","IEEE","IEEE Conferences"
"Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties","Z. Min; J. Wang; S. Song; M. Q. -. Meng","Robotics, Perception and Artificial intelligence Lab, The Chinese University of Hong Kong, Hong Kong SAR, N.T., China; Robotics, Perception and Artificial intelligence Lab, The Chinese University of Hong Kong, Hong Kong SAR, N.T., China; School of Mechanical Engineering and Automation, Shenzhen Graduate School of Harbin Institute of Technology, Shenzhen, 518052, China; Robotics, Perception and Artificial intelligence Lab, The Chinese University of Hong Kong, Hong Kong SAR, N.T., China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1290","1297","Alignment of two point clouds is an essential problem in medical robotics and computer-assisted surgery. In this paper, we first formally formulate the generalized point cloud registration problem in a probabilistic manner. Specifically, not only positional but also the orientational information are incorporated into registration. Notably, the positional error is assumed to obey a multivariate Gaussian distribution to accommodate anisotropic cases. Expectation conditional maximization framework is utilized to solve the problem. In E-step, the correspondence probabilities between points in two generalized point clouds are computed. In M -step, the constrained optimization problem with respect to the transformation matrix is re-formulated as an unconstrained one. Extensive experiments are conducted to compare the proposed algorithm with the state-of-the-art registration methods. The experimental results demonstrate the algorithm's robustness to noise and outliers, fast convergence speed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593558","","Three-dimensional displays;Hidden Markov models;Covariance matrices;Surgery;Optimization;Mixture models;Linear programming","expectation-maximisation algorithm;Gaussian distribution;image registration;matrix algebra;optimisation","anisotropic positional uncertainties;E-step;correspondence probabilities;M-step;transformation matrix;constrained optimization problem;expectation conditional maximization framework;multivariate Gaussian distribution;positional error;generalized point cloud registration problem;computer-assisted surgery;medical robotics;robust generalized point cloud registration","","","24","","","","","IEEE","IEEE Conferences"
"Towards Material Classification of Scenes Using Active Thermography","H. Bai; T. Bhattacharjee; H. Chen; A. Kapusta; C. C. Kemp","Georgia Institute of Technology, Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines; University of Washington, Paul G. Allen School of Computer Science and Engineering; Georgia Institute of Technology, Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines; Georgia Institute of Technology, Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines; Georgia Institute of Technology, Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4262","4269","By briefly heating the local environment with a heat lamp and observing what happens with a thermal camera, robots could potentially infer properties of their surroundings. However, this form of active thermography introduces large signal variations compared to traditional active thermography, which has typically been used to characterize small regions of materials in carefully controlled settings. We demonstrate that a data-driven approach with modern machine learning methods can be used to classify material samples over relatively large surface areas and variable distances. We also introduce the use of z-normalization to improve material classification and reduce variation due to distance and heating intensity. Our best performing algorithm achieved an overall accuracy of 77.7% for multi-class classification among 12 materials placed at varying distances (20 cm, 30 cm, and 40 cm). The observations were made for 5 seconds with 1s of heating and 4s of cooling. We also provide a demonstration of performance with a multi-material scene.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594469","","Heating systems;Cameras;Heat transfer;Robot sensing systems;Surface treatment","image classification;infrared imaging;learning (artificial intelligence);temperature measurement","multimaterial scene;varying distances;multiclass classification;heating intensity;material classification;variable distances;relatively large surface areas;modern machine learning methods;data-driven approach;signal variations;thermal camera;heat lamp;size 20.0 cm;size 40.0 cm;size 30.0 cm;time 4.0 s;time 5.0 s;time 1.0 s","","","46","","","","","IEEE","IEEE Conferences"
"Development of Master-slave Type Lower Limb Motion Teaching System","T. Tagami; T. Kawase; D. Morisaki; R. Miyazaki; T. Miyazaki; T. Kanno; K. Kawashima","Department of Bioscience and Engineering, College of Systems Engineering and Science, Shibaura Institute of Technology, 307 Fukasaku, Minuma-ku, Saitama City, Saitama, 337-8570, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, 2-3-10 Kandasurugadai, Chiyoda-ku, Tokyo, 101-0062, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, 2-3-10 Kandasurugadai, Chiyoda-ku, Tokyo, 101-0062, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, 2-3-10 Kandasurugadai, Chiyoda-ku, Tokyo, 101-0062, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, 2-3-10 Kandasurugadai, Chiyoda-ku, Tokyo, 101-0062, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, 2-3-10 Kandasurugadai, Chiyoda-ku, Tokyo, 101-0062, Japan; Institute of Biomaterials and Bioengineering, Tokyo Medical and Dental University, 2-3-10 Kandasurugadai, Chiyoda-ku, Tokyo, 101-0062, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2762","2767","Motor skill learning is fundamental in many physical activities of human. In the processes of learning of motor skills, learners often receive visual or physical information about postures from teachers. However, the information about postures usually cannot be transmitted precisely. In this paper, we propose a motion teaching system to transmit teachers' motion to learners directly by using a motion capture and an assist suit. The assist suit, which has a pneumatic artificial rubber muscle (PARM) as an actuator, was designed to move a learner's hip joint with less loss of assistive force and less constraint of motion. Hip joint motion of a teacher can be transmitted to the assist suit by master-slave control. In addition, to compensate the delay of the PARM, posture of the teacher is predicted before the occurence by a recurrent neural network by using electromyogram signals and the past joint angle. We confirmed the system can transmit a teacher's motion to a learner in real time, and with the neural network, the delay of the learner's motion could be suppressed to approximately 0.1s, which is enough to feel visual and physical information synchronous. Therefore, the proposed motion teaching system would have the ability to transmit teachers' motion to learners visually and physically with precision sufficient to facilitate skill transmission.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593737","","Hip;Education;Visualization;Force;Neural networks;Delays;Belts","control engineering computing;electromyography;medical robotics;motion control;pneumatic actuators;recurrent neural nets;robot vision;teaching","pneumatic artificial rubber muscle;PARM;assistive force;hip joint motion;master-slave type lower limb motion teaching system;motor skill learning;physical activities;teachers motion;recurrent neural network;electromyogram signals;learners motion","","","16","","","","","IEEE","IEEE Conferences"
"Optimizing Scan Homogeneity for Building Full-3D Lidars Based on Rotating a Multi-Beam Velodyne Range-Finder","A. Mandow; J. Morales; J. A. Gomez-Ruiz; A. J. García-Cerezo","Andalucía Tech Universidad de Málaga, Robotics and Mechatronics Lab, Málaga, 29071, Spain; Andalucía Tech Universidad de Málaga, Robotics and Mechatronics Lab, Málaga, 29071, Spain; Andalucía Tech Universidad de Málaga, Robotics and Mechatronics Lab, Málaga, 29071, Spain; Andalucía Tech Universidad de Málaga, Robotics and Mechatronics Lab, Málaga, 29071, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4788","4793","Multi-beam lidar (MBL) scanners are compact, light, and accessible 3D sensors with high data rates, but they offer limited vertical resolution and field of view (FOV). Some recent robotics research has profited from the addition of a degree-of-freedom (DOF) to an MBL to build rotating multibeam lidars (RMBL) that can achieve high-resolution scans with full spherical FOV. In a previous work, we offered a methodology to analyze the complex 3D scan measurement distributions produced by RMBLs with a rolling DOF and no pitching. In this paper, we investigate the effect of introducing constant pitch angles in the construction of the RMBLs with the purpose of finding a kinematic configuration that optimizes scan homogeneity with a spherical FOV. To this end, we propose a scalar index of 3D sensor homogeneity that is based on the spherical formulation of Ripley's K function. The optimization is performed for the widely used Puck (VLP-16) and HDL-32 sensors by Velodyne.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593916","","Three-dimensional displays;Laser radar;Indexes;Kinematics;Robot sensing systems","image sensors;object detection;optical radar;optical scanners","scan homogeneity;3D sensor homogeneity;spherical formulation;HDL-32 sensors;building full-3D lidars;robotics research;constant pitch angles;rolling DOF;RMBLs;complex 3D scan measurement distributions;spherical FOV;high-resolution scans;rotating multibeam lidars;degree-of-freedom;vertical resolution;high data rates;accessible 3D sensors;MBL;multibeam lidar scanners;multibeam Velodyne range-finder","","","16","","","","","IEEE","IEEE Conferences"
"Real-time Convolutional Networks for Depth-based Human Pose Estimation","A. Martínez-González; M. Villamizar; O. Canévet; J. Odobez","Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","41","47","We propose to combine recent Convolutional Neural Networks (CNN) models with depth imaging to obtain a reliable and fast multi-person pose estimation algorithm applicable to Human Robot Interaction (HRI) scenarios. Our hypothesis is that depth images contain less structures and are easier to process than RGB images while keeping the required information for human detection and pose inference, thus allowing the use of simpler networks for the task. Our contributions are threefold. (i) we propose a fast and efficient network based on residual blocks (called RPM) for body landmark localization from depth images; (ii) we created a public dataset DIH comprising more than 170k synthetic images of human bodies with various shapes and viewpoints as well as real (annotated) data for evaluation; (iii) we show that our model trained on synthetic data from scratch can perform well on real data, obtaining similar results to larger models initialized with pre-trained networks. It thus provides a good trade-off between performance and computation. Experiments on real data demonstrate the validity of our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593383","","Feature extraction;Pose estimation;Computational modeling;Three-dimensional displays;Shape;Detectors;Cameras","convolutional neural nets;feature extraction;human-robot interaction;image colour analysis;inference mechanisms;learning (artificial intelligence);pose estimation","convolutional neural networks models;human robot interaction;depth-based human pose estimation;pose inference;residual blocks;body landmark localization;depth imaging;human bodies;human detection;RGB images","","","32","","","","","IEEE","IEEE Conferences"
"Slip Modeling and Estimation for a Planetary Exploration Rover: Experimental Results from Mt. Etna","K. Bussmann; L. Meyer; F. Steidle; A. Wedler","Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Institute of Robotics and Mechatronics, German Aerospace Center (DLR)","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2449","2456","For wheeled mobile systems, the wheel odometry is an important source of information about the current motion of the vehicle. It is used e.g. in the context of pose estimation and self-localization of planetary rovers, which is a crucial part of the success of planetary exploration missions. Depending on the wheel-soil interaction properties, wheel odometry measurements are subject to inherent errors such as wheel slippage. In this paper, a parameter-based approach for whole-body slip modeling and calibration is applied to a four-wheeled lightweight rover system. Details on the method for slip parameter calibration as well as the system-specific implementation are given. Experimental results from a test campaign on Mt. Etna are presented, showing significant improvements of the resulting wheel odometry measurements. The results are validated during a long range drive of approx. 900 m and discussed w. r. t. the advantages but also limitations of the method within a space exploration scenario.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594294","","Wheels;Jacobian matrices;Trajectory;Current measurement;Extraterrestrial measurements;Soil;Mathematical model","aerospace robotics;mobile robots;planetary rovers;position control;wheels","wheel-soil interaction properties;inherent errors;wheel slippage;parameter-based approach;whole-body slip modeling;lightweight rover system;slip parameter calibration;system-specific implementation;experimental results;Mt. Etna;resulting wheel odometry measurements;space exploration scenario;planetary exploration rover;wheeled mobile systems;planetary rovers;planetary exploration missions","","","24","","","","","IEEE","IEEE Conferences"
"Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition","P. Yin; L. Xu; Z. Liu; L. Li; H. Salman; Y. He; W. Xu; H. Wang; H. Choset","State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; Robotics Institute at Carnegie Mellon University, Pittsburgh, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, USA; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Department of Mechanical Engineering, University of Auckland, New Zealand; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Robotics Institute at Carnegie Mellon University, Pittsburgh, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1162","1167","Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593562","","Octrees;Laser radar;Task analysis;Decoding;Simultaneous localization and mapping;Generative adversarial networks","entropy;feature extraction;geometry;image matching;image recognition;learning (artificial intelligence);mobile robots;octrees;optical radar;robot vision;unsupervised learning","Generative Adversarial Network;adversarial feature;place recognition;global geometry map;Conditional Entropy Reduction module;unsupervised place feature;local 2D maps;dynamic octree mapping module;core modules;LiDAR inputs;end-to-end feature;geometry matching;traditional methods;LiDAR-based place recognition;unsupervised feature learning;feature size;place recognition task;North Campus Long-Term LiDAR dataset;feature learning process;place feature learning","","","22","","","","","IEEE","IEEE Conferences"
"Robust Odometry using Sensor Consensus Analysis","A. W. Palmer; N. Nourani-Vatani","Siemens AG, Berlin, Germany; Siemens AG, Berlin, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3167","3173","Odometry forms an important component of many manned and autonomous systems. In the rail industry in particular, having precise and robust odometry is crucial for the correct operation of the Automatic Train Protection systems that ensure the safety of high-speed trains in operation around the world. Two problems commonly encountered in such odometry systems are miscalibration of the wheel encoders and slippage of the wheels under acceleration and braking, resulting in incorrect velocity estimates. This paper introduces an odometry system that addresses these problems. It comprises of an Extended Kalman Filter that tracks the calibration of the wheel encoders as state variables, and a measurement pre-processing stage called Sensor Consensus Analysis (SCA) that scales the uncertainty of a measurement based on how consistent it is with the measurements from the other sensors. SCA uses the statistical z-test to determine when an individual measurement is inconsistent with the other measurements, and scales the uncertainty until the z-test passes. This system is demonstrated on data from German Intercity-Express highspeed trains and it is shown to successfully deal with errors due to miscalibration and wheel slip.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594473","","Wheels;Robot sensing systems;Acceleration;Measurement uncertainty;Global Positioning System;Extraterrestrial measurements;Length measurement","calibration;distance measurement;Kalman filters;measurement uncertainty;nonlinear filters;sensors;statistical testing","odometry system;measurement pre-processing stage;sensor consensus analysis;German Intercity-Express highspeed trains;wheel slip;autonomous systems;rail industry;extended Kalman filter;automatic train protection systems;incorrect velocity estimation;robust odometry systems;wheel encoder miscalibration;wheel slippage;wheel encoder calibration;SCA;statistical z-testing;measurement uncertainty","","1","20","","","","","IEEE","IEEE Conferences"
"Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds","J. Stria; V. Hlavác","Robotics and Cybernetics at the Czech Technical University in Prague, Czech Institute of Informatics, Czech Republic; Robotics and Cybernetics at the Czech Technical University in Prague, Czech Institute of Informatics, Czech Republic","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5307","5312","The presented work deals with classification of garment categories including pants, shorts, shirts, T-shirts and towels. The knowledge of the garment category is crucial for its robotic manipulation. Our work focuses particularly on garments being held in a hanging state by a robotic arm. The input of our method is a set of depth maps taken from different viewpoints around the garment. The depths are fused into a single 3D point cloud. The cloud is fed into a convolutional neural network that transforms it into a single global feature vector. The network utilizes a generalized convolution operation defined over the local neighborhood of a point. It can deal with permutations of the input points. It was trained on a large dataset of common 3D objects. The extracted feature vector is classified with SVM trained on smaller datasets of garments. The proposed method was evaluated on publicly available data and compared to the original methods, achieving competitive performance and better generalization capability.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593741","","Clothing;Three-dimensional displays;Feature extraction;Robot sensing systems;Convolution;Image reconstruction","clothing;computer graphics;control engineering computing;convolutional neural nets;feature extraction;image classification;manipulators;neurocontrollers;robot vision;service robots;support vector machines","3D objects;feature vector extraction;t-shirts;hanging garments classification;3D point clouds;SVM;generalized convolution operation;single global feature vector;convolutional neural network;depth maps;robotic arm;hanging state;robotic manipulation;garment category","","","27","","","","","IEEE","IEEE Conferences"
"Performance of an IMU-Based Sensor Concept for Solving the Direct Kinematics Problem of the Stewart-Gough Platform","S. Schulz; A. Seibel; J. Schlattmann","Workgroup on System Technologies and Engineering Design Methodology, Hamburg University of Technology, Hamburg, 21073, Germany; Workgroup on System Technologies and Engineering Design Methodology, Hamburg University of Technology, Hamburg, 21073, Germany; Workgroup on System Technologies and Engineering Design Methodology, Hamburg University of Technology, Hamburg, 21073, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5055","5062","The direct kinematics problem of the Stewart-Gough platform can be solved by measuring the manipulator platform's orientation and two of the linear actuators' orientations instead of the six linear actuators' lengths. In this paper, the effect of measurement errors on the calculated manipulator platform's pose is investigated using the Cramer-Ran lower bound and extensive experiments on a state-of-the-art Stewart-Gough platform. Furthermore, different algorithms and filters for one-time as well as continuous pose determinations are investigated. Finally, possible sensor fusion concepts for the one-time pose determination are presented to increase the robustness against noise and measurement errors.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594039","","Manipulators;Actuators;Kinematics;Standards;Measurement errors;Accelerometers;Sensor fusion","actuators;manipulator kinematics;pose estimation;sensor fusion","IMU-based sensor concept;direct kinematics problem;linear actuators;measurement errors;calculated manipulator platform;state-of-the-art Stewart-Gough platform;one-time pose determination;robustness;sensor fusion concepts","","","20","","","","","IEEE","IEEE Conferences"
"Closed form solution for Rotation Estimation using Photometric Spherical Moments","H. Hadj-Abdelkader; O. Tahri; H. Benseddik","IBISC lab. EA 4526, University of Evry-Val-d'Essonne-Paris Saclay, France; INSA Centre Val de Loire, PRISME lab. EA 4229, University of Orleans, Bourges, France; MIS lab. EA 4290, University of Picardie Jules Verne, Amiens, 80039","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","627","634","This paper presents new schemes to estimate 3D rotation from spherical images. Unlike existing approaches, spherical moment properties are exploited to obtain a closed form solution without iteratively mimimizing a cost function. Actually, three methods using spherical moments are proposed: two of them can be classified as dense approaches, while the third one is hybrid combining geometrical features with dense ones. Experimental results using both synthetic images and acquired images using catadioptric cameras with different scenarios show the effectiveness of our approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593920","","Cameras;Estimation;Three-dimensional displays;Visual servoing;Closed-form solutions;Motion estimation","cameras;motion estimation;photometry","3D rotation estimation;geometrical features;catadioptric camera;synthetic images;cost function;spherical moment properties;spherical images;photometric spherical moments","","","32","","","","","IEEE","IEEE Conferences"
"The benefits and challenges of robotics in the mineral raw materials sector - an overview","L. Lopes; T. Miklovicz; E. Bakker; Z. Milosevic","La Palma Research Centre, Garafia, 37878, Spain; La Palma Research Centre, Garafia, 37878, Spain; La Palma Research Centre, Garafia, 37878, Spain; Centre for Automation and Robotics (CAR), Universidad Politecnica de Madrid, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1507","1512","Robotics applications in the raw materials sector are becoming increasingly common due to their many perceived benefits. In mining, the extended use of robotics is especially seen in the exploration and exploitation phases, where mineral resources are discovered, extracted and processed. The use of robotics in the mining industry started in the 60s and today it is seen in the automation of material transport or in robotic digging and loading. Potential benefits include improved productivity, decreased production costs, better operational efficiency, increased safety, reduced waste and, ultimately, more value creation. The increasing amount of robotics used in the raw materials sector is coupled with a series of ethical and legal issues, regulatory challenges and policy requirements that affect both producers and end-users of robotic technologies. The benefits and challenges of robotics applications, often overlooked by the stakeholders, can hinder both their integration in the sector and the further development of mining activities, if not properly addressed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594218","","Service robots;Minerals;Productivity;Fuel processing industries;Robot sensing systems;Raw materials","industrial robots;mineral processing industry;mining industry;raw materials","mineral raw materials sector;material transport;robotic digging;robotic loading;mining industry","","","26","","","","","IEEE","IEEE Conferences"
"Comparison of Multimodal Heading and Pointing Gestures for Co-Located Mixed Reality Human-Robot Interaction","D. Krupke; F. Steinicke; P. Lubos; Y. Jonetzko; M. Görner; J. Zhang","Department of Informatics, Group Human Computer Interaction (HCI), University of Hamburg, Germany; Department of Informatics, Group Human Computer Interaction (HCI), University of Hamburg, Germany; Department of Informatics, Group Human Computer Interaction (HCI), University of Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), University of Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), University of Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), University of Hamburg, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Mixed reality (MR)opens up new vistas for human-robot interaction (HRI)scenarios in which a human operator can control and collaborate with co-located robots. For instance, when using a see-through head-mounted-display (HMD)such as the Microsoft HoloLens, the operator can see the real robots and additional virtual information can be superimposed over the real-world view to improve security, acceptability and predictability in HRI situations. In particular, previewing potential robot actions in-situ before they are executed has enormous potential to reduce the risks of damaging the system or injuring the human operator. In this paper, we introduce the concept and implementation of such an MR human-robot collaboration system in which a human can intuitively and naturally control a co-located industrial robot arm for pick-and-place tasks. In addition, we compared two different, multimodal HRI techniques to select the pick location on a target object using (i)head orientation (aka heading)or (ii)pointing, both in combination with speech. The results show that heading-based interaction techniques are more precise, require less time and are perceived as less physically, temporally and mentally demanding for MR-based pick-and-place scenarios. We confirmed these results in an additional usability study in a delivery-service task with a multi-robot system. The developed MR interface shows a preview of the current robot programming to the operator, e. g., pick selection or trajectory. The findings provide important implications for the design of future MR setups.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594043","","Virtual reality;Service robots;Task analysis;Collaboration;Visualization;Manipulators","control engineering computing;helmet mounted displays;human-robot interaction;intelligent robots;mobile robots;multi-robot systems;service robots;user interfaces;virtual reality","multimodal heading;pointing gestures;human operator;co-located robots;head-mounted-display;HRI situations;enormous potential;MR human-robot collaboration system;industrial robot arm;multimodal HRI techniques;heading-based interaction techniques;multirobot system;current robot programming;human-robot interaction scenarios;virtual information;pick-and-place scenarios;potential robot actions;co-located mixed reality human-robot interaction;Microsoft HoloLens","","","26","","","","","IEEE","IEEE Conferences"
"On the Kinematics of Wheeled Motion Control of a Hybrid Wheeled-Legged CENTAURO robot","M. Kamedula; N. Kashiri; N. G. Tsagarakis","Department of Advanced Robotics, Istituto Italiano di Technologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Technologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Technologia, Via Morego 30, Genoa, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2426","2433","Legged-wheeled robots combine the advantages of efficient wheeled mobility with the adaptability to real-world terrains through the legged locomotion. Due to this hybrid mobility skill, they can excel in many application scenarios where other mobile platforms are not suitable for. However, their versatile mobility increases the number of constraints in their motion control where both the properties of legged and wheeled systems need to be considered. Relevant schemes for legged-wheeled platforms so far have been developed exploiting separate motion control of the wheeled and legged functionalities. This paper discusses the legged-wheeled motion kinematics without constraining the camber angles of the wheels, and it proposes a first-order inverse kinematics scheme that stabilizes the legged-wheeled system in the wheeled motion. Furthermore, the work adopts a floating base model that allows to easily incorporate the legged motion to the scheme. The developed controller is tested in simulation and experiments on a legged-wheeled centaur-like robot - CENTAURO.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594222","","Legged locomotion;Wheels;Kinematics;Robot kinematics;Solid modeling","legged locomotion;motion control;robot kinematics;stability;wheels","wheeled-legged CENTAURO robot;real-world terrains;mobile platforms;versatile mobility;first-order inverse kinematics scheme;wheeled mobility;legged-wheeled motion kinematics control;wheels camber angles;legged-wheeled system stability;floating base model;legged-wheeled centaur-like robot","","1","22","","","","","IEEE","IEEE Conferences"
"Multi-Cable Rolling Locomotion with Spherical Tensegrities Using Model Predictive Control and Deep Learning","B. Cera; A. M. Agogino","Berkeley, Mechanical Engineering Department, The University of California, CA, 94720, USA; Berkeley, Mechanical Engineering Department, The University of California, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This work presents a model-based approach for creating robust control policies for rolling locomotion with a spherical tensegrity topology. Utilizing the structured dynamics of Class-1 tensegrity systems, we turn to model predictive control (MPC) to generate optimal multi-cable actuation trajectories for dynamic rolling. Although the resulting multi-cable state-action trajectories successfully outperform the benchmark single-cable policy performance in speed, computational constraints prevent MPC from being applied in real-time. To address this, we demonstrate that a contextual policy trained using supervised deep learning on the generated optimal MPC trajectories can be used as an end-to-end feedback policy for real-time directed rolling locomotion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594401","","Mathematical model;Predictive control;Topology;Robot kinematics;Dynamics;Optimization","actuators;cables (mechanical);differential equations;feedback;learning (artificial intelligence);open loop systems;predictive control;robust control;trajectory control","generated optimal MPC trajectories;supervised deep learning;contextual policy;benchmark single-cable policy performance;resulting multicable state-action trajectories;dynamic rolling;multicable actuation trajectories;Class-1 tensegrity systems;structured dynamics;spherical tensegrity topology;robust control policies;model-based approach;model predictive control;spherical tensegrities;multicable rolling locomotion;end-to-end feedback policy","","","16","","","","","IEEE","IEEE Conferences"
"Safety-Related Tasks Within the Set-Based Task-Priority Inverse Kinematics Framework","P. Di Lillo; F. Arrichiello; G. Antonelli; S. Chiaverini","Department of Electrical and Information Engineering, The University of Cassino and Southern Lazio, Via G. Di Biasio 43, Cassino (FR), 03043, Italy; Department of Electrical and Information Engineering, The University of Cassino and Southern Lazio, Via G. Di Biasio 43, Cassino (FR), 03043, Italy; Department of Electrical and Information Engineering, The University of Cassino and Southern Lazio, Via G. Di Biasio 43, Cassino (FR), 03043, Italy; Department of Electrical and Information Engineering, The University of Cassino and Southern Lazio, Via G. Di Biasio 43, Cassino (FR), 03043, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6130","6135","In this paper we present a framework that allows the motion control of a robotic arm automatically handling different kinds of safety-related tasks. The developed controller is based on a Task-Priority Inverse Kinematics algorithm that allows the manipulator's motion while respecting constraints defined either in the joint or in the operational space in the form of equality-based or set-based tasks. This gives the possibility to define, among the others, tasks as joint-limits, obstacle avoidance or limiting the workspace in the operational space. Additionally, an algorithm for the real-time computation of the minimum distance between the manipulator and other objects in the environment using depth measurements has been implemented, effectively allowing obstacle avoidance tasks. Experiments with a Jaco<sup>2</sup> manipulator, operating in an environment where an RGB-D sensor is used for the obstacles detection, show the effectiveness of the developed system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593884","","Task analysis;Manipulators;Robot sensing systems;Kinematics;Collision avoidance;Safety","collision avoidance;manipulator kinematics;mobile robots;motion control","equality-based task;task-priority inverse kinematics algorithm;set-based task-priority inverse kinematics framework;Jaco2 manipulator;RGB-D sensor;obstacle detection;obstacle avoidance tasks;joint-limits;set-based tasks;operational space;robotic arm;motion control;safety-related tasks","","1","24","","","","","IEEE","IEEE Conferences"
"Plenoptic Monte Carlo Object Localization for Robot Grasping Under Layered Translucency","Z. Zhou; Z. Sui; O. C. Jenkins","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","In order to fully function in human environments, robot perception needs to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL)as a method for localizing object poses in the presence of translucency using plenoptic (light-field)observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593629","","Three-dimensional displays;Cameras;Glass;Monte Carlo methods;Pose estimation;Robot sensing systems","approximation theory;cameras;Gaussian distribution;image colour analysis;manipulators;Monte Carlo methods;robot vision","stained glass panels;object poses;Monte Carlo object localization algorithm;localizing objects;manipulating objects;translucent materials;Lytro first generation light field camera;robot grasping;layered translucency;human environments;robot perception;open challenges;transparent objects;drinking glasses;refractive media;partial occlusions;Michigan progress fetch robot;plenoptic Monte Carlo object localization;depth likelihood volume;PMCL","","","30","","","","","IEEE","IEEE Conferences"
"Impedance Based Force Control for Aerial Robot Peg-in-Hole Insertion Tasks","M. Car; A. Ivanovic; M. Orsag; S. Bogdan","University of Zagreb, Authors are with Faculty of Electrical and Computer Engineering, Zagreb, Croatia, 10000; University of Zagreb, Authors are with Faculty of Electrical and Computer Engineering, Zagreb, Croatia, 10000; University of Zagreb, Authors are with Faculty of Electrical and Computer Engineering, Zagreb, Croatia, 10000; University of Zagreb, Authors are with Faculty of Electrical and Computer Engineering, Zagreb, Croatia, 10000","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6734","6739","This paper demonstrates the experimental validation of canonical peg-in-hole manipulation task using an aerial robot. The robot consists of a multirotor platform equipped with a dual arm multi degree of freedom manipulator. The paper discusses the introduced kinematic constraints which make sure the robot holds a bolt with both arms. We build our peg-in-hole approach using impedance control which is the foundation of compliant interaction with the environment. We utilize a finite state automaton to plan a multi stage strategy which relies on tactile perception in order to pin point the target. Finally, the whole body locomotion is considered, meaning both the degrees of freedom of multirotor base and the dual arm manipulator are considered.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593808","","Force;Impedance;Task analysis;Manipulator dynamics;Rotors;Kinematics","aerospace robotics;force control;manipulator kinematics;mobile robots;motion control;rotors","whole body locomotion;tactile perception;finite state automaton;aerial robot peg-in-hole insertion tasks;impedance based force control;dual arm multidegree of freedom manipulator;kinematic constraints;dual arm manipulator;multirotor base;multistage strategy;impedance control;peg-in-hole approach;multirotor platform;canonical peg-in-hole manipulation task","","","19","","","","","IEEE","IEEE Conferences"
"Optimization-based Design and Analysis of Planar Rotary Springs","N. Georgiev; J. Burdick","Mechanical and Civil Engineering, California Inst. of Tech., Pasadena, CA, USA; Mechanical and Civil Engineering, California Inst. of Tech., Pasadena, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","927","934","This paper develops new methods to design high performance rotary series elastic actuator springs for robotics applications. The approach is based on a spring arm mathematical model that was previously introduced by the authors. The key contribution is the development of an optimization-based design method which maximizes the springs' overall torque density through optimization of the arm profile. An improved analysis algorithm allows for rapid torsional loading response simulation with possible internal contacts between the spring arms. The proposed design and analysis algorithms are validated through FEA and prototype mechanical testing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594186","","Springs;Strain;Stress;Mathematical model;Robots;Actuators;Optimization","actuators;finite element analysis;optimisation;robots;springs (mechanical);torque;torsion","rotary series elastic actuator springs;rapid torsional loading;FEA;mechanical testing;planar rotary springs;optimization-based design method;robotics applications","","","10","","","","","IEEE","IEEE Conferences"
"Contingent Contact-Based Motion Planning","E. Páll; A. Sieverling; O. Brock","Technische Universität Berlin, Robotics and Biology Laboratory, Germany; Technische Universität Berlin, Robotics and Biology Laboratory, Germany; Technische Universität Berlin, Robotics and Biology Laboratory, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6615","6621","A robot with contact sensing capability can reduce uncertainty relative to the environment by deliberately moving into contact and matching the resulting contact measurement to different possible states in the world. We present a manipulation planner that finds and sequences these actions by reasoning explicitly about the uncertainty over the robot's state. The planner incrementally constructs a policy that covers all possible contact states during a manipulation and finds contingencies for each of them. In contrast to conformant planners (without contingencies), the planned contingent policies are more robust. We demonstrate this in simulated and real-world manipulation experiments. In contrast to POMDP-based planners, we show that our planner can be directly applied to high-dimensional configuration spaces.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594365","","Robot sensing systems;Uncertainty;Planning;Partitioning algorithms;Vegetation","manipulators;mobile robots;path planning;robust control","POMDP-based planners;contingent contact-based motion planning;contact sensing capability;manipulation planner;conformant planners;high-dimensional configuration spaces","","","29","","","","","IEEE","IEEE Conferences"
"CINet: A Learning Based Approach to Incremental Context Modeling in Robots","F. Irmak Doğan; İ. Bozcan; M. Çelik; S. Kalkan","Department of Computer Engineering, KOVAN Research Lab, Middle East Technical University, Ankara, Turkey; Department of Computer Engineering, KOVAN Research Lab, Middle East Technical University, Ankara, Turkey; Department of Computer Engineering, KOVAN Research Lab, Middle East Technical University, Ankara, Turkey; Department of Computer Engineering, KOVAN Research Lab, Middle East Technical University, Ankara, Turkey","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4641","4646","There have been several attempts at modeling context in robots. However, either these attempts assume a fixed number of contexts or use a rule-based approach to determine when to increment the number of contexts. In this paper, we pose the task of when to increment as a learning problem, which we solve using a Recurrent Neural Network. We show that the network successfully (with 98% testing accuracy) learns to predict when to increment, and demonstrate, in a scene modeling problem (where the correct number of contexts is not known), that the robot increments the number of contexts in an expected manner (i.e., the entropy of the system is reduced). We also present how the incremental model can be used for various scene reasoning tasks.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593633","","Context modeling;Training;Robots;Computational modeling;Resource management;Recurrent neural networks;Testing","learning (artificial intelligence);recurrent neural nets;robots","incremental context modeling;robots;rule-based approach;recurrent neural network;CINet;learning based approach;scene reasoning tasks","","","26","","","","","IEEE","IEEE Conferences"
"Design of an Autonomous Robot for Mapping, Navigation, and Manipulation in Underground Mines","R. Lösch; S. Grehl; M. Donner; C. Buhl; B. Jung","Institute of Computer Science, Technical University Bergakademie Freiberg, Akademiestraße 6, Freiberg, 09599, Germany; Institute of Computer Science, Technical University Bergakademie Freiberg, Akademiestraße 6, Freiberg, 09599, Germany; Institute of Geomonitoring and Mine Surveying, Technical University Bergakademie Freiberg, Akademiestraße 6, Freiberg, 09599, Germany; Institute of Computer Science, Technical University Bergakademie Freiberg, Akademiestraße 6, Freiberg, 09599, Germany; Institute of Computer Science, Technical University Bergakademie Freiberg, Akademiestraße 6, Freiberg, 09599, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1407","1412","Underground mines are a dangerous working environment and, therefore, robots could help putting less humans at risk. Traditional robots, sensors, and software often do not work reliably underground due to the harsh environment. This paper analyzes requirements and presents a robot design capable of navigating autonomously underground and manipulating objects with a robotic arm. The robot's base is a robust four wheeled platform powered by electric motors and able to withstand the harsh environment. It is equipped with color and depth cameras, lighting, laser scanners, an inertial measurement unit, and a robotic arm. We conducted two experiments testing mapping and autonomous navigation. Mapping a 75 meters long route including a loop closure results in a map that qualitatively matches the original map to a good extent. Testing autonomous driving on a previously created map of a second, straight, 150 meters long route was also successful. However, without loop closure, rotation errors cause apparent deviations in the created map. These first experiments showed the robot's operability underground.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594190","","Robot sensing systems;Manipulators;Cameras;Navigation;Mobile robots","cameras;inertial systems;manipulators;mining;mobile robots;robot vision;sensors","autonomous driving;autonomous robot;manipulation;underground mines;dangerous working environment;harsh environment;robot design;underground objects;manipulating objects;robotic arm;robust four wheeled platform;depth cameras;inertial measurement unit;autonomous navigation","","","16","","","","","IEEE","IEEE Conferences"
"Generation of Context-Dependent Policies for Robot Rescue Decision-Making in Multi-Robot Teams","S. Al-Hussaini; J. M. Gregory; S. K. Gupta","Viterbi School of Engineering, University of Southern California, CA, USA; U.S. Army Research Laboratory, Adelphi, MD, USA; Viterbi School of Engineering, University of Southern California, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4317","4324","We propose a scalable, parallelizable policy synthesis framework intended for a robot presented with the decision of exploration or rescue, given some time-varying, stochastic mission conditions, referred to as context. We demonstrate the feasibility of such a solution using physics-based simulations to synthesize a policy in a computationally-efficient manner and exhibit superior performance with regards to the minimization of probability of mission failure when compared to two feasible baseline approaches. Furthermore, we present preliminary results that suggest our approach is robust to errors in the state estimation used to build mission context, which further supports the notion of real-world applicability.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594114","","Robots;Task analysis;Computational modeling;State estimation;Probabilistic logic;Switches;Navigation","decision making;multi-robot systems;probability;rescue robots;robust control;state estimation","computationally-efficient manner;feasible baseline approaches;context-dependent policies;robot rescue decision-making;multirobot teams;scalable policy synthesis framework;parallelizable policy synthesis framework;time-varying;stochastic mission conditions;physics-based simulations;probability minimization;state estimation","","","20","","","","","IEEE","IEEE Conferences"
"Efficient Computation of Invariably Safe States for Motion Planning of Self-Driving Vehicles","C. Pek; M. Althoff","Department of Computer Science, Technical University of Munich, Garching, D-85748, Germany; Department of Computer Science, Technical University of Munich, Garching, D-85748, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3523","3530","Safe motion planning requires that a vehicle reaches a set of safe states at the end of the planning horizon. However, safe states of vehicles have not yet been systematically defined in the literature, nor does a computationally efficient way to obtain them for online motion planning exist. To tackle the aforementioned issues, we introduce invariably safe sets. These are regions that allow vehicles to remain safe for an infinite time horizon. We show how invariably safe sets can be computed and propose a tight under-approximation which can be obtained efficiently in linear time with respect to the number of traffic participants. We use invariably safe sets to lift safety verification from finite to infinite time horizons. In addition, our sets can be used to determine the existence of feasible evasive maneuvers and the criticality of scenarios by computing the time-to-react metric.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593597","","Trajectory;Planning;Safety;Dynamics;Vehicle dynamics;Measurement;Reachability analysis","collision avoidance;Markov processes;road vehicles;stochastic systems","self-driving vehicles;planning horizon;infinite time horizon;time-to-react metric;motion planning","","","40","","","","","IEEE","IEEE Conferences"
"Depth Estimation of Optically Transparent Microrobots Using Convolutional and Recurrent Neural Networks","M. Grammatikopoulou; L. Zhang; G. Yang","Imperial College London, Hamlyn Centre for Robotic Surgery, London, United Kingdom; Imperial College London, Hamlyn Centre for Robotic Surgery, London, United Kingdom; Imperial College London, Hamlyn Centre for Robotic Surgery, London, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4895","4900","Estimating the three-dimensional (3D) position of microrobots is necessary in order to develop closed-loop control techniques and to improve the user's 3D perception in the micro-scale. This paper describes a depth estimation method based on supervised learning for optically transparent microrobots of known geometry. The proposed methodology uses Convolutional Neural Networks (CNNs) combined with a Recurrent Network, in particular a Long Short-Term Memory (LSTM) cell for depth regression. The proposed depth regression model is independent of the 3D orientation of the microrobot and is robust to varying illumination levels while it uses learned data-specific features. The model is trained and validated using microscope images and ground truth data generated from 3D-printed microrobots imaged in an Optical Tweezers (OT) setup. The validation results demonstrate that the proposed trained model can reconstruct the depth of the microrobot independently of its 3D orientation with submicron accuracy for the test set.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593776","","Three-dimensional displays;Estimation;Solid modeling;Optical imaging;Lighting;Data models;Microscopy","closed loop systems;convolutional neural nets;learning (artificial intelligence);microrobots;neurocontrollers;pose estimation;position control;recurrent neural nets;regression analysis;robot vision;three-dimensional printing","optically transparent microrobots;closed-loop control techniques;depth estimation method;supervised learning;depth regression model;3D-printed microrobots;recurrent neural networks;convolutional neural networks;optical tweezers setup;three-dimensional position estimation;long short-term memory cell","","","14","","","","","IEEE","IEEE Conferences"
"Automatic Calibration of Multiple Cameras and Depth Sensors with a Spherical Target","J. Kümmerle; T. Kühner; M. Lauer","Research Department “Mobile Perception Systems”, FZI Research Center for Information Technology, Karlsruhe, Germany; Research Department “Mobile Perception Systems”, FZI Research Center for Information Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute of Measurement and Control Systems, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","In this work we present a novel approach for multi-sensor calibration that significantly outperforms current state-of-the-art. We introduce a new spherical calibration target which has major benefits over existing targets. Those are subresolution detection accuracy in both camera and depth sensor, view invariance and applicability to a wider range of sensor setups than current approaches. With our method a single person achieves high quality calibration in less than a minute. No preparations for setting up the environment for calibration is needed. Our method is fast, easy to use and fully automatic. We evaluate our method in simulation and show high accuracy with an error of less than 3mm in translation and 0.1 0 in rotation on real data.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593955","","Calibration;Cameras;Image edge detection;Laser radar;Three-dimensional displays;Detectors","calibration;cameras;sensor fusion;spatial variables measurement","automatic calibration;multisensor calibration;spherical calibration target;subresolution detection accuracy;camera;depth sensor","","","22","","","","","IEEE","IEEE Conferences"
"Dual-arm robotic manipulation of flexible cables","J. Zhu; B. Navarro; P. Fraisse; A. Crosnier; A. Cherubini","LIRMM, Université de Montpellier, CNRS, Montpellier, France; LIRMM, Université de Montpellier, CNRS, Montpellier, France; LIRMM, Université de Montpellier, CNRS, Montpellier, France; LIRMM, Université de Montpellier, CNRS, Montpellier, France; LIRMM, Université de Montpellier, CNRS, Montpellier, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","479","484","Deforming a cable to a desired (reachable) shape is a trivial task for a human to do without even knowing the internal dynamics of the cable. This paper proposes a framework for cable shapes manipulation with multiple robot manipulators. The shape is parameterized by a Fourier series. A local deformation model of the cable is estimated on-line with the shape parameters. Using the deformation model, a velocity control law is applied on the robot to deform the cable into the desired shape. Experiments on a dual-arm manipulator are conducted to validate the framework.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593780","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593780","","Shape;Strain;Power cables;Deformable models;Manipulators;Task analysis","cables (mechanical);deformation;Fourier series;manipulator dynamics;manipulators;mobile robots;multi-robot systems;position control;velocity control","arm robotic manipulation;flexible cables;trivial task;multiple robot manipulators;local deformation model;shape parameters;dual-arm manipulator;cable shape manipulation","","","14","","","","","IEEE","IEEE Conferences"
"Reach-Avoid Problems via Sum-or-Squares Optimization and Dynamic Programming","B. Landry; M. Chen; S. Hemley; M. Pavone","Department of Aeronautics and Astronautics, Stanford University; Simon Fraser University, School of Computing Science; Department of Mechanical Engineering, Stanford University; Department of Aeronautics and Astronautics, Stanford University","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4325","4332","Reach-avoid problems involve driving a system to a set of desirable configurations while keeping it away from undesirable ones. Providing mathematical guarantees for such scenarios is challenging but have numerous potential practical applications. Due to the challenges, analysis of reach-avoid problems involves making trade-offs between generality of system dynamics, generality of problem setups, optimality of solutions, and computational complexity. In this paper, we combine sum-of-squares optimization and dynamic programming to address the reach-avoid problem, and provide a conservative solution that maintains reaching and avoidance guarantees. Our method is applicable to polynomial system dynamics and to general problem setups, and is more computationally scalable than previous related methods. Through a numerical example involving two single integrators, we validate our proposed theory and compare our method to Hamilton-Jacobi reachability. Having validated our theory, we demonstrate the computational scalability of our method by computing the reach-avoid set of a system involving two kinematic cars.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594078","","Optimization;Dynamic programming;System dynamics;Games;Planning;Automobiles;Vehicle dynamics","dynamic programming;reachability analysis;state-space methods","reach-avoid problem;dynamic programming;sum-of-squares optimization;polynomial system dynamics;mathematical guarantees","","","40","","","","","IEEE","IEEE Conferences"
"Preliminary Evaluation of Null-Space Dynamic Process Model Identification with Application to Cooperative Navigation of Underwater Vehicles","Z. J. Harris; T. M. Paine; L. L. Whitcomb","Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, 21218, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3453","3459","This paper reports a method and preliminary evaluation of a novel null-space least-squares parameter identification method for a fully nonlinear second -order 6-degree-of-freedom (DOF) dynamic process model of an underactuated underwater vehicle (UV) for which both the model parameters and the control-input parameters are unknown. This paper further reports the application of the identified plant models in combined underwater communication and navigation (cooperative navigation) of UVs. We report an approach to model identification that simultaneously identifies 6-DOF UV nonlinear plant-model parameters, control-surface parameters, and thruster-model parameters. We believe this approach is suitable for identifying plant model parameters from data obtained in full-scale experimental trials of UVs in controlled motion. The reported approach to nonlinear model identification of UVs is evaluated in simulation studies. The resulting identified UV plant models are further evaluated in simulated cooperative navigation missions of the UV that are representative of high-precision survey missions. To the best of our knowledge, this paper reports the first method to identify 6-DOF UV model parameters, control-surface parameters, and thruster-model parameters simultaneously.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594257","","Navigation;Vehicle dynamics;Acoustics;Underwater vehicles;Heuristic algorithms;Kinematics;Kalman filters","least squares approximations;marine communication;parameter estimation;position control;underwater vehicles;vehicle dynamics","UV model parameters;control-surface parameters;thruster-model parameters;preliminary evaluation;null-space dynamic process model identification;underactuated underwater vehicle;control-input parameters;UV nonlinear plant-model parameters;nonlinear model identification;underwater communication;cooperative navigation;null-space least-squares parameter identification method","","","31","","","","","IEEE","IEEE Conferences"
"Robot-driven Trajectory Improvement for Feeding Tasks","T. Rhodes; M. Veloso","Robotics Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2991","2996","Kinesthetic learning is a type of learning from demonstration in which the teacher manually moves the robot through the demonstrated trajectory. It shows great promise in the area of assistive robotics since it enables a caretaker who is not an expert in computer programming to communicate a novel task to an assistive robot. However, the trajectory the caretaker demonstrates to solve the task may be a high-cost trajectory for the robot. The demonstrated trajectory could be high-cost because the teacher does not know what trajectories are easy or hard for the robot to perform, which would be due to a limitation of the teacher's knowledge, or because the teacher has difficulty moving all the robotic joints precisely along the desired trajectories, which would be due to a limitation of the teacher's coordination. We propose the Parameterized Similar Path Search (PSPS) algorithm to extend kinesthetic learning so that a robot can improve the learned trajectory over a known cost function. This algorithm is based on active learning from the robot through collaboration between the robot's knowledge of the cost function and the caretaker's knowledge of the constraints of the assigned task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593525","","Trajectory;Task analysis;Robot kinematics;Cost function;Training;Manipulators","assisted living;handicapped aids;learning (artificial intelligence);medical robotics;mobile robots;path planning;search problems;trajectory control","robotic joints;kinesthetic learning;active learning;robot-driven trajectory improvement;assistive robotics;parameterized similar path search algorithm;PSPS;feeding tasks;computer programming","","","23","","","","","IEEE","IEEE Conferences"
"Modeling Social Interaction Based on Joint Motion Significance","N. J. Cho; S. H. Lee; T. Kwon; I. H. Suh; H. Kim","Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Smart Research Group, Korea Institute of Industrial Technology, Cheonan, Korea; Department of Computer and Software, Hanyang University, Seoul, Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Korea; Smart Research Group, Korea Institute of Industrial Technology, Cheonan, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3373","3380","In this paper, we propose a method to model social interaction between a human and a virtual avatar. To this end, two human performers fist perform social interactions according to the Learning from Demonstration paradigm. Then, the relative relevance of all joints of both performers should be reasonably modeled based on human demonstrations. However, among all possible combinations of relative joints, it is necessary to select only some of the combinations that play key roles in social interaction. We select such significant features based on the joint motion significance, which is a metric to measure the significance degree by calculating both temporal entropy and spatial entropy of all human joints from a Gaussian mixture model. To evaluate our proposed method, we performed experiments on five social interactions: hand shaking, hand slapping, shoulder holding, object passing, and target kicking. In addition, we compared our method to existing modeling methods using different metrics, such as principal component analysis and information gain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594436","","Entropy;Hidden Markov models;Motion segmentation;Motion measurement;Trajectory;Shoulder;Feature extraction","avatars;entropy;feature extraction;Gaussian processes;inference mechanisms;learning (artificial intelligence);principal component analysis;regression analysis","modeling social interaction;joint motion significance;human performers;human demonstrations;relative joints;human joints;Gaussian mixture model","","","20","","","","","IEEE","IEEE Conferences"
"Challenges of Autonomous Flight in Indoor Environments","G. De Croon; C. De Wagter","Faculty of Aerospace Engineering, Delft University of Technology, Micro Air Vehicle Laboratory, Delft, the Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Micro Air Vehicle Laboratory, Delft, the Netherlands","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1003","1009","Indoor navigation has been a major focus of drone research over the last few decades. The main reason for the term “indoor” came from the fact that in outdoor environments, drones could rely on global navigation systems such as GPS for their position and velocity estimates. By focusing on unknown indoor environments, the research had to focus on solutions using onboard sensors and processing. In this article, we present an overview of the state of the art and remaining challenges in this area, with a focus on small drones.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593704","","Indoor environments;Drones;Robots;Measurement;Global Positioning System;Collision avoidance;Cameras","aircraft navigation;autonomous aerial vehicles;Global Positioning System;indoor navigation;sensors","indoor environments;GPS;velocity estimates;global navigation systems;drone research;indoor navigation;autonomous flight;onboard sensors","","","73","","","","","IEEE","IEEE Conferences"
"Towards Aerial Recovery of Parachute-Deployed Payloads","A. Shankar; S. Elbaum; C. Detweiler","Department of Computer Science and Engineering, University of Nebraska-Lincoln, Nebraska, USA; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Nebraska, USA; Department of Computer Science and Engineering, University of Nebraska-Lincoln, Nebraska, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4700","4707","Sensor payloads suspended from parachutes are often used in atmospheric profiling applications. They drift freely and often end up landing in inaccessible regions that make their retrieval challenging or impossible. In this paper, we develop and evaluate an approach using a multirotor unmanned aerial system to autonomously retrieve the parachute while it is still in the air. The system relies only on the initial conditions of the parachute-payload system and feedback from the vehicle's onboard cameras to track and then intercept the parachute mid-air in under 40 seconds on average. We present the results from our field experiments where we demonstrate the feasibility of the system and discuss its applicability to long-term payload transportation systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594082","","Payloads;Target tracking;Cameras;Robot sensing systems;Vehicle dynamics;Aerodynamics","aerospace robotics;aircraft control;mobile robots;position control","parachute-deployed payloads;sensor payloads;atmospheric profiling applications;inaccessible regions;multirotor unmanned aerial system;parachute-payload system;long-term payload transportation systems;aerial recovery","","","15","","","","","IEEE","IEEE Conferences"
"High-Speed and Intelligent Pre-Grasp Motion by a Robotic Hand Equipped with Hierarchical Proximity Sensors","Y. Hirai; Y. Suzuki; T. Tsuji; T. Watanabe","Kanazawa University, Graduate School of Natural Science and Technology, Kakuma-machi, Kanazawa, 9201192, Japan; Faculty of Mechanical Engineering, Institute of Science and Engineering, Kanazawa University, Kakuma-machi, Kanazawa, 9201192, Japan; Faculty of Mechanical Engineering, Institute of Science and Engineering, Kanazawa University, Kakuma-machi, Kanazawa, 9201192, Japan; Faculty of Mechanical Engineering, Institute of Science and Engineering, Kanazawa University, Kakuma-machi, Kanazawa, 9201192, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7424","7431","Quickness, preciseness and robustness are required in manipulation tasks of robotic hands for automation of manufacturing sites. Previous researches have found that sensing from fingertips equipped with proximity sensors is available for the requirements, because it complements blind areas of vision sensors. In this paper, we develop a novel optical proximity sensor for robot fingertips which provides two levels of proximity information with different purposes, sampling rates, information quantity and quality. The lower-level information from the sensor is for high-speed feedback control of a robotic hand, and the higher-level information is for recognizing the shape and size of an object. A prototype of the sensor with 5 × 5 matrix of photo detectors is presented, and its availability is shown through basic characteristic tests. A motion experiment using a robotic hand equipped with the prototype sensors is also conducted. The result confirms that the robotic hand can adjust the position and orientation of the fingertips to various objects and then correct the grasping form according to the object size within 1s.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594261","","Robot sensing systems;Phototransistors;Grasping;Photoconductivity;Task analysis","manipulators;motion measurement;optical sensors;photodetectors;shape measurement;size measurement","high-speed intelligent pre-grasp motion;hierarchical optical proximity sensor;robotic hand manipulation;shape recognition;size recognition;photodetectors;high-speed feedback control;robot fingertips;vision sensors;time 1.0 s","","","20","","","","","IEEE","IEEE Conferences"
"Robust and Stretched-Knee Biped Walking Using Joint-Space Motion Control","K. Nguyen; S. Noda; Y. Kojio; F. Sugai; S. Nozawa; Y. Kakiuchi; K. Okada; M. Inaba","Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Department of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1247","1254","Comparing to IK (Inverse Kinematics) based motion control, joint-space motion control is more advantageous in terms of not being restricted by kinematics singularity problem. In this paper, we start with SIMBICON (Simple Biped Locomotion Control) based controller, a joint-space motion control method, extend it for enhancing walking's robustness and versatility. We propose a motion optimization method considering walking robustness, desired walking velocity and energy efficient minimization for walking motion generation. This method enables us to achieve human-like walking motion, which has stretched-knee posture and robust to large push disturbances. We also apply our proposed method to a life-sized biped robot and validate its effectiveness with push recovery and walking on unknown debris experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594440","","Legged locomotion;Foot;Torque;Optimization;Robustness;Knee","humanoid robots;legged locomotion;motion control;robot kinematics;robust control","IK based motion control;kinematics singularity problem;motion optimization method;human-like walking motion;SIMBICON;inverse kinematics;joint-space motion control;stretched-knee biped walking;walking robustness;simple biped locomotion control","","","25","","","","","IEEE","IEEE Conferences"
"Robotic Subsurface Pipeline Mapping with a Ground-penetrating Radar and a Camera","H. Li; C. Chou; L. Fan; B. Li; D. Wang; D. Song","CS Department, Civil Aviation University of China, Tianjin, 300300, China; CSE Department, Texas A&M University, College Station, TX, 77843, USA; CS Department, Civil Aviation University of China, Tianjin, 300300, China; CSE Department, Texas A&M University, College Station, TX, 77843, USA; CSE Department, Texas A&M University, College Station, TX, 77843, USA; CSE Department, Texas A&M University, College Station, TX, 77843, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3145","3150","We propose a novel subsurface pipeline mapping method by fusing Ground Penetrating Radar (GPR) scans and camera images. To facilitate the simultaneous detection of multiple pipelines, we model the GPR sensing process and prove hyperbola response for general scanning with non-perpendicular angles. Furthermore, we fuse visual simultaneous localization and mapping outputs, encoder readings with GPR scans to classify hyperbolas into different pipeline groups. We extensively apply the J-Linkage method and maximum likelihood estimation to improve algorithm robustness and accuracy. As the result, we optimally estimate the radii and locations of all pipelines. We have implemented our method and tested it in physical experiments with representative pipeline configurations. The results show that our method successfully reconstructs all subsurface pipes. Moreover, the average localization error is 4.69cm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594006","","Ground penetrating radar;Pipelines;Cameras;Three-dimensional displays;Trajectory;Robot sensing systems","buried object detection;geophysical image processing;geophysical techniques;ground penetrating radar;image reconstruction;maximum likelihood estimation;pipelines;radar detection;radar imaging;robot vision","pipeline groups;hyperbola response;GPR sensing process;Ground Penetrating Radar scans;subsurface pipeline mapping method;robotic subsurface pipeline mapping;subsurface pipes;representative pipeline configurations;maximum likelihood estimation;J-Linkage method;hyperbolas;GPR scans;mapping outputs;visual simultaneous localization;nonperpendicular angles;general scanning;size 4.69 cm","","","19","","","","","IEEE","IEEE Conferences"
"Online Foot-Strike Detection Using Inertial Measurements for Multi-Legged Walking Robots","P. Čížek; J. Kubík; J. Faigl","Faculty of Electrical Engineering, Department of Computer Science, Czech Technical University, Prague, Czech Republic; Faculty of Electrical Engineering, Department of Computer Science, Czech Technical University, Prague, Czech Republic; Faculty of Electrical Engineering, Department of Computer Science, Czech Technical University, Prague, Czech Republic","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7622","7627","Proprioceptive terrain sensing is essential for rough terrain traversal because it helps legged robots to negotiate individual steps by reacting to terrain irregularities. In this work, we propose to utilize inertial data in the detection of the contact between the leg and the terrain during the stride phase of the leg. We show that relatively cheap accelerometers can be utilized to reliably detect a foot-strike, and thus allow the robot to crawl irregular terrains. The continuous data processing is compared with the interrupt mode in which data are provided only around the foot-strike event. The interrupt mode exhibits significantly better performance, and it also supports generalization of the foot-strike event detector learned from data collected in slow locomotion to faster locomotion where the signals slightly change. The proposed solution is experimentally validated using a real hexapod walking robot for which the walking speed has been improved in comparison to the previous adaptive motion gait based on a force threshold-based position controller for the foot-strike detection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594010","","Legged locomotion;Robot sensing systems;Accelerometers;Servomotors;Reliability","accelerometers;gait analysis;legged locomotion;motion control;position control;terrain mapping","interrupt mode;hexapod walking robot;inertial measurements;multilegged walking robots;proprioceptive terrain sensing;terrain irregularities;inertial data;online foot strike detection;foot strike event detector;data processing;accelerometers;terrain traversal","","","24","","","","","IEEE","IEEE Conferences"
"A Framework for Robot Grasp Transferring with Non-rigid Transformation","H. Lin; T. Tang; Y. Fan; M. Tomizuka","Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2941","2948","Grasp planning is essential for robots to execute dexterous tasks. Solving the optimal grasps for various objects online, however, is challenging due to the heavy computation load during exhaustive sampling, and the difficulties to consider task requirements. This paper proposes a framework to combine analytic approach with learning for efficient grasp generation. The example grasps are taught by human demonstration and mapped to similar objects by a non-rigid transformation. The mapped grasps are evaluated analytically and refined by an orientation search to improve the grasp robustness and robot reachability. The proposed approach is able to plan high-quality grasps, avoid collision, satisfy task requirements, and achieve efficient online planning. The effectiveness of the proposed method is verified by a series of experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593668","","Task analysis;Robots;Grasping;Planning;Collision avoidance;Grippers;Databases","collision avoidance;control engineering computing;dexterous manipulators;grippers;learning (artificial intelligence);optimisation;path planning","orientation search;collision avoidance;grasp generation;dexterous tasks execution;online planning;grasp planning;robot grasp transferring;task requirements;robot reachability;grasp robustness;nonrigid transformation;human demonstration;analytic approach","","","19","","","","","IEEE","IEEE Conferences"
"Interleaving Hierarchical Task Planning and Motion Constraint Testing for Dual-Arm Manipulation","A. Suárez-Hernández; G. Alenyà; C. Torras","Institut de Robòtica i Informàtica Industrial (CSIC-UPC), Llorens i Artigas 4-6, Barcelona, 08028, Spain; Institut de Robòtica i Informàtica Industrial (CSIC-UPC), Llorens i Artigas 4-6, Barcelona, 08028, Spain; Institut de Robòtica i Informàtica Industrial (CSIC-UPC), Llorens i Artigas 4-6, Barcelona, 08028, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4061","4066","In recent years the topic of combining motion and symbolic planning to perform complex tasks in the field of robotics has received a lot of attention. The underlying idea is to have access at once to the reasoning capabilities of a task planner and to the ability of the motion planner to verify that the plan is feasible from a physical and geometrical point of view. The present work describes a framework to perform manipulation tasks that require the use of two robotic manipulators. To do so we employ a Hierarchical Task Network (HTN) planner interleaved with geometric constraint verification. In this framework we also consider observation actions and handle noisy perceptions from a probabilistic perspective. These ideas are put into practice by means of an experimental set-up in which two Barrett WAM robots have to cooperatively solve a geometric puzzle. Our findings provide further evidence that considering explicitly physical constraints during task planning, rather than deferring their validation to the moment of execution, is advantageous in terms of execution time and breadth of situations that can be handled.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593847","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593847","","Task analysis;Planning;Uncertainty;Shape;Manipulators;Cameras","control engineering computing;geometry;inference mechanisms;manipulators;path planning;planning (artificial intelligence)","dual-arm manipulation;symbolic planning;reasoning capabilities;robotic manipulators;geometric constraint verification;Barrett WAM robots;geometric puzzle;hierarchical task network planner;hierarchical task planning;motion constraint testing;motion planning","","","15","","","","","IEEE","IEEE Conferences"
"Efficient and Asymptotically Optimal Kinodynamic Motion Planning via Dominance-Informed Regions","Z. Littlefield; K. E. Bekris","The Computer Science Dept. of Rutgers University, Frelinghuysen Road, Piscataway, NJ, 110, USA; The Computer Science Dept. of Rutgers University, Frelinghuysen Road, Piscataway, NJ, 110, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Motion planners have been recently developed that provide path quality guarantees for robots with dynamics. This work aims to improve upon their efficiency, while maintaining their properties. Inspired by informed search principles, one objective is to use heuristics. Nevertheless, comprehensive and fast spatial exploration of the state space is still important in robotics. For this reason, this work introduces Dominance-Informed Regions (DIR), which express both whether parts of the space are unexplored and whether they lies along a high quality path. Furthermore, to speed up the generation of a successful successor state, which involves collision checking or physics-based simulation, a proposed strategy generates the most promising successor in an informed way, while maintaing properties. Overall, this paper introduces a new informed and asymptotically optimal kinodynamic motion planner, the Dominance-Informed Region Tree (DIRT). The method balances exploration-exploitation tradeoffs without many explicit parameters. It is shown to outperform sampling-based and search-based methods for robots to significant dynamics.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593672","","Task analysis;Trajectory;Planning;Aerospace electronics;Robots;Dynamics;Cost function","mobile robots;optimal control;path planning;robot dynamics;sampling methods;search problems;trees (mathematics)","dominance-informed regions;high quality path;search-based methods;sampling-based methods;DIRT;dominance-informed region tree;spatial exploration;robot dynamics;collision checking;informed search principles;asymptotically optimal kinodynamic motion planner;physics-based simulation;successful successor state","","1","23","","","","","IEEE","IEEE Conferences"
"The KIT Prosthetic Hand: Design and Control","P. Weiner; J. Starke; F. Hundhausen; J. Beil; T. Asfour","NA; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3328","3334","The development and control of prosthetic hands is an active research area and recently progress in mechatronics, sensor integration and innovative control has been made. However, integration of different components into a prosthetic hand remains challenging due to space constraints, the requirements regarding holistic integration and the need for a user interface. In this paper, we present the KIT prosthetic hand, a novel five-finger 3D printed hand prosthesis, with its underactuated mechanism, sensors and embedded control system. The hand mechanics is based on the underactuated TUAT/Karlsruhe mechanism with two motors actuating 10 degrees of freedom. The mechanism has been realized in 3D printing technologies to facilitate a personalization of the prosthetic hand in terms of size and kinematic parameters. The prosthesis has been designed as a 50<sup>th</sup> percentile male hand. It integrates an advanced embedded system as well as an RGB camera in the base of the palm and a colour display in the back of the hand. Experiments indicate a finger tip force of 7.48 N to 11.82 N, a hook grasp force of 120 N and a hand closing time of ~ 1.3 s.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593851","","Embedded systems;Grasping;Tendons;Robot sensing systems;Thumb;Prosthetic hand","actuators;biomechanics;cameras;colour displays;dexterous manipulators;embedded systems;mechatronics;medical robotics;prosthetics;three-dimensional printing","mechatronics;kinematic parameters;RGB camera;colour display;innovative control;sensor integration;hand closing time;percentile male hand;underactuated TUAT/Karlsruhe mechanism;hand mechanics;embedded control system;underactuated mechanism;five-finger 3D printed hand prosthesis;KIT prosthetic hand","","2","28","","","","","IEEE","IEEE Conferences"
"Robot Approaching and Engaging People in a Human-Robot Companion Framework","E. Repiso; A. Garrell; A. Sanfeliu","Institut de Robòtica i Informàtica Industrial (CSIC-UPC), Barcelona, Llorens Artigas 4–6, 08028, Spain; Institut de Robòtica i Informàtica Industrial (CSIC-UPC), Barcelona, Llorens Artigas 4–6, 08028, Spain; Institut de Robòtica i Informàtica Industrial (CSIC-UPC), Barcelona, Llorens Artigas 4–6, 08028, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8200","8205","This paper presents a new model to make robots capable of approaching and engaging people with a human-like behavior, while they are walking in a side-by-side formation with a person. This method extends our previous work [1], which allows the robot to adapt its navigation behaviour according to the person being accompanied and the dynamic environment. In the current work, the robot is able to predict the best encounter point between the human-robot group and the approached person. Then, in the encounter point the robot modifies its position to achieve an engagement with both people. The encounter point is computed using a gradient descent method that takes into account all people predictions. Moreover, we make use of the Extended Social Force Model (ESFM), and it is modified to include the dynamic goal. The method has been validated over several situations and in real-life experiments, in addition, a user study has been realized to reveal the social acceptability of the robot in this task.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594149","","Robots;Force;Task analysis;Dynamics;Measurement;Collision avoidance;Navigation","gradient methods;human-robot interaction;path planning","encounter point;human-robot group;user study;ESFM;extended social force model;dynamic environment;navigation behaviour;human-robot companion framework;gradient descent method","","","16","","","","","IEEE","IEEE Conferences"
"Robust Humanoid Control Using a QP Solver with Integral Gains","R. Cisneros; M. Benallegue; A. Benallegue; M. Morisawa; H. Audren; P. Gergondet; A. Escande; A. Kheddar; F. Kanehiro","AIST, Humanoid Research Group, Tsukuba, Japan; AIST, Humanoid Research Group, Tsukuba, Japan; UMI3218/RL, CNRS-AIST JRL, Tsukuba, Japan; AIST, Humanoid Research Group, Tsukuba, Japan; Ascent Robotics, Tokyo, Japan; UMI3218/RL, CNRS-AIST JRL, Tsukuba, Japan; UMI3218/RL, CNRS-AIST JRL, Tsukuba, Japan; UMI3218/RL, CNRS-AIST JRL, Tsukuba, Japan; AIST, Humanoid Research Group, Tsukuba, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7472","7479","We propose a control framework for torque controlled humanoid robots that efficiently minimizes the tracking error in a Quadratic Programming (QP)formulated as multiobjective weighted tasks with constraints. It results in an optimal dynamically-feasible reference that can be tracked robustly, with exponential convergence, without joint torque feedback, in the presence of non modelled torque bias and low-frequency bounded disturbances. This is achieved by introducing integral gains in a Lyapunov-stable torque control, which exploit the passivity properties of the dynamical model of the robot and their effect on the dynamic constraints of the QP solver. The robustness of this framework is demonstrated in simulation by commanding our robot, the HRP-5P, to achieve simultaneously several objectives in the configuration and the Cartesian spaces, in the presence of non-modeled static and kinetic joint friction, as well as an uncertain torque scale.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593417","Robust control;Torque control;Passivity;Quadratic programming;Humanoid robots","Torque;Humanoid robots;Convergence;Acceleration;Torque control;Task analysis","humanoid robots;Lyapunov methods;quadratic programming;robot dynamics;robust control;torque control","low-frequency bounded disturbances;Lyapunov-stable torque control;dynamical model;dynamic constraints;QP solver;kinetic joint friction;robust humanoid control;torque controlled humanoid robots;multiobjective weighted tasks;optimal dynamically-feasible reference;exponential convergence;joint torque feedback;nonmodelled torque bias;quadratic programming;HRP-5P robot","","1","23","","","","","IEEE","IEEE Conferences"
"ASPiC: An Acting System Based on Skill Petri Net Composition","C. Lesire; F. Pommereau","The French Aerospace Lab, ONERA, Toulouse, France; university of Evry, IBISC laboratory, Paris-Saclay, Evry, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6952","6958","Acting systems aim at refining high-level actions into executable commands, while managing access to resources, possible failures, or any other unpredictable situation. Improving the trust on autonomous robots also requires to have a formal model of acting, and the capability to perform some analysis on this model. In this paper, we present ASPiC, an acting system based on the modeling of robot's skills using a specific control-flow Petri net model. The skills can then be combined using well-defined operators to build a complete plan that refines a high-level action. Some properties are guaranteed by construction, while others can be verified on the resulting plan model. ASPiC is finally applied to an area protection mission by an autonomous surface vehicle.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594328","","Petri nets;Robots;Analytical models;Adaptation models;Tools;Planning;Inductors","path planning;Petri nets;robots","ASPiC;acting system;skill Petri net composition;high-level action;executable commands;autonomous robots;formal model;robot skills;control-flow Petri net model;autonomous surface vehicle;area protection mission","","1","17","","","","","IEEE","IEEE Conferences"
"HERI II: A Robust and Flexible Robotic Hand based on Modular Finger design and Under Actuation Principles","Z. Ren; N. Kashiri; C. Zhou; N. G. Tsagarakis","Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, via Morego, 30, Genova, 16163, Italy; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, via Morego, 30, Genova, 16163, Italy; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, via Morego, 30, Genova, 16163, Italy; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, via Morego, 30, Genova, 16163, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1449","1455","This paper introduces the design of a novel under-actuated hand with highly integrated modular finger units, which can be easily reconfigured in terms of finger arrangement and number to account for the manipulation needs of different applications. Each finger module is powered by a single actuator through an under-actuated transmission and equipped with a sensory system for delicate and precise grasping, which includes absolute position measurements, contact pressure sensing at finger phalanxes and motor current readings. Finally, intrinsic elasticity integrated in the transmission system make the hand robust and adaptive to impacts when interacting with the objects and environment. This highly integrated hand (HERI II) was developed for the Centauro Robot to enable robust and resilient manipulation. A set of experiments demonstrating the hand's grasping performance were carried out and fully verified the design effectiveness of the proposed hand.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594507","","Grasping;Tendons;Force;Pulleys;Thumb;Robots","actuators;elasticity;manipulators;position measurement","design effectiveness;resilient manipulation;robust manipulation;Centauro Robot;transmission system;motor current readings;finger phalanxes;contact pressure;absolute position measurements;precise grasping;delicate grasping;sensory system;under-actuated transmission;single actuator;finger module;finger arrangement;highly integrated modular finger units;under-actuated hand;actuation principles;modular finger design;HERI II","","1","18","","","","","IEEE","IEEE Conferences"
"State Estimation for MRI-Actuated Cathers via Catadioptric Stereo Camera","T. Greigarn; R. Jackson; M. C. Çavuşoğlu","Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1795","1800","An MRI-actuated catheter is a novel robotic catheter system that utilizes the MR scanner for both remote steering and catheter tracking. In order to develop the mathematical model and the planning algorithm of the catheter in parallel to the MR tracking system, an alternative catheter tracking method is needed. This paper presents a catheter tracking algorithm based on the particle filter and the catadioptric camera system. The motion model of the particle filter is based on the quasi-static kinematics of the catheter. The measurement model calculates the weights of the particles according to the normalized crosscorrelation of the segmented image from camera and a virtual rendering of the catheter. The efficacy of the tracking algorithm is demonstrates via experimental results.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594153","","Catheters;Cameras;Actuators;Tracking;Atmospheric measurements;Particle measurements;Mirrors","biomedical MRI;cameras;catheters;image segmentation;medical robotics;particle filtering (numerical methods)","particle filter;catadioptric camera system;tracking algorithm;MRI-actuated cathers;catadioptric stereo camera;MRI-actuated catheter;novel robotic catheter system;MR tracking system;alternative catheter tracking method","","","11","","","","","IEEE","IEEE Conferences"
"Trajectory Optimization of Robot-Assisted Endovascular Catheterization with Reinforcement Learning","W. Chi; J. Liu; M. E. M. K. Abdelaziz; G. Dagnino; C. Riga; C. Bicknell; G. Yang","Hamlyn Centre for Robotic Surgery, Imperial College London, London, SW7 2AZ, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, SW7 2AZ, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, SW7 2AZ, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, SW7 2AZ, UK; Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London, W2 1NY, UK; Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London, W2 1NY, UK; Hamlyn Centre for Robotic Surgery, Imperial College London, London, SW7 2AZ, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3875","3881","Emerging robot-assisted endovascular intervention has the potential to reduce X-ray radiations to the operator while enhancing the stability and dexterity of catheter manipulation. Supervised and shared autonomy of endovascular procedures could add further improvements in reduced fatigue and cognitive workloads of the operator, higher success rates of cannulation and improved surgical outcomes. However, robotic path planning for endovascular procedure is challenging due to complex and non-linear flow dynamics inside the vasculature. This paper presents a learning-based robotic catheterization platform addressing those challenges, this approach incorporates path integral reinforcement learning (RL) framework based on dynamic movement primitives (DMP) to enhance catheterization tasks by a customized robotic manipulator. The robotic trajectories were optimized through RL in order to avoid unwanted contacts between the catheter tip and the vessel wall. The proposed methods can adapt to different flow simulations, vascular models, and catheterization tasks. The quality of the catheterization was evaluated with performance metrics. The results show significant refinement of catheter paths by the proposed approach, resulting in shorter overall lengths and fewer contact forces, which can potentially reduce risks in endothelial wall damages, embolization, and stroke. The results support the development of robotic path planning for endovascular procedures as well as designing intelligent, hands-on robotic navigation platforms.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593421","","Robots;Catheters;Task analysis;Catheterization;Surgery;Trajectory;Navigation","blood vessels;cardiovascular system;catheters;diagnostic radiography;learning (artificial intelligence);manipulator dynamics;medical image processing;medical robotics;mobile robots;path planning;patient treatment;surgery;telerobotics","catheter manipulation;learning-based robotic catheterization platform;dynamic movement primitives;catheterization tasks;customized robotic manipulator;robotic trajectories;catheter tip;hands-on robotic navigation platforms;trajectory optimization;robot-assisted endovascular catheterization;flow simulations;X-ray radiation reduction;path integral RL;path integral reinforcement learning","","","26","","","","","IEEE","IEEE Conferences"
"State Estimate Recovery for Autonomous Quadcopters","L. Beffa; A. Ledergerber; R. D'Andrea","Dynamic Systems and Control, ETH Zurich, Switzerland; Dynamic Systems and Control, ETH Zurich, Switzerland; Dynamic Systems and Control, ETH Zurich, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","A method for recovery from the complete loss of the state estimate is presented for autonomous quadcopters. Given an aerodynamic force model, the only measurements used to reinitialize the state estimate by means of a bank of extended Kalman filters are the angular rate and linear acceleration measurements of an IMU. The method is integrated within a complete recovery logic on a quadcopter platform and experimentally evaluated.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594332","","Aerodynamics;Gravity;Mathematical model;Accelerometers;Propellers;Data models;Position measurement","acceleration measurement;aerodynamics;autonomous aerial vehicles;channel bank filters;helicopters;Kalman filters;nonlinear filters;robot dynamics;state estimation","state estimate recovery;autonomous quadcopters;aerodynamic force model;extended Kalman filters;linear acceleration measurements;complete recovery logic;quadcopter platform;IMU","","","21","","","","","IEEE","IEEE Conferences"
"A Revisited Approach to Lateral Acceleration Modeling for Quadrotor UAVs State Estimation","D. Sartori; D. Zou; L. Pei; W. Yu","Shanghai Jiao Tong University., Shanghai Key Laboratory of Navigation and Location Based Services; Shanghai Jiao Tong University., Shanghai Key Laboratory of Navigation and Location Based Services; Shanghai Jiao Tong University., Shanghai Key Laboratory of Navigation and Location Based Services; Shanghai Jiao Tong University., Shanghai Key Laboratory of Navigation and Location Based Services","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5711","5718","Quadrotor state estimation generally relies on the vehicle aerodynamics modeling to achieve improved performance. In this paper the effects of the rotors angular speeds on the quadrotor drag, and therefore on the lateral accelerations, are investigated. While these effects are usually disregarded, we analyze their modeling starting from the Blade Element Theory and flight test data. Two lateral acceleration formulations are proposed. They are adopted within a velocity and attitude state estimator and validated in real-world flights. The EKF-based estimator fuses measurements from low-cost sensors present in the majority of quadrotors (IMU, magnetometer, ultrasonic sensor, optical flow) with the accelerations of the vehicle predicted from the revisited models. Experimental results show the benefits of adopting these innovative models in the estimator when compared with the existing modeling approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593600","","Rotors;Blades;Acceleration;Optical sensors;Data models;Atmospheric modeling;Aerodynamics","aerodynamics;autonomous aerial vehicles;blades;drag;helicopters;Kalman filters;mobile robots;nonlinear filters;robot dynamics;state estimation","lateral acceleration modeling;quadrotor UAVs state estimation;rotors angular speeds;quadrotor drag;lateral accelerations;flight test data;attitude state estimator;EKF-based estimator;velocity state estimator;vehicle aerodynamics modeling;blade element theory","","","23","","","","","IEEE","IEEE Conferences"
"People as Sensors: Imputing Maps from Human Actions","O. Afolabi; K. Driggs–Campbell; R. Dong; M. J. Kochenderfer; S. S. Sastry","Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Aeronautics and Astronautics Department, Stanford University, Stanford, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Aeronautics and Astronautics Department, Stanford University, Stanford, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2342","2348","Despite growing attention in autonomy, there are still many open problems, including how autonomous vehicles will interact and communicate with other agents, such as human drivers and pedestrians. Unlike most approaches that focus on pedestrian detection and planning for collision avoidance, this paper considers modeling the interaction between human drivers and pedestrians and how it might influence map estimation, as a proxy for detection. We take a mapping inspired approach and incorporate people as sensors into mapping frameworks. By taking advantage of other agents' actions, we demonstrate how we can impute portions of the map that would otherwise be occluded. We evaluate our framework in human driving experiments and on real-world data, using occupancy grids and landmark-based mapping approaches. Our approach significantly improves overall environment awareness and outperforms standard mapping techniques.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594511","","Random variables;Estimation;Automobiles;Computational modeling;Intelligent sensors","collision avoidance;driver information systems;mobile robots;pedestrians;road vehicles","human actions;autonomous vehicles;pedestrian detection;collision avoidance;map estimation;human driving experiments;landmark-based mapping approaches;agents actions","","","21","","","","","IEEE","IEEE Conferences"
"Secure Data Recording and Bio-Inspired Functional Integrity for Intelligent Robots","S. Taurer; B. Dieber; P. Schartner","Institute for Robotics and Mechatronics - Robotic Systems, JOANNEUM RESEARCH, Klagenfurt, Austria; Institute for Robotics and Mechatronics - Robotic Systems, JOANNEUM RESEARCH, Klagenfurt, Austria; Institute of Applied Informatics, Alpen-Adria Universität Klagenfurt","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8723","8728","As modern robots become more intelligent, also their use will broaden in public and professional areas. While the aim is to make robots beneficial to humans and society, using those complex machines in complex environments will eventually lead to incidents. To enable forensic investigations, ethical evaluations and transparent function of intelligent robots in a society, we contribute the concept of a secure robot data recorder that is similar to a flight data recorder in airplanes. However, since robots work in a highly networked and uncontrolled environment, our concept pays special attention to security and tamper proofness. In addition, we extend the concept with an approach inspired by cockroaches to increase the functional integrity of the robot. We present a prototype implementation along with discussions on the required properties and limits of secure data recording.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593994","","Digital signatures;Intelligent robots;Public key;Forensics","data recording;digital forensics;intelligent robots;security of data","modern robots;complex machines;bio-inspired functional integrity;secure data recording;uncontrolled environment;flight data recorder;intelligent robots;transparent function","","1","20","","","","","IEEE","IEEE Conferences"
"PAMPC: Perception-Aware Model Predictive Control for Quadrotors","D. Falanga; P. Foehn; P. Lu; D. Scaramuzza","NA; NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sensing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, together with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the conflict between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593739","","Cameras;Trajectory;Optimization;Robot vision systems;Predictive control;Planning","autonomous aerial vehicles;helicopters;mobile robots;nonlinear programming;path planning;predictive control;robot vision","PAMPC;lighting conditions;visual-inertial odometry pipeline;low-power ARM computer;nonlinear optimization problem;action objective;numerical optimization;perception-aware model predictive control framework;model-based optimization framework;perception objective;quadrotor;motion planning","","","21","","","","","IEEE","IEEE Conferences"
"Action Selection for Interactive Object Segmentation in Clutter","T. Patten; M. Zillich; M. Vincze","Automation and Control Institute, TU Wien, Vision for Robotics Laboratory, Vienna, 1040, Austria; Automation and Control Institute, TU Wien, Vision for Robotics Laboratory, Vienna, 1040, Austria; Automation and Control Institute, TU Wien, Vision for Robotics Laboratory, Vienna, 1040, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6297","6304","Robots operating in human environments are often required to recognise, grasp and manipulate objects. Identifying the locations of objects amongst their complex surroundings is therefore an important capability. However, when environments are unstructured and cluttered, as is typical for indoor human environments, reliable and accurate object segmentation is not always possible because the scene representation is often incomplete or ambiguous. We overcome the limitations of static object segmentation by enabling a robot to directly interact with the scene with non-prehensile actions. Our method does not rely on object models to infer object existence. Rather, interaction induces scene motion and this provides an additional clue for associating observed parts to the same object. We use a probabilistic segmentation framework in order to identify segmentation uncertainty. This uncertainty is then used to guide a robot while it manipulates the scene. Our probabilistic segmentation approach recursively updates the segmentation given the motion cues and the segmentation is monitored during interaction, thus providing online feedback. Experiments performed with RGB-D data show that the additional source of information from motion enables more certain object segmentation that was otherwise ambiguous. We then show that our interaction approach based on segmentation uncertainty maintains higher quality segmentation than competing methods with increasing clutter.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593918","","Motion segmentation;Tracking;Probabilistic logic;Object segmentation;Octrees;Manipulators","image colour analysis;image motion analysis;image segmentation","RGB-D data;higher quality segmentation;probabilistic segmentation approach;segmentation uncertainty;probabilistic segmentation framework;scene motion;object existence;object models;nonprehensile actions;static object segmentation;scene representation;indoor human environments;complex surroundings;interactive object segmentation","","","26","","","","","IEEE","IEEE Conferences"
"LiDAR-Based Object Tracking and Shape Estimation Using Polylines and Free-Space Information","S. Kraemer; C. Stiller; M. E. Bouzouraa","Karlsruhe Institute of Technology, Institute of Measurement and Control Systems, Germany; Karlsruhe Institute of Technology, Institute of Measurement and Control Systems, Germany; AUDI AG, Pre-Development for Automated Driving, Ingolstadt, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4515","4522","Reliable object perception is a vital requirement for automated driving. Despite the availability of precise contour measurements, most state-of-the-art tracking systems still represent object geometry as bounding boxes. However, there are objects operating in public traffic for which the box assumption is highly inappropriate. We therefore propose to represent object contours using 2D polylines. Taking into account the mutual dependence of object poses and shape, our tracking framework targets at a simultaneous estimation of both states. Moreover, we propose to augment scan segments with free-space information at their boundaries and show how this knowledge can be incorporated into the tracking framework and beyond. Evaluation with real scan data shows that our method produces accurate dynamic estimates and consistent shape reconstructions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593385","","Shape;Estimation;Laser modes;Measurement by laser beam;Radar tracking;Geometry;Shape measurement","image reconstruction;image segmentation;object detection;object tracking;optical radar;traffic engineering computing","tracking framework targets;simultaneous estimation;free-space information;accurate dynamic estimates;consistent shape reconstructions;polylines;reliable object perception;automated driving;precise contour measurements;object geometry;bounding boxes;public traffic;box assumption;object contours;object poses;2D polylines;tracking systems","","","17","","","","","IEEE","IEEE Conferences"
"Efficient Absolute Orientation Revisited","M. Lourakis; G. Terzakis","Foundation for Research and Technology - Hellas, Institute of Computer Science, Heraklion, Greece; University of Portsmouth, Faculty of Technology, Portsmouth, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5813","5818","Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding 3D points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigenand singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594296","","Quaternions;Estimation;Symmetric matrices;Eigenvalues and eigenfunctions;Matrix decomposition;Covariance matrices;Computer vision","attitude measurement;computer vision;matrix decomposition;optimisation;singular value decomposition","fast optimal attitude matrix algorithm;optimal linear attitude estimator method;3D point sets;OLAE method;computer vision;similarity transformation;absolute orientation estimation;attitude estimation techniques;FOAM-based solution;singular-value matrix decompositions;absolute orientation algorithm;robotics","","","28","","","","","IEEE","IEEE Conferences"
"Configuration Space Metrics","H. J. Jeon; A. D. Dragan","NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5101","5108","When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics - metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593564","","Task analysis;Euclidean distance;Manifolds;End effectors;Elbow","manipulator kinematics;path planning","configuration space metrics;robot manipulators;task constraint;Euclidean distance metric;robot behavior;3DOF arm;Jaco 7DOF arm","","","17","","","","","IEEE","IEEE Conferences"
"Vehicle Rebalancing for Mobility-on-Demand Systems with Ride-Sharing","A. Wallar; M. Van Der Zee; J. Alonso-Mora; D. Rus","Computer Science and Artificial Intelligence Laboratory of the Massachusetts Institute of Technology, 32 Vassar St, Cambridge, MA, 02139, USA; Department - of Cognitive Robotics, Delft University of Technology, Mekelweg 2, CD Delft, 2628, Netherlands; Department - of Cognitive Robotics, Delft University of Technology, Mekelweg 2, CD Delft, 2628, Netherlands; Computer Science and Artificial Intelligence Laboratory of the Massachusetts Institute of Technology, 32 Vassar St, Cambridge, MA, 02139, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4539","4546","Recent developments in Mobility-on-Demand (MoD) systems have demonstrated the potential of road vehicles as an efficient mode of urban transportation Newly developed algorithms can compute vehicle routes in real-time for batches of requests and allow for multiple requests to share vehicles. These algorithms have primarily focused on optimally producing vehicle schedules to pick up and drop off requests. The redistribution of idle vehicles to areas of high demand, known as rebalancing, on the contrary has received little attention in the context of ride-sharing. In this paper, we present a method to rebalance idle vehicles in a ride-sharing enabled MoD fleet. This method consists of an algorithm to optimally partition the fleet operating area into rebalancing regions, an algorithm to determine a real-time demand estimate for every region using incoming requests, and an algorithm to optimize the assignment of idle vehicles to these rebalancing regions using an integer linear program. Evaluation with historical taxi data from Manhattan shows that we can service 99.8% of taxi requests in Manhattan using 3000 vehicles with an average waiting time of 57.4 seconds and an average in-car delay of 13.7 seconds. Moreover, we can achieve a higher service rate using 2000 vehicles than prior work achieved with 3000. Furthermore, with a fleet of 3000 vehicles, we reduce the average travel delay by 86%, the average waiting time by 37%, and the amount of ignored requests by 95% compared to earlier work at the expense of an increased distance travelled by the fleet.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593743","","Schedules;Real-time systems;Delays;Partitioning algorithms;Public transportation;Automobiles","integer programming;linear programming;road traffic;road vehicles;scheduling;vehicle routing","historical taxi data;integer linear programming;idle vehicle redistribution;MoD systems;urban transportation;mobility-on-demand systems;real-time demand estimate;fleet operating area;MoD fleet;vehicle routes;road vehicles;ride-sharing;vehicle rebalancing;average waiting time;rebalancing regions;time 13.7 s","","","17","","","","","IEEE","IEEE Conferences"
"Coping with Context Change in Open-Ended Object Recognition without Explicit Context Information","S. Hamidreza Kasaei; L. Seabra Lopes; A. Maria Tomé","University of Aveiro, 810-193, Portugal; University of Aveiro, 810-193, Portugal; University of Aveiro, 810-193, Portugal","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","To deploy a robot in a human-centric environment, it is important that the robot is able to continuously acquire and update object categories while working in the environment. Therefore, autonomous robots must have the ability to continuously execute learning and recognition in a concurrent or interleaved fashion. One of the main challenges in unconstrained human environments is to cope with the effects of context change. This paper presents two main contributions: (i) an approach for evaluating open-ended object category learning and recognition methods in multi-context scenarios; (ii) evaluation of different object category learning and recognition approaches regarding their ability to cope with the effects of context change. Off-line evaluation approaches such as cross-validation do not comply with the simultaneous nature of learning and recognition. A teaching protocol, supporting context change, was therefore designed and used in this work for experimental evaluation. Seven learning and recognition approaches were evaluated and compared using the protocol. The best performance, in terms of number of learned categories, was obtained with a recently proposed local variant of Latent Dirichlet Allocation (LDA), closely followed by a Bag-of-Words (BoW) approach. In terms of adaptability, i.e. coping with context change, the best result was obtained with BoW, immediately followed by the local LDA variant.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593922","","Robots;Visualization;Protocols;Histograms;Context modeling;Three-dimensional displays;Training","learning (artificial intelligence);mobile robots;object recognition","object category learning;learning recognition;evaluation approaches;recognition approaches;multicontext scenarios;recognition methods;unconstrained human environments;autonomous robots;object categories;human-centric environment;explicit context information;open-ended object recognition;context change","","","21","","","","","IEEE","IEEE Conferences"
"Free-View, 3D Gaze-Guided, Assistive Robotic System for Activities of Daily Living","M. Wang; A. A. Kogkas; A. Darzi; G. P. Mylonas","NA; Department of Surgery and Cancer, Imperial College London, HARMS Lab, London, W21PF, UK; Department of Surgery and Cancer, Imperial College London, HARMS Lab, London, W21PF, UK; Department of Surgery and Cancer, Imperial College London, HARMS Lab, London, W21PF, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2355","2361","Patients suffering from quadriplegia have limited body motion which prevents them from performing daily activities. We have developed an assistive robotic system with an intuitive free-view gaze interface. The user's point of regard is estimated in 3D space while allowing free head movement and is combined with object recognition and trajectory planning. This framework allows the user to interact with objects using fixations. Two operational modes have been implemented to cater for different eventualities. The automatic mode performs a pre-defined task associated with a gaze-selected object, while the manual mode allows gaze control of the robot's end-effector position on the user's frame of reference. User studies reported effortless operation in automatic mode. A manual pick and place task achieved a success rate of 100% on the users' first attempt.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594045","","Three-dimensional displays;Cameras;Task analysis;Robot kinematics;Object recognition;Planning","assisted living;end effectors;gaze tracking;medical robotics;object recognition;trajectory control;user interfaces","gaze control;assistive robotic system;daily living;free-view gaze interface;object recognition;trajectory planning;quadriplegia patient;end-effector position","","","19","","","","","IEEE","IEEE Conferences"
"A Novel Soft Elbow Exosuit to Supplement Bicep Lifting Capacity","C. M. Thalman; Q. P. Lam; P. H. Nguyen; S. Sridar; P. Polygerinos","Arizona State University, Polytechnic School, Ira A. Fulton Schools of Engineering, Mesa, AZ 85212, USA; Arizona State University, Polytechnic School, Ira A. Fulton Schools of Engineering, Mesa, AZ 85212, USA; Arizona State University, Polytechnic School, Ira A. Fulton Schools of Engineering, Mesa, AZ 85212, USA; Arizona State University, Polytechnic School, Ira A. Fulton Schools of Engineering, Mesa, AZ 85212, USA; Arizona State University, Polytechnic School, Ira A. Fulton Schools of Engineering, Mesa, AZ 85212, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6965","6971","This paper investigates the design of a soft elbow exosuit capable of providing supplemental lifting assistance by reducing muscle activity of the bicep muscle. The aim is to improve the efficiency and endurance of workers who are tasked with repetitive lifting. The design consists of an array of pneumatically pressurized soft actuators, which are encased in nylon fabric that allows for a high force-to-weight ratio of 211.SN/g. An analytical model governing the bending behavior of two consecutive actuators and torque generated by the exosuit is developed, with test results showing less than 10% error from the theoretical model. An elbow joint torque value of 27.6N.m is achieved at 300kPa, which is comparable to the 30N.m maximum set by OSHA requirements in the USA. Further testing with a healthy participant is performed using surface electromyography (sEMG) sensors and a motion capture system to assess the capabilities of the exosuit to provide active assistance to the bicep during isometric and concentric contractions. Measurable assistance to lifting is observed with minimal obstruction to the user's range of motion for all experiments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594403","","Actuators;Elbow;Torque;Shape;Force;Injuries;Muscles","bending;biomechanics;electromyography;medical robotics;pneumatic actuators;torque","measurable assistance;bicep lifting capacity;supplemental lifting assistance;muscle activity;bicep muscle;repetitive lifting;pneumatically pressurized soft actuators;high force-to-weight ratio;analytical model;bending behavior;consecutive actuators;theoretical model;elbow joint torque value;surface electromyography sensors;active assistance;soft elbow exosuit;nylon fabrics;motion capture system;concentric contractions;isometric contractions;pressure 300.0 kPa;SN","","","24","","","","","IEEE","IEEE Conferences"
"Learning Robotic Grasping Strategy Based on Natural-Language Object Descriptions","A. B. Rao; K. Krishnan; H. He","Department of Industrial Systems and Manufacturing Engineering, Wichita State University, Wichita, KS, 67260, USA; Department of Industrial Systems and Manufacturing Engineering, Wichita State University, Wichita, KS, 67260, USA; Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, KS, 67260, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","882","887","Given the description of an object, s physical attributes, humans can determine a proper strategy and grasp an object. This paper proposes an approach to determine grasping strategy for an anthropomorphic robotic hand simply based on natural-language descriptions of an object. A learning-based approach is proposed to help a robotic hand learn suitable grasp poses starting from the natural language description of the object. Object features are parsed from natural-language descriptions by using a customized natural-language processing technique. The most likely grasp type for the given object is learned from the human grasping taxonomy based on the parsed features. The grasping strategy generated by the proposed approach is evaluated both by simulation study and execution of the grasps on an AR10 robotic hand.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593886","","Robots;Grasping;Taxonomy;Shape;Natural language processing;Kinematics;Task analysis","control engineering computing;dexterous manipulators;learning (artificial intelligence);natural language processing","robotic grasping strategy;natural-language object descriptions;anthropomorphic robotic hand;natural-language descriptions;learning-based approach;natural language description;object features;natural-language processing technique;grasp type;human grasping taxonomy;AR10 robotic hand","","","30","","","","","IEEE","IEEE Conferences"
"A Novel Cable Actuation Mechanism for 2-DOF Hyper-redundant Bending Robot Composed of Pulleyless Rolling Joints","J. Suh","Electronics and Telecommunications Research Institute (ETRI), Daegu, 42994, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","961","966","Many surgical robots are remotely actuated by means of wire cables. In the past, the cables wound around circular pulleys at the robot joints did not constitute a problem of the cable driver structure. However, the pulleys inside the joints are removed recently in order to miniaturize the joints, so a specially designed cable driver suitable for the miniature joint structure is required for stable driving. In this paper, we propose a novel cable driver design for driving a pulleyless rolling joint and extend it to 2-DOF structure. Then, the proposed cable driver is manufactured using 3D printing with the 2-DOF bending joint, and an experiment is performed to evaluate them using the prototype. The cable driver proposed in this paper can drive pulleyless rolling joints stably with low cable tension. In addition, it can decouple yaw and pitch motion of the joints completely, therefore it can be applied to a variety of thin robots and instruments including steerable endoscopes and surgical robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593890","","Joints;Mechanical cables;Pulleys;Fasteners;Robots;Muscles;Hysteresis","actuators;buckling;cables (mechanical);catheters;endoscopes;fixtures;medical robotics;motion control;production engineering computing;pulleys;redundant manipulators;surgery;three-dimensional printing","hyper-redundant bending robot composed;pulleyless rolling joint;surgical robots;wire cables;robot joints;miniature joint structure;cable driver design;3D printing;steerable endoscopes","","","18","","","","","IEEE","IEEE Conferences"
"A Parallel Robotic Mechanism for the Stabilization and Guidance of an Endoscope Tip in Laser Osteotomy","M. Eugster; P. C. Cattin; A. Zam; G. Rauter","Department of Biomedical Engineering, University of Basel, Switzerland; Department of Biomedical Engineering, University of Basel, Switzerland; Department of Biomedical Engineering, University of Basel, Switzerland; Department of Biomedical Engineering, University of Basel, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1306","1311","This paper presents a parallel robotic mechanism for endoscope tip stabilization and guidance for a robot-assisted minimally invasive laser osteotome. The mechanism attaches to the bone of the patient, providing a stable and robust platform for the laser integrated in the endoscope tip which has to be moved precisely in the sub-millimeter range along a preoperatively planned path. This method is only possible because cutting bone with laser instead of using conventional bone drills and saws involves considerably lower interaction forces. The design, kinematics, control, and motion performance of the concept are presented for an upscaled prototype. The obtained deviation of the endoscope tip motion from the reference path lies in the sub-millimeter range. This result allows us to conclude that the concept is more than promising. Furthermore, we expect that the herein presented principle will influence the way osteotomies will be performed in the future.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594188","","Endoscopes;Bones;Laser beam cutting;Rails;Kinematics;End effectors","bone;endoscopes;laser applications in medicine;medical robotics;orthopaedics;surgery","parallel robotic mechanism;laser osteotomy;endoscope tip stabilization;robot-assisted minimally invasive laser osteotome;robust platform;sub-millimeter range;endoscope tip motion","","","11","","","","","IEEE","IEEE Conferences"
"Continuous Shared Control for Robotic Arm Reaching Driven by a Hybrid Gaze-Brain Machine Interface","Y. Wang; G. Xu; A. Song; B. Xu; H. Li; C. Hu; H. Zeng","Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China; Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China; Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China; Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China; Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China; Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China; Southeast University, School of Instrument Science and Engineering, Nanjing, 210096, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4462","4467","The brain-machine interface (BMI) has been reported to offer the potential for controlling the assistive robot for the motor impaired people, using the non-invasively obtained electroencephalogram (EEG) signals. However, the EEG based BMI may not be sufficient and stable to drive the robot moving freely in its 2D or 3D workspace. The robot autonomy may provide assistance for the BMI users with the shared control paradigm. Nevertheless, users suffers from several limitations of the current shared control paradigms applied on BMI, e.g., loss of sense of control, high mental workload due to unintuitive control with the human-robot interface and fixed level of assistance. To overcome these drawbacks, we propose a new control paradigm for the robotic arm reaching task where the robot autonomy is dynamically blended with the gaze-BMI control from a user. In this paradigm, the hybrid gaze-BMI constitutes an intuitive and effective input to continuously control the robotic arm end-effector moving freely in its 2D workspace, with an adjustable speed proportional to the motion intention strength. Furthermore, the adjustable level of assistance by our paradigm allows the system to balance the user's capabilities and feelings of control while compensating for the reaching task's difficulty. The proposed paradigm is verified in the task where a healthy subject utilizes the hybrid gaze-BMI to control the robotic arm end-effector reaching for a target object while avoiding the obstacle in the path. The experimental results demonstrate that the movements with our shared control paradigm are safer, more efficient and less difficult than those without shared control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594367","","Robot kinematics;End effectors;Task analysis;Electroencephalography;Robot sensing systems","brain-computer interfaces;continuous systems;electroencephalography;end effectors;handicapped aids;human-robot interaction;medical control systems;medical robotics;motion control","shared control paradigm;human-robot interface;robot autonomy;gaze-BMI control;hybrid gaze-BMI;robotic arm end-effector;continuous shared control;hybrid gaze-brain machine interface;brain-machine interface;assistive robot;motor impaired people;motion intention strength;obstacle avoidance","","","12","","","","","IEEE","IEEE Conferences"
"Vision-Based Terrain Classification and Solar Irradiance Mapping for Solar-Powered Robotics","N. Kingry; M. Jung; E. Derse; R. Dai","Mechanical and Aerospace Engineering Department, The Ohio State University, Columbus, Ohio; Mechanical and Aerospace Engineering Department, The Ohio State University, Columbus, Ohio; Mechanical Engineering Department, Iowa State University, Ames; Mechanical and Aerospace Engineering Department, The Ohio State University, Columbus, Ohio","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5834","5840","This paper examines techniques for real-time terrain classification and solar irradiance mapping for outdoor, solar-powered mobile robots using a vision-based Artificial Neural Network (ANN). This process is completed sequentially. First, terrain classification is completed by extracting key features from visual-spectrum images captured from an on-board camera using Haar wavelet transform to identify both color and textural information. These features are then classified using an ANN to identify grass, concrete, asphalt, gravel, and mulch. Using the terrain classes, the image is then analyzed using concepts from high dynamic range imagery to establish the solar irradiance map of the area. In this way, our sequential methodology presented allows unmanned vehicles to classify the terrain and map the irradiance of a given area with no prior knowledge. Whereas, the terrain classification can be used in determining energy consumption or traversability criteria and the irradiance map can be used to estimate the energy harvesting capabilities.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593635","Field Robotics;Image Processing;Solar Mapping;Terrain Classification;Solar Robotics","Image color analysis;Feature extraction;Neural networks;Training;Image segmentation;Wavelet transforms;Sensors","cameras;energy harvesting;feature extraction;Haar transforms;image classification;image colour analysis;image texture;mobile robots;neural nets;robot vision;solar power;terrain mapping;wavelet transforms","outdoor mobile robots;feature extraction;visual-spectrum images;on-board camera;Haar wavelet transform;color information;textural information;ANN;high dynamic range imagery;energy consumption;traversability criteria;energy harvesting capabilities;vision-based artificial neural network;sequential methodology;solar irradiance map;terrain classes;solar-powered mobile robots;real-time terrain classification;solar irradiance mapping;vision-based terrain classification","","","28","","","","","IEEE","IEEE Conferences"
"Towards Real-Time Unsupervised Monocular Depth Estimation on CPU","M. Poggi; F. Aleotti; F. Tosi; S. Mattoccia","University of Bologna, Department of Computer Science and Engineering (DISI), Bologna, 40136, Italy; University of Bologna, Department of Computer Science and Engineering (DISI), Bologna, 40136, Italy; University of Bologna, Department of Computer Science and Engineering (DISI), Bologna, 40136, Italy; University of Bologna, Department of Computer Science and Engineering (DISI), Bologna, 40136, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5848","5854","Unsupervised depth estimation from a single image is a very attractive technique with several implications in robotic, autonomous navigation, augmented reality and so on. This topic represents a very challenging task and the advent of deep learning enabled to tackle this problem with excellent results. However, these architectures are extremely deep and complex. Thus, real-time performance can be achieved only by leveraging power-hungry GPUs that do not allow to infer depth maps in application fields characterized by low-power constraints. To tackle this issue, in this paper we propose a novel architecture capable to quickly infer an accurate depth map on a CPU, even of an embedded system, using a pyramid of features extracted from a single input image. Similarly to state-of-the-art, we train our network in an unsupervised manner casting depth estimation as an image reconstruction problem. Extensive experimental results on the KITTI dataset show that compared to the top performing approach our network has similar accuracy but a much lower complexity (about 6% of parameters) enabling to infer a depth map for a KITTI image in about 1.7 s on the Raspberry Pi 3 and at more than 8 Hz on a standard CPU. Moreover, by trading accuracy for efficiency, our network allows to infer maps at about 2 Hz and 40 Hz respectively, still being more accurate than most state-of-the-art slower methods. To the best of our knowledge, it is the first method enabling such performance on CPUs paving the way for effective deployment of unsupervised monocular depth estimation even on embedded systems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593814","","Estimation;Feature extraction;Computer architecture;Training;Decoding;Image resolution;Real-time systems","embedded systems;estimation theory;feature extraction;image reconstruction;image sensors;learning (artificial intelligence);microprocessor chips;mobile robots;object detection;robot vision;stereo image processing","robotic navigation;autonomous navigation;deep learning;low-power constraints;embedded system;single input image;image reconstruction problem;KITTI image;depth map;CPU;unsupervised monocular depth estimation;features extraction;time 1.7 s;frequency 8.0 Hz;frequency 40.0 Hz","","","30","","","","","IEEE","IEEE Conferences"
"Online Adaptation of Robot Pushing Control to Object Properties","S. Krivic; J. Piater","Department of Computer Science, Universität Innsbruck, Innsbruck, 6020, Austria; Department of Computer Science, Universität Innsbruck, Innsbruck, 6020, Austria","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4614","4621","Pushing is a common task in robotic scenarios. In real-world environments, robots need to manipulate various unknown objects without previous experience. We propose a data-driven approach for learning local inverse models of robot-object interaction for push manipulation. The robot makes observations of the object behaviour on the fly and adapts its movement direction. The proposed model is probabilistic, and we update it using maximum a posteriori (MAP) estimation. We test our method by pushing objects with a holonomic mobile robot base. Validation of results over a diverse object set demonstrates a high degree of robustness and a high success rate in pushing objects towards a fixed target and along a path compared to previous methods. Moreover, based on learned inverse models, the robot can learn object properties and distinguish between different object behaviours when they are pushed from different sides.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594192","","Inverse problems;Adaptation models;Robot kinematics;Friction;Feedforward systems;Task analysis","learning (artificial intelligence);manipulators;mobile robots;path planning","unknown objects;data-driven approach;local inverse models;robot-object interaction;push manipulation;object behaviour;maximum a posteriori estimation;pushing objects;holonomic mobile robot base;diverse object set;learned inverse models;object properties;online adaptation;robot pushing control;robotic scenarios;real-world environments;MAP","","","20","","","","","IEEE","IEEE Conferences"
"Robust Fixed-Wing UAV Guidance with Circulating Artificial Vector Fields","A. M. C. Rezende; V. M. Gonçalves; G. V. Raffo; L. C. A. Pimenta","The Federal University of Minas Gerais (UFMG), Graduate Program in Electrical Engineering; The Federal University of Minas Gerais (UFMG), Graduate Program in Electrical Engineering; The Federal University of Minas Gerais (UFMG), Graduate Program in Electrical Engineering; The Federal University of Minas Gerais (UFMG), Graduate Program in Electrical Engineering","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5892","5899","This paper presents a guidance vector field strategy to control a fixed-wing UAV (unmanned aerial vehicle)subject to uncertainty in order to converge to and circulate a closed curve in ℝ<sup>3</sup>. The control system is designed based on a reference model of the airplane with constrained input controls. The law is independent of the vector field's structure, however, some analysis considers a consolidated vector field approach. Asymptotic stability is proven with Lyapunov Theory and ultimate bounds are found when bounded uncertainties are taken into account. The control law is continuous except in the surroundings of the unavoidable field's singularities. A theorem ensures asymptotic convergence when a switch is made. Simulations with a 6 DOF, 12 states realistic aircraft model demonstrate the efficiency of the strategy and its advantages.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594371","","Convergence;Uncertainty;Atmospheric modeling;Aircraft;Three-dimensional displays;Unmanned aerial vehicles;Shape","aircraft control;asymptotic stability;autonomous aerial vehicles;control system synthesis;Lyapunov methods;robust control;vectors","constrained input controls;asymptotic stability;control law;robust fixed-wing UAV guidance;guidance vector field strategy;unmanned aerial vehicle;closed curve;control system;aircraft model;artificial vector fields","","","18","","","","","IEEE","IEEE Conferences"
"Fully Convolutional Grasp Detection Network with Oriented Anchor Box","X. Zhou; X. Lan; H. Zhang; Z. Tian; Y. Zhang; N. Zheng","National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Xi'an Jiaotong University, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi'an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Xi'an Jiaotong University, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi'an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Xi'an Jiaotong University, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi'an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Xi'an Jiaotong University, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi'an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Xi'an Jiaotong University, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi'an, Shaanxi, China; National Engineering Laboratory for Visual Information Processing and Applications, School of Electronic and Information Engineering, Xi'an Jiaotong University, Institute of Artificial Intelligence and Robotics, No.28 Xianning Road, Xi'an, Shaanxi, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7223","7230","In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594116","","Feature extraction;Robots;Computational modeling;Grippers;Solid modeling;Computer architecture;Predictive models","feature extraction;feedforward neural nets;grippers;human-robot interaction;image classification;image colour analysis;image matching;inference mechanisms;learning (artificial intelligence);object detection;object recognition;regression analysis;robot vision","parallel-plate robotic gripper;RGB images;oriented anchor box mechanism;matching strategy;end-to-end fully convolutional neural network;feature extractor;deep convolutional neural network;multigrasp predictor regresses;predefined oriented rectangles;anchor boxes;standard Cornell Grasp Dataset;image-wise split;object-wise split;latest state-of-the-art approach;grasping poses;convolutional grasp detection network","","2","22","","","","","IEEE","IEEE Conferences"
"Iterative Learning Vector Field for FES-Supported Cyclic Upper Limb Movements in Combination with Robotic Weight Compensation","A. Passon; T. Seel; J. Massmann; C. Freernan; T. Schauer","Control Systems Group at TU Berlin, Einsteinufer 17 EN-11, Berlin, 10587; Control Systems Group at TU Berlin, Einsteinufer 17 EN-11, Berlin, 10587; Control Systems Group at TU Berlin, Einsteinufer 17 EN-11, Berlin, 10587; Electronics and Computer Science, University of Southampton, United Kingdom; Control Systems Group at TU Berlin, Einsteinufer 17 EN-11, Berlin, 10587","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5169","5174","Robotics and Functional Electrical Stimulation (FES) are well-established technologies for the rehabilitation of stroke and spinal cord injured (SCI) patients. We propose a hybrid solution that combines feedback-controlled FES of biceps and triceps as well as posterior and anterior deltoid with a cable-driven robotic system to support repetitive arm movements, like “breaststroke swimming” exercises. The robotic system partially compensates the arm weight by controlling the cable tension forces, and the FES promotes motion in the transversal plane. To adjust the FES support to the needs of the individual patients we use an iterative learning vector field (ILVF) which encodes the stimulation intensities that are applied to guide the patient along a pre-specified reference trajectory in the joint angle space. In contrast to previous iterative learning control approaches, the ILVF allows the patient to perform the motion at self-selected cadence. The proposed learning algorithm explicitly takes the dynamics of the artificially activated muscles into account and assures smooth stimulation intensity profiles. The control algorithm is tested in simulations using a complex neuro-musculoskeletal model. For “breaststroke” motions, the initial RMS error of purely volitional movements is reduced from 38° to 10° within 21 cycles by the adaptive FES support. After 50 iterations of the ILVF, the algorithm converges to a steady state RMS error of 4°. Changes in the patient's muscle activity and cadence were well tolerated by the control system and did not cause a noticable increase in the steady state RMS error.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594120","","Iron;Muscles;Trajectory;Manipulators;Torque;Aerospace electronics","bioelectric phenomena;biomechanics;iterative methods;learning (artificial intelligence);medical computing;medical robotics;muscle;neuromuscular stimulation;neurophysiology;patient rehabilitation;physiological models","control system;spinal cord injured patients;functional electrical stimulation;iterative learning control approaches;prespecified reference trajectory;self-selected cadence;smooth stimulation intensity profiles;complex neuromusculoskeletal model;initial RMS error;steady state RMS error;adaptive FES support;purely volitional movements;breaststroke motions;control algorithm;artificially activated muscles;learning algorithm;joint angle space;stimulation intensities;ILVF;transversal plane;cable tension forces;arm weight;breaststroke swimming exercises;repetitive arm movements;cable-driven robotic system;anterior deltoid;posterior deltoid;triceps;biceps;feedback-controlled FES;robotic weight compensation;FES-supported cyclic upper limb movements;iterative learning vector field","","","20","","","","","IEEE","IEEE Conferences"
"Closed-Loop Temperature Control of Nylon Artificial Muscles","C. S. Haines; G. Niemeyer","The University of Texas at Dallas, Richardson, TX, 75080, USA; Disney Research Los Angeles, Glendale, CA, 91201, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6980","6985","Coiled actuators made from polymer fibers are fast becoming popular due to their low-cost and ease of fabrication. Unfortunately, reliable real-time temperature measurement has been frustrated by the small fiber diameter of typical actuators. By using coiled polymer fibers wrapped with a metal wire, we demonstrate the ability to concurrently drive a muscle by electrothermal heating, and monitor muscle temperature through the wire resistance. This simple method enables convenient overheat protection for these muscles, as well as the possibility for closed-loop temperature control. Using this platform, we demonstrate a nested controller using temperature and position feedback to improve contraction speed, and investigate the cooling rates of various configurations that increase total force output.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593599","","Muscles;Temperature measurement;Wires;Force;Heating systems;Resistance","closed loop systems;coils;electroactive polymer actuators;pneumatic actuators;polymer fibres;temperature control;temperature measurement","temperature measurement;electrothermal heating;muscle temperature monitoring;overheat protection;nested controller;wire resistance;metal wire;coiled polymer fibers;coiled actuators;nylon artificial muscles;closed-loop temperature control","","1","16","","","","","IEEE","IEEE Conferences"
"Compensating for Context by Learning Local Models of Perception Performance","H. Hu; G. Kantor","Carnegie Mellon University, Robotics Institute, Pittsburgh, Pennsylvania, 15213; Carnegie Mellon University, Robotics Institute, Pittsburgh, Pennsylvania, 15213","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4629","4634","Perception system performance can vary dramatically with contextual factors such as environmental geometry, appearance, and other phenomena. In this work we present a theoretical framework for understanding the role of context in perception and discuss three approaches for predicting probabilistic performance from observations by efficiently learning local performance models. We compare these approaches with experiments on the monocular and stereo visual odometry systems for a ground robot, and show that they can effectively predict system failures in a wide variety of environments.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593778","","Context modeling;Visual odometry;Data models;Training data;Predictive models;Prediction algorithms","distance measurement;mobile robots;probability;robot vision;stereo image processing","perception performance;perception system performance;environmental geometry;probabilistic performance;monocular odometry systems;stereo visual odometry systems;system failures;ground robot","","","14","","","","","IEEE","IEEE Conferences"
"Drivers' Manoeuvre Prediction for Safe HRI","E. J. Lopez Pulgarin; G. Herrmann; U. Leonards","Aerospace and Mechanical Engineering (CAME), University of Bristol, the School of Civil, Bristol, UK; Aerospace and Mechanical Engineering (CAME), University of Bristol, the School of Civil, Bristol, UK; University of Bristol, the School of Experimental Psychology, Bristol, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Machines with high levels of autonomy such as robots and our growing need to interact with them creates challenges to ensure safe operation. The recent interest to create autonomous vehicles through the integration of control and decision-making systems makes such vehicles robots too. We therefore applied estimation and decision-making mechanisms currently investigated for human-robot interaction to human-vehicle interaction. In other words, we define the vehicle as an autonomous agent with which the human driver interacts, and focus on understanding the human intentions and decision-making processes. These are then integrated into the ro-bot`s/vehicle's own control and decision-making system not only to understand human behaviour while it occurs but to predict the next actions. To obtain knowledge about the human's intentions, this work relies heavily on the use of motion tracking data (i.e. skeletal tracking, body posture)gathered from drivers whilst driving. We use a data-driven approach to both classify current driving manoeuvres and predict future manoeuvres, by using a fixed prediction window and augmenting a standard set of manoeuvres. Results are validated against drivers of different sizes, seat preferences and levels of driving expertise to evaluate the robustness of the methods; precision and recall metrics higher than 95% for manoeuvre classification and 90% for manoeuvre prediction with time-windows of up to 1.3 seconds are obtained. The idea of prediction adds a highly novel aspect to human-robot/human-vehicle interaction, allowing for decision and control at a later point.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593957","","Task analysis;Vehicles;Robots;Roads;Decision making;Predictive models;Training","control engineering computing;decision making;human-robot interaction;mobile robots;motion control;road safety;road traffic control;traffic engineering computing","safe HRI;autonomous vehicles;decision-making systems;vehicles robots;human-robot interaction;autonomous agent;human driver interacts;motion tracking data;manoeuvre classification;drivers manoeuvre prediction;human-vehicle interaction","","","27","","","","","IEEE","IEEE Conferences"
"$\Phi$ Clust: Pheromone-Based Aggregation for Robotic Swarms","F. Arvin; A. E. Turgut; T. Krajník; S. Rahimi; İ. E. Okay; S. Yue; S. Watson; B. Lennox","The University of Manchester, Robotics for Extreme Environments Lab (REEL), School of Electrical and Electronic Engineering, Manchester, M13 9PL, United Kingdom; Mechanical Engineering Department, Middle East Technical University, Ankara, 06800, Turkey; Faculty of Electrical Engineering, Czech Technical University, Artificial Intelligence Centre, Prague, Czechia; Mechanical Engineering Department, Middle East Technical University, Ankara, 06800, Turkey; Mechanical Engineering Department, Middle East Technical University, Ankara, 06800, Turkey; University of Lincoln, Computational Intelligence Laboratory (CIL), School of Computer Science, Lincoln, LN6 7TS, UK; The University of Manchester, Robotics for Extreme Environments Lab (REEL), School of Electrical and Electronic Engineering, Manchester, M13 9PL, United Kingdom; The University of Manchester, Robotics for Extreme Environments Lab (REEL), School of Electrical and Electronic Engineering, Manchester, M13 9PL, United Kingdom","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4288","4294","In this paper, we proposed a pheromone-based aggregation method based on the state-of-the-art BEECLUST algorithm. We investigated the impact of pheromone-based communication on the efficiency of robotic swarms to locate and aggregate at areas with a given cue. In particular, we evaluated the impact of the pheromone evaporation and diffusion on the time required for the swarm to aggregate. In a series of simulated and real-world evaluation trials, we demonstrated that augmenting the BEECLUST method with artificial pheromone resulted in faster aggregation times.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593961","Swarm Robotics;Aggregation;Pheromone;Bio-inspired","Robot sensing systems;Biological system modeling;Aggregates;Swarm robotics;Temperature sensors","aggregation;fuzzy control;fuzzy set theory;image colour analysis;mobile robots;multi-robot systems","pheromone diffusion;BEECLUST algorithm;pheromone-based communication;pheromone-based aggregation method;ΦClust;artificial pheromone;BEECLUST method;pheromone evaporation;robotic swarms","","","29","","","","","IEEE","IEEE Conferences"
"Repeatability and Reproducibility Analysis of a Multistable Module Devoted to Digital Microrobotics","I. Bouhadda; A. Mohand-Ousaid; G. Bourbon; P. L. Moal; P. Lutz; H. Hussein; Y. Haddab","FEMTO-ST Insti-tute/CNRS, are with Université Bourgogne Franche-Comté, Besançon, France; FEMTO-ST Insti-tute/CNRS, are with Université Bourgogne Franche-Comté, Besançon, France; FEMTO-ST Insti-tute/CNRS, are with Université Bourgogne Franche-Comté, Besançon, France; FEMTO-ST Insti-tute/CNRS, are with Université Bourgogne Franche-Comté, Besançon, France; FEMTO-ST Insti-tute/CNRS, are with Université Bourgogne Franche-Comté, Besançon, France; LIRMM/CNRS, are with Université de Montpellier, Montpellier, France; LIRMM/CNRS, are with Université de Montpellier, Montpellier, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4889","4894","The digital microrobot, called DiMiBot, opened a new paradigm in the design of microrobots by using mechanical stability instead of complex control strategies. Current DiMiBot robots are based on the use of bistable modules to reach discrete stable positions. However, the number of stable positions depends on the number of bistable modules. As a consequence, the mechanism size increases rapidly and its miniaturization becomes complex and non-intuitive. To tackle this issue, a new multistable module has been developed to reach several stable positions within a miniaturized structure. In this paper, we focus on the reapitability and the reproducibility analysis of the developed multistable module in terms of displacement. This study is mandatory to demonstrate the effectiveness of the module as it is expected to be an elementary component of the next generation of DiMiBot. To this end, a series of experimental measurements are conducted on individual and multiple modules. The results analysis show a good agreement between the theoretical and the experimental displacements. In other words, the multistable prototype is able to reach 13 stable positions linearly in one dimensional direction with a step of about 10 μm. These capabilities open a promising perspectives and applications of this module to achieve microrobotics tasks. For example, it can be integrated in complex systems devoted to advanced tasks or accurate positioning in MEMS devices.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594259","","Clamps;Actuators;Prototypes;Task analysis;Switches;Silicon;Micromechanical devices","digital control;mechanical stability;micromanipulators;micromechanical devices;microrobots;robot dynamics","mechanical stability;complex control strategies;bistable modules;mechanism size;repeatability analysis;multistable module;DiMiBot robots;digital microrobotics;complex systems;multistable prototype;multiple modules;reproducibility analysis;miniaturized structure;discrete stable positions","","","18","","","","","IEEE","IEEE Conferences"
"Pre-clinical validation of the UHP multifunctional upper-limb rehabilitation robot based platform","A. Mancisidor; A. Zubizarreta; I. Cabanes; A. Brull; A. Rodriguez; J. H. Jung","Department of Automatic Control and System Engineering, Faculty of Engineering in Bilbao, University of the Basque Country (UPV/EHU), Plaza Ingeniero Torres Quevedo 1, Bilbao, 48013, Spain; Department of Automatic Control and System Engineering, Faculty of Engineering in Bilbao, University of the Basque Country (UPV/EHU), Plaza Ingeniero Torres Quevedo 1, Bilbao, 48013, Spain; Department of Automatic Control and System Engineering, Faculty of Engineering in Bilbao, University of the Basque Country (UPV/EHU), Plaza Ingeniero Torres Quevedo 1, Bilbao, 48013, Spain; Department of Automatic Control and System Engineering, Faculty of Engineering in Bilbao, University of the Basque Country (UPV/EHU), Plaza Ingeniero Torres Quevedo 1, Bilbao, 48013, Spain; Rodriguez is with Department of Physiology, Faculty of Medicine and Nursing, University of the Basque Country (UPV/EHU), Barrio Sarriena s/n, Leioa, Bizkaia, E-48940, Spain; Neurorehabilitation- Area, Health Division, TECNALIA Research and Innovation, Mikeletegi Pasealekua 1–3, Donostia-San, Sebastian, 20009, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2299","2304","Interest in robotic devices for rehabilitation has increased in the last years, due to the increasing number of patients that require rehabilitation therapies, and the need to optimize existing resources. The UHP rehabilitation robot is a multifunctional device that allows to execute robotized therapies for the upper-limb using a simple pantograph based reconfigurable structure and the implementation of advanced position/force control approaches. However, in applications such as rehabilitation, where the robotic device interacts directly with the user, complying with the demands of the users is as important as complying with the functional requirements. Otherwise, the patient will reject the robotic device. Therefore, in this work the pre-clinical validation of the UHP upper-limb rehabilitation robotic platform is presented. 25 subjects of different physical characteristics have participated in the evaluation of the device, evaluating not only the correct behaviour of the device, but also its safety and adaptativity. Results show the correct behaviour of the platform, and a good acceptance rate of the device.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593527","","Rehabilitation robotics;Training;Games;Software;Robot sensing systems;Elbow","biomechanics;force control;medical robotics;patient rehabilitation;position control","robotic device interacts;pre-clinical validation;upper-limb rehabilitation robotic platform;UHP multifunctional upper-limb rehabilitation robot;rehabilitation therapies;UHP rehabilitation robot;multifunctional device;robotized therapies;advanced position-force control approaches","","","21","","","","","IEEE","IEEE Conferences"
"Multi-Robot Virtual Structure Switching and Formation Changing Strategy in an Unknown Occluded Environment","D. Roy; A. Chowdhury; M. Maitra; S. Bhattacharya","Embedded Systems and Robotics, Tata Consultancy Services Limited, TCS Research and Innovation, Kolkata, India; Embedded Systems and Robotics, Tata Consultancy Services Limited, TCS Research and Innovation, Kolkata, India; Department of Electrical Engineering, Jadavpur University, Kolkata, India; Department of Electrical Engineering, Jadavpur University, Kolkata, India","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4854","4861","This paper presents a switching strategy of a region-based shape controller for a swarm-robotic framework to overcome the traditional obstacle-avoidance problem in the virtual structure methodology. In this control approach, initially, the robots move as a group inside a circular region which we conceive to be the initial virtual structure, while preserving a specific pattern, say a triangular formation, among them. In order to avoid static/dynamic obstacles, while approaching towards the target without any prior knowledge about the environment, the virtual-circle is allowed to shrink up to a certain limit. The shrinking phenomena of the virtual circle will depend upon the number of agents within the circle and the distance between two the nearest obstacles sensed by the agents through which the swarm should be able to pass. If the situation demands, the structure may assume the shape of an ellipse of equivalent area continually throughout the path described by the swarm encapsulated within the variable structure. To achieve this, two-layer hierarchical control strategy has been proposed. Moreover, if the shape of the virtual structure changes, the formation of the swarm inside the region may also change. To make the inter-agent formation flexible inside the newly formed virtual structure, a spanning-tree-assisted-shape-matching algorithm has been employed for accommodating all the agents inside the virtual region which helps in the formation change in the agents as well. Finally, simulation results and stability analysis of the controllers are provided to demonstrate our proposed technique.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594438","","Shape;Robots;Switches;Convergence;Simulation;Stability analysis","collision avoidance;hierarchical systems;multi-robot systems;stability;switching systems (control);trees (mathematics)","multirobot virtual structure switching;formation changing strategy;region-based shape controller;swarm-robotic framework;traditional obstacle-avoidance problem;virtual structure methodology;triangular formation;shrinking phenomena;variable structure;two-layer hierarchical control strategy;inter-agent formation;spanning-tree-assisted-shape-matching algorithm;stability analysis","","","31","","","","","IEEE","IEEE Conferences"
"Laser-Based Reactive Navigation for Multirotor Aerial Robots using Deep Reinforcement Learning","C. Sampedro; H. Bavle; A. Rodriguez-Ramos; P. de la Puente; P. Campoy","Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, Spain; Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politecnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1024","1031","Navigation in unknown indoor environments with fast collision avoidance capabilities is an ongoing research topic. Traditional motion planning algorithms rely on precise maps of the environment, where re-adapting a generated path can be highly demanding in terms of computational cost. In this paper, we present a fast reactive navigation algorithm using Deep Reinforcement Learning applied to multi rotor aerial robots. Taking as input the 2D-laser range measurements and the relative position of the aerial robot with respect to the desired goal, the proposed algorithm is successfully trained in a Gazebo-based simulation scenario by adopting an artificial potential field formulation. A thorough evaluation of the trained agent has been carried out both in simulated and real indoor scenarios, showing the appropriate reactive navigation behavior of the agent in the presence of static and dynamic obstacles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593706","","Navigation;Robots;Unmanned aerial vehicles;Lasers;Heuristic algorithms;Reinforcement learning;Planning","autonomous aerial vehicles;collision avoidance;learning (artificial intelligence);mobile robots","traditional motion planning algorithms;precise maps;fast reactive navigation algorithm;multirotor aerial robots;2D-laser range measurements;Gazebo-based simulation scenario;artificial potential field formulation;laser-based reactive navigation;collision avoidance capabilities;reactive navigation behavior;deep reinforcement learning;dynamic obstacles;static obstacles","","","28","","","","","IEEE","IEEE Conferences"
"A Singularity-Robust LQR Controller for Parallel Robots","R. Bordalba; J. M. Porta; L. Ros","CSIC-UPC, Institut de Robòtica i Informática Industrial, Barcelona, Spain; CSIC-UPC, Institut de Robòtica i Informática Industrial, Barcelona, Spain; CSIC-UPC, Institut de Robòtica i Informática Industrial, Barcelona, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","270","276","Parallel robots exhibit the so-called forward singularities, which complicate substantially the planning and control of their motions. Often, such complications are circumvented by restricting the motions to singularity-free regions of the workspace. However, this comes at the expense of reducing the motion range of the robot substantially. It is for this reason that, recently, efforts are underway to control singularity-crossing trajectories. This paper proposes a reliable controller to stabilize such kind of trajectories. The controller is based on the classical theory of linear quadratic regulators, which we adapt appropriately to the case of parallel robots. As opposed to traditional computed-torque methods, the obtained controller does not rely on expensive inverse dynamics computations. Instead, it uses an optimal control law that is easy to evaluate, and does not generate instabilities at forward singularities. The performance of the controller is exemplified on a five-bar parallel robot accomplishing two tasks that require the traversal of singularities.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594084","","Trajectory;Parallel robots;Robot kinematics;Regulators;Task analysis","control system synthesis;linear quadratic control;mobile robots;nonlinear control systems;optimal control;robust control;torque control","singularity-robust LQR controller;five-bar parallel robot;optimal control law;expensive inverse dynamics computations;reliable controller;singularity-crossing trajectories;motion range;singularity-free regions;forward singularities;parallel robots","","","19","","","","","IEEE","IEEE Conferences"
"Heterogeneous Sensor-Robot Team Positioning and Mixed Strategy Scheduling","B. T. Hartman; R. D. Tatum; M. J. Bays","NSWC, Panama City Division, Panama City, FL; NSWC, Panama City Division, Panama City, FL; NSWC, Panama City Division, Panama City, FL","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3137","3144","We are faced with the problem of optimally placing a heterogeneous team of sensors and effector robots in an area while taking into account the environment, anticipated arrival traffic, and desired power consumption of the team. We stage the problems of anticipating arrival traffic and determining a proper power schedule as an adversarial game, incorporating our analysis of the game in the objective function which evaluates sensor positions. We obtain the set of sensor positions which performs best at the desired power consumption, evaluating the mixed strategy of sensor activity that best counters the anticipated potential arrival paths. To determine an approximate global optima for a large number of heterogeneous nodes, we employ Adaptive Simulated Annealing (ASA) to ensure our algorithm is flexible over a varied range of scenarios. We compare the proposed algorithm to a gradient-based greedy placement algorithm with a uniform power schedule within simulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594263","","Robot sensing systems;Schedules;Robot kinematics;Games;Linear programming","game theory;multi-robot systems;scheduling;sensor placement;simulated annealing","heterogeneous sensor-robot team positioning;mixed strategy scheduling;effector robots;anticipated arrival traffic;adversarial game;sensor positions;anticipated potential arrival paths;uniform power schedule;adaptive simulated annealing","","","18","","","","","IEEE","IEEE Conferences"
"Walking Assistance and Resistance of Walking Motion by Trunk and Pelvis Motion Assist","K. Hashimoto; T. Tanaka; T. Kusaka","Hokaido University, The Graduate School of Information Science and Technology, Hokkaido, Japan; Hokaido University, The Graduate School of Information Science and Technology, Hokkaido, Japan; Hokaido University, The Graduate School of Information Science and Technology, Hokkaido, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8597","8602","The aim of this study was to develop a walking assistance device by controlling trunk and pelvis motion. Human gait motion is a whole-body exercise that includes both lower body and upper body motion. Therefore, focusing on trunk and pelvic rotational motion, assist and resist the walking by applying external forces. By introducing periodic input control, control the timing of the supplementary force, and assist the walking. As an experimental result, the walking assistance improves gait by decreasing energy loss, and the walking resistance applies a load during walking.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593531","","Legged locomotion;Pelvis;Oscillators;Force;Control systems;Shafts;Knee","gait analysis;handicapped aids;legged locomotion;motion control","walking assistance device;human gait motion;whole-body exercise;lower body;upper body motion;pelvic rotational motion;periodic input control;walking resistance;walking motion","","","16","","","","","IEEE","IEEE Conferences"
"Approximate Distributed Spatiotemporal Topic Models for Multi-Robot Terrain Characterization","K. Doherty; G. Flaspohler; N. Roy; Y. Girdhar","Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory (CSAIL), 77 Massachusetts Ave, MA, 02139, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory (CSAIL), 77 Massachusetts Ave, MA, 02139, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory (CSAIL), 77 Massachusetts Ave, MA, 02139, USA; Department of Applied Ocean Physics and Engineering, Woods Hole Oceanographic Institution, 86 Water St, Woods Hole, MA, 02543, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3730","3737","Unsupervised learning techniques, such as Bayesian topic models, are capable of discovering latent structure directly from raw data. These unsupervised models can endow robots with the ability to learn from their observations without human supervision, and then use the learned models for tasks such as autonomous exploration, adaptive sampling, or surveillance. This paper extends single-robot topic models to the domain of multiple robots. The main difficulty of this extension lies in achieving and maintaining global consensus among the unsupervised models learned locally by each robot. This is especially challenging for multi-robot teams operating in communication-constrained environments, such as marine robots. We present a novel approach for multi-robot distributed learning in which each robot maintains a local topic model to categorize its observations and model parameters are shared to achieve global consensus. We apply a combinatorial optimization procedure that combines local robot topic distributions into a globally consistent model based on topic similarity, which we find mitigates topic drift when compared to a baseline approach that matches topics naïvely, We evaluate our methods experimentally by demonstrating multi-robot underwater terrain characterization using simulated missions on real seabed imagery. Our proposed method achieves similar model quality under bandwidth-constraints to that achieved by models that continuously communicate, despite requiring less than one percent of the data transmission needed for continuous communication.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594442","","Adaptation models;Robot sensing systems;Spatiotemporal phenomena;Data models;Visualization;Mathematical model","learning (artificial intelligence);mobile robots;multi-robot systems;oceanographic equipment;optimisation;underwater equipment;unsupervised learning","distributed spatiotemporal topic models;real seabed imagery;multirobot underwater terrain characterization;local robot topic distributions;local topic model;multirobot distributed learning;marine robots;multirobot teams;multiple robots;single-robot topic models;learned models;unsupervised models;raw data;latent structure;Bayesian topic models;unsupervised learning techniques;multirobot terrain characterization","","","18","","","","","IEEE","IEEE Conferences"
"Segmenting and Sequencing of Compliant Motions","T. M. Hagos; M. Suomalainen; V. Kyrki","Aalto University, School of Electrical Engineering, Finland; Aalto University, School of Electrical Engineering, Finland; Aalto University, School of Electrical Engineering, Finland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper proposes an approach for segmenting a task consisting of compliant motions into phases, learning a primitive for each segmented phase of the task, and reproducing the task by sequencing primitives online based on the learned model. As compliant motions can “probe” the environment, using the interaction between the robot and the environment to detect phase transitions can make the transitions less prone to positional errors. This intuition leads us to model a task with a non-homogeneous Hidden Markov Model (HMM), wherein hidden phase transition probabilities depend on the interaction with the environment (wrench measured by an F/T sensor). Expectation-maximization algorithm is employed in estimating the parameters of the HMM model. During reproduction, the phase changes of a task are detected online using the forward algorithm, with the parameters learned from demonstrations. Cartesian impedance controller parameters are learned from the demonstrations to reproduce each phase of the task. The proposed approach is studied with a KUKA LWR4+ arm in two setups. Experiments show that the method can successfully segment and reproduce a task consisting of compliant motions with one or more demonstrations, even when demonstrations do not have the same starting position and external forces occur from different directions. Finally, we demonstrate that the method can also handle rotational motions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593710","","Hidden Markov models;Task analysis;Motion segmentation;Adaptation models;Computational modeling;Impedance","end effectors;expectation-maximisation algorithm;force sensors;hidden Markov models;human-robot interaction;motion control;probability","nonhomogeneous hidden Markov model;expectation-maximization algorithm;cartesian impedance controller parameter;KUKA LWR4+ arm;parameter estimation;HMM model;hidden phase transition probabilities;segmented phase;compliant motions","","","20","","","","","IEEE","IEEE Conferences"
"Modeling and Trajectory Tracking Control of a New Parallel Flexible Link Robot","M. Morlock; N. Meyer; M. Pick; R. Seifried","University of Technology, Institute of Mechanics and Ocean Engineering, Hamburg, 21073, Germany; University of Technology, Institute of Mechanics and Ocean Engineering, Hamburg, 21073, Germany; University of Technology, Institute of Mechanics and Ocean Engineering, Hamburg, 21073, Germany; University of Technology, Institute of Mechanics and Ocean Engineering, Hamburg, 21073, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6484","6489","A completely new compliant lightweight robot is presented with a kinematic loop and a highly flexible link. It is explained how to model such parallel robots accurately but still computationally efficient. The elastic deformations are described with the floating frame of reference approach. For the flexible components this allows to use linear finite element models, which can represent arbitrary geometries. These models are further reduced by modal truncation and a Component Mode Synthesis minimizing the number of elastic degrees of freedom, which is necessary for real-time control purposes. The obtained model of the underactuated robot is non-minimum phase for the end-effector as output. Thus, for the applied trajectory tracking controller which is based on servo constraints, the concept of stable inversion is used. The performance is compared to a relocated minimum phase output. Corresponding simulations are validated by first experimental results showing the need for and high accuracy of the flexible model and the trajectory tracking control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594008","","Robots;Strain;Finite element analysis;Trajectory tracking;Kinematics;Mathematical model;Shape","control system synthesis;elastic deformation;end effectors;finite element analysis;flexible manipulators;geometry;manipulator dynamics;tracking;trajectory control","arbitrary geometries;modal truncation;Component Mode Synthesis;underactuated robot;flexible model;trajectory tracking control;kinematic loop;elastic deformations;linear finite element models;parallel flexible link robot;compliant lightweight robot;end-effector","","","15","","","","","IEEE","IEEE Conferences"
"Flatness-Based Model Predictive Control for Quadrotor Trajectory Tracking","M. Greeff; A. P. Schoellig","University of Toronto Institute for Aerospace Studies (UTIAS), Dynamic Systems Lab, Canada; University of Toronto Institute for Aerospace Studies (UTIAS), Dynamic Systems Lab, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6740","6745","The use of model predictive control for quadro-tor applications requires balancing trajectory tracking performance and constraint satisfaction with fast computation. This paper proposes a Flatness-based Model Predictive Control (FMPC) approach that can be applied to quadrotors, and more generally, differentially flat nonlinear systems. Our proposed FMPC couples feedback model predictive control with feedforward linearization. The proposed approach has the computational advantage that, similar to linear model predictive control, it only requires solving a convex quadratic program instead of a nonlinear program. However, unlike linear model predictive control, we still account for the nonlinearity in the model through the use of an inverse term. In simulation, we demonstrate improved robustness over approaches that couple model predictive control with feedback linearization. In experiments using quadrotor vehicles, we also demonstrate improved trajectory tracking compared to classical linear and nonlinear model predictive control approaches.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594012","","Feedforward systems;Predictive control;Feedback linearization;Robustness;Computational modeling;Predictive models;Trajectory","control system synthesis;convex programming;feedback;feedforward;helicopters;nonlinear control systems;nonlinear programming;position control;predictive control;quadratic programming;stability;trajectory control","quadrotor trajectory tracking;trajectory tracking performance;constraint satisfaction;differentially flat nonlinear systems;FMPC couples feedback model predictive control;linear model predictive control;couple model predictive control;nonlinear model;control approaches;flatness-based model predictive control approach","","","21","","","","","IEEE","IEEE Conferences"
"Integration of a Canine Agent in a Wireless Sensor Network for Information Gathering in Search and Rescue Missions*This work was partially funded by the Spanish project DPI2015-65186-R. The publication has received support from Universidad de Málaga Campus de Excelencia Andalucía Tech.","J. J. Fernández-Lozano; A. Mandow; M. Martín-Guzmán; J. Martín-Ávila; J. Serón; J. L. Martínez; J. A. Gomez-Ruiz; C. Socarras-Bertiz; J. Miranda-Páez; A. García-Cerezo","Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain; Universidad de La Guajira, Riohacha, Colombia; Ctedra de Seguridad, Emergencias y Catstrofes, Universidad de Málaga, Málaga, 29071, Spain; Robotics and Mechatronics Lab, Andalucía Tech, Universidad de Málaga, Málaga, 29071, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5685","5690","Search and rescue operations in the context of emergency response to human or natural disasters have the major goal of finding potential victims in the shortest possible time. Multi-agent teams, which can include specialized human respondents, robots and canine units, complement the strengths and weaknesses of each agent, like all-terrain mobility or capability to locate human beings. However, efficient coordination of heterogeneous agents requires specific means to locate the agents, and to provide them with the information they require to complete their mission. The major contribution of this work is an application of Wireless Sensor Networks (WSN) to gather information from a multi-agent team and to make it available to the rest of the agents while keeping coverage. In particular, a canine agent has been equipped with a mobile node installed on a harness, providing information about the dog's location as well as gas levels. The configuration of the mobile node allows for flexible arrangement of the system, being able to integrate static as well as mobile nodes. The gathered information is available at an external database, so that the rest of the agents and the control center can use it in real time. The proposed scheme has been tested in realistic scenarios during search and rescue exercises.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593849","","Dogs;Wireless sensor networks;Receivers;Mobile nodes;Transmitters;Databases","disasters;emergency management;emergency services;multi-agent systems;rescue robots;wireless sensor networks","search and rescue missions;wireless sensor networks;robots;mobile node;heterogeneous agents;multiagent team;natural disasters;human disasters;emergency response;information gathering;wireless sensor network;canine agent","","","23","","","","","IEEE","IEEE Conferences"
"Static Kinematics for an Antagonistically Actuated Robot Based on a Beam-Mechanics-Based Model","A. Stilli; E. Kolokotronis; J. Fraś; A. Ataka; K. Althoefer; H. A. Wurdemann","University College London, Dept. of Computer Science, London, WC1E 7JE, UK; University College London, Dept. of Mechanical Engineering, London, WC1E 7JE, UK; Queen Mary University of London, School of Engineering and Materials Science, London, E1 4NS, UK; Dept. of Informatics, King's College London, Centre for Robotic Research, Strand, London, WC2R 2LS, UK; Queen Mary University of London, School of Engineering and Materials Science, London, E1 4NS, UK; University College London, Dept. of Mechanical Engineering, London, WC1E 7JE, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6959","6964","Soft robotic structures might play a major role in the 4<sup>th</sup> industrial revolution. Researchers have successfully demonstrated advantages of soft robotics over traditional robots made of rigid links and joints in several application areas including manufacturing, healthcare and surgical interventions. However, soft robots have limited ability to exert higher forces when it comes to interaction with the environment, hence, change their stiffness on demand over a wide range. One stiffness mechanism embodies tendon-driven and pneumatic air actuation in an antagonistic way achieving variable stiffness values. In this paper, we apply a beam-mechanics-based model to this type of soft stiffness controllable robot. This mathematical model takes into account the various stiffness levels of the soft robotic manipulator as well as interaction forces with the environment at the tip of the manipulator. The analytical model is implemented into a robotic actuation system made of motorised linear rails with load cells (obtaining applied forces to the tendons) and a pressure regulator. Here, we present and analyse the performance and limitations of our model.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593674","","Manipulators;Tendons;Force;Soft robotics;Mathematical model;Service robots","manipulator kinematics;pneumatic actuators","static kinematics;beam-mechanics-based model;soft robotic structures;industrial revolution;soft robotics;traditional robots;rigid links;joints;soft robots;stiffness mechanism embodies;pneumatic air actuation;variable stiffness values;soft stiffness controllable robot;mathematical model;stiffness levels;soft robotic manipulator;interaction forces;analytical model;robotic actuation system;actuated robot","","","24","","","","","IEEE","IEEE Conferences"
"Dual-Arm Coordinated Motion Planning and Compliance Control for Capturing Moving Objects with Large Momentum","L. Yan; Y. Yang; W. Xu; S. Vijayakumar","Harbin Institute of Technology, The School of Mechanical Engineering and Automation, Shenzhen, 518055, China; University of Edinburgh, The Institute of Perception, Action and Behaviour, School of Informatics, Edinburgh, EH8 9AB, U.K.; Harbin Institute of Technology, The School of Mechanical Engineering and Automation, Shenzhen, 518055, China; University of Edinburgh, The Institute of Perception, Action and Behaviour, School of Informatics, Edinburgh, EH8 9AB, U.K.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7137","7144","Capturing a moving object with large momentum by a dual-arm robot is especially challenging because of the requirement of dual-arm coordinated motion planning for tracking the moving object, and the operational force control for contact and momentum transfer. In this paper, we present a dual-arm coordinated motion planning and compliance control method with a unique null-space projected relative Jacobian and relative operational force between the two arms. The proposed method is able to plan dual-arm capturing motion and control the capturing force without disturbing the tracking motion. We have also adopted a direct collocation trajectory optimization method to generate optimal trajectory to decrease the object's momentum with minimum effort. Simulation and experiment of dual-arm robots picking up a moving box on a mobile platform are carried out to verify the proposed method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593853","","Planning;Force;Robot kinematics;Jacobian matrices;Trajectory;Tracking","compliance control;force control;Jacobian matrices;manipulators;motion control;optimal control;path planning;trajectory control","dual-arm coordinated motion planning;dual-arm robot;operational force control;dual-arm capturing motion;object tracking;compliance control;null-space projected relative Jacobian;collocation trajectory optimization","","","23","","","","","IEEE","IEEE Conferences"
"The TUM VI Benchmark for Evaluating Visual-Inertial Odometry","D. Schubert; T. Goll; N. Demmel; V. Usenko; J. Stückler; D. Cremers","Technical University of Munich, Garching bei München, 85748, Germany; Technical University of Munich, Garching bei München, 85748, Germany; Technical University of Munich, Garching bei München, 85748, Germany; Technical University of Munich, Garching bei München, 85748, Germany; Technical University of Munich, Garching bei München, 85748, Germany; Technical University of Munich, Garching bei München, 85748, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1680","1687","Visual odometry and SLAM methods have a large variety of applications in domains such as augmented reality or robotics. Complementing vision sensors with inertial measurements tremendously improves tracking accuracy and robustness, and thus has spawned large interest in the development of visual-inertial (VI) odometry approaches. In this paper, we propose the TUM VI benchmark, a novel dataset with a diverse set of sequences in different scenes for evaluating VI odometry. It provides camera images with 1024×1024 resolution at 20 Hz, high dynamic range and photometric calibration. An IMU measures accelerations and angular velocities on 3 axes at 200 Hz, while the cameras and IMU sensors are time-synchronized in hardware. For trajectory evaluation, we also provide accurate pose ground truth from a motion capture system at high frequency (120 Hz) at the start and end of the sequences which we accurately aligned with the camera and IMU measurements. The full dataset with raw and calibrated data is publicly available. We also evaluate state-of-the-art VI odometry approaches on our dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593419","","Cameras;Calibration;Simultaneous localization and mapping;Benchmark testing;Visual odometry;Time measurement","augmented reality;calibration;cameras;distance measurement;image capture;image sensors;image sequences;mobile robots;optical tracking;pose estimation;robot vision;SLAM (robots);synchronisation","visual-inertial odometry;photometric calibration;motion capture system;IMU measurements;pose ground truth;inertial measurements;vision sensors;augmented reality;SLAM methods;visual odometry;IMU sensors;camera images;TUM VI benchmark;frequency 20.0 Hz;frequency 200.0 Hz;frequency 120.0 Hz","","2","22","","","","","IEEE","IEEE Conferences"
"Supervised Autonomous Locomotion and Manipulation for Disaster Response with a Centaur-Like Robot","T. Klamt; D. Rodriguez; M. Schwarz; C. Lenz; D. Pavlichenko; D. Droeschel; S. Behnke","Autonomous Intelligent Systems group of University of Bonn, Germany; Autonomous Intelligent Systems group of University of Bonn, Germany; Autonomous Intelligent Systems group of University of Bonn, Germany; Autonomous Intelligent Systems group of University of Bonn, Germany; Autonomous Intelligent Systems group of University of Bonn, Germany; Autonomous Intelligent Systems group of University of Bonn, Germany; Autonomous Intelligent Systems group of University of Bonn, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","Mobile manipulation tasks are one of the key challenges in the field of search and rescue (SAR) robotics requiring robots with flexible locomotion and manipulation abilities. Since the tasks are mostly unknown in advance, the robot has to adapt to a wide variety of terrains and workspaces during a mission. The centaur-like robot Centauro has a hybrid legged-wheeled base and an anthropomorphic upper body to carry out complex tasks in environments too dangerous for humans. Due to its high number of degrees of freedom, controlling the robot with direct teleoperation approaches is challenging and exhausting. Supervised autonomy approaches are promising to increase quality and speed of control while keeping the flexibility to solve unknown tasks. We developed a set of operator assistance functionalities with different levels of autonomy to control the robot for challenging locomotion and manipulation tasks. The integrated system was evaluated in disaster response scenarios and showed promising performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594509","","Task analysis;Three-dimensional displays;Legged locomotion;Cameras;Robot vision systems","disasters;legged locomotion;manipulators;motion control;rescue robots;telerobotics","autonomous locomotion;mobile manipulation tasks;SAR;flexible locomotion;terrains;anthropomorphic upper body;complex tasks;direct teleoperation approaches;supervised autonomy approaches;disaster response scenarios;centaur-like robot Centauro;hybrid legged-wheeled base;operator assistance functionalities;search and rescue","","4","28","","","","","IEEE","IEEE Conferences"
"Robotic Boreblending: The Future of In-Situ Gas Turbine Repair","D. Alatorre; B. Nasser; A. Rabani; A. Nagy-Sochacki; X. Dong; D. Axinte; J. Kell","NA; NA; NA; NA; NA; NA; NA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1401","1406","Automation of inspection and repair tasks on complex installations is gaining attention from industries with high-value assets such as aerospace, nuclear and marine. This paper reports on a five degrees of freedom robotic system capable of performing accurate and repeatable repair procedures through a narrow inspection port, which minimizes the cost and downtime associated with unscheduled maintenance. Careful study of the target working volume and repair process informed the design of a robotic probe capable of replicating the operation. Kinematic analysis of the robot's flexible, prismatic and rotary joints was used to define accurate machining paths in 3D space, and the results were verified using an optical motion capture system (accuracy of 0.25 mm). After comprehensive verifications of the constitutive elements, the robotic system was successfully demonstrated for repair of a high-pressure compressor aerofoil in a gas turbine. The results not only proves the ability of the system to address such difficult repair scenarios but also highlights a domain of opportunities in developing specialist robotics for repair of high-value assets, which is a subject to growing global demand.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594155","","Tools;Blades;Maintenance engineering;Turbines;Joints;End effectors","compressors;gas turbines;industrial robots;inspection;maintenance engineering","maintenance;robot flexible joints;kinematic analysis;In-Situ Gas Turbine Repair;robotic boreblending","","","12","","","","","IEEE","IEEE Conferences"
"An Origami-Inspired Flexible Pneumatic Actuator","F. Schmitt; O. Piccin; L. Barbé; B. Bayle","ICube Laboratory, University of Strasbourg-CNRS, France; INSA Strasbourg, ICube Laboratory, France; ICube Laboratory, University of Strasbourg-CNRS, France; ICube Laboratory, University of Strasbourg-CNRS, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","436","441","This paper presents a new actuator designed to produce forces under short stroke displacements. Two variants of the prototype have been manufactured using Multi-Material Additive Manufacturing process, based on a flexible origami-inspired architecture. The structure consists of an airtight chamber constituted by rigid plates combined with flexible hinges and surfaces in order to allow the generation of motion. We propose several insights on integration issues such as limited material resistance and maximum range of motion. Both versions of the prototype are then tested to assess their performances for single strokes and cyclic loading.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593423","","Actuators;Geometry;Prototypes;Shape;Soft robotics;Three-dimensional printing","architecture;hinges;mechanical testing;plates (structures);pneumatic actuators;prototypes;rapid prototyping (industrial);shear modulus;three-dimensional printing","prototype;origami-inspired flexible pneumatic actuator design;multimaterial additive manufacturing process;mechanical testing;airtight chamber;flexible origami-inspired architecture;short stroke displacements;material resistance;flexible hinges;rigid plates","","","26","","","","","IEEE","IEEE Conferences"
"Design and Evaluation of Torque Based Bipedal Walking Control System That Prevent Fall Over by Impulsive Disturbance","T. Shirai; Y. Nagamatsu; H. Suzuki; S. Nozawa; K. Okada; M. Inaba","Department of Mechano-Informatics, University of Tokyo, Japan; Department of Mechano-Informatics, University of Tokyo, Japan; Department of Mechano-Informatics, University of Tokyo, Japan; Department of Mechano-Informatics, University of Tokyo, Japan; Department of Mechano-Informatics, University of Tokyo, Japan; Department of Mechano-Informatics, University of Tokyo, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","739","746","In this paper, we develop a bipedal robot control system that has an ability to perform instantaneous high power and flexibility to absorb an impulsive disturbance. We utilize a sensor-less whole body torque control method executed in a high responsive realtime distributed system. This system also includes a robust online walking controller that can avoid fall over caused by a strong collision with the robot's legs. We evaluated the proposed control system by hitting a rubber ball or adding a leg sweep disturbance and verified the functionality of the absorbing motion and the balance restoring motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594334","","Robot sensing systems;Torque;Legged locomotion;Actuators;Humanoid robots","legged locomotion;motion control;torque control","torque based bipedal walking control system;impulsive disturbance;bipedal robot control system;robust online walking controller;leg sweep disturbance;distributed system;sensorless whole body torque control method","","","22","","","","","IEEE","IEEE Conferences"
"Efficient Map Representations for Multi-Dimensional Normal Distributions Transforms","C. Schulz; R. Hanten; A. Zell","Cognitive Systems Group at the Computer Science Department, University of Tübingen, Sand 1, Tübingen, 72076, Germany; Cognitive Systems Group at the Computer Science Department, University of Tübingen, Sand 1, Tübingen, 72076, Germany; Cognitive Systems Group at the Computer Science Department, University of Tübingen, Sand 1, Tübingen, 72076, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2679","2686","Efficient 2D and 3D map representations of both static and dynamic, indoor and outdoor environments are crucial for navigation of driving and flying robots. In this paper, we propose a fast and accurate approach for 2D and 3D Normal Distributions Transform (NDT) mapping based on indexed kd-trees. Similar to other approaches, we also model free space, which allows us to obtain occupancy probabilities. Additionally, we provide optional visibility based updates to enhance map consistency in case of noisy data, e.g. from stereo cameras. Unlike other available implementations, our approach is natively applicable to large-scale environments and in real-time, because our maps are able to grow dynamically. This also offers applicability to exploration tasks. To evaluate our approach, we present experimental results on publicly available datasets and discuss the mapping efficiency in terms of accuracy, runtime and memory management. As an exemplary use case, we apply our maps to Monte Carlo Localization on a well-known large-scale dataset.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593602","","Three-dimensional displays;Robot sensing systems;Gaussian distribution;Two dimensional displays;Task analysis;Transforms","mobile robots;Monte Carlo methods;normal distribution;probability;robot vision;stereo image processing;transforms","indoor environments;outdoor environments;driving flying robots;fast approach;accurate approach;indexed kd-trees;free space;occupancy probabilities;map consistency;large-scale environments;mapping efficiency;efficient map representations;3D map representations;static environments;dynamic environments;multidimensional normal distributions transforms;3D normal distributions transform mapping","","1","23","","","","","IEEE","IEEE Conferences"
"Airborne Docking for Multi-Rotor Aerial Manipulations","R. Miyazaki; R. Jiang; H. Paul; K. Ono; K. Shimonomura","NA; NA; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, 5258577, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, 5258577, Japan; Department of Robotics, Ritsumeikan University, Kusatsu, Shiga, 5258577, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4708","4714","We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594513","","Winches;Bars;Cameras;Robot vision systems;DC motors;Propellers","autonomous aerial vehicles;mobile robots","multirotor aerial robots;transport multirotor UAV;winch mechanism;onboard locolization;mobile manipulation system;airborne docking method;IMU data;multirotor aerial manipulations","","","11","","","","","IEEE","IEEE Conferences"
"A Sensor-less Catheter Contact Force Estimation Approach in Endovascular Intervention Procedures*","M. Razban; J. Dargahi; B. Boulet","Industrial & Aerospace Engineering, Department of Concordia University and Surgical Innovation Fellow in McGill University, Masoud Razban is with Robotic Surgery Lab in Mechanical, Montreal, Canada; Industrial & Aerospace Engineering Department, Concordia University, Robotic Surgery Lab and professor in Mechanical, Montreal, Canada; Intelligent Machines (CIM) and professor in Department of Electrical and Computer Engineering, McGill University, Montreal, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2100","2106","Catheter/guidewire manipulation in endovascu-lar intervention procedures are associated with risks of injury on vessel wall and embolization. Determination of catheter/guidewire-vessel interaction contact forces can improve the navigation process safety and efficiency which prevent injuries in both manual and robotic vascular interventions. This study proposes a sensor-less sensing solution to estimate multiple contact point forces at the side of catheter/guidewire exerted on the vasculature. This goal is achieved by using image feedback of catheter-vessel interaction and numerical finite element modeling (FEM). Real-time image processing algorithms are implemented to track interaction contact points on catheter/guidewire. Image-based deflection measurement and contact points tracking data are given to a nonlinear finite element beam model to estimate the forces. The variable equivalent bending modulus of the guidewire is found through a series of three-point-bending tests. To directly measure contact point forces, an experimental platform is prepared which simulates catheter/guidewire-vessel interaction with two, three and four contact points. The effectiveness of the proposed approach is tested in six scenarios in which force estimation accuracy of more than 87.9% is achieved. The proposed approach can be applied to various types of under-actuated catheter/guidewire in endovascular intervention procedures. This study proves that multiple catheter/guidewire side contact forces can be estimated by using the deflected shape and equivalent bending modulus property without embedding any force sensor.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593387","","Catheters;Force;Robot sensing systems;Estimation;Force measurement;Phantoms;Finite element analysis","bending;blood vessels;catheters;finite element analysis;medical image processing","force estimation accuracy;endovascular intervention procedures;multiple catheter;sensor-less catheter contact force estimation approach;vessel wall;embolization;navigation process safety;robotic vascular interventions;sensor-less sensing solution;multiple contact point forces;image feedback;catheter-vessel interaction;real-time image processing algorithms;interaction contact points;image-based deflection measurement;nonlinear finite element beam model;three-point-bending tests;catheter-guidewire-vessel interaction contact forces;catheter-guidewire manipulation;bending modulus property;under-actuated catheter-guidewire;catheter-guidewire-vessel interaction","","","23","","","","","IEEE","IEEE Conferences"
"Automated Tool Coordinate Calibration System of an Industrial Robot","R. C. Luo; H. Wang","Intelligent Robotics and Automation Research, National Taiwan University, International Center of Excellence, Taipei, Taiwan; National Taiwan University, International Center of Excellence in Intelligent Robotics and Automation Research, Taipei, Taiwan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5592","5597","Due to the widespread use of industrial robots in market, its application has extended to welding, painting, and freight handling. And tool coordinate calibration is regularly modified after tool replacement due to collision accident or routine maintenance. After tool replacement, operators often rebuild tool coordinates. This is the traditional mode of operation in the current industrial practices. However, smart factory will make artificial intelligence method replace manual method. This paper presents a system independent method for automatic calibration of the tool coordinate system which is faster, simpler, cheaper and more effective than the manual method. The proposed method required images to be captured using two “eye to hand” cameras and one “eye in hand” camera. Tool position data is then acquired through CamShift and MeanShift algorithm for image trajectory tracking along with coordinate system conversion, several methods like PCA, LDA can deal with the vision data. Optimal Deep Neural Network (DNN) method error compensation of a robot allows the tool to automatically run with the calibration system functions. We have developed a 6 degrees of freedom(DoF) industrial robot for this experiment. Nine different kinds of DNN models are built and finally with suitable tool coordinate error compensation for the current robot, tool calibration can be achieved adaptively and efficiently.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594298","Calibration;Tool Coordinate;CamShift;MeanShift;DNN","Tools;Robot kinematics;Cameras;Calibration;Service robots;Robot vision systems","artificial intelligence;calibration;cameras;computer vision;error compensation;industrial manipulators;industrial robots;machine tools;neural nets;position control;production engineering computing;robot vision","tool calibration;automated tool;freight handling;tool replacement;collision accident;routine maintenance;tool coordinates;current industrial practices;artificial intelligence method;manual method;system independent method;automatic calibration;hand camera;tool position data;coordinate system conversion;calibration system functions;current robot;6-degree-0f-freedom industrial robot;optimal deep neural network method error compensation","","","15","","","","","IEEE","IEEE Conferences"
"Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots","E. A. Topp; M. Stenmark; A. Ganslandt; A. Svensson; M. Haage; J. Malec","Lund University, Department of Computer Science, Lund, Sweden; Cognibotics AB, Lund, Sweden; Lund University, Department of Computer Science, Lund, Sweden; Lund University, Department of Computer Science, Lund, Sweden; Lund University, Department of Computer Science, Lund, Sweden; Lund University, Department of Computer Science, Lund, Sweden","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5672","5678","We assume that an intuitive means for the specification, re-use, modification and transfer of synchronized motions-both regarding the two arms of a dual-arm robotic system, as well as regarding the coordination of a user and a robot-is key in interactive and collaborative settings as they are currently targeted for industrial applications. We show, how our knowledge based approach to end-user programming of synchronized motions and other generalizable, robot-agnostic skills can support such specification of coordinated actions between two robot arms and explain how that could be extended to include coordination with a human user. We describe the underlying ontologies and possibilities to populate those with an interface for intuitive programming, and show the generality of our approach through a task transfer between different kinematics (different robots), where the user is supported through underlying reasoning about the fulfillment of certain parameters or constraints for the involved skills.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593566","","Robot kinematics;Synchronization;Service robots;Ontologies;Manipulators;Task analysis","control engineering computing;human-robot interaction;industrial manipulators;manipulator kinematics;ontologies (artificial intelligence);production engineering computing;robot programming","ontology-based knowledge representation;dual-arm robotic system;industrial applications;end-user programming;robot arms;intuitive programming;task transfer;kinematics;robot-agnostic skills;industrial robots skill reusability","","","26","","","","","IEEE","IEEE Conferences"
"Real-Time Light Field Processing for Autonomous Robotics","A. Bajpayee; A. H. Techet; H. Singh","MIT, Cambridge, MA; MIT, Cambridge, MA; Northeastern University, Boston, MA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4218","4225","Typical autonomous robotics systems incorporate multiple cameras, LIDAR sensors and sophisticated computing resources. In this paper we present a software framework for utilizing any array of multiple cameras with sufficient field-of-view (FOV) overlap as a light field imaging system. We show that the typical linear arrays that exist on autonomous cars are sufficient to capture stable time resolved light fields even when moving at highway speeds. We elaborate on the potential pitfalls associated with such a technique namely loss of calibration between cameras due to high frequency vibrations and sudden shocks associated with driving over potholes and highlight a method that can compensate for such effects. We demonstrate that the light fields collected by simple linear arrays can be processed in real time for a wide variety of useful applications including occlusion removal, for signal enhancement in featureless images captured in very low light, for reflection removal and for improved visibility in extreme conditions associated with snow and heavy rain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594477","","Cameras;Robot vision systems;Vibrations;Calibration;Three-dimensional displays","calibration;cameras;image sensors;mobile robots;optical radar;robot vision;telerobotics","autonomous robotics systems;LIDAR sensors;time light field processing;simple linear arrays;high frequency vibrations;light fields;autonomous cars;light field imaging system;field-of-view;software framework","","","38","","","","","IEEE","IEEE Conferences"
"Inverse Learning of Robot Behavior for Collaborative Planning","M. Trivedi; P. Doshi","The Computer Science Department, University of Georgia, Athens, GA 30602; The Computer Science Department, University of Georgia, Athens, GA 30602","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Inverse reinforcement learning (IRL) is an important basis for learning from demonstrations. Observing an agent, human or robotic, perform a task provides information and facilitates learning the task. We show how the agent's preferences learned using IRL can be incorporated in a subject robot's decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. We prioritize a real-world application, where a line robot will autonomously collaborate with another robot in sorting ripe and unripe fruit such as oranges. Toward this, our evaluations utilize a colored-ball sorting task as an analog using simulated TurtleBots equipped with Phantom X arms. Our method is comprehensive providing first answers to questions such as how should the robot acquire the complete model for the collaborative planning problem and how should it solve the problem to obtain a plan that permits collaboration without disrupting the line robot's behavior.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593745","","Task analysis;Planning;Robot kinematics;Sorting;Teamwork","behavioural sciences computing;decision making;learning (artificial intelligence);mobile robots;multi-robot systems;optimisation;planning (artificial intelligence)","robots decision making;TurtleBots;Phantom X arms;line robots behavior;collaborative planning problem;colored-ball sorting task;unripe fruit;ripe fruit;IRL;inverse reinforcement learning","","","21","","","","","IEEE","IEEE Conferences"
"Expert-Guided Kinodynamic RRT Path Planner for Non-Holonomic Robots","J. M. Sanz; M. Hernani; G. Zaragoza; A. Brunete","GMV Innovating Solutions, Tres Cantos, Madrid, 28760, Spain; Universidad Politécnica de Madrid, Centre for Automation and Robotics (CAR UPM-CSIC), Spain; Universidad Politécnica de Madrid, Centre for Automation and Robotics (CAR UPM-CSIC), Spain; Universidad Politécnica de Madrid, Centre for Automation and Robotics (CAR UPM-CSIC), Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6540","6545","In this paper, an Expert-Guided Kinodynamic RRT algorithm (EGK-RRT) is presented. It aims to consider how a human pilot would navigate a kinodynamic robot. One of the characteristics of this algorithm is the fact that, unlike the original RRT for kinodynamic systems, it generates deterministic control sequences which can be reproduced as long as the sequence of references (sampled states) are known. Here, the performance of the proposed algorithm is tested against the basic RRT, showing that the EGK-RRT greatly improves in terms of execution speed. In addition to this, the influence of using a visibility check and an inertia estimation in order to select the nearest neighbor is also analyzed, demonstrating that a combination of both factors leads to a better overall performance, both in execution speed and in quality of the generated path.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593924","","Robots;Navigation;Heuristic algorithms;Aerospace electronics;Path planning;Planning;Mathematical model","mobile robots;path planning;robot dynamics","nonholonomic robots;EGK-RRT;expert-guided kinodynamic RRT path planner;expert-guided kinodynamic RRT algorithm;deterministic control sequences","","","14","","","","","IEEE","IEEE Conferences"
"Estimating Door Shape and Manipulation Model for Daily Assistive Robots Based on the Integration of Visual and Touch Information","K. Nagahama; K. Takeshita; H. Yaguchi; K. Yamazaki; T. Yamamoto; M. Inaba","Faculty of Engineering, AIS Lab, Shinshu University, Nagano, 4-17-1, Japan; Toyota Motor Corporation; University of Tokyo, JSK Robotics Lab, Tokyo, 7-3-1, Hongo, Bukyo-ku, Japan; Faculty of Engineering, AIS Lab, Shinshu University, Nagano, 4-17-1, Japan; Toyota Motor Corporation; University of Tokyo, JSK Robotics Lab, Tokyo, 7-3-1, Hongo, Bukyo-ku, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7660","7666","We propose a method for a robot to manipulate an unknown door based on a single user instruction. The primary contributions of this paper are (i) to reduce the user instruction to a single click and (ii) to develop an efficient method to estimate an appropriate shape and manipulation model for a target door by integrating visual and touch information obtained by a robot. The proposed method first detects door candidates using a 3-D camera and then estimates the manipulation model of each candidate based on prior learning results. During door manipulation, the system integrates visual and touch information to estimate the shape and manipulation model to generate an appropriate motion. We evaluated the proposed method experimentally, and the results prove that the proposed method is effective.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593391","","Shape;Robot kinematics;Trajectory;Visualization;Robot vision systems","collision avoidance;learning (artificial intelligence);manipulators;mobile robots;motion control;robot vision;service robots","visual touch information;door manipulation;door candidates;target door;appropriate shape;single click;single user instruction;unknown door;daily assistive robots;manipulation model;door shape","","","20","","","","","IEEE","IEEE Conferences"
"Culturally aware Planning and Execution of Robot Actions","A. A. Khaliq; U. Köckemann; F. Pecora; A. Saffiotti; B. Bruno; C. T. Recchiuto; A. Sgorbissa; H. Bui; N. Y. Chong","AASS, Örebro University, Fakultetsgatan 1, Örebro, S-70182, Sweden; AASS, Örebro University, Fakultetsgatan 1, Örebro, S-70182, Sweden; AASS, Örebro University, Fakultetsgatan 1, Örebro, S-70182, Sweden; AASS, Örebro University, Fakultetsgatan 1, Örebro, S-70182, Sweden; DIBRIS, University of Genova, Via Opera Pia 13, Genova, 16145, Italy; DIBRIS, University of Genova, Via Opera Pia 13, Genova, 16145, Italy; DIBRIS, University of Genova, Via Opera Pia 13, Genova, 16145, Italy; JAIST, Japan Advanced Institute of Science and Technology, 1-1 Asahidai, Nomi, Ishikawa, 923-1292, Japan; JAIST, Japan Advanced Institute of Science and Technology, 1-1 Asahidai, Nomi, Ishikawa, 923-1292, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","326","332","The way in which humans behave, speak and interact is deeply influenced by their culture. For example, greeting is done differently in France, in Sweden or in Japan; and the average interpersonal distance changes from one cultural group to the other. In order to successfully coexist with humans, robots should also adapt their behavior to the culture, customs and manners of the persons they interact with. In this paper, we deal with an important ingredient of cultural adaptation: how to generate robot plans that respect given cultural preferences, and how to execute them in a way that is sensitive to those preferences. We present initial results in this direction in the context of the CARESSES project, a joint EU-Japan effort to build culturally competent assistive robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593570","","Cultural differences;Robot sensing systems;Planning;Knowledge based systems;Computer architecture;Cognition","cultural aspects;mobile robots;path planning","robot actions;cultural group;cultural adaptation;interpersonal distance;robot plans generation;cultural preferences;CARESSES project;assistive robots;culturally aware planning","","","34","","","","","IEEE","IEEE Conferences"
"An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory","Y. Furuta; K. Okada; Y. Kakiuchi; M. Inaba","Department of Creative-Informatics, Graduate School of Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-city, Tokyo, 113-8656, Japan; Department of Creative-Informatics, Graduate School of Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-city, Tokyo, 113-8656, Japan; Department of Creative-Informatics, Graduate School of Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-city, Tokyo, 113-8656, Japan; Department of Creative-Informatics, Graduate School of Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-city, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594481","Service Robots;Learning and Adaptive Systems;Big Data in Robotics and Automation","Task analysis;Probabilistic logic;Semantics;Planning;Robot sensing systems;Solid modeling","mobile robots;path planning","robot agent;local-rule-aware home assistive tasks;semantic map;long-term episodic memory;home environments;global society;probabilistic object localization map;Fetch robots;semantic common knowledge;PR2 robot;robotic system;time 41.0 d","","","17","","","","","IEEE","IEEE Conferences"
"Fabrication and Locomotion of Flexible Nanoswimmers","B. Jang; A. Aho; B. J. Nelson; S. Pané","ETH Zurich, Institute of Robotics and Intelligent Systems, Zurich, Tannenstrasse 3, 8092, Switzerland; ETH Zurich, Institute of Robotics and Intelligent Systems, Zurich, Tannenstrasse 3, 8092, Switzerland; ETH Zurich, Institute of Robotics and Intelligent Systems, Zurich, Tannenstrasse 3, 8092, Switzerland; ETH Zurich, Institute of Robotics and Intelligent Systems, Zurich, Tannenstrasse 3, 8092, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6193","6198","Small-scale robots with soft joints and hinges have recently attracted interest because these components allow for more sophisticated locomotion mechanisms. Here, we investigate two different types of nanoscale swimmers as depicted in Figure 1. One consists of a rigid magnetic head linked to a semi-soft tail (1-link swimmer). Another consists of a rigid magnetic head and tail connected by a soft hinge (2-link swimmer). Both swimmers exhibit undulatory locomotion under an applied oscillating magnetic field. The speeds of the swimmers are assessed as a function of the oscillating magnetic field frequency and the sweeping angle. We find that a resonance-like frequency increases as the length decreases, and, in general, the speed increases as the sweeping angle increases. Last, we show that 2-link swimmers can also swim in a corkscrew-like pattern under rotating magnetic fields.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594047","","Nickel;Magnetic fields;Gold;Resonant frequency;Magnetosphere;Fabrication;Fasteners","hinges;magnetic fields;microrobots;mobile robots;motion control;numerical analysis","1-link swimmer;semisoft tail;nanoscale swimmers;sophisticated locomotion mechanisms;hinges;soft joints;small-scale robots;flexible nanoswimmers;magnetic fields;oscillating magnetic field frequency;undulatory locomotion;2-link swimmer;soft hinge;rigid magnetic head","","","31","","","","","IEEE","IEEE Conferences"
"Model-free and learning-free grasping by Local Contact Moment matching","M. Adjigble; N. Marturi; V. Ortenzi; V. Rajasekaran; P. Corke; R. Stolkin","Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, UK; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, UK; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4001, Australia; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, UK; ARC Centre of Excellence for Robotic Vision, Queensland University of Technology, Brisbane, QLD, 4001, Australia; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2933","2940","This paper addresses the problem of grasping arbitrarily shaped objects, observed as partial point-clouds, without requiring: models of the objects, physics parameters, training data, or other a-priori knowledge. A grasp metric is proposed based on Local Contact Moment (LoCoMo). LoCoMo combines zero-moment shift features, of both hand and object surface patches, to determine local similarity. This metric is then used to search for a set of feasible grasp poses with associated grasp likelihoods. LoCoMo overcomes some limitations of both classical grasp planners and learning-based approaches. Unlike force-closure analysis, LoCoMo does not require knowledge of physical parameters such as friction coefficients, and avoids assumptions about fingertip contacts, instead enabling robust contacts of large areas of hand and object surface. Unlike more recent learning-based approaches, LoCoMo does not require training data, and does not need any prototype grasp configurations to be taught by kinesthetic demonstration. We present results of real-robot experiments grasping 21 different objects, observed by a wrist-mounted depth camera. All objects are grasped successfully when presented to the robot individually. The robot also successfully clears cluttered heaps of objects by sequentially grasping and lifting objects until none remain.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594226","","Grasping;Robots;Measurement;Grippers;Shape;Three-dimensional displays;Training data","dexterous manipulators;grippers;image matching;learning (artificial intelligence);path planning;robot vision","local contact moment matching;LoCoMo metric;grasp planners;learning-based approaches;prototype grasp configurations;robust contacts;fingertip contacts;physical parameters;force-closure analysis;object surface patches;zero-moment shift features;learning-free grasping","","1","30","","","","","IEEE","IEEE Conferences"
"Online Self-Supervised Long-Range Scene Segmentation for MAVs","S. Daftry; Y. Agrawal; L. Matthies","California Institute of Technology, Jet Propulsion Laboratory, Pasadena, CA, USA; California Institute of Technology, Jet Propulsion Laboratory, Pasadena, CA, USA; California Institute of Technology, Jet Propulsion Laboratory, Pasadena, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5194","5199","Recently, there have been numerous advances in the development of payload and power constrained lightweight Micro Aerial Vehicles (MAVs). As these robots aspire for highspeed autonomous flights in complex dynamic environments, robust scene understanding at long-range becomes critical. The problem is heavily characterized by either the limitations imposed by sensor capabilities for geometry-based methods, or the need for large-amounts of manually annotated training data required by data-driven methods. This motivates the need to build systems that have the capability to alleviate these problems by exploiting the complimentary strengths of both geometry and data-driven methods. In this paper, we take a step in this direction and propose a generic framework for adaptive scene segmentation using self-supervised online learning. We present this in the context of vision-based autonomous MAV flight, and demonstrate the efficacy of our proposed system through extensive experiments on benchmark datasets and realworld field tests.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594405","","Image segmentation;Training;Robot sensing systems;Visualization;Real-time systems;Convolution","autonomous aerial vehicles;image segmentation;learning (artificial intelligence);microrobots;mobile robots;object detection;robot vision","vision-based autonomous MAV flight;self-supervised online learning;adaptive scene segmentation;data-driven methods;manually annotated training data;geometry-based methods;sensor capabilities;robust scene understanding;complex dynamic environments;autonomous flights;lightweight MicroAerial Vehicles;MAVs;online self-supervised long-range scene segmentation","","","29","","","","","IEEE","IEEE Conferences"
"Adaptive FES Assistance Using a Novel Gait Phase Detection Approach","W. Huo; V. Arnez-Paniagua; M. Ghedira; Y. Amirat; J. Gracies; S. Mohammed","Signals and Intelligent Systems (LISSI)of the University of Paris-Est Creteil, Laboratory of Images, Vitry-sur-Seine, France; Signals and Intelligent Systems (LISSI)of the University of Paris-Est Creteil, Laboratory of Images, Vitry-sur-Seine, France; University of Paris-Est Creteil, Laboratoire Analyse et Restauration du Mouvement (ARM), Hospital Henri Mondor, AP-HP, EA 7377, France; Signals and Intelligent Systems (LISSI)of the University of Paris-Est Creteil, Laboratory of Images, Vitry-sur-Seine, France; University of Paris-Est Creteil, Laboratoire Analyse et Restauration du Mouvement (ARM), Hospital Henri Mondor, AP-HP, EA 7377, France; Signals and Intelligent Systems (LISSI)of the University of Paris-Est Creteil, Laboratory of Images, Vitry-sur-Seine, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents an adaptive knee-joint based Functional Electrical Stimulation (FES)method to correct the foot drop of paretic patients during swing phase. The rationale behind the adaptive FES is to amplify dorsiflexor stimulation in the late swing when it is most needed in order to face the increased plantar flexor co-contraction as gastrocnemius muscles are stretched by knee re-extension. To accurately detect the swing phase (i.e., toes off (TO)and initial contact (IC)), a novel algorithm is proposed by using a foot-mounted inertial measurement unit (IMU). The proposed strategy is verified by experiments conducted with three healthy subjects and three paretic patients. The experimental results show that highly accurate detection of TO/I C can be achieved under different walking speeds and foot contact conditions (normal and abnormal gaits). The clinical experimental results with paretic patients also reveal that similar effects on ankle dorsiflexion can be observed during mid and late swing using the proposed adaptive FES with respect to the classical FES method, while the adaptive FES used lower stimulation intensity.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594051","","Integrated circuits;Iron;Foot;Legged locomotion;Knee;Accelerometers;Sensors","bioelectric phenomena;bone;gait analysis;neuromuscular stimulation","walking speeds;gastrocnemius muscles;knee reextension;plantar flexor cocontraction;adaptive knee-joint based functional electrical stimulation method;classical FES method;abnormal gaits;normal gaits;foot contact conditions;foot-mounted inertial measurement unit;late swing;dorsiflexor stimulation;swing phase;paretic patients;foot drop;gait phase detection approach;adaptive FES assistance","","","24","","","","","IEEE","IEEE Conferences"
"Cooperative Control for Knee Joint Flexion-Extension Movement Restoration","M. A. Alouane; H. Rifai; Y. Amirat; S. Mohammed","Signaux et Systémes Intelligents, Laboratoire Images Universite Paris-Est Créteil (UPEC), 120 rue Paul Armangot, Vitry-Sur-Seine, France; Signaux et Systémes Intelligents, Laboratoire Images Universite Paris-Est Créteil (UPEC), 120 rue Paul Armangot, Vitry-Sur-Seine, France; Signaux et Systémes Intelligents, Laboratoire Images Universite Paris-Est Créteil (UPEC), 120 rue Paul Armangot, Vitry-Sur-Seine, France; Signaux et Systémes Intelligents, Laboratoire Images Universite Paris-Est Créteil (UPEC), 120 rue Paul Armangot, Vitry-Sur-Seine, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5175","5180","This paper describes a cooperative control approach that combines the use of a powered knee joint orthosis along with Functional Electrical Stimulation (FES) for knee joint flexion-extension movement restoration. A closed-loop adaptive control and an open-loop FES of the quadriceps muscle group are combined together to track a desired knee joint angle trajectory of flexion/extension movements. A nonlinear disturbance observer is used to estimate the torque provided by the subject's muscles through the FES. Simulations and experiments with a healthy subject show the feasibility of the proposed approach. Experiments show the repeatability of motion and the complementarity between the torque provided by the quadriceps muscle through FES and the one delivered by the orthosis actuator to ensure satisfactory tracking of the desired trajectory.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594230","","Torque;Muscles;Knee;Iron;Estimation;Fatigue;Trajectory","adaptive control;closed loop systems;medical control systems;neuromuscular stimulation;nonlinear control systems;observers;orthotics;patient rehabilitation;torque control","knee joint angle trajectory;cooperative control;functional electrical stimulation;quadriceps muscle group;nonlinear disturbance observer;torque estimation;rehabilitation technologies;open-loop FES;closed-loop adaptive control;powered knee joint orthosis;knee joint flexion-extension movement restoration","","","25","","","","","IEEE","IEEE Conferences"
"CROC: Convex Resolution of Centroidal Dynamics Trajectories to Provide a Feasibility Criterion for the Multi Contact Planning Problem","P. Fernbach; S. Tonneau; M. Taïx","CNRS, LAAS, 7 avenue du colonel Roche, Toulouse, F31400, France; CNRS, LAAS, 7 avenue du colonel Roche, Toulouse, F31400, France; CNRS, LAAS, 7 avenue du colonel Roche, Toulouse, F31400, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We tackle the transition feasibility problem, that is the issue of determining whether there exists a feasible motion connecting two configurations of a legged robot. To achieve this we introduce CROC, a novel method for computing centroidal dynamics trajectories in multi-contact planning contexts. Our approach is based on a conservative and convex reformulation of the problem, where we represent the center of mass trajectory as a Bezier curve comprising a single free control point as a variable. Under this formulation, the transition problem is solved efficiently with a Linear Program (LP)of low dimension. We use this LP as a feasibility criterion, incorporated in a sampling-based contact planner, to discard efficiently unfeasible contact plans. We are thus able to produce robust contact sequences, likely to define feasible motion synthesis problems. We illustrate this application on various multi-contact scenarios featuring HRP2 and HyQ. We also show that we can use CROC to compute valuable initial guesses, used to warm-start non-linear solvers for motion generation methods. This method could also be used for the 0 and 1-Step capturability problem. The source code of CROC is available under an open source BSD-2 License.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593888","","Trajectory;Dynamics;Planning;Acceleration;Legged locomotion;Kinematics","approximation theory;computational geometry;legged locomotion;linear programming;motion control;path planning;sampling methods;trajectory control","CROC;feasibility criterion;multicontact planning problem;transition feasibility problem;legged robot;conservative reformulation;convex reformulation;Bezier curve;transition problem;sampling-based contact planner;motion generation methods;center of mass trajectory;convex resolution of centroidal dynamics trajectories;free control point;contact sequences;motion synthesis problems;linear program","","2","26","","","","","IEEE","IEEE Conferences"
"Learning and Generation of Actions from Teleoperation for Domestic Service Robots*This work was supported by JST, CREST","K. Iwata; T. Aoki; T. Horii; T. Nakamura; T. Nagai","University of Electro-Communications, Department of Mechanical Engineering and Intelligent Systems, Chofushi, Tokyo, 1-5-1 Chofugaoka, 182-8585, Japan; University of Electro-Communications, Department of Mechanical Engineering and Intelligent Systems, Chofushi, Tokyo, 1-5-1 Chofugaoka, 182-8585, Japan; University of Electro-Communications, Department of Mechanical Engineering and Intelligent Systems, Chofushi, Tokyo, 1-5-1 Chofugaoka, 182-8585, Japan; University of Electro-Communications, Department of Mechanical Engineering and Intelligent Systems, Chofushi, Tokyo, 1-5-1 Chofugaoka, 182-8585, Japan; University of Electro-Communications, Department of Mechanical Engineering and Intelligent Systems, Chofushi, Tokyo, 1-5-1 Chofugaoka, 182-8585, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8184","8191","In this paper, we propose a method for motion learning aimed at the execution of autonomous household chores by service robots in real environments. For robots to act autonomously in a real environment, it is necessary to define the appropriate actions for the environment. However, it is difficult to define these actions manually. Therefore, body motions that are common to multiple actions are defined as motion primitives. Complex actions can then be learned by combining these motion primitives. For learning motion primitives, we propose a reference-point and object-dependent Gaussian process hidden semi-Markov model (RPOD-GP-HSMM). For verification, a robot is teleoperated to perform the actions included in several domestic household chores. The robot then learns the associated motion primitives from the robot's body information and object information.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593892","","Task analysis;Trajectory;Motion segmentation;Service robots;End effectors","Gaussian processes;hidden Markov models;home automation;intelligent robots;mobile robots;motion control;service robots;telerobotics","autonomous household chores;body motions;object-dependent Gaussian process;domestic household chores;domestic service robots;motion primitives;teleoperation;motion learning;reference-point Gaussian process;hidden semiMarkov model","","","26","","","","","IEEE","IEEE Conferences"
"Real-Time Grasp Planning for Multi-Fingered Hands by Finger Splitting","Y. Fan; T. Tang; H. Lin; M. Tomizuka","Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, 94720, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4045","4052","Grasp planning for multi-fingered hands is computationally expensive due to the joint-contact coupling, surface nonlinearities and high dimensionality, thus is generally not affordable for real-time implementations. Traditional planning methods by optimization, sampling or learning work well in planning for parallel grippers but remain challenging for multi-fingered hands. This paper proposes a strategy called finger splitting, to plan precision grasps for multi-fingered hands starting from optimal parallel grasps. The finger splitting is optimized by a dual-stage iterative optimization including a contact point optimization (CPO) and a palm pose optimization (PPO), to gradually split fingers and adjust both the contact points and the palm pose. The dual-stage optimization is able to consider both the object grasp quality and hand manipulability, address the nonlinearities and coupling, and achieve efficient convergence within one second. Simulation results demonstrate the effectiveness of the proposed approach. The simulation video is available at [1].","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594369","","Optimization;Planning;Grippers;Search problems;Grasping;Databases;Real-time systems","grippers;iterative methods;learning (artificial intelligence);optimisation","time grasp planning;multifingered hands;traditional planning methods;optimal parallel grasps;dual-stage iterative optimization;contact point optimization;finger splitting","","","26","","","","","IEEE","IEEE Conferences"
"Path-Following through Control Funnel Functions","H. Ravanbakhsh; S. Aghli; C. Heckman; S. Sankaranarayanan","Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA; Department of Computer Science, University of Colorado, Boulder, CO, 80309, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","401","408","We present an approach to path following using so-called control funnel functions. Synthesizing controllers to “robustly” follow a reference trajectory is a fundamental problem for autonomous vehicles. Robustness, in this context, requires our controllers to handle a specified amount of deviation from the desired trajectory. Our approach considers a timing law that describes how fast to move along a given reference trajectory and a control feedback law for reducing deviations from the reference. We synthesize both feedback laws using “control funnel functions” that jointly encode the control law as well as its correctness argument over a mathematical model of the vehicle dynamics. We adapt a previously described demonstration-based learning algorithm to synthesize a control funnel function as well as the associated feedback law. We implement this law on top of a 1/8th scale autonomous vehicle called the Parkour car. We compare the performance of our path following approach against a trajectory tracking approach by specifying trajectories of varying lengths and curvatures. Our experiments demonstrate the improved robustness obtained from the use of control funnel functions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593637","","Trajectory;Robustness;Autonomous vehicles;Timing;Vehicle dynamics;Automobiles;Trajectory tracking","control system synthesis;feedback;learning (artificial intelligence);mobile robots;motion control;road vehicles;robot dynamics;robust control;trajectory control;vehicle dynamics","control feedback laws;control funnel functions;path following;reference trajectory;autonomous vehicles;robustness;timing law;mathematical model;vehicle dynamics;demonstration-based learning algorithm;autonomous vehicle;Parkour car;trajectory tracking","","","35","","","","","IEEE","IEEE Conferences"
"Human Pose Estimation in Presence of Occlusion Using Depth Camera Sensors, in Human-Robot Coexistence Scenarios","A. Casalino; S. Guzman; A. Maria Zanchettin; P. Rocco","Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Piazza L. Da Vinci 32, Milano, 20133, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","Collaborative robotics over the last few years has gained increasing interest in the industrial scenario. Co-bots can be equipped with vision sensors and cognitive software layers, allowing the robot to figure out human intentions. To make this level of perception possible, human pose estimation algorithms are required. Several techniques have been already proposed to tackle this problem, which however present some weaknesses in particular when occlusions occur. This work proposes an algorithm for human pose estimation in the situations of partial occlusion, based on particle filter techniques. We have proved its validity in a realistic human-robot coexistence scenario, where a human and a dual arm robot have to perform tasks in a shared workspace.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593816","","Pose estimation;Kinematics;Service robots;Mathematical model;Collaboration;Robot sensing systems","cameras;human-robot interaction;image filtering;image sensors;mobile robots;particle filtering (numerical methods);pose estimation;robot vision","human-robot coexistence scenario;collaborative robotics;industrial scenario;vision sensors;cognitive software layers;human intentions;human pose estimation algorithms;partial occlusion;dual arm robot;depth camera sensors;particle filter techniques","","","18","","","","","IEEE","IEEE Conferences"
"Development of Wide Angle Fovea Lens for High-Definition Imager Over 3 Mega Pixels","S. Shimizu; R. Murakami; M. Tominaga; Y. Akamine; N. Kawasaki; O. Shimomura; K. Ishimaru; S. Mita","Shibaura Institute of Technology, 3-9-14 Shibaura, Minato-ku, Tokyo, 108-8548, JAPAN; Shibaura Institute of Technology, 3-9-14 Shibaura, Minato-ku, Tokyo, 108-8548, JAPAN; SOKEN Inc., 500–20 Minamiyama, Komenoki-cho, Nisshin, Aichi, 470-0111, JAPAN; SOKEN Inc., 500–20 Minamiyama, Komenoki-cho, Nisshin, Aichi, 470-0111, JAPAN; SOKEN Inc., 500–20 Minamiyama, Komenoki-cho, Nisshin, Aichi, 470-0111, JAPAN; SOKEN Inc., 500–20 Minamiyama, Komenoki-cho, Nisshin, Aichi, 470-0111, JAPAN; SOKEN Inc., 500–20 Minamiyama, Komenoki-cho, Nisshin, Aichi, 470-0111, JAPAN; Toyota Institute of Technology, 2-12-1 Hisakata, Tenpaku-ku, Nagoya, Aichi, 468-8511, JAPAN","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4232","4237","This paper presents a high-quality wide-angle fovea lens, i.e., the WAF lens, for the autonomous robot's and vehicle's super-sensing vision system. The WAF lens is well-known in the field of robotic vision with respect to its unique design concept, biologically-inspired from a visual system of the primates. The WAF lens achieves the following two conflicting properties in imaging simultaneously: (1) wide field of view (FOV) and (2) high magnification factor (although only the central FOV achieves it partially). In this paper, the authors designs the WAF lens for the high-resolution photosensitive imaging chip more than 3M pixels. For this design, we decide the following targets on the assumption of applying this WAF lens for the stereo vision system: (1) The WAF lens can measure a very far distance over 100m ahead from the imager accurately. (2) The WAF lens can observe approximately 100-degree wide FOV on the same time. We produce a prototype of this WAF lens with much higher optical performance than our previous developments. The compound system of the prototype includes four aspherical surfaces in its front part to project enough bright images so that the WAF lens is available not only at daytime but also in dark situations at night. The authors experiment and demonstrate the projection tests using the prototype, and discuss about the results as the inspection of this challenging development.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594194","","Lenses;Prototypes;Spatial resolution;Cameras;Robots;Optical imaging","image sensors;lenses;photodetectors;robot vision;stereo image processing;visual perception","WAF lens;wide angle fovea lens;high-definition imager;autonomous robot;vehicle supersensing vision system;robotic vision;field of view;FOV;high-resolution photosensitive imaging chip;stereo vision system;optical performance;aspherical surface;projection testing","","","15","","","","","IEEE","IEEE Conferences"
"Attention-Aware Cross-Modal Cross-Level Fusion Network for RGB-D Salient Object Detection","H. Chen; Y. Li; D. Su","City University of Hong Kong, Department of Mechanical Engineering, Kowloon, Hong Kong SAR; City University of Hong Kong, Department of Mechanical Engineering, Kowloon, Hong Kong SAR; Shenzhen Research Institute, City University of Hong Kong","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6821","6826","Convolutional neural networks have achieved wide success in RGB saliency detection. Recently, the advent of RGB-D sensors such as Kinect provide additional geometric saliency cues. However, the key challenge for RGB-D salient object detection that how to fuse RGB and depth information sufficiently is still under-studied. Traditional works mainly follow the two-stream architecture and combine RGB and depth features/decisions in an early or late point. The multi-modal fusion stage is performed by directly concatenating the features from two modalities without selection. In this work, we address this question by proposing a novel network with a distinguished insight: A selection module is significantly helpful for more informative and sufficient cross-modal cross-level combination. To this end, we introduce a top-down RGB-D fusion network which integrates an attention-aware cross-modal cross-level fusion block in each level to select discriminative features from each level and each modality. Extensive experiments on public datasets show that the proposed network is able to solve the key problems in RGB-D fusion and achieves state-of-the-art performance on RGB-D salient object detection.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594373","","Object detection;Feature extraction;Fuses;Task analysis;Computer architecture;Visualization;Adaptation models","convolutional neural nets;feature extraction;image colour analysis;image fusion;object detection","geometric saliency cues;selection module;public datasets;attention-aware cross-modal cross-level fusion block;RGB-D fusion network;informative cross-modal cross-level combination;multimodal fusion stage;depth features/decisions;depth information;RGB-D sensors;convolutional neural networks;RGB-D salient object detection;attention-aware cross-modal cross-level fusion network","","1","40","","","","","IEEE","IEEE Conferences"
"Good Feature Selection for Least Squares Pose Optimization in VO/VSLAM","Y. Zhao; P. A. Vela","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1183","1189","This paper aims to select features that contribute most to the pose estimation in VO/VSLAM. Unlike existing feature selection works that are focused on efficiency only, our method significantly improves the accuracy of pose tracking, while introducing little overhead. By studying the impact of feature selection towards least squares pose optimization, we demonstrate the applicability of improving accuracy via good feature selection. To that end, we introduce the Max-logDet metric to guide the feature selection, which is connected to the conditioning of least squares pose optimization problem. We then describe an efficient algorithm for approximately solving the NP-hard Max-logDet problem. Integrating Max-logDet feature selection into a state-of-the-art visual SLAM system leads to accuracy improvements with low overhead, as demonstrated via evaluation on a public benchmark.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593641","","Feature extraction;Optimization;Pose estimation;Simultaneous localization and mapping;Measurement uncertainty;Approximation algorithms","computational complexity;control engineering computing;feature extraction;least squares approximations;optimisation;pose estimation;robot vision;SLAM (robots)","least squares pose optimization;pose estimation;pose tracking;NP-hard Max-logDet problem;feature selection;VO-VSLAM;integrating Max-logDet feature selection","","","28","","","","","IEEE","IEEE Conferences"
"Shock Absorbing Exoskeleton for Vertical Mobility System: Concept and Feasibility Study","J. Ueda; M. Turkseven; E. Kim; Q. Lowery; C. Bivens; M. Mayo","Georgia Institute of Technology, G.W.W. School of Mechanical Engineering, 771 Ferst Drive, Atlanta, GA, U.S.A; Georgia Institute of Technology, G.W.W. School of Mechanical Engineering, 771 Ferst Drive, Atlanta, GA, U.S.A; Georgia Institute of Technology, G.W.W. School of Mechanical Engineering, 771 Ferst Drive, Atlanta, GA, U.S.A; Georgia Institute of Technology, G.W.W. School of Mechanical Engineering, 771 Ferst Drive, Atlanta, GA, U.S.A; Aerospace & Acoustics Technologies Division, Georgia Tech Research Institute, Atlanta, GA, U.S.A; Aerospace & Acoustics Technologies Division, Georgia Tech Research Institute, Atlanta, GA, U.S.A","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3342","3349","The goal of this research is to develop a lower-extremity wearable link mechanism (i.e., exoskeleton robot) that is capable of reducing load against targeted body parts such as bones, joints and muscles, for shock absorption that help to support exploration of extreme environments. One of the applications of such exoskeleton is to protect a pilot of a personal vertical mobility system, or JetPack, when landing. The shock absorbing exoskeleton is to introduce series and parallel viscoelasticity to the human skeletal system. The paper presents a pilot study to validate this body-protective exoskeleton concept by analyzing kinematic and dynamic models of a human-exoskeleton coupled system based on a multi-element viscoelastic model in rheology. A proof-of-concept prototype is developed and experimental data is presented.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593820","","Exoskeletons;Electric shock;Muscles;Joints;Bones;Force;Injuries","biomechanics;medical robotics;motion control;robot dynamics;robot kinematics;shock absorbers;viscoelasticity;wearable robots","lower-extremity wearable link mechanism;exoskeleton robot;shock absorbing exoskeleton;human skeletal system;human-exoskeleton coupled system;vertical mobility system;dynamic models;kinematic models;multielement viscoelastic model","","","25","","","","","IEEE","IEEE Conferences"
"Motion Planning and Goal Assignment for Robot Fleets Using Trajectory Optimization","J. Salvado; R. Krug; M. Mansouri; F. Pecora","Orebro University, AASS Research Centre; Perception and Learning Lab, KTH Royal Institute of Technology, Robotics; Orebro University, AASS Research Centre; Orebro University, AASS Research Centre","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7939","7946","This paper is concerned with automating fleets of autonomous robots. This involves solving a multitude of problems, including goal assignment, motion planning, and coordination, while maximizing some performance criterion. While methods for solving these sub-problems have been studied, they address only a facet of the overall problem, and make strong assumptions on the use-case, on the environment, or on the robots in the fleet. In this paper, we formulate the overall fleet management problem in terms of Optimal Control. We describe a scheme for solving this problem in the particular case of fleets of non-holonomic robots navigating in an environment with obstacles. The method is based on a two-phase approach, whereby the first phase solves for fleet-wide boolean decision variables via Mixed Integer Quadratic Programming, and the second phase solves for real-valued variables to obtain an optimized set of trajectories for the fleet. Examples showcasing the features of the method are illustrated, and the method is validated experimentally.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594118","","Robot kinematics;Collision avoidance;Aerospace electronics;Indexes;Trajectory;Geometry","integer programming;mobile robots;multi-robot systems;optimal control;path planning;quadratic programming","mixed integer quadratic programming;autonomous robots;automating fleets;trajectory optimization;robot fleets;fleet-wide boolean decision variables;phase solves;two-phase approach;nonholonomic robots;Optimal Control;fleet management problem;performance criterion;motion planning;goal assignment","","","26","","","","","IEEE","IEEE Conferences"
"Automatic Fall Risk Assessment for Challenged Users Obtained from a Rollator Equipped with Force Sensors and a RGB-D Camera","J. Ballesteros; J. M. Peula; A. B. Martinez; C. Urdiales","University of Malaga, Department of Electronic Technology, Malaga, Spain; University of Malaga, Department of Electronic Technology, Malaga, Spain; Polytechnic University of Catalonia, Department of Automatic Control, Barcelona, Spain; University of Malaga, Department of Electronic Technology, Malaga, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7356","7361","Fall risk assessments provide a useful tool to prevent morbidity and mortality provoked by falls. Nowadays, these assessments are usually performed manually by the medical staff. This approach has three main drawbacks: (i) it is time consuming, so it is only performed a few times per volunteer during their rehabilitation process; (ii) it requires supervision by medical staff, so assessment at home or preferred environments is not feasible; and (iii) fall risk is evaluated in a global way, so imminent fall risk is not available for decision making in assistive navigation. In this paper we propose an imminent fall risk estimator for rollator's users that can be automatically obtained on the fly. Its main advantages are: (i) it can be used in everyday conditions in any environment; (ii) it does not require assistance of medical staff; and (iii) it is suitable for a variety of users with minimal configuration changes. We have validated our estimator with a set of volunteers (n=10) presenting different physical and cognitive disabilities. Although the number of volunteer is limited, results show that our estimator is coherent to two traditional, well accepted assessments: the Tinetti Mobility Test and the walking speed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594122","","Wearable sensors;Force sensors;Senior citizens;Foot;Legged locomotion;Assistive devices","force sensors;gait analysis;handicapped aids;patient rehabilitation;risk management","medical staff;rehabilitation process;preferred environments;assistive navigation;imminent fall risk estimator;automatic fall risk assessment;challenged users;force sensors;RGB-d camera;rollator;cognitive disability;physical disability;Tinetti mobility test;walking speed","","","23","","","","","IEEE","IEEE Conferences"
"Quaternion Joint: Dexterous 3-DOF Joint Representing Quaternion Motion for High-Speed Safe Interaction","Y. Kim; J. Kim; W. Jang","Korea University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; Korea University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea; Korea University of Technology and Education (Koreatech), Cheonan-City, Rep. of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","935","942","This paper presents a dexterous three degree-of-freedom (3-DOF) wrist mechanism with a large range of motion and uniform manipulability without singular points throughout the entire range of motion. It has a 2-DOF spherical pure rolling joint surrounded by two pairs of actuating wires, the motions of which directly represent the quaternion values of the joint; this joint is therefore named the quaternion joint. Based on this property, it has simple and clear forward and inverse kinematics and high manipulability. By adding a 1-DOF rotation joint at the distal end of the quaternion joint, it can be extended to a 3-DOF joint mechanism. To precisely approximate the spherical pure rolling motion in a confined central space, a novel parallel mechanism composed of three identical supporting linkages was introduced. Unlike conventional parallel mechanisms, it has a compact and simple structure with no interference among the supporting linkages. Because the wrist mechanism is a tendon-driven mechanism, and is thus suitable for lightweight manipulators, it is mounted to a low-inertia manipulator with high stiffness and strength, namely, LIMS2-AMBIDEX, which is an improved version of the authors' previous research. The basic concept and thorough theoretical analysis of the wrist mechanism are described herein, and the simulations and experiments conducted for a quantitative validation are presented.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594301","","Wires;Wrist;Manipulators;Quaternions;Pulleys;Kinematics","actuators;dexterous manipulators;manipulator dynamics;manipulator kinematics","quaternion joint;wrist mechanism;tendon-driven mechanism;dexterous 3-DOF joint;quaternion motion;forward kinematics;inverse kinematics;lightweight manipulators","","","11","","","","","IEEE","IEEE Conferences"
"TSSD: Temporal Single-Shot Detector Based on Attention and LSTM","X. Chen; Z. Wu; J. Yu","Chinese Academy of Sciences, The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, China and University of Chinese Academy of Sciences, Beijing 100190, Beijing 100049, China; Chinese Academy of Sciences, The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, China and University of Chinese Academy of Sciences, Beijing 100190, Beijing 100049, China; Chinese Academy of Sciences, The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, China and University of Chinese Academy of Sciences, Beijing 100190, Beijing 100049, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Temporal object detection has attracted significant attention, but most popular methods can not leverage the rich temporal information in video or robotic vision. Although many different algorithms have been developed for video detection task, real-time online approaches are frequently deficient. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)for robotic vision. Distinct from previous methods, we aim to temporally integrate pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a high-level ConvLSTM unit as well as a low-level one (HL-LSTM)for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, ConvLSTM-based attention and attention-based ConvLSTM (A&CL), in which the ConvLSTM-based attention is specially tailored for background suppression and scale suppression while the attention-based ConvLSTM temporally integrates attention-aware features. Finally, our method is evaluated on ImageNet VID dataset. Extensive comparisons on detection performance confirm the superiority of the proposed approach, and the developed TSSD achieves a considerably enhanced accuracy vs. speed trade-off, i.e., 64.8% mAP vs. 27 FPS.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593963","","Feature extraction;Detectors;Robots;Task analysis;Visualization;Lenses;Proposals","feature extraction;object detection;robot vision;video signal processing","convolutional long short-term memory;creative temporal analysis unit;multiscale feature maps;high-level ConvLSTM unit;pyramidal feature hierarchy;attention mechanism;real-time online approaches;video detection task;robotic vision;rich temporal information;temporal object detection;temporal single-shot detector;developed TSSD;attention-aware features;scale suppression;background suppression;ConvLSTM-based attention;attention-based ConvLSTM","","","24","","","","","IEEE","IEEE Conferences"
"Assisted Control for Semi-Autonomous Power Infrastructure Inspection Using Aerial Vehicles","A. McFadyen; F. Dayoub; S. Martin; J. Ford; P. Corke","Queensland University of Technology, Science & Engineering Faculty, Brisbane, Australia; Queensland University of Technology, Science & Engineering Faculty, Brisbane, Australia; Queensland University of Technology, Science & Engineering Faculty, Brisbane, Australia; Queensland University of Technology, Science & Engineering Faculty, Brisbane, Australia; Queensland University of Technology, Science & Engineering Faculty, Brisbane, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5719","5726","This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593529","","Inspection;Wires;Measurement;Robot sensing systems;Collision avoidance;Unmanned aerial vehicles;Task analysis","aerospace robotics;collision avoidance;inspection;optical sensors;power overhead lines;sensor placement","collision avoidance;optical sensors;sensor placement;fixed energy infrastructure;aerial inspection;multirotor platform;assisted control technology;aerial vehicles;semiautonomous power infrastructure inspection;proximity inspection tasks;assisted control approach","","","10","","","","","IEEE","IEEE Conferences"
"Tire Force Estimation of Dynamic Wheeled Mobile Robots using Tire-Model Based Constrained Kalman Filtering","S. Jeon; R. Chung; D. Lee","Department of Mechanical & Aerospace Engineering, Seoul National University, IAMD, Seoul, 151-744, Republic of Korea; Department of Mechanical & Aerospace Engineering, Seoul National University, IAMD, Seoul, 151-744, Republic of Korea; Department of Mechanical & Aerospace Engineering, Seoul National University, IAMD, Seoul, 151-744, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2470","2477","We propose a novel real-time algorithm to estimate the full three-dimensional individual tire forces (i.e., vertical, longitudinal as well as lateral) of a car-like rearwheel-driven four wheel wheeled mobile robots equipped with onboard navigation sensors and wheel encoders. The key enabling idea for this is to utilize the tire model (i.e., the magic formula) in a feedback manner on the framework of the constrained Kalman filtering to render the tire force estimation: 1) more accurate as compared to the typical tire force estimation techniques neglecting the tire-road interaction; and 2) more robust as compared to the results adopting the tire model, yet, only in an open-loop manner. Our proposed algorithm, while performing this full tire force onboard/real-time estimation, also provides the estimation of: 1) tire-road friction coefficient; and 2) torque inputs of the rear left and right wheels, which are connected via differential gear. Simulations with CarSim and outdoor experiments are performed to validate the proposed estimation algorithm.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593708","","Tires;Wheels;Force;Estimation;Dynamics;Sensors;Friction","automobiles;feedback;friction;gears;Kalman filters;mobile robots;robot dynamics;tyres;wheels","wheel encoders;tire-road interaction;estimation algorithm;three-dimensional individual tire forces;dynamic wheeled mobile robots;tire-model based constrained Kalman filtering;tire force real-time estimation;tire force estimation techniques;car-like rearwheel-driven four wheel wheeled mobile robots;onboard navigation sensors;feedback;tire-road friction coefficient;torque inputs;differential gear;CarSim","","","25","","","","","IEEE","IEEE Conferences"
"Design of Lizard-Inspired Robot with Lateral Body Motion","J. Kim; H. Kim; Y. Kim; H. S. Kim; J. Kim","Seoul National University, School of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea; Seoul National University, School of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea; Seoul National University, School of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea; Department of Mechanical System Engineering, Kyonggi University, Suwon-si, Gyeonggi-do, 16227, South Korea; Seoul National University, School of Mechanical and Aerospace Engineering, Seoul, 08826, South Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","A new lizard-inspired robot is presented in this paper, which enables to maintain its moving direction by lateral body motions even during high-speed bipedal running. First, a dynamic model for lizard-inspired robot is derived to simulate the lateral body motion of real lizard. Based upon the simulation using dynamic model, the lizard-inspired robot is tactfully built so that its hind leg is optimally designed on a 4-bar mechanism and its body is simplified to consist of two body links and a tail connected by two revolute joints. The experiments verify that the proposed robot can maintain its moving direction via proper lateral motions during high-speed bipedal running similar to that of real lizard.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594086","","Legged locomotion;Dynamics;Foot;Atmospheric modeling;Force;Mathematical model","legged locomotion;motion control;robot dynamics","bipedal running;4-bar mechanism;hind leg;revolute joints;dynamic model;lizard-inspired robot;lateral body motion","","","20","","","","","IEEE","IEEE Conferences"
"Nonlinear Adaptive Control of Quadrotor Multi-Flipping Maneuvers in the Presence of Time-Varying Torque Latency","Y. Chen; N. O. Pérez-Arancibia","University of Southern California (USC), Department of Aerospace and Mechanical Engineering, Los Angeles, CA, 90089-1453, USA; University of Southern California (USC), Department of Aerospace and Mechanical Engineering, Los Angeles, CA, 90089-1453, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","The dynamics of quadrotors are affected by time-varying torque latency, which can greatly alter the stability robustness and performance of the closed-loop control schemes employed for flight; this issue is especially relevant during the execution of aerobatic maneuvers such as high-speed multi-flips. To address this problem, we propose two controller synthesis methods associated with two different modeling approaches. In the first approach, we describe torque latency with a linear time-invariant (LTI)model, identified through ground experiments, which is then used to design a backstepping-based nonlinear controller. In the second approach, we employ an improved linear time-varying (LTV)model with a priori unknown parameters, which is used to synthesize and implement a novel nonlinear adaptive control scheme updated in real time using the recursive least-squares (RLS)algorithm. Empirical observations suggest that the torque delay affecting the system depends on the time-varying angular speed of the flyer and its derivative. This phenomenon is explained by the fact that the aerodynamic forces produced by, and acting on, the rotating propellers vary with the local velocity of the incident flows. Hence, in the proposed adaptive structure, we define the parameters of the LTV latency model as linear functions of the angular speed reference and its derivative. Experimental results compellingly demonstrate the efficacy of the methods introduced in this paper; compared to the highperformance linear controller in [1]-[3], the backstepping-based control scheme and adaptive controller decrease the average root mean square (RMS)value of the control error by 17.82 % and 38.42 %, respectively.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594265","","Torque;Aerodynamics;Linear systems;Adaptation models;Vehicle dynamics;Angular velocity;Propellers","adaptive control;aerodynamics;aircraft control;closed loop systems;control nonlinearities;control system synthesis;delays;helicopters;least squares approximations;linear systems;nonlinear control systems;position control;robust control;time-varying systems;torque control","recursive least-squares algorithm;high-performance linear controller;adaptive controller;nonlinear adaptive control scheme;linear time-varying model;linear time-invariant model;backstepping-based control scheme;LTV latency model;time-varying angular speed;torque delay;backstepping-based nonlinear controller;controller synthesis methods;high-speed multiflips;aerobatic maneuvers;closed-loop control schemes;stability robustness;time-varying torque;quadrotor multiflipping maneuvers","","","25","","","","","IEEE","IEEE Conferences"
"Design of a Lightweight, Ergonomic Manipulator for Enabling Expressive Gesturing in Telepresence Robots","J. T. Slack; K. Del-Row; Z. Anderson; R. M. Albacete Di Bartolomeo; J. L. Gorlcwicz; J. B. Weinberg","Department of Mechanical and Aerospace Engineering, Saint Louis Tlnivercirv, Saint Louis, MO, 63103, USA; Department of Mechanical and Aerospace Engineering, Saint Louis Tlnivercirv, Saint Louis, MO, 63103, USA; Department of Computer Science, Southern Illinois University of Ed-wardsville, IL, 62025, USA; Department of Mechanical and Aerospace Engineering, Saint Louis Tlnivercirv, Saint Louis, MO, 63103, USA; Department of Mechanical and Aerospace Engineering, Saint Louis Tlnivercirv, Saint Louis, MO, 63103, USA; Department of Computer Science, Southern Illinois University of Ed-wardsville, IL, 62025, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5491","5496","Recent research on telepresence robots demonstrates that while they enable new heights of remote communication, there still exists challenges for both local and remote users in creating a connectedness one only encounters in face-to-face interactions. A large part of communication is beyond hearing and vision. Tangible interactions, expressive gestures, and physical referencing represent three of the primary social behaviors missing in the current telepresence experience. There is an inherent, subconscious quality to these physical actions that has been shown to allow more expressive and engaging communication. In this project we present the design, fabrication, and initial performance validation of a lightweight, ergonomic manipulator with a heavy, anthropomorphic end effector that enables gesturing capabilities for telepresence interactions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593533","","Manipulators;Shoulder;Telepresence;Elbow;Kinematics;Torque","end effectors;ergonomics;gesture recognition;human-robot interaction;telerobotics","anthropomorphic end effector;telepresence experience;expressive gesturing;tangible interactions;face-to-face interactions;remote users;local users;remote communication;telepresence robots;telepresence interactions;ergonomic manipulator;lightweight manipulator;engaging communication;expressive communication;physical actions;subconscious quality;primary social behaviors;physical referencing;expressive gestures","","","31","","","","","IEEE","IEEE Conferences"
"Design of an Autonomous Precision Pollination Robot","N. Ohi; K. Lassak; R. Watson; J. Strader; Y. Du; C. Yang; G. Hedrick; J. Nguyen; S. Harper; D. Reynolds; C. Kilic; J. Hikes; S. Mills; C. Castle; B. Buzzo; N. Waterland; J. Gross; Y. Park; X. Li; Y. Gu","Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, WVU, Lane Department of Computer Science and Electrical Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Davis College of Agriculture, Natural Resources, and Design, WVU, Division of Plant and Soil Sciences, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Davis College of Agriculture, Natural Resources, and Design, WVU, Division of Plant and Soil Sciences, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA; Davis College of Agriculture, Natural Resources, and Design, WVU, Division of Plant and Soil Sciences, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, WVU, Lane Department of Computer Science and Electrical Engineering, Morgantown, WV, 26506, USA; Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University (WVU), Department of Mechanical and Aerospace Engineering, Morgantown, WV, 26506, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7711","7718","Precision robotic pollination systems can not only fill the gap of declining natural pollinators, but can also surpass them in efficiency and uniformity, helping to feed the fast-growing human population on Earth. This paper presents the design and ongoing development of an autonomous robot named “BrambleBee”, which aims at pollinating bramble plants in a greenhouse environment. Partially inspired by the ecology and behavior of bees, BrambleBee employs state-of-the-art localization and mapping, visual perception, path planning, motion control, and manipulation techniques to create an efficient and robust autonomous pollination system.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594444","","Cameras;End effectors;Agriculture;Robot vision systems;Three-dimensional displays","greenhouses;mobile robots;motion control;path planning","precision robotic pollination systems;natural pollinators;uniformity;human population;ongoing development;autonomous robot;BrambleBee;ecology;visual perception;robust autonomous pollination system;autonomous precision pollination robot","","","53","","","","","IEEE","IEEE Conferences"
"Dynamic Modelling and Motion Planning for the Nonprehensile Manipulation and Locomotion Tasks of the Quadruped Rsbot*This work is supported by the project of Robotics Innovation Based on Advanced Materials under Ritsumeikan Global Innovation Research Organization (R-GIRO)","G. Zhang; S. Ma; Y. Li","Ritsumeikan University, Ritsumeikan Global Innovation Research Organization, Shiga, Japan; Ritsumeikan University, Department of Robotics, Shiga, Japan; Shandong University, School of Control Science and Engineering, Jinan, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents the dynamic modelling and motion planning method for a quadruped robot that uses its legs for nonprehensile manipulation as well as locomotion. Three different working modes named Drive Mode, Inchworm Mode and Scoot Mode are proposed to enable the robot to move forward together with the object. We firstly introduce a universal model for these modes and deduce its dynamic equation. Then the contact force constraints are combined and mapped to the system state variables. Based on the acquired state acceleration constraints, the motion planning problem can be solved by designing system state paths in the phase space. After that, we described the mathematical problems within the three working modes and generate the robot motions accordingly. Finally, experimental results obtained through simulations and physical tests are reported to demonstrate the effectiveness of our method.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593712","","Robot kinematics;Legged locomotion;Force;Friction;Mathematical model;Planning","legged locomotion;manipulator dynamics;motion control;path planning","Drive Mode;Inchworm Mode;Scoot Mode;universal model;dynamic equation;contact force constraints;system state variables;system state paths;robot motions;nonprehensile manipulation;locomotion tasks;quadruped robot;dynamic modelling;motion planning method;state acceleration constraints","","","10","","","","","IEEE","IEEE Conferences"
"End to End Vehicle Lateral Control Using a Single Fisheye Camera","M. Toromanoff; E. Wirbel; F. Wilhelm; C. Vejarano; X. Perrotton; F. Moutarde","PSL Research University, Center for Robotics, MINES ParisTech, France; Valeo Driving Assistance Research, France; Valeo Driving Assistance Research, France; Valeo Driving Assistance Research, France; Valeo Driving Assistance Research, France; PSL Research University, Center for Robotics, MINES ParisTech, France","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3613","3619","Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594090","","Automobiles;Cameras;Roads;Training;Neural networks;Testing","automobiles;cameras;collision avoidance;convolutional neural nets;mobile robots;robot vision;steering systems","label augmentation;short range fisheye camera;open road driving;single fisheye camera;convolutional neural networks;steering angle;autonomous cars;end-to-end control evaluation;end-to-end vehicle lateral control;urban road;sharp turns;obstacle avoidance;data augmentation","","","19","","","","","IEEE","IEEE Conferences"
"Steerable Locomotion Controller for Six-strut Icosahedral Tensegrity Robots","M. Vespignani; C. Ercolani; J. M. Friesen; J. Bruce","Dynamic Tensegrity Robotics Lab, Intelligent Robotics Group, NASA Ames Research Center, Moffett Field, CA, 94035, USA; EPFL, Biorobotics Laboratory (BIOROB), Lausanne, CH-1015, Switzerland; UC San Diego Coordinated Robotics Lab, MC 0411, La Jolla, CA, 92093, USA; Dynamic Tensegrity Robotics Lab, Intelligent Robotics Group, NASA Ames Research Center, Moffett Field, CA, 94035, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2886","2892","This paper proposes a novel steerable locomotion controller for six-strut tensegrity robots. Tensegrity robots are lightweight and have many promising features such as robustness, shape-shifting capabilities, and deployability, making them good candidates for exploration and scouting of remote areas. Despite these advantages, tensegrity robots are challenging to control due to their large number of degrees of freedom, nonlinear dynamics, and intrinsic compliance. Recently, many step-wise motion controllers have been employed to simplify the locomotion problem, thanks to the discrete nature of the tensegrity structure. In this paper we present a novel locomotion controller which will steer the direction of motion of a six-strut tensegrity robot when used in conjunction with any preexisting step-wise controller. We validated our controller on the SUPERball v2 robot, showing straight and curved trajectories, and an example of navigation around obstacles. Our method is computationally inexpensive, only requires knowledge about the current base triangle (e.g, via accelerometer data), and can be generalized to any six-strut tensegrity robot which can perform step-wise locomotion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593676","","Robot kinematics;NASA;Trajectory;Face;Robot sensing systems;Navigation","accelerometers;mobile robots;motion control;nonlinear dynamical systems;robust control","steerable locomotion controller;nonlinear dynamics;six-strut icosahedral tensegrity robots;step-wise locomotion;SUPERball v2 robot;preexisting step-wise controller;tensegrity structure;locomotion problem;step-wise motion controllers","","","23","","","","","IEEE","IEEE Conferences"
"Lane Marking Quality Assessment for Autonomous Driving","B. Li; D. Song; H. Li; A. Pike; P. Carlson","Department of Computer Science and Engineering, Texas A&M University, College Station, TX, 77843, US; Computer Science Department University of China, Civil Aviation, Tianjin, 300300; Minjiang University, Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Fuzhou, 350108, China; College Station, Texas A&M Transportation Institute, TX, 77843, US; College Station, Road Infrastructure, Inc., TX, 77843, US","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Measuring the quality of roads and ensuring they are ready for autonomous driving is important for future transportation systems. Here we focus on developing metrics and algorithms to assess lane marking (LM)qualities from an egocentric view of an inspection vehicle equipped with a global positioning system (GPS)receiver, a frontal-view camera, and a light detection and ranging (LIDAR)system. We propose three quality metrics for LMs: correctness, shape, and visibility. The correctness metric measures the divergence between the expected LMs based on prior map inputs and the actual sensor inputs. The shape metric evaluates smoothness in road curvature and width range. The visibility metric evaluates the contrast between LMs and background road surfaces. We propose a dual-modal algorithm to compute these metrics. We have implemented the algorithms and tested them under KITTI dataset. The results show that our metrics can successfully detect LM anomalies in all testing scenarios.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593855","","Roads;Measurement;Laser radar;Cameras;Shape;Global Positioning System;Three-dimensional displays","cameras;Global Positioning System;image processing;optical radar;road vehicles;traffic engineering computing","road curvature;background road surfaces;dual-modal algorithm;lane marking quality assessment;autonomous driving;future transportation systems;inspection vehicle;frontal-view camera;global positioning system receiver;light detection and ranging system;LIDAR","","","26","","","","","IEEE","IEEE Conferences"
"Robust Decentralized Context-Aware Sensor Fault Detection with In-Place Self-Calibration","J. L. Paneque; J. R. Martinez-Dedios; A. Ollero","Robotics, Vision and Control Group, University of Seville, Seville, Spain; Robotics, Vision and Control Group, University of Seville, Seville, Spain; Robotics, Vision and Control Group, University of Seville, Seville, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3130","3136","There is a high demand in advanced fault detection methods suitable for sensor networks monitoring complex dynamic systems such as industrial plants or large infrastructure units. This paper proposes a robust and efficient decentralized sensor fault detection method with in-place sensor self-recalibration capability that extracts and uses complex context information referred to the full monitored process. The method includes three main components, all decentralized and sharing the same statistical framework: 1) a consensus-based modeling step based on decentralized RANSAC; 2) a statistical analysis based on Bayesian networks and Hidden Markov Models in which each sensor identifies inconsistencies with the consensus model and determines if it is correctly calibrated, uncalibrated or faulty and; 3) a final step in which each uncalibrated sensor self-recalibrates using the consensus model. The proposed method is efficient in the use of computational and communicational resources, it is scalable and robust against outliers, transmission errors, sensor failures and network topology changes. It has been extensively validated in an experimental industrial setting.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593680","","Robot sensing systems;Hidden Markov models;Computational modeling;Monitoring;Temperature measurement;Bayes methods;Analytical models","Bayes methods;calibration;fault diagnosis;hidden Markov models;sensors;statistical analysis","complex context information;decentralized RANSAC;Bayesian networks;uncalibrated sensor;hidden Markov models;robust decentralized context-aware sensor fault detection methods;industrial plants;in-place sensor self-recalibration capability;consensus-based modeling step;statistical analysis;network topology;complex dynamic systems","","","17","","","","","IEEE","IEEE Conferences"
"StreetMap - Mapping and Localization on Ground Planes using a Downward Facing Camera","X. Chen; A. S. Vempati; P. Beardsley","Disney Research Zurich, Stampfenbachstrasse 48, Zurich, 8006, Switzerland; Disney Research Zurich, Stampfenbachstrasse 48, Zurich, 8006, Switzerland; Disney Research Zurich, Stampfenbachstrasse 48, Zurich, 8006, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1672","1679","This paper describes a system to map a ground-plane, and to subsequently use the map for localization of a mobile robot. The robot has a downward-facing camera, and works on a variety of ground textures including general texture like tarmac, man-made designs like carpet, and rectilinear textures like indoor tiles or outdoor slabs. Such textures provide a basis for measuring relative motion (i.e. computer mouse functionality). But the goal here is the more challenging one of absolute localization. The paper describes a complete working pipeline to build a globally consistent map of a given ground-plane and subsequently to localize within this map at real-time. Two algorithms are described. The first is a feature-based approach which is general to any ground plane texture. The second algorithm takes advantage of the extra constraints available for common rectilinear textures like indoor tiling, paving slabs, and laid brickwork. Quantitative and qualitative experimental results are shown for mapping and localization on a variety of ground-planes.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594157","","Cameras;Robot vision systems;Feature extraction;Robot kinematics;Slabs","cameras;feature extraction;image filtering;image texture;mobile robots;robot vision","rectilinear textures;indoor tiling;ground plane texture;globally consistent map;complete working pipeline;absolute localization;indoor tiles;general texture;ground textures;mobile robot;downward facing camera","","","20","","","","","IEEE","IEEE Conferences"
"Cable Actuated Dexterous (CADEX) Glove for Effective Rehabilitation of the Hand for Patients with Neurological diseases","D. H. Kim; H. Park","Mechanical Engineering Department, Korea Advanced Institute of Science and Technology, Daejoen, 34141, S. Korea; Mechanical Engineering Department, Korea Advanced Institute of Science and Technology, Daejoen, 34141, S. Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2305","2310","Neuroplastic changes in motor cortex is essential for the recovery motor function of patients with neurological diseases. To enlarge neuroplastic change, various movements should be provided to stimulate larger motor cortical area, and because hands occupy the largest area, it is especially important. Many wearable robotic devices have been developed for rehabilitation of the hand, and soft robotic devices in particular have drawn attention for their compact design. However, most soft devices provide simple thumb motions, which flex or extend all joints without assistance of opposition/reposition of the carpometacarpal joint although the importance in producing various grasps. In this study, the design of a cable actuated dexterous (CADEX) glove is proposed. For dexterous motion, the structure and orientation of major finger tendons were replicated with exotendons (actuated cables), and four exotendons were used for the thumb with the path optimized to provide flexion/extension of the thumb and decoupled opposition/reposition of the carpometacarpal with other joints. To provide consistent motion, silicon was used for stable anchoring of exotendons while preventing slippage and reducing deformation. The motion generated by the CADEX glove was experimentally evaluated for a single healthy subject. The result shows that the CADEX glove could flex and extend the finger with various ratios among joints, and the opposition/reposition of carpometacarpal joint of the thumb could be achieved consistently with minimal effect on the other joints. The CADEX glove is expected to help providing various tasks which is expected to enhance the functional recovery of patients with neurological disease.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594336","","Thumb;Force;Routing;Silicon;Tendons;IP networks","actuators;biomechanics;bone;dexterous manipulators;diseases;medical disorders;medical robotics;neurophysiology;patient rehabilitation","decoupled opposition-reposition;functional recovery;CADEX glove;consistent motion;actuated cables;exotendons;dexterous motion;carpometacarpal joint;simple thumb motions;compact design;soft robotic devices;wearable robotic devices;hands;larger motor cortical area;recovery motor function;motor cortex;neuroplastic change;neurological disease;effective rehabilitation;cable actuated dexterous glove","","","21","","","","","IEEE","IEEE Conferences"
"Motion Planning for an Underwater Mobile Manipulator by Exploiting Loose Coupling","D. Youakim; A. Dornbush; M. Likhachev; P. Ridao","University of Girona, Computer Vision & Robotics Institute; The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University; University of Girona, Computer Vision & Robotics Institute","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7164","7171","Intervention Autonomous Underwater Vehicle or I-AUV has recently started to grab researchers attention in the last 20 years. Only three I-AUVs have demonstrated autonomous manipulation skills: ALIVE, SAUVIM and GIRONA 500. While prior systems rely on variations of the task-priority redundancy control framework, our recent research showed preliminary results using motion planning for floating-based intervention in the presence of obstacles. With the increasing need for autonomously performing more complex manipulation tasks, two main challenges need to be addressed: the high-dimensionality of the system, and the motion coordination between the mobile base and the working arm. The latter challenge is of high importance if accurate execution is required, especially considering the floating nature of the AUV and the control challenges that come with it. Our approach relies on exploiting the loose coupling between the AUV and the arm. In particular we present an approach based on MR-MHA * (Multi-Representation, Multi-Heuristic A*), and we show how it can generate efficient trajectories by exploiting decoupling. We show for the first time the use of a search-based planner on a high-dimensional underwater manipulator. In addition, we support our claims with experimental analysis of the generated trajectories with respect to various metrics in different environments. Furthermore, we demonstrate the ability of our approach to conduct a full intervention mission in a realistic simulated underwater intervention environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593604","","Task analysis;Planning;Manipulators;Search problems;Trajectory;Kinematics","autonomous underwater vehicles;manipulators;motion control;path planning;trajectory control","intervention autonomous underwater vehicle;MR-MHA *;multirepresentation multiheuristic A*;realistic simulated underwater intervention environment;intervention mission;generated trajectories;high-dimensional underwater manipulator;search-based planner;motion coordination;complex manipulation tasks;floating-based intervention;task-priority redundancy control framework;GIRONA 500;SAUVIM;autonomous manipulation skills;I-AUV;underwater mobile manipulator;motion planning","","1","21","","","","","IEEE","IEEE Conferences"
"Milligram-Scale Micro Aerial Vehicle Design for Low-Voltage Operation","P. Bhushan; C. J. Tomlin","Department of Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA, 94720, USA; Department of Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA, 94720, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","We present a 70mg, 3cm wing-span, flapping wing aerial vehicle capable of generating up to 60mg of lift using an electromagnetic actuator with low-voltage input (≈5.5V). Its design is novel, with the actuation and transmission integrated into a single resonant mechanism, thus not requiring any small-linear-displacement amplifying stages seen in other works. It can produce ±45° wing strokes and ±45° wing plane rotations at 98Hz operation mimicking relevant insects at this size scale. With required input power of only 250mW, it is, to the best of our knowledge, the most energy efficient electromagnetic design at the sub-100mg scale reported to date, and an order of magnitude more efficient than all other electromagnetic works.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594515","","Magnetic resonance;Actuators;Springs;Magnetic separation;Loss measurement;Mathematical model;Laser beams","aerodynamics;aerospace components;autonomous aerial vehicles;electromagnetic actuators;microrobots","milligram-scale microaerial vehicle design;low-voltage operation;wing-span;wing aerial vehicle;electromagnetic actuator;low-voltage input;actuation;single resonant mechanism;small-linear-displacement amplifying stages;±45° wing strokes;±45° wing plane;energy efficient electromagnetic design;electromagnetic works;mass 70.0 mg;size 3.0 cm;mass 60.0 mg;voltage 5.5 V;frequency 98.0 Hz;power 250.0 mW;mass 100.0 mg","","","25","","","","","IEEE","IEEE Conferences"
"Single Leg Dynamic Motion Planning with Mixed-Integer Convex Optimization","Y. Ding; C. Li; H. Park","Department of Mechanical Science and Engineering Department, University of Illinois at Urbana-Champaign, IL, 61801, USA; Department of Mechanical Science and Engineering Department, University of Illinois at Urbana-Champaign, IL, 61801, USA; Department of Mechanical Science and Engineering Department, University of Illinois at Urbana-Champaign, IL, 61801, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","This paper proposes a mixed-integer convex programming formulation for dynamic motion planning. Many dynamic constraints such as the actuator torque constraint are nonlinear and non-convex due to the trigonometrical terms from the Jacobian matrix. This often causes the optimization problem to converge to local optima or even infeasible set. In this paper, we convexify the torque constraint by formulating a mixed-integer quadratically-constrained program (MIQCP). More specifically, the workspace is discretized into a union of disjoint polytopes and torque constraint is enforced upon a convex outer approximation of the torque ellipsoid, obtained by solving a semidefinite program (SDP). Bilinear terms are approximated by McCormick envelope convex relaxation. The proposed MIQCP framework could be solved efficiently to global optimum and the generated trajectories could exploit the rich features of the rough terrain without any initial guess from the designer. The demonstrated experiment results prove that this approach is currently capable of planning consecutive jumps that navigates a single-legged robot through challenging terrains.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594161","","Torque;Dynamics;Planning;Legged locomotion;Ellipsoids;Trajectory","actuators;approximation theory;convex programming;integer programming;Jacobian matrices;legged locomotion;path planning;quadratic programming;robot dynamics","trigonometrical terms;Jacobian matrix;optimization problem;mixed-integer quadratically-constrained program;convex outer approximation;torque ellipsoid;semidefinite program;bilinear terms;McCormick envelope convex relaxation;actuator torque;leg dynamic motion planning;MIQCP;SDP;mixed-integer convex programming","","","21","","","","","IEEE","IEEE Conferences"
"Mobile Continuum Robot with Unlimited Extensible Sections","A. Kanada; T. Mashimo","Department of Mechanical Engineering, Toyohashi University of Technology, Tenpaku-cho, Toyohashi, Aichi, 441-8580, Japan; Department of Mechanical Engineering, Toyohashi University of Technology, Tenpaku-cho, Toyohashi, Aichi, 441-8580, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7117","7122","Typical continuum robots, such as pneumatic and tendon-driven robots, have a restricted section length and require a large external component for pulleys and a compressor, making them unsuitable for locomotion. This paper presents a new mobile continuum robot design with virtually unlimited extensible sections. A driving unit, which has a mechanism similar to the rack-and-pinion, consists of three DC motors with gears, each of which moves each flexible tube. The rotation of the motor translates the flexible tube, which has a helical groove on the surface that meshes with the gear. The long flexible tube provides a large traveling distance as long as it does not buckle. The elongation and bending motion of each section may be controlled during operation by varying the speed of each flexible tube. This design not only allows the expansion of the robot to otherwise unreachable work areas but also improves the locomotion velocity by generating a large traveling distance of the flexible tubes. The most important point in this paper is to use multiple driving units for locomotion. Since all the driving units can be mounted on the same tubes, by increasing the number of them, the robot can take various forms without expanding its diameter. A preliminary prototype was built, and its crawling locomotion performance was tested using two operating sequences. The results indicate that earthworm-like locomotion can be achieved with good performance by elongating the sections even when the ground is slippery. The proposed design can be easily be rebuilt by anyone with access to a basic 3D printer.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594340","","Electron tubes;DC motors;Gears;Trajectory;Springs;End effectors","bending;buckling;DC motors;force control;gears;mobile robots;motion control;pulleys","typical continuum robots;restricted section length;locomotion;mobile continuum robot design;virtually unlimited extensible sections;driving unit;gear;long flexible tube;traveling distance;multiple driving units;DC motors;crawling locomotion performance;3D printer;helical groove;tendon-driven robots","","","16","","","","","IEEE","IEEE Conferences"
"Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles","A. Kumar; J. R. McBride; G. Pandey","Department of Electrical Engineering, Indian Institute of Technology, Kanpur; Research & Innovation Center, Ford Motor Company; Research & Innovation Center, Ford Motor Company","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3233","3240","We propose an end-to-end real time framework to generate high resolution graphics grade textured 3D map of urban environment. The generated detailed map finds its application in the precise localization and navigation of autonomous vehicles. It can also serve as a virtual test bed for various vision and planning algorithms as well as a background map in the computer games. In this paper, we focus on two important issues: (i) incrementally generating a map with coherent 3D surface, in real time and (ii) preserving the quality of color texture. To handle the above issues, firstly, we perform a pose-refinement procedure which leverages camera image information, Delaunay triangulation and existing scan matching techniques to produce high resolution 3D map from the sparse input LIDAR scan. This 3D map is then texturized and accumulated by using a novel technique of ray-filtering which handles occlusion and inconsistencies in pose-refinement. Further, inspired by human fovea, we introduce foveal-processing which significantly reduces the computation time and also assists ray-filtering to maintain consistency in color texture and coherency in 3D surface of the output map. Moreover, we also introduce texture error (TE) and mean texture mapping error (MTME), which provides quantitative measure of texturing and overall quality of the textured maps.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593998","","Three-dimensional displays;Laser radar;Cameras;Real-time systems;Image color analysis;Global Positioning System","cameras;computer vision;image reconstruction;image resolution;image texture;mesh generation;mobile robots;optical radar;robot vision","scan matching techniques;end-to-end real time framework;real time incremental foveal texture mapping;real time incremental foveal texture mapping;precise localization;detailed map;urban environment;high resolution graphics grade;texture mapping error;texture error;output map;computation time;ray-filtering;sparse input LIDAR scan;high resolution 3D;camera image information;pose-refinement procedure;color texture;coherent 3D surface;computer games;background map;planning algorithms;virtual test bed;autonomous vehicles;navigation","","","42","","","","","IEEE","IEEE Conferences"
"Robotic Hand-Free-Stick for Walking Balance Assistance","Y. Tanaka; N. Oyama; T. Takenaka","Nagasaki University, Graduate School of Engineering, 1–14 Bunkyou-machi, Nagasaki, 852-8521, Japan; Nagasaki University, Graduate School of Engineering, 1–14 Bunkyou-machi, Nagasaki, 852-8521, Japan; Nagasaki University, Graduate School of Engineering, 1–14 Bunkyou-machi, Nagasaki, 852-8521, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5445","5450","This paper proposes a wearable robotic stick for walking assistance, called “Hand-Free-Stick” (HFS), for people with non-serious dysfunction in their gait. The basic idea of the proposed HFS is to enlarge ZMP (Zero moment point) area of a user under hands free conditions and to augment his/her body balance ability in walking. A boots type prototype of the HFS is developed with a lightweight robotic stick using a servomotor, in which the slider-link mechanism works to regulate the stick angle and length at the same time. The stick motion is controlled by a single-board computer based on the distribution of foot/feet pressures measured by the sensor system using eight load cells attached at the sole of boots. A set of walking tests with/without the prototype of HFS is carried out for four healthy subjects and demonstrates the effectiveness of the proposed HFS to expand the ZMP area leading to walking balance assistance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593389","","Legged locomotion;Hafnium;Foot;Prototypes;Senior citizens;Weight measurement","gait analysis;handicapped aids;humanoid robots;legged locomotion;pressure measurement;servomotors","stick motion;walking tests;HFS;ZMP area;walking balance assistance;robotic hand-free-stick;wearable robotic stick;walking assistance;nonserious dysfunction;Zero moment point;hands free conditions;body balance ability;boots type prototype;lightweight robotic stick;slider-link mechanism;stick angle;hand-free-stick","","","21","","","","","IEEE","IEEE Conferences"
"Fire-Aware Planning of Aerial Trajectories and Ignitions","E. Beachly; C. Detweiler; S. Elbaum; B. Duncan; C. Hildebrandt; D. Twidwell; C. Allen","Computer Science and Engineering Department, University of Nebraska; Computer Science and Engineering Department, University of Nebraska; Computer Science and Engineering Department, University of Nebraska; Computer Science and Engineering Department, University of Nebraska; Computer Science and Engineering Department, University of Nebraska; Department of Agronomy and Horticulture, University of Nebraska; U.S. Geological Survey, Nebraska Cooperative Fish and Wildlife Unit","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","685","692","Prescribed fires can lessen wildfire severity and control invasive species, but they can also be risky and costly. Unmanned aerial systems can reduce those drawbacks by, for example, dropping ignition spheres to ignite the most hazardous areas. Existing systems, however, lack awareness of the fire vectors to operate autonomously, safely, and efficiently. In this work we address that limitation, introducing an approach that integrates a lightweight fire simulator and a planner for trajectories and ignition sphere drop waypoints. Both components are unique in that they are amenable to input from the system's sensors and the fire crew to increase fire awareness. We conducted a preliminary study that confirms that such inputs improve the accuracy of the fire simulation to counter the unpredictability of the target environment. The field study of the system showed that the fire-aware planner generated safe trajectories with effective ignitions leveraging the fire simulator predictions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593568","","Ignition;Robots;Computational modeling;Planning;Sensors;Mathematical model;Trajectory","aerospace computing;aerospace control;autonomous aerial vehicles;computer simulation;helicopters;ignition;path planning;trajectory control;wildfires","fire-aware planning;aerial trajectories;fire vectors;fire simulation;fire-aware planner;fire simulator predictions;ignition spheres;unmanned aerial system for prescribed fires;helicopter;UAS-Rx Android application","","","21","","","","","IEEE","IEEE Conferences"
"Sinc-Based Dynamic Movement Primitives for Encoding Point-to-point Kinematic Behaviors","D. Papageorgiou; A. Sidiropoulos; Z. Doulgeri","Department of Electrical and Computer Engineering, Authors are with the Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece; Department of Electrical and Computer Engineering, Authors are with the Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece; Department of Electrical and Computer Engineering, Authors are with the Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","8339","8345","This work proposes the utilization of sinc functions as kernels of Dynamic Movement Primitives (DMP) models for encoding point-to-point kinematic behaviors. The proposed method presents a number of advantages with respect to the state of the art, as it (i) involves a simple learning technique, (ii) provides a method to determine the minimum required number of basis functions, based on the frequency content of the demonstrated motion and (iii) provides the ability to pre-define the reproduction accuracy of the learned behavior. The ability of the proposed model to accurately reproduce the behavior is demonstrated through simulations and experiments. Comparisons with the Gaussian-based DMP model show the proposed method's superiority in terms of computational complexity of learning and accuracy for a specific number of kernels.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594479","","Complexity theory;Kinematics;Biological system modeling;Computational modeling;Frequency modulation;Encoding","control engineering computing;learning (artificial intelligence);robot kinematics;robot programming","simple learning technique;sinc functions;sinc-based dynamic movement primitives;point-to-point kinematic behaviors","","","11","","","","","IEEE","IEEE Conferences"
"A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement","T. Furukawa; G. Dissanayake; T. Attia; J. Hodges","Virginia Tech, Department of Mechanical Engineering, Blacksburg, VA, USA; University of Technology, Center for Autonomous Systems, Sydney, NSW, Australia; Virginia Tech, Department of Mechanical Engineering, Blacksburg, VA, USA; Virginia Tech, Department of Mechanical Engineering, Blacksburg, VA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7151","7157","This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593747","","Robot kinematics;Robot sensing systems;Bayes methods;Mobile robots;Uncertainty","Bayes methods;image fusion;image sensors;Kalman filters;mobile robots;nonlinear filters;object detection;probability;remotely operated vehicles;robot vision","mobile robot;multistage Bayesian approaches;multistage localization approach;global coordinate frame;multistage target observation approach;target engagement;multiple sensors;Bayesian framework;simultaneous robot localization;sensors on-board;target detection;associated detection probability;extended Kalman filter;unmanned ground vehicle","","","14","","","","","IEEE","IEEE Conferences"
"A Novel Monocular-Based Navigation Approach for UAV Autonomous Transmission-Line Inspection","J. Bian; X. Hui; X. Zhao; M. Tan","Chinese Academy of Sciences, Institute of Automation, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 100190, China; Chinese Academy of Sciences, Institute of Automation, Beijing, 100190, China; Chinese Academy of Sciences, Institute of Automation, Beijing, 100190, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","7","This paper proposes a unique and robust UAV autonomous navigation approach along one side of overhead transmission lines for inspection. To this end, we establish a perspective model and develop a novel Pan/Tilt monocular-based navigation scheme. Simultaneously, the following three key issues are addressed. First, to locate the effective landmark - transmission tower timely and reliably, we customize a neural network for tower detection and combine it with a fast and smooth tracking. Second, to provide UAV with a robust and precise heading, we detect the transmission lines and compute and optimize their vanishing point. Third, to keep a safe distance from transmission lines, we optimize a homography matrix to restore the parallel nature of transmission lines and perceive the distance variation by a point set registration model. Finally, by the designed UAV platform, we test the whole system in a real-world transmission-line inspection scenario under different weather condition and achieve an encouraging result. Our approach provides great flexibility for refined inspection and effectively improves inspection safety.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593926","","Poles and towers;Inspection;Navigation;Power transmission lines;Kernel;Cameras;Safety","autonomous aerial vehicles;control engineering computing;image registration;inspection;mobile robots;neural nets;object detection;path planning;poles and towers;power overhead lines;robot vision","UAV autonomous navigation approach;pan-tilt monocular-based navigation scheme;neural network;homography matrix;distance variation;point set registration model;tower detection;overhead transmission lines;UAV autonomous transmission-line inspection","","","30","","","","","IEEE","IEEE Conferences"
"Mechanical subsystems integration and structural analysis for the autonomous underwater explorer","J. Villa; A. Heininen; S. Zavari; T. Salomaa; O. Usenius; J. Laitinen; J. Aaltonen; K. T. Koskinen","Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland; Faculty of Engineering Science, Mechanical Engineering and Industrial systems, Tampere University of Technology (TUT), Tampere, Finland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1488","1493","The aim of this study is to analyse the modular mechanical design and integration of all three low-level modules in UX-1 (pendulum, ballast system and propulsion unit). The components of the perception and navigation systems have position and orientation requirements that dictate the shape of the hull. A structural strength analysis using Finite Element method (FEM) was made to study the hull strength during deep dives. The results are presented here, which indicates that the hull endures pressures related to deep dives. Also for validation, strain gauge locations were defined.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593393","","Shape;Robots;Electronic ballasts;Manifolds;Propulsion;Finite element analysis;Cameras","autonomous underwater vehicles;finite element analysis;mechanical strength;mobile robots;robot dynamics;strain gauges","position requirements;finite element method;perception unit;FEM;strain gauge locations;modular mechanical design;autonomous underwater explorer;structural analysis;mechanical subsystems integration;hull endures pressures;deep dives;hull strength;structural strength analysis;orientation requirements;navigation systems;propulsion unit;ballast system;UX-1","","1","15","","","","","IEEE","IEEE Conferences"
"A Gripper for Object Search and Grasp Through Proximity Sensing","N. Yamaguchi; S. Hasegawa; K. Okada; M. Inaba","Development of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Tokyo, 113-8656, Japan; Development of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Tokyo, 113-8656, Japan; Development of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Tokyo, 113-8656, Japan; Development of Mechano-Informatics, The University of Tokyo, 7-3-1 Hongo, Tokyo, 113-8656, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Robots need to adapt themselves to various surroundings in order to achieve robust object search and grasp in unknown environments. For this adaptation, robot motions should be implemented as combination of primitive motions which are based on sensor reaction. Among various sensing methods, non contact sensing is required as a means of preventing operation failures such as pushing objects. Especially, proximity sensors have been proved effective in avoiding occlusion problems. In this paper, we first develop a gripper on which proximity sensors are mounted all around, and then calculate distance between the gripper and objects using proposed calibration method. This enables robots to recognize detailed shapes of objects surrounding the gripper. We also propose primitive motions for object search and grasp, and describe the contents of each motion. The motions are based on sensor information obtained from the gripper. We verify the effectiveness of our system through an experiment in which a real robot performs complex tasks by combination of the primitive motions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593572","","Robot sensing systems;Rubber;Grippers;Calibration;Search problems","calibration;grippers;manipulators;mobile robots;motion control;robot vision","object grasp;object search;calibration method;proximity sensors;sensor reaction;robot motions;proximity sensing;sensor information;primitive motions;gripper","","","23","","","","","IEEE","IEEE Conferences"
"Tracking a moving sound source from a multi-rotor drone","L. Wang; R. Sanchez-Matilla; A. Cavallaro","Centre for Intelligent Sensing, Queen Mary University of London, U.K.; Centre for Intelligent Sensing, Queen Mary University of London, U.K.; Centre for Intelligent Sensing, Queen Mary University of London, U.K.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2511","2516","We propose a method to track from a multi-rotor drone a moving source, such as a human speaker or an emergency whistle, whose sound is mixed with the strong ego-noise generated by rotating motors and propellers. The proposed method is independent of the specific drone and does not need pre-training nor reference signals. We first employ a time-frequency spatial filter to estimate, on short audio segments, the direction of arrival of the moving source and then we track these noisy estimations with a particle filter. We quantitatively evaluate the results using a ground-truth trajectory of the sound source obtained with an on-board camera and compare the performance of the proposed method with baseline solutions.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594483","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594483","","Drones;Time-frequency analysis;Direction-of-arrival estimation;Microphone arrays;Loudspeakers;Propellers","acoustic signal processing;audio signal processing;autonomous aerial vehicles;cameras;feature extraction;helicopters;humanoid robots;particle filtering (numerical methods);signal denoising;spatial filters;time-frequency analysis","ground-truth trajectory;noisy estimations;direction of arrival;ego-noise;human speaker;multirotor drone;moving sound source;moving source;short audio segments;time-frequency spatial filter;specific drone;propellers;motors;emergency whistle","","","30","","","","","IEEE","IEEE Conferences"
"Deep Learning for Exploration and Recovery of Uncharted and Dynamic Targets from UAV-like Vision","W. Andrew; C. Greatwood; T. Burghardt","Department of Computer Science, Faculty of Engineering, University of Bristol, UK; Department of Aerospace Engineering, Faculty of Engineering, University of Bristol, UK; Department of Computer Science, Faculty of Engineering, University of Bristol, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1124","1131","This paper discusses deep learning for solving static and dynamic search and recovery tasks - such as the retrieval of all instances of actively moving targets - based on partial-view Unmanned Aerial Vehicle (UAV)-like sensing. In particular, we demonstrate that abstracted tactic and strategic explorational agency can be implemented effectively via a single deep network that optimises in unity: the mapping of sensory inputs and positional history towards navigational actions. We propose a dual-stream classification paradigm that integrates one Convolutional Neural Network (CNN) for sensory processing with a second one for interpreting an evolving longterm map memory. In order to learn effective search behaviours given agent location and agent-centric sensory inputs, we train this design against 400k+ optimal navigational decision samples from each set of static and dynamic evolutions for different multi-target behaviour classes. We quantify recovery performance across an extensive range of scenarios; including probabilistic placement and dynamics, as well as fully random target walks and herd-inspired behaviours. Detailed results comparisons show that our design can outperform naive, independent stream and off-the-shelf DRQN solutions. We conclude that the proposed dual-stream architecture can provide a unified, rationally motivated and effective architecture for solving online search tasks in dynamic, multi-target environments. With this paper we publish<sup>3</sup> key source code and associated models.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593751","","Navigation;Robot sensing systems;Task analysis;History;Visualization;Vehicle dynamics;Reinforcement learning","autonomous aerial vehicles;convolutional neural nets;image classification;learning (artificial intelligence);mobile robots;path planning;probability;random processes;robot vision;target tracking","online search tasks;multitarget environments;dynamic targets;UAV-like vision;deep learning;dynamic search;strategic explorational agency;single deep network;navigational actions;dual-stream classification paradigm;sensory processing;agent location;static evolutions;dynamic evolutions;probabilistic placement;fully random target walks;herd-inspired behaviours;dual-stream architecture;unmanned aerial vehicle;convolutional neural network;multitarget behaviour classes;optimal navigational decision samples;long term map memory","","","42","","","","","IEEE","IEEE Conferences"
"Joint 3D Proposal Generation and Object Detection from View Aggregation","J. Ku; M. Mozifian; J. Lee; A. Harakeh; S. L. Waslander","Department of Mechanical and Mechatronics Engineering, Faculty of Engineering, University of Waterloo, University Avenue, Waterloo, ON, 200, Canada; Department of Mechanical and Mechatronics Engineering, Faculty of Engineering, University of Waterloo, University Avenue, Waterloo, ON, 200, Canada; Department of Mechanical and Mechatronics Engineering, Faculty of Engineering, University of Waterloo, University Avenue, Waterloo, ON, 200, Canada; Department of Mechanical and Mechatronics Engineering, Faculty of Engineering, University of Waterloo, University Avenue, Waterloo, ON, 200, Canada; Department of Mechanical and Mechatronics Engineering, Faculty of Engineering, University of Waterloo, University Avenue, Waterloo, ON, 200, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","8","We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios. The proposed neural network architecture uses LIDAR point clouds and RGB images to generate features that are shared by two subnetworks: a region proposal network (RPN) and a second stage detector network. The proposed RPN uses a novel architecture capable of performing multimodal feature fusion on high resolution feature maps to generate reliable 3D object proposals for multiple object classes in road scenes. Using these proposals, the second stage detection network performs accurate oriented 3D bounding box regression and category classification to predict the extents, orientation, and classification of objects in 3D space. Our proposed architecture is shown to produce state of the art results on the KITTI 3D object detection benchmark [1] while running in real time with a low memory footprint, making it a suitable candidate for deployment on autonomous vehicles. Code is available at: https://github.com/kujason/avod.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594049","","Three-dimensional displays;Feature extraction;Proposals;Computer architecture;Agriculture;Object detection;Two dimensional displays","image classification;image colour analysis;image fusion;mobile robots;neural nets;object detection;optical radar;radar detection;regression analysis;road vehicle radar;robot vision","high resolution feature maps;reliable 3D object proposals;multiple object classes;category classification;second stage detection network;AVOD;KITTI 3D object detection;autonomous vehicles;3D bounding box regression;multimodal feature fusion;RPN;region proposal network;RGB images;LIDAR point clouds;neural network architecture;autonomous driving scenarios;Aggregate View Object Detection network;joint 3D proposal generation","","1","21","","","","","IEEE","IEEE Conferences"
"Angle-Encoded Swarm Optimization for UAV Formation Path Planning","V. T. Hoang; M. D. Phung; T. H. Dinh; Q. P. Ha","Faculty of Engineering and Information Technology (FElT), School of Electrical and Data Engineering University of Technology Sydney (UTS), 81 Broadway, Ultimo, NSW 2007, Australia; Faculty of Engineering and Information Technology (FElT), School of Electrical and Data Engineering University of Technology Sydney (UTS), 81 Broadway, Ultimo, NSW 2007, Australia; Faculty of Engineering and Information Technology (FElT), School of Electrical and Data Engineering University of Technology Sydney (UTS), 81 Broadway, Ultimo, NSW 2007, Australia; Faculty of Engineering and Information Technology (FElT), School of Electrical and Data Engineering University of Technology Sydney (UTS), 81 Broadway, Ultimo, NSW 2007, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5239","5244","This paper presents a novel and feasible path planning technique for a group of unmanned aerial vehicles (DAVs) conducting surface inspection of infrastructure. The ultimate goal is to minimise the travel distance of DAVs while simultaneously avoid obstacles, and maintain altitude constraints as well as the shape of the UAV formation. A multiple-objective optimisation algorithm, called the Angle-encoded Particle Swarm Optimization (θ- PSO) algorithm, is proposed to accelerate the swarm convergence with angular velocity and position being used for the location of particles. The whole formation is modelled as a virtual rigid body and controlled to maintain a desired geometric shape among the paths created while the centroid of the group follows a pre-determined trajectory. Based on the testbed of 3DR Solo drones equipped with a proprietary Mission Planner, and the Internet-of- Things (loT) for multi-directional transmission and reception of data between the DAV s, extensive experiments have been conducted for triangular formation maintenance along a monorail bridge. The results obtained confirm the feasibility and effectiveness of the proposed approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593930","Quadcopter;θ-PSO;path planning;loT;triangular formation;collision avoidance","Trajectory;Collision avoidance;Unmanned aerial vehicles;Task analysis;Cost function;Shape","autonomous aerial vehicles;collision avoidance;mobile robots;multi-robot systems;particle swarm optimisation","angle-encoded particle swarm optimization;3DR solo drones;mission planner;Internet-of- Things;UAV formation path planning;triangular formation maintenance;swarm convergence;multiple-objective optimisation algorithm;unmanned aerial vehicles;feasible path planning technique","","","28","","","","","IEEE","IEEE Conferences"
"Pose Estimation and Map Formation with Spiking Neural Networks: towards Neuromorphic SLAM","R. Kreiser; A. Renner; Y. Sandamirskaya; P. Pienroj","Institute of Neuroinformatics and ZNZ, University of Zurich and ETH Zurich, Winterthurerstr. 190, Zurich, 8057, Switzerland; Institute of Neuroinformatics and ZNZ, University of Zurich and ETH Zurich, Winterthurerstr. 190, Zurich, 8057, Switzerland; Institute of Neuroinformatics and ZNZ, University of Zurich and ETH Zurich, Winterthurerstr. 190, Zurich, 8057, Switzerland; D-ITET, ETH Zurich, Gloriastrasse 35, Zurich, 8092, Switzerland","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2159","2166","In this paper, we investigate the use of ultra low-power, mixed signal analog/digital neuromorphic hardware for implementation of biologically inspired neuronal path integration and map formation for a mobile robot. We perform spiking network simulations of the developed architecture, interfaced to a simulated robotic vehicle. We then port the neuronal map formation architecture on two connected neuromorphic devices, one of which features on-board plasticity, and demonstrate the feasibility of a neuromorphic realization of simultaneous localization and mapping (SLAM).","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594228","","Neurons;Neuromorphics;Collision avoidance;Simultaneous localization and mapping;Synapses","mixed analogue-digital integrated circuits;mobile robots;neural nets;neurophysiology;pose estimation;SLAM (robots)","pose estimation;spiking neural networks;neuromorphic SLAM;biologically inspired neuronal path integration;mobile robot;neuronal map formation architecture;simultaneous localization and mapping;mixed signal analog-digital neuromorphic hardware;ultra low-power neuromorphic hardware;robotic vehicle simulation;on-board plasticity","","1","39","","","","","IEEE","IEEE Conferences"
"FBG-Based Control of a Continuum Manipulator Interacting with Obstacles*","S. Sefati; R. J. Murphy; F. Alambeigi; M. Pozin; I. Iordachita; R. H. Taylor; M. Armand","Johns Hopkins University, Laboratory for Computational Sensing and Robotics, Baltimore, MD, USA; Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, USA; Johns Hopkins University, Laboratory for Computational Sensing and Robotics, Baltimore, MD, USA; Johns Hopkins University, Department of Mechanical Engineering, Baltimore, MD, USA; Johns Hopkins University, Laboratory for Computational Sensing and Robotics, Baltimore, MD, USA; Johns Hopkins University, Laboratory for Computational Sensing and Robotics, Baltimore, MD, USA; Johns Hopkins University, Laboratory for Computational Sensing and Robotics, Baltimore, MD, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6477","6483","Tracking and controlling the shape of continuum dexterous manipulators (CDM) in constraint environments is a challenging task. The imposed constraints and interaction with unknown obstacles may conform the CDM's shape and therefore demands for shape sensing methods which do not rely on direct line of sight. To address these issues, we integrate a novel Fiber Bragg Grating (FBG) shape sensing unit into a CDM, reconstruct the shape in real-time, and develop an optimization-based control algorithm using FBG tip position feedback. The CDM is designed for less-invasive treatment of osteolysis (bone degradation). To evaluate the performance of the feedback control algorithm when the CDM interacts with obstacles, we perform a set of experiments similar to the real scenario of the CDM interaction with soft and hard lesions during the treatment of osteolysis. In addition, we propose methods for identification of the CDM collisions with soft or hard obstacles using the jacobian information. Results demonstrate successful control of the CDM tip based on the FBG feedback and indicate repeatability and robustness of the proposed method when interacting with unknown obstacles.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594407","","Shape;Manipulators;Jacobian matrices;Robot sensing systems;Strain;Real-time systems","bone;Bragg gratings;dexterous manipulators;feedback;fibre optic sensors;medical robotics;patient treatment","FBG feedback;FBG-based control;continuum dexterous manipulators;constraint environments;shape sensing methods;optimization-based control algorithm;FBG tip position feedback;feedback control algorithm;CDM interaction;CDM collisions;soft obstacles;hard obstacles;CDM tip;fiber Bragg grating shape sensing unit;CDM shape;bone degradation;osteolysis less-invasive treatment;hard lesions;soft lesions;jacobian information","","","29","","","","","IEEE","IEEE Conferences"
"Towards a Real-Time Environment Reconstruction for VR-Based Teleoperation Through Model Segmentation","S. Kohn; A. Blank; D. Puljiz; L. Zenkel; O. Bieber; B. Hein; J. Franke","Instrumentation & Control - Autonomous Systems (ICTA)Framatome GmbH; Instrumentation & Control - Autonomous Systems (ICTA)Framatome GmbH; Intelligent Process Automation and Robotics Lab (IPR) Karlsruhe Institute of Technology (KIT); Instrumentation & Control - Autonomous Systems (ICTA)Framatome GmbH; Instrumentation & Control - Autonomous Systems (ICTA)Framatome GmbH; Intelligent Process Automation and Robotics Lab (IPR) Karlsruhe Institute of Technology (KIT); Erlangen-Nurnberg (FAU), Institute for Factory Automation and Production Systems (FAPS) Friedrich-Alexander-Universitat","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Over the next few years, more and more autonomous mobile robot systems will find their way into modern shop floors. However, it will be necessary to provide human-machine interfaces for interventions in unexpected situations like system-deadlocks, algorithm failures or inabilities. Using virtual or mixed reality-technologies, multi-modal teleoperation offers potential for being a suitable human-machine interface. Essential challenges in this field are, among others, a real-time remote control, a time-efficient and holistic environment detection using multiple sensors, a noise-reduced visualization of sensor-data, and capabilities of object recognition. This paper summarizes research results regarding an architecture capable of a near realtime, interoperable, and operator-supporting teleoperation. The focus of this paper is on a method to efficiently process and visualize point-clouds to meet high frame rate demands of virtual reality applications. To provide near real-time feedback of the robot and its environment over large distances, the presented method is capable to segment known objects from unknown objects to reduce bandwidth requirements. The results of this paper were evaluated using a industrial articulated robotic arm for teleoperation via a long distance UDP/IP communication.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594053","","Cameras;Calibration;Solid modeling;Robot vision systems;Task analysis","control engineering computing;image reconstruction;image segmentation;industrial manipulators;man-machine systems;mobile robots;object recognition;real-time systems;robot vision;telerobotics;virtual reality","model segmentation;autonomous mobile robot systems;human-machine interfaces;virtual reality-technologies;mixed reality-technologies;multimodal teleoperation;real-time remote control;noise-reduced visualization;object recognition;operator-supporting teleoperation;real-time feedback;industrial articulated robotic arm;real-time environment reconstruction;VR-based teleoperation;known object segmentation;point-cloud visualization;long distance UDP/IP communication","","","16","","","","","IEEE","IEEE Conferences"
"Development of a Hybrid Gripper with Soft Material and Rigid Structures","W. Park; S. Seo; J. Bae","Department of Mechanical Engineering, UNIST, Bio-Robotics and Control (BiRC) Laboratory, Ulsan, Korea; Department of Mechanical Engineering, UNIST, Bio-Robotics and Control (BiRC) Laboratory, Ulsan, Korea; Department of Mechanical Engineering, UNIST, Bio-Robotics and Control (BiRC) Laboratory, Ulsan, Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5930","5935","For decades, various robotic grippers have been developed due to its necessity for the robotic manipulators. In case of the conventional robotic grippers with rigid components, an underactuated mechanism was required to satisfy gripping motion. Recently, soft grippers have been studied actively, which have realize bending motion with a simple morphological structure itself and inherent compliance to the environment. In this field of study, it has been rarely investigated to improve the fingertip force and actuation speed with specified design parameters. Thus, in this study, a hybrid gripper, which consists of both soft and rigid components, was suggested based on the key design principles: 1) the ratio of rigid parts against the soft chamber, 2) the cross-sectional shape of the chamber. The suggested principles were verified using the finite element methods (FEMs). As a result, the improved performance of the hybrid gripper was verified in terms of the fingertip force and the actuation speed, compared with the performance of the previously developed soft pneumatic actuators (SPAs). As an application, the three-fingered gripper was manufactured and tested by grasping different types of objects.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594232","","Grippers;Force;Shape;Strain;Robots;Actuators;Mathematical model","bending;finite element analysis;grippers;manipulators;motion control;pneumatic actuators","hybrid gripper;robotic manipulators;conventional robotic grippers;rigid components;gripping motion;soft grippers;bending motion;fingertip force;morphological structure;soft pneumatic actuators;underactuated mechanism;finite element methods;FEM;SPAs;three-fingered gripper;soft components","","","26","","","","","IEEE","IEEE Conferences"
"A Lightweight Redundant Manipulator with High Stable Wireless Communication and Compliance Control","L. Han; L. Yan; W. Xu","School of Mechanical Engineering and Automation, Shenzhen, 518055, China; School of Mechanical Engineering and Automation, Shenzhen, 518055, China; Harbin Institute of Technology, State Key Laboratory of Robotics and System, Harbin, 150001, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6622","6627","For traditional manipulators, there is a large number of electrical cables between the motion controller and the joint servo controllers. It is very inconvenient for maintenance, update, and safe operation. In this paper, we develop a lightweight redundant manipulator with high stable wireless communication link and compliance control. The motion controller, servo controller, and communication link are taken as a whole system to be optimized. The manipulator body and the motion controller are physically separated. It is very helpful for building distributed networked-manufacturing system or intelligent manufacturing system for Industry 4.0. The control system can be quickly updated by changing the object's identification without reconnect the communication cables. The mechanical part of the manipulator contains modular joints and links. Each joint is integrated with hall sensors, an incremental magnetic encoder, an absolute magnetic encoder and current sensors. The electrical part includes a central controller, seven joint servo controllers, and a wireless communication module based on ZigBee. By designing the application layer protocol, the communication stability is improved. In order to achieve the force control requirements in fine operation like assembly. A wireless compliance control frame is then designed. The compliance control method is realized on the central controller, by which the generated control commands are sent to the joint servo controllers through a wireless link. The problems caused by large electrical cables are then solved. Finally, the prototype and the experimental system are developed. Some experiments are carried out, including wireless communication test, trajectory tracking experiments, load carrying experiments, and wireless impedance control experiments. Results verify the functions and performance of the developed 7-DOF manipulator.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593500","7-DOF manipulator;Multilevel control system;ZigBee;Wireless compliance Control","Manipulators;ZigBee;Wireless communication;Servomotors;Wireless sensor networks;Impedance;Sensors","compliance control;control engineering computing;dexterous manipulators;force control;intelligent manufacturing systems;motion control;position control;production engineering computing;protocols;redundant manipulators;servomechanisms;wireless sensor networks;Zigbee","7-DOF manipulator;application layer protocol;ZigBee;absolute magnetic encoder;incremental magnetic encoder;hall sensors;Industry 4.0;distributed networked-manufacturing system;joint servo controllers;intelligent manufacturing system;manipulator body;high stable wireless communication link;motion controller;lightweight redundant manipulator;wireless impedance control experiments;electrical cables;wireless compliance control frame;force control requirements;communication stability;wireless communication module;central controller;communication cables","","","20","","","","","IEEE","IEEE Conferences"
"Ladder Climbing with a Snake Robot","T. Takemori; M. Tanaka; F. Matsuno","Graduate School of Engineering, Kyoto University, Department of Mechanical Engineering and Science, Kyoto, 606-8501, Japan; Graduate School of Engineering, Kyoto University, Department of Mechanical Engineering and Science, Kyoto, 606-8501, Japan; The University of Electro-Communications, Department of Mechanical and Intelligent Systems Engineering, Tokyo, 182-8585, Japan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","This paper presents a method that allows a snake robot to climb a ladder. We propose a ladder climbing method for a snake robot that has a smooth surface shape. We design a novel gait for the snake using a gait design method that configures the target form of the snake robot by connecting simple shapes. The climbing motion is executed via shift control and the corresponding motion required to catch the next step on the ladder. In addition, we developed a snake robot that has a smooth exterior body surface through construction of pectinate-shaped parts of the links. We demonstrated the effectiveness of both the proposed gait and the design of the snake robot experimentally.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594411","","Snake robots;Shape;Propulsion;Modeling;Mathematical model","gait analysis;legged locomotion;mobile robots;motion control","gait design method;ladder climbing method;snake robot","","","17","","","","","IEEE","IEEE Conferences"
"Setting up a Reinforcement Learning Task with a Real-World Robot","A. Rupam Mahmood; D. Korenkevych; B. J. Komer; J. Bergstra","Kindred Inc.; Kindred Inc.; Kindred Inc.; Kindred Inc.","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4635","4640","Reinforcement learning is a promising approach to developing hard-to-engineer adaptive solutions for complex and diverse robotic tasks. However, learning with real-world robots is often unreliable and difficult, which resulted in their low adoption in reinforcement learning research. This difficulty is worsened by the lack of guidelines for setting up learning tasks with robots. In this work, we develop a learning task with a UR5 robotic arm to bring to light some key elements of a task setup and study their contributions to the challenges with robots. We find that learning performance can be highly sensitive to the setup, and thus oversights and omissions in setup details can make effective learning, reproducibility, and fair comparison hard. Our study suggests some mitigating steps to help future experimenters avoid difficulties and pitfalls. We show that highly reliable and repeatable experiments can be performed in our setup, indicating the possibility of reinforcement learning research extensively based on real-world robots.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593894","","Task analysis;Robot sensing systems;Instruction sets;Delays;Reinforcement learning;Robot kinematics","learning (artificial intelligence);manipulators;multi-robot systems","hard-to-engineer adaptive solutions;complex tasks;diverse robotic tasks;reinforcement learning research;learning task;real-world robot;effective learning;learning performance;task setup;UR5 robotic arm","","","18","","","","","IEEE","IEEE Conferences"
"Design and Experimental Characterisation of a Hydrostatic Transmission for Upper Limb Exoskeletons","M. Bolignari; G. Moreuil; M. Fontana","Department of Industrial Engineering, University of Trento, Via Som-marive 9, Trento, 38123; Department of Industrial Engineering, University of Trento, Via Som-marive 9, Trento, 38123; Department of Industrial Engineering, University of Trento, Via Som-marive 9, Trento, 38123","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2768","2773","This paper introduces a novel hydrostatic air-liquid torque transmission system for an upper limb exoskeleton. The proposed design is based on remote electrical actuation, with grounded motors, combined with high performance fluid power transmission employed to deliver the power to the joints of the exoskeleton. The fluid transmission is based on rolling membrane cylinders that guarantee leakage-free operation, no backlash, and virtually zero stick-friction. This solution makes it possible to obtain easy controllability, good efficiency, intrinsic backdrivable operation, and reduced mass/inertia of the links of the robot. Additionally, the proposed system can be potentially implemented at relatively low-costs thanks to the employment of standard components and an architecture based on a modular approach. A test bench of the fluid transmission system is developed and a campaign of experiments is conducted to characterize its static/dynamic response for different choice of design parameters. In addition, we present a preliminary complete integrated arrangement of an upper limb exoskeleton equipped with the proposed transmission system. Results confirm the feasibility of the proposed actuation approach for the envisaged application.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593639","","Exoskeletons;Torque;Robots;Hydraulic systems;Layout;Pulleys;Actuators","controllability;force control;friction;hydrostatics;medical robotics;power transmission (mechanical);torque control;wearable robots","high performance fluid power transmission;leakage-free operation;virtually zero stick-friction;intrinsic backdrivable operation;fluid transmission system;design parameters;upper limb exoskeleton;hydrostatic transmission;remote electrical actuation;hydrostatic air-liquid torque transmission system;rolling membrane cylinders;controllability","","","20","","","","","IEEE","IEEE Conferences"
"Social Robots as a Means of Integration? an Explorative Acceptance Study considering Gender and Non-verbal Behaviour","B. Lugrin; J. Dippold; K. Bergmann","Human Computer Interaction, University of Wuerzburg, Germany; Human Computer Interaction, University of Wuerzburg, Germany; University of Applied Sciences Bielefeld, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2026","2032","The integration of migrants and refugees is currently a severe challenge for European states. Especially the imparting of culture- and gender-specific behaviours is an important issue. Social robots might be a valuable tool to introduce refugees to culture-specific behaviours of their host country. In this paper, we investigate the general acceptance of a social robot as well as users' perception of a robot presenting stereo-typical Arabic vs. German female non-verbal behaviour to Syrian newcomers to Germany. Our preliminary study revealed a generally positive attitude towards robots and the idea of an educational robot. Culture-specific manipulations were reflected in participants' partial preference for the Arabic version, but not in participants' perceptual ratings.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593818","","Robot sensing systems;Mouth;Cultural differences;Training;Europe","computer aided instruction;educational robots;gender issues;human-robot interaction","culture-specific behaviours;social robot;german female nonverbal behaviour;educational robot;culture-specific manipulations;European states;gender-specific behaviours","","","39","","","","","IEEE","IEEE Conferences"
"A Method for Robot Motor Fatigue Management in Physical Interaction and Human-Robot Collaboration Tasks","L. Peternel; N. Tsagarakis; A. Ajoudani","Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab, HHCM Lab, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab, HHCM Lab, Genoa, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, HRI2 Lab, HHCM Lab, Genoa, Italy","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2850","2856","Collaborative robots are often designed with limited power and force capacity, with the aim to provide affordable solutions and ensure human safety in case of accidental collisions and impacts. If a task requires a power beyond this capacity, or is performed repeatedly over long periods, such limits may be exceeded, which can cause inevitable robot damage and contribute to the lost productivity. In such cases, where hardware solutions and improvements are not applicable, effective software frameworks can prolong robot productivity and lifetime. To this end, in this paper we propose a novel technique for the monitoring and management of robot fatigue in repetitive or high-effort task execution scenarios. The robot fatigue is estimated by the measured temperature of motors in the joints. The proposed fatigue management system is composed of two-stage reaction process that is triggered by different levels of the estimated fatigue. The first stage exploits the kinematic redundancy of robot structure in attempt to minimise the load in the specific joints that under fatigue by reconfiguration in the joint space through the null space of the Cartesian task production. If the first stage is not successful in reducing the fatigue, the second stage is activated that gradually reduces the forces of hybrid controller. At that point, the human co-worker can temporarily take over the task execution until the robot will be recovered from the excessive fatigue. To validate the proposed approach we conducted experiments on KUKA Lightweight Robot performing two interaction tasks: autonomous surface wiping and collaborative human-robot surface polishing.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594196","","Robots;Task analysis;Fatigue;Temperature measurement;Torque;Force;Collision avoidance","collision avoidance;fatigue;human-robot interaction;industrial accidents;industrial robots;mobile robots;motion control;robot kinematics","human co-worker;KUKA lightweight robot;human-robot collaboration tasks;software frameworks;robot motor fatigue management;robot kinematic redundancy;collaborative human-robot surface polishing;autonomous surface wiping;Cartesian task production;two-stage reaction process;robot productivity;hardware solutions;accidental collisions;human safety","","1","24","","","","","IEEE","IEEE Conferences"
"An Investigation of 2nd-Order Fixed Point SLIP Behavior","I. Kontolatis; E. Papadopoulos","School of Mechanical Engineering, National Technical University of Athens; School of Mechanical Engineering, National Technical University of Athens","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1739","1744","This paper introduces alternative behaviors described by the SLIP model when it is subject to a range of initial conditions. A non-dimensional SLIP model and a numerical return map search scheme are used to determine fixed points as a function of non-dimensional leg stiffness and vertical displacement under friction constraints. A SLIP model behavior analysis is performed, using an analytical stance phase approximation, by diverging from the fixed points, i.e. by increasing/decreasing initial horizontal velocity, and/or touchdown angle. The results show that beyond the regular fixed points, the SLIP model performs an alternative, stable behavior that repeats itself every two cycles of motion. We call these 2<sup>nd</sup>-order fixed points and the regular ones 1<sup>st</sup>-order fixed points. A numerical simulation scheme was developed to investigate 2<sup>nd</sup>-order fixed points for a wide range of horizontal velocities and touchdown angles. Results show that 2<sup>nd</sup>-order fixed points respecting the friction cone constraints exist that can lead to a number of different behaviors such as high jumps, obstacle avoidance of different heights, or backward motion.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594375","","Legged locomotion;Springs;Friction;Mathematical model;Numerical models;Trajectory","approximation theory;collision avoidance;friction;legged locomotion;nonlinear control systems;pendulums","1st-order fixed points;2nd-order fixed points;2nd-order fixed point SLIP behavior;analytical stance phase approximation;friction cone constraints;obstacle avoidance;SLIP model behavior analysis;nondimensional leg stiffness;numerical return map search scheme;nondimensional SLIP model","","","16","","","","","IEEE","IEEE Conferences"
"Robocentric Visual-Inertial Odometry","Z. Huai; G. Huang","NSF (IIS-1566129), DTRA (HDTRA1-16-1-0039) and Google, The Dept. of Mechanical Engineering, The University of Delaware (UD)College of Engineering, UD Cybersecurity Initiative, University of Delaware, Newark, DE 19716, USA; NSF (IIS-1566129), DTRA (HDTRA1-16-1-0039) and Google, The Dept. of Mechanical Engineering, The University of Delaware (UD)College of Engineering, UD Cybersecurity Initiative, University of Delaware, Newark, DE 19716, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6319","6326","In this paper, we propose a novel robocentric formulation of visual-inertial navigation systems (VINS)within a multi-state constraint Kalman filter (MSCKF)framework and develop an efficient, lightweight, robocentric visual-inertial odometry (R-VIO)algorithm for consistent localization in challenging environments using only monocular vision. The key idea of the proposed approach is to deliberately reformulate the 3D VINS with respect to a moving local frame (i.e., robocentric), rather than a fixed global frame of reference as in the standard world-centric VINS, and instead utilize high-accuracy relative motion estimates for global pose update. As an immediate advantage of using this robocentric formulation, the proposed R-VIO can start from an arbitrary pose, without the need to align its orientation with the global gravity vector. More importantly, we analytically show that the proposed robocentric EKF-based VINS does not undergo the observability mismatch issue as in the standard world-centric frameworks which was identified as the main cause of inconsistency of estimation. The proposed R-VIO is extensively tested through both Monte Carlo simulations and real-world experiments using different sensor platforms in different environments and shown to achieve competitive performance with the state-of-the-art VINS algorithms in terms of consistency, accuracy and efficiency.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593643","","Robot sensing systems;Three-dimensional displays;Computational efficiency;Navigation;Standards;Gravity;Quaternions","distance measurement;inertial navigation;Kalman filters;mobile robots;Monte Carlo methods;motion estimation;nonlinear filters;position measurement;SLAM (robots)","robocentric EKF-based VINS;standard world-centric frameworks;R-VIO;real-world experiments;state-of-the-art VINS;robocentric visual-inertial odometry;visual-inertial navigation systems;consistent localization;challenging environments;monocular vision;moving local frame;standard world-centric VINS;global gravity vector;multistate constraint Kalman filter framework;visual-inertial odometry algorithm;global pose;high-accuracy relative motion;robocentric formulation","","2","28","","","","","IEEE","IEEE Conferences"
"Seeing Behind the Scene: Using Symmetry to Reason About Objects in Cluttered Environments","A. Ecins; C. Fermüller; Y. Aloimonos","University of Maryland, Department of Computer Science, College Park, MD, 20742, USA; University of Maryland, Department of Computer Science, College Park, MD, 20742, USA; University of Maryland, Department of Computer Science, College Park, MD, 20742, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7193","7200","Symmetry is a common property shared by the majority of man-made objects. This paper presents a novel bottom-up approach for segmenting symmetric objects and recovering their symmetries from 3D pointclouds of natural scenes. Candidate rotational and reflectional symmetries are detected by fitting symmetry axes/planes to the geometry of the smooth surfaces extracted from the scene. Individual symmetries are used as constraints for the foreground segmentation problem that uses symmetry as a global grouping principle. Evaluation on a challenging dataset shows that our approach can reliably segment objects and extract their symmetries from incomplete 3D reconstructions of highly cluttered scenes, outperforming state-of-the-art methods by a wide margin.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593822","","Three-dimensional displays;Shape;Task analysis;Two dimensional displays;Pipelines;Surface treatment;Object segmentation","feature extraction;geometry;image reconstruction;image segmentation;natural scenes;object detection","cluttered scenes;scene extraction;3D reconstructions;objects segment;symmetry axes-planes;geometry;pointclouds;foreground segmentation problem;smooth surfaces;reflectional symmetries;natural scenes;symmetric objects;cluttered environments","","","24","","","","","IEEE","IEEE Conferences"
"Minimal Construct: Efficient Shortest Path Finding for Mobile Robots in Polygonal Maps","M. Missura; D. D. Lee; M. Bennewitz","University of Bonn, Humanoid Robots Lab, Germany; University of Pennsylvania, GRASP Laboratory, USA; University of Bonn, Humanoid Robots Lab, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7918","7923","With the advent of polygonal maps finding their way into the navigational software of mobile robots, the Visibility Graph can be used to search for the shortest collision-free path. The nature of the Visibility Graph-based shortest path algorithms is such that first the entire graph is computed in a relatively time-consuming manner. Then, the graph can be searched efficiently any number of times for varying start and target state combinations with the A* or the Dijkstra algorithm. However, real-world environments are typically too dynamic for a map to remain valid for a long time. With the goal of obtaining the shortest path quickly in an ever changing environment, we introduce a rapid path finding algorithm-Minimal Construct-that discovers only a necessary portion of the Visibility Graph around the obstacles that actually get in the way. Collision tests are computed only for lines that seem heuristically promising. This way, shortest paths can be found much faster than with a state-of-the-art Visibility Graph algorithm and as our experiments show, even grid-based A* searches are outperformed in most cases with the added benefit of smoother and shorter paths.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594124","","Navigation;Heuristic algorithms;Mobile robots;Software;Complexity theory;Standards","collision avoidance;graph theory;mobile robots;navigation","mobile robots;polygonal maps;navigational software;shortest collision-free path;Dijkstra algorithm;visibility graph algorithm;minimal construct;visibility graph-based shortest path algorithms;shortest path finding;A* algorithm","","","20","","","","","IEEE","IEEE Conferences"
"Dexterous Manipulation Graphs","S. Cruciani; C. Smith; D. Kragic; K. Hang","Robotics, Perception and Learning Lab, EECS at KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS at KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS at KTH Royal Institute of Technology, Stockholm, Sweden; Department of Computer Science and Engineering, Institute of Advanced Study, Hong Kong University of Science and Technology, Hong Kong","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2040","2047","We propose the Dexterous Manipulation Graph as a tool to address in-hand manipulation and reposition an object inside a robot's end-effector. This graph is used to plan a sequence of manipulation primitives so to bring the object to the desired end pose. This sequence of primitives is translated into motions of the robot to move the object held by the end-effector. We use a dual arm robot with parallel grippers to test our method on a real system and show successful planning and execution of in-hand manipulation.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594303","","Grippers;End effectors;Planning;Dynamics;Shape","dexterous manipulators;end effectors;graph theory;grippers","Dexterous Manipulation graphs;in-hand manipulation;end-effector;dual arm robot;end pose;parallel grippers","","","18","","","","","IEEE","IEEE Conferences"
"Modular Sensor Fusion for Semantic Segmentation","H. Blum; A. Gawel; R. Siegwart; C. Cadena","Autonomous Systems Lab of ETH Zurich; Autonomous Systems Lab of ETH Zurich; Autonomous Systems Lab of ETH Zurich; Autonomous Systems Lab of ETH Zurich","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","3670","3677","Sensor fusion is a fundamental process in robotic systems as it extends the perceptual range and increases robustness in real-world operations. Current multi-sensor deep learning based semantic segmentation approaches do not provide robustness to under-performing classes in one modality, or require a specific architecture with access to the full aligned multi-sensor training data. In this work, we analyze statistical fusion approaches for semantic segmentation that overcome these drawbacks while keeping a competitive performance. The studied approaches are modular by construction, allowing to have different training sets per modality and only a much smaller subset is needed to calibrate the statistical models. We evaluate a range of statistical fusion approaches and report their performance against state-of-the-art baselines on both realworld and simulated data. In our experiments, the approach improves performance in IoU over the best single modality segmentation results by up to 5%. We make all implementations and configurations publicly available.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593786","","Semantics;Image segmentation;Robot sensing systems;Training;Fuses;Computer architecture","image segmentation;learning (artificial intelligence);sensor fusion;statistical analysis","training sets;single modality segmentation results;statistical models;competitive performance;statistical fusion approaches;aligned multisensor training data;specific architecture;semantic segmentation approaches;current multisensor deep learning;real-world operations;perceptual range;robotic systems;fundamental process;modular sensor fusion","","","28","","","","","IEEE","IEEE Conferences"
"Joint Ego-motion Estimation Using a Laser Scanner and a Monocular Camera Through Relative Orientation Estimation and 1-DoF ICP","K. Huang; C. Stachniss","University of Bonn, Germany; University of Bonn, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","671","677","Pose estimation and mapping are key capabilities of most autonomous vehicles and thus a number of localization and SLAM algorithms have been developed in the past. Autonomous robots and cars are typically equipped with multiple sensors. Often, the sensor suite includes a camera and a laser range finder. In this paper, we consider the problem of incremental ego-motion estimation, using both, a monocular camera and a laser range finder jointly. We propose a new algorithm, that exploits the advantages of both sensors-the ability of cameras to determine orientations well and the ability of laser range finders to estimate the scale and to directly obtain 3D point clouds. Our approach estimates the 5 degrees of freedom relative orientation from image pairs through feature point correspondences and formulates the remaining scale estimation as a new variant of the iterative closest point problem with only one degree of freedom. We furthermore exploit the camera information in a new way to constrain the data association between laser point clouds. The experiments presented in this paper suggest that our approach is able to accurately estimate the ego-motion of a vehicle and that we obtain more accurate frame-to-frame alignments than with one sensor modality alone.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593965","","Cameras;Iterative closest point algorithm;Lasers;Three-dimensional displays;Robot vision systems;Image color analysis","automobiles;cameras;iterative methods;laser ranging;mobile robots;motion estimation;optical scanners;pose estimation;sensor fusion;SLAM (robots)","joint ego-motion estimation;laser scanner;monocular camera;autonomous vehicles;SLAM algorithms;sensor suite;laser range finder;3D point clouds;iterative closest point problem;sensor modality;orientation estimation;autonomous cars;pose estimation;autonomous robots;1-DoF ICP;data association","","","22","","","","","IEEE","IEEE Conferences"
"Automated Control of Multifunctional Magnetic Spores Using Fluorescence Imaging for Microrobotic Cargo Delivery","L. Yang; Y. Zhang; C. Vong; L. Zhang","Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin, Hong Kong, NT, china; Department of Biomedical Engineering, The Chinese University of Hong Kong (CUHK), Shatin, Hong Kong, NT, china; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin, Hong Kong, NT, china; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin, Hong Kong, NT, china","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","6","Microrobotic cargo delivery possesses promising perspective for precision medicine, and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this paper, we propose an automated control approach for a new microrobotic cargo carrier, i. e. the multifunctional magnetic spore (Mag-Spore). By surface functionalization of the spore with Fe<sub>3</sub>O4 nanoparticles and carbon quantum dots, it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our strategy utilizes fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores and cells. Then, information of the cells and Mag-Spores for planning and control is identified via image processing, and an optimal path planner with obstacle avoidance capability is designed based on the Particle Swarm Optimization (PSO)algorithm. To make the Mag-Spore follow the planed path accurately, an observer-based trajectory tracking controller is synthesized. Simulations and experiments are conducted to demonstrate the effectiveness of the proposed control approach.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593790","","Magnetic resonance imaging;Automation;Magnetic multilayers;Carbon;Stem cells;Optimization","cellular transport;collision avoidance;fluorescence;goods distribution;microrobots;mobile robots;nanoparticles;particle swarm optimisation;path planning;position control;quantum dots;tracking;trajectory control","Mag-Spore;fluorescence microscopy;fluorescence imaging;observer-based trajectory tracking controller;multifunctional magnetic Spores;microrobotic cargo delivery possesses;complex environmental conditions;obstructed optical feedback;automated control approach;microrobotic cargo carrier;multifunctional magnetic spore","","","24","","","","","IEEE","IEEE Conferences"
"Real-Time Segmentation with Appearance, Motion and Geometry","M. Siam; S. Eikerdawy; M. Gamal; M. Abdel-Razek; M. Jagersand; H. Zhang","University of Alberta; University of Alberta; Cairo University; Cairo University; University of Alberta; University of Alberta","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5793","5800","Real-time Segmentation is of crucial importance to robotics related applications such as autonomous driving, driving assisted systems, and traffic monitoring from unmanned aerial vehicles imagery. We propose a novel two-stream convolutional network for motion segmentation, which exploits flow and geometric cues to balance the accuracy and computational efficiency trade-offs. The geometric cues take advantage of the domain knowledge of the application. In case of mostly planar scenes from high altitude unmanned aerial vehicles (UAVs), homography compensated flow is used. While in the case of urban scenes in autonomous driving, with GPS/IMU sensory data available, sparse projected depth estimates and odometry information are used. The network provides 4.7× speedup over the state of the art networks in motion segmentation from 153ms to 36ms, at the expense of a reduction in the segmentation accuracy in terms of pixel boundaries. This enables the network to perform real-time on a Jetson T×2. In order to recuperate some of the accuracy loss, geometric priors is used while still achieving a much improved computational efficiency with respect to the state-of-the-art. The usage of geometric priors improved the segmentation in UAV imagery by 5.2 % using the metric of IoU over the baseline network. While on KITTI-MoSeg the sparse depth estimates improved the segmentation by 12.5 % over the baseline. Our proposed motion segmentation solution is verified on the popular KITTI and VIVID datasets, with additional labels we have produced. The code for our work is publicly available at<sup>1</sup>.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594088","","Motion segmentation;Computer vision;Real-time systems;Convolutional codes;Autonomous vehicles;Unmanned aerial vehicles;Image segmentation","autonomous aerial vehicles;cameras;distance measurement;Global Positioning System;image motion analysis;image segmentation;mobile robots;motion estimation;object detection;remotely operated vehicles;robot vision","domain knowledge;planar scenes;high altitude unmanned aerial vehicles;homography compensated flow;urban scenes;autonomous driving;depth estimates;segmentation accuracy;geometric priors;UAV imagery;baseline network;sparse depth;motion segmentation solution;assisted systems;traffic monitoring;unmanned aerial vehicles imagery;two-stream convolutional network;geometric cues;computational efficiency trade-offs;real-time segmentation;GPS-IMU sensory data;KITTI-MoSeg","","","41","","","","","IEEE","IEEE Conferences"
"Adaptive Model Predictive Control for High-Accuracy Trajectory Tracking in Changing Conditions","K. Pereida; A. P. Schoellig","University of Toronto, Institute for Aerospace Studies (UTIAS), Dynamic Systems Lab, Canada; University of Toronto, Institute for Aerospace Studies (UTIAS), Dynamic Systems Lab, Canada","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7831","7837","Robots and automated systems are increasingly being introduced to unknown and dynamic environments where they are required to handle disturbances, unmodeled dynamics, and parametric uncertainties. Robust and adaptive control strategies are required to achieve high performance in these dynamic environments. In this paper, we propose a novel adaptive model predictive controller that combines model predictive control (MPC) with an underlying L<sub>1</sub> adaptive controller to improve trajectory tracking of a system subject to unknown and changing disturbances. The L<sub>1</sub> adaptive controller forces the system to behave in a predefined way, as specified by a reference model. A higher-level model predictive controller then uses this reference model to calculate the optimal reference input based on a cost function, while taking into account input and state constraints. We focus on the experimental validation of the proposed approach and demonstrate its effectiveness in experiments on a quadrotor. We show that the proposed approach has a lower trajectory tracking error compared to non-predictive, adaptive approaches and a predictive, nonadaptive approach, even when external wind disturbances are applied.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594267","","Adaptation models;Predictive models;Trajectory tracking;Uncertainty;Adaptive control;Vehicle dynamics","adaptive control;helicopters;mobile robots;optimisation;predictive control;robust control;trajectory control;uncertain systems","wind disturbances;cost function;optimal reference input;quadrotor;MPC;trajectory tracking error;predictive approach;adaptive control strategies;unmodeled dynamics;dynamic environments;automated systems;adaptive model predictive control;nonadaptive approach","","","21","","","","","IEEE","IEEE Conferences"
"Contact Force Control of an Aerial Manipulator in Pressing an Emergency Switch Process","X. Meng; Y. He; Q. Li; F. Gu; L. Yang; T. Yan; J. Han","State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, 110016, China","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","2107","2113","The dangerous work situation in industrial leakage accidents urgently needs a flexible and small robot to help workers perform operations and to protect them from being injured. An aerial manipulator system consisting of a hexa-rotor UAV and a one-DOF manipulator is developed, and is used to press an emergency switch to shut off machinery in an emergency. In practical application, an aerial manipulator usually performs contact operations as the UAV platform is in hover flight. The hovering UAV acting as a spring-mass-damper system is firstly proved. Then, based on the derived spring-mass-damper system model and the impedance control algorithm, the force-sensorless contact force control method is presented. That is, the force is indirectly controlled through controlling the UAV's position error and pitch angle simultaneously. The practical operation experiment of pressing an emergency button shows that the proposed method is able to control the contact force as the aerial manipulator interacts with the external environment.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593535","","Manipulators;Force;Contacts;Attitude control;Force control;Pressing","aerospace robotics;aircraft control;autonomous aerial vehicles;force control;manipulators;position control;springs (mechanical);vibration control","emergency switch process;dangerous work situation;industrial leakage accidents;flexible robot;small robot;aerial manipulator system;hexa-rotor UAV;UAV platform;hover flight;impedance control algorithm;force-sensorless contact force control method;one-DOF manipulator;spring-mass-damper system model","","","20","","","","","IEEE","IEEE Conferences"
"A Novel Fabrication of PDMS Chip using Atmospheric Pressure Plasma Jet: Hydrophobicity Modification and Feasibility Test","Y. Yu; L. Kuo; M. Wu; J. Wu; C. D. Tsai","department of mechanical engineering, National Chiao Tung University, Taiwan; department of mechanical engineering, National Chiao Tung University, Taiwan; department of mechanical engineering, National Chiao Tung University, Taiwan; department of mechanical engineering, National Chiao Tung University, Taiwan; department of mechanical engineering, National Chiao Tung University, Taiwan","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","278","283","This paper presents a new application of atmospheric pressure plasma jet (APPJ) aiming for fabricating a microfluidic system on a polydimethylsiloxane (PDMS) surface. While PDMS is widely used for microfluidic chips, the fabrication of a chip requires different instruments which are not easily accessible for small-scale companies or laboratories. Therefore, we are motivated to develop a simple and low-cost method for such a fluidic system fabrication. The idea of this work is to directly pattern a fluidic channel on a PDMS surface with a plasma jet, which is known for its capability of modifying the hydrophobicity on a surface. The feasibility test first showed that fluid only flows in plasma-treated regions as having physical walls. The plasma parameters were then optimized using Taguchi method based on experiments. The optimization significantly reduce the required plasma treating time from more than 30 treating rounds to only 3 treating rounds, over ten times improved. Methods for further improving the resolution to micrometer-scale have been discussed. In addition to the advantages of fast and low-cost of the proposed method, making microfluidic channels on the surfaces of PDMS chip is also convenient for recollecting cultured cells on a chip in the field of regenerative medicine.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594446","","Plasmas;Surface treatment;Optimization;Argon;Power supplies;Plasma measurements;Fabrication","bioMEMS;cellular biophysics;hydrophobicity;lab-on-a-chip;microchannel flow;microfabrication;optimisation;plasma jets;plasma materials processing;polymers;Taguchi methods","plasma parameters;microfluidic channels;PDMS chip;atmospheric pressure plasma jet;hydrophobicity modification;feasibility test;polydimethylsiloxane surface;microfluidic chips;simple cost method;low-cost method;fluidic system fabrication;optimization;regenerative medicine;cultured cells;Taguchi method","","","25","","","","","IEEE","IEEE Conferences"
"A Software Framework for Planning Under Partial Observability","M. Hoerger; H. Kurniawati; A. Elfes","The University of Queensland, St Lucia, Brisbane, QLD, 4072, Australia; The University of Queensland, St Lucia, Brisbane, QLD, 4072, Australia; CSIRO, Pullenvale, Brisbane, QLD, 4069, Australia","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","9","Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593714","","Planning;Robot sensing systems;Computational modeling;Observability;Computer architecture;Standards","application program interfaces;decision theory;Markov processes;mobile robots;path planning;planning (artificial intelligence);software tools","robotics tasks;software tools;software toolkit;POMDP solvers;robot motion planning;partial observability problems;software framework;reliable robot operation;partially observable Markov decision process;abstract solver API;online POMDP planning toolkit;OPPT","","","21","","","","","IEEE","IEEE Conferences"
"Gait Learning for Soft Microrobots Controlled by Light Fields","A. von Rohr; S. Trimpe; A. Marco; P. Fischer; S. Palagi","University of Lübeck, Institute for Electrical Engineering in Medicine, Lübeck, 23562, Germany; Max Planck Institute for Intelligent Systems, Intelligent Control Systems Group, Stuttgart, 70569, Germany; Max Planck Institute for Intelligent Systems, Intelligent Control Systems Group, Stuttgart, 70569, Germany; Max Planck Institute for Intelligent Systems, Micro, Nano, and Molecular Systems Group, Stuttgart, 70569, Germany; Max Planck Institute for Intelligent Systems, Micro, Nano, and Molecular Systems Group, Stuttgart, 70569, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6199","6206","Soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. This inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. Albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. Common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. Here we propose a probabilistic learning approach for light-controlled soft microrobots based on Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. These features are obtained by designing the learning scheme through the comparison of different GP priors and BO settings on a semi-synthetic data set. The developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. These encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594092","","Robots;Cost function;Kernel;Strain;Laser beams;Tuning","Bayes methods;control engineering computing;control system synthesis;Gaussian processes;learning (artificial intelligence);medical robotics;microrobots;optimisation","self-adaptive microrobotic systems;light-controlled soft microrobots;probabilistic learning control;gait learning;light fields;analytical control design;gait optimization;locomotion models;data-driven approaches;Bayesian optimization;Gaussian processes;BO;GPs","","","19","","","","","IEEE","IEEE Conferences"
"LiDAR and Camera Calibration Using Motions Estimated by Sensor Fusion Odometry","R. Ishikawa; T. Oishi; K. Ikeuchi","The University of Tokyo, Institute of Industrial Science, Japan; The University of Tokyo, Institute of Industrial Science, Japan; Microsoft, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","7342","7349","This paper proposes a targetless and automatic camera-LiDAR calibration method. Our approach extends the hand-eye calibration framework to 2D-3D calibration. The scaled camera motions are accurately calculated using a sensor-fusion odometry method. We also clarify the suitable motions for our calibration method. Whereas other calibrations require the LiDAR reflectance data and an initial extrinsic parameter, the proposed method requires only the three-dimensional point cloud and the camera image. The effectiveness of the method is demonstrated in experiments using several sensor configurations in indoor and outdoor scenes. Our method achieved higher accuracy than comparable state-of-the-art methods.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593360","","Cameras;Calibration;Three-dimensional displays;Laser radar;Two dimensional displays;Estimation;Sensor fusion","calibration;cameras;distance measurement;image sensors;motion estimation;motion measurement;optical radar;sensor fusion","camera imaging;automatic targetless camera-LiDAR calibration method;2D-3D calibration;scaled camera motion calculation;three-dimensional point cloud;motion estimation;sensor-fusion odometry method;hand-eye calibration framework;LiDAR reflectance data","","","28","","","","","IEEE","IEEE Conferences"
"Reasoning Systems for Semantic Navigation in Mobile Robots","J. Crespo; R. Barber; O. M. Mozos; D. BeBler; M. Beetz","UNIVERSITY OF CARLOS III OF MADRID, 28911, Spain; UNIVERSITY OF CARLOS III OF MADRID, 28911, Spain; Technical University of Cartagena, 30202, Spain; Institute of Artificial Intelligent at the University of Bremen, 28359, Germany; Institute of Artificial Intelligent at the University of Bremen, 28359, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","5654","5659","Semantic navigation is the navigation paradigm in which environmental semantic concepts and their relationships are taken into account to plan the route of a mobile robot. This paradigm facilitates the interaction with humans and the understanding of human environments in terms of navigation goals and tasks. At the high level, a semantic navigation system requires two main components: a semantic representation of the environment, and a reasoning system. This paper is focused on develop a model of the environment using semantic concepts. This paper presents two solutions for the semantic navigation paradigm. Both systems implement an ontological model. Whilst the first one uses a relational database, the second one is based on KnowRob. Both systems have been integrated in a semantic navigator. We compare both systems at the qualitative and quantitative levels, and present an implementation on a mobile robot as a proof of concept.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594271","","Navigation;Ontologies;Semantics;Cognition;Mobile robots;Relational databases","control engineering computing;inference mechanisms;mobile robots;navigation;ontologies (artificial intelligence);path planning","semantic navigation paradigm;mobile robot;environmental semantic concepts;ontological model;KnowRob;relational database;reasoning system;semantic representation;semantic navigation system","","","18","","","","","IEEE","IEEE Conferences"
"Deep Semantic Lane Segmentation for Mapless Driving","A. Meyer; N. O. Salscheider; P. F. Orzechowski; C. Stiller","FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; Institute for Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","869","875","In autonomous driving systems a strong relation to highly accurate maps is taken to be inevitable, although street scenes change frequently. However, a preferable system would be to equip the automated cars with a sensor system that is able to navigate urban scenarios without an accurate map. We present a novel pipeline using a deep neural network to detect lane semantics and topology given RGB images. On the basis of this classification, the information about the road scene can be extracted just from the sensor setup supporting mapless autonomous driving. In addition to superseding the huge effort of creating and maintaining highly accurate maps, our system reduces the need for precise localization. Using an extended Cityscapes dataset, we show accurate ego lane detection including lane semantics on challenging scenarios for autonomous driving.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594450","","Roads;Semantics;Neural networks;Image segmentation;Autonomous vehicles;Three-dimensional displays;Pipelines","automobiles;feature extraction;image colour analysis;image segmentation;mobile robots;neural nets;object detection;path planning;road traffic;robot vision","deep semantic lane segmentation;autonomous driving systems;automated cars;sensor system;urban scenarios;deep neural network;lane semantics;road scene;mapless autonomous driving;street scenes;RGB images;lane detection;cityscapes dataset","","","25","","","","","IEEE","IEEE Conferences"
"Design, Modeling and Control of a Spherical Autonomous Underwater Vehicle for Mine Exploration","R. A. S. Fernandez; E. A. Parrar; Z. Milosevic; S. Dominguez; C. Rossi","Centre for Automation and Robotics (CAR), Universidad Politecnica de Madrid, Madrid, Spain; Centre for Automation and Robotics (CAR), Universidad Politecnica de Madrid, Madrid, Spain; Centre for Automation and Robotics (CAR), Universidad Politecnica de Madrid, Madrid, Spain; Centre for Automation and Robotics (CAR), Universidad Politecnica de Madrid, Madrid, Spain; Centre for Automation and Robotics (CAR), Universidad Politecnica de Madrid, Madrid, Spain","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1513","1519","This paper presents the design, implementation and validation of a novel spherical Autonomous Underwater Vehicle (AUV) prototype, developed for inspection and exploration of flooded mine tunnel networks. The unique mechanical, electrical and hardware design is presented, as well as the development of a theoretical 6 degree-of-freedom (DOF) high-fidelity dynamic model of the system. A series of underwater experiments were carried out in a controlled environment to test the standard motion patterns of the AUV with a Proportional-Integral-Derivative (PID) controller. The performance of the PID controller will be used as the baseline for comparison of more advanced control schemes. The experimental results demonstrated that the spherical AUV was able to realize the tested underwater motions with notable performance.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594016","","Prototypes;DC motors;Manifolds;Mathematical model;Robots;Propulsion;Shape","autonomous underwater vehicles;control system synthesis;intelligent control;motion control;oceanographic equipment;position control;three-term control","flooded mine tunnel networks;unique mechanical hardware design;electrical hardware design;high-fidelity dynamic model;underwater experiments;controlled environment;standard motion patterns;Proportional-Integral-Derivative controller;PID controller;advanced control schemes;spherical AUV;tested underwater motions;spherical autonomous underwater vehicle;vehicle prototype;novel spherical autonomous","","1","26","","","","","IEEE","IEEE Conferences"
"3. Conference Application","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","6","10","IROS 2018 Proceedings will be given in electronic iProceeding or eProceeding format, based on availability, to every full-registered person in the conference.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594286","","","","","","","","","","","","IEEE","IEEE Conferences"
"Organizing Committee","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","13","21","Provides a listing of current committee members and society officers.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594191","","","","","","","","","","","","IEEE","IEEE Conferences"
"Welcome message","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","11","12","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593673","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","33","37","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593949","","","","","","","","","","","","IEEE","IEEE Conferences"
"About Madrid","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","26","32","Presents information on the conference venue.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593784","","","","","","","","","","","","IEEE","IEEE Conferences"
"IROS 2018 Technical Program","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","12","Provides a schedule of conference events and a listing of which papers were presented in each session.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593782","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program at a Glance","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","4","4","Provides a schedule of conference events and a listing of which papers were presented in each session.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594269","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Front cover]","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","1","Presents the front cover or splash screen of the proceedings record.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593956","","","","","","","","","","","","IEEE","IEEE Conferences"
"IROS 2018 Author Index","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","41","Presents an index of the authors whose articles are published in the conference proceedings record.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8594323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594323","","","","","","","","","","","","IEEE","IEEE Conferences"
"Index of papers","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","31","Presents the table of contents/splash page of the proceedings record.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593509","","","","","","","","","","","","IEEE","IEEE Conferences"
"Content List","","","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","2018","","","1","118","Presents the table of contents/splash page of the proceedings record.","2153-0866;2153-0858","978-1-5386-8094-0978-1-5386-8093-3978-1-5386-8095","10.1109/IROS.2018.8593802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593802","","","","","","","","","","","","IEEE","IEEE Conferences"
